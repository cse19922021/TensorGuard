[
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/b6b1c01adfdadf93a4a1d30c3661ff177412a876",
        "Bug description": "torch.view_as_complex fails with segfault for a zero dimensional tensor (#44175)\n\nSummary:\nFixes https://github.com/pytorch/pytorch/issues/44061\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/44175\n\nReviewed By: colesbury\n\nDifferential Revision: D23628103\n\nPulled By: anjali411\n\nfbshipit-source-id: 6f70b5824150121a1617c0757499832923ae02b5",
        "Sample Code": "",
        "API Signature": "\n torch. view_as_complex ( input )   \u2192 \u00b6",
        "Bug fix": [
            "@@ -48,6 +48,7 @@ Tensor view_as_complex(const Tensor& self) {\n     self.scalar_type() == kFloat || self.scalar_type() == kDouble || self.scalar_type() == kHalf,\n     \"view_as_complex is only supported for half, float and double tensors, but got a tensor of scalar type: \", self.scalar_type());\n \n+  TORCH_CHECK(self.dim() != 0, \"Input tensor must have one or more dimensions\");\n   auto new_sizes = self.sizes().vec();\n   TORCH_CHECK(new_sizes[self.dim()-1] == 2, \"Tensor must have a last dimension of size 2\");\n   new_sizes.pop_back();\n",
            "@@ -19220,6 +19220,12 @@ class TestViewOps(TestCase):\n             RuntimeError, \"Tensor must have a last dimension of size 2\",\n             lambda: torch.view_as_complex(x))\n \n+        # zero dimension tensor\n+        z = torch.tensor(2.0)\n+        self.assertRaisesRegex(\n+            RuntimeError, \"Input tensor must have one or more dimensions\",\n+            lambda: torch.view_as_complex(z))\n+\n         y = x.reshape(0, 2)  # torch.Size([0, 2])\n         res = torch.view_as_complex(y)\n         self.assertTrue(self.is_view_of(x, res))\n"
        ]
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/c010ef7f0c6d837809a7e973048afac76373e3de",
        "Bug description": "use non-overflowing divide in cuda kernel util GET_BLOCKS (#44391)\n\nSummary:\nFixes https://github.com/pytorch/pytorch/issues/43476.\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/44391\n\nReviewed By: mrshenli\n\nDifferential Revision: D23602424\n\nPulled By: walterddr\n\nfbshipit-source-id: 40ed81547f933194ce5bf4a5bcebdb3434298bc1",
        "Sample Code": "",
        "API Signature": null,
        "Bug fix": [
            "@@ -25,16 +25,15 @@ namespace at { namespace cuda { namespace detail {\n constexpr int CUDA_NUM_THREADS = 1024;\n \n // CUDA: number of blocks for threads.\n-inline int GET_BLOCKS(const int N)\n-{\n-  AT_ASSERTM(N > 0, \"CUDA kernel launch blocks must be positive, but got N=\", N);\n-  return (N + CUDA_NUM_THREADS - 1) / CUDA_NUM_THREADS;\n-}\n-\n inline int GET_BLOCKS(const int64_t N) {\n   AT_ASSERTM(N > 0, \"CUDA kernel launch blocks must be positive, but got N=\", N);\n   constexpr int64_t max_int = std::numeric_limits<int>::max();\n-  return GET_BLOCKS(static_cast<int>(std::min(max_int, N)));\n+\n+  // Round up division for positive number that cannot cause integer overflow\n+  auto block_num = (N - 1) / CUDA_NUM_THREADS + 1;\n+  AT_ASSERTM(block_num <= max_int, \"Can't schedule too many blocks on CUDA device\");\n+\n+  return static_cast<int>(block_num);\n }\n \n }}}  // namespace at::cuda::detail\n"
        ]
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/42b4a7132e7c6f1df963b473d1583e4791fb1808",
        "Bug description": "Raise error if `at::native::embedding` is given 0-D weight (#42550)\n\nSummary:\nPreviously, `at::native::embedding` implicitly assumed that the `weight` argument would be 1-D or greater. Given a 0-D tensor, it would segfault. This change makes it throw a RuntimeError instead.\n\nFixes https://github.com/pytorch/pytorch/issues/41780\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/42550\n\nReviewed By: smessmer\n\nDifferential Revision: D23040744\n\nPulled By: albanD\n\nfbshipit-source-id: d3d315850a5ee2d2b6fcc0bdb30db2b76ffffb01",
        "Sample Code": "",
        "API Signature": "\n torch.nn.functional. embedding ( input ,  weight ,  padding_idx ,  max_norm ,  norm_type ,  scale_grad_by_freq ,  sparse ) [source] \u00b6",
        "Bug fix": [
            "@@ -13,6 +13,7 @@ namespace at { namespace native {\n \n Tensor embedding(const Tensor & weight, const Tensor & indices,\n                  int64_t padding_idx, bool scale_grad_by_freq, bool sparse) {\n+  TORCH_CHECK(weight.dim() >= 1, \"'weight' must be at least 1-D\");\n   auto indices_arg = TensorArg(indices, \"indices\", 1);\n   checkScalarType(\"embedding\", indices_arg, kLong);\n \n",
            "@@ -9901,6 +9901,12 @@ class TestNNDeviceType(NNTestCase):\n         fn = fn_wrapper(device)\n         _assertGradAndGradgradChecks(self, fn, (weight, ))\n \n+    def test_embedding_scalar_weight_error(self, device):\n+        indices = torch.rand(2, 2, device=device).long()\n+        weight = torch.tensor(1.0, device=device)\n+        with self.assertRaisesRegex(RuntimeError, \"'weight' must be at least 1-D\"):\n+            torch.nn.functional.embedding(indices, weight)\n+\n     @dtypesIfCUDA(torch.float16, torch.float64)\n     @dtypes(torch.float64)\n     def test_embedding_backward(self, device, dtype):\n",
            "@@ -10306,6 +10306,12 @@ class TestTorchDeviceType(TestCase):\n         self.assertRaisesRegex(RuntimeError, \"duplicate or invalid\", torch.norm, x, \"nuc\", (0, 0))\n         self.assertRaisesRegex(RuntimeError, \"duplicate or invalid\", torch.norm, x, \"nuc\", (0, 2))\n \n+    def test_embedding_scalar_weight_error(self, device):\n+        indices = torch.rand(2, 2, device=device).long()\n+        weight = torch.tensor(1.0)\n+        with self.assertRaisesRegex(RuntimeError, \"'weight' must be at least 1-D\"):\n+            torch.embedding(weight, indices)\n+\n     def test_dist(self, device):\n         def run_test(x, y):\n             for p in [0, 1, 2, 3, 4, inf, -inf]:\n"
        ]
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/42281",
        "Issue title": "`torch.Generator` produces segfault when input is `device='cuda'` on a machine that is not CUDA-enabled",
        "Bug description": "\r\nThe bug is as described in the title. The bug appears to be only with v1.6.0. \r\n\r\nThe case of inputting `device='cuda'` on a machine that is not CUDA-enabled might be rare. But a segfault as outcome doesn't seem to be desirable in any scenario.\r\n\r\n## ",
        "Sample Code": "\r\nRun the following on a cpu-only machine:\r\n```python\r\nimport torch\r\ng = torch.Generator(device='cuda')\r\n```\r\nOutcome:\r\n```bash\r\nSegmentation fault: 11\r\n```\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/24137",
        "Issue title": "[distributed] NCCL Backend doesn't support torch.bool data type",
        "Bug description": "\r\n\r\nIn version 1.2.0, NCCL backend doesn't support `torch.bool` datatype. Broadcasting a tensor of this type throws error \"RuntimeError: Unsupported data type for NCCL process group\".\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nCreate a file test.py with following contents:\r\n```py\r\nimport torch\r\nimport argparse\r\nfrom torch import distributed as dist\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument(\"--local_rank\", type=int)\r\n\r\nargs = parser.parse_args()\r\n\r\ntorch.distributed.init_process_group(\"nccl\")\r\n\r\nlocal_rank = args.local_rank\r\n\r\ndevice = torch.device(local_rank)\r\n\r\nif local_rank == 0:\r\n    element = False\r\nelse:\r\n    element = True\r\n\r\n\r\ndef broadcast_scalar(scalar, src=0, device=\"cpu\"):\r\n    scalar_tensor = torch.tensor(scalar).to(device)\r\n    with torch.no_grad():\r\n        scalar_tensor = dist.broadcast(scalar_tensor, src)\r\n    return scalar_tensor.item()\r\n\r\n\r\nbroadcast_scalar(element, src=0, device=device)\r\n```\r\n\r\nRun it with following command:\r\n`python -u -m torch.distributed.launch --nproc_per_node 2 test.py`\r\n\r\nThis has been tested on 2 GPUs.\r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n\r\nCreate a file test.py with following contents:\r\n```py\r\nimport torch\r\nimport argparse\r\nfrom torch import distributed as dist\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument(\"--local_rank\", type=int)\r\n\r\nargs = parser.parse_args()\r\n\r\ntorch.distributed.init_process_group(\"nccl\")\r\n\r\nlocal_rank = args.local_rank\r\n\r\ndevice = torch.device(local_rank)\r\n\r\nif local_rank == 0:\r\n    element = False\r\nelse:\r\n    element = True\r\n\r\n\r\ndef broadcast_scalar(scalar, src=0, device=\"cpu\"):\r\n    scalar_tensor = torch.tensor(scalar).to(device)\r\n    with torch.no_grad():\r\n        scalar_tensor = dist.broadcast(scalar_tensor, src)\r\n    return scalar_tensor.item()\r\n\r\n\r\nbroadcast_scalar(element, src=0, device=device)\r\n```\r\n\r\nRun it with following command:\r\n`python -u -m torch.distributed.launch --nproc_per_node 2 test.py`\r\n\r\nThis has been tested on 2 GPUs.\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/327",
        "Issue title": "Segmentation fault when dividing by zero with integer tensors",
        "Bug description": "\r\n\r\nIn version 1.2.0, NCCL backend doesn't support `torch.bool` datatype. Broadcasting a tensor of this type throws error \"RuntimeError: Unsupported data type for NCCL process group\".\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nCreate a file test.py with following contents:\r\n```py\r\nimport torch\r\nimport argparse\r\nfrom torch import distributed as dist\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument(\"--local_rank\", type=int)\r\n\r\nargs = parser.parse_args()\r\n\r\ntorch.distributed.init_process_group(\"nccl\")\r\n\r\nlocal_rank = args.local_rank\r\n\r\ndevice = torch.device(local_rank)\r\n\r\nif local_rank == 0:\r\n    element = False\r\nelse:\r\n    element = True\r\n\r\n\r\ndef broadcast_scalar(scalar, src=0, device=\"cpu\"):\r\n    scalar_tensor = torch.tensor(scalar).to(device)\r\n    with torch.no_grad():\r\n        scalar_tensor = dist.broadcast(scalar_tensor, src)\r\n    return scalar_tensor.item()\r\n\r\n\r\nbroadcast_scalar(element, src=0, device=device)\r\n```\r\n\r\nRun it with following command:\r\n`python -u -m torch.distributed.launch --nproc_per_node 2 test.py`\r\n\r\nThis has been tested on 2 GPUs.\r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n\r\nCreate a file test.py with following contents:\r\n```py\r\nimport torch\r\nimport argparse\r\nfrom torch import distributed as dist\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument(\"--local_rank\", type=int)\r\n\r\nargs = parser.parse_args()\r\n\r\ntorch.distributed.init_process_group(\"nccl\")\r\n\r\nlocal_rank = args.local_rank\r\n\r\ndevice = torch.device(local_rank)\r\n\r\nif local_rank == 0:\r\n    element = False\r\nelse:\r\n    element = True\r\n\r\n\r\ndef broadcast_scalar(scalar, src=0, device=\"cpu\"):\r\n    scalar_tensor = torch.tensor(scalar).to(device)\r\n    with torch.no_grad():\r\n        scalar_tensor = dist.broadcast(scalar_tensor, src)\r\n    return scalar_tensor.item()\r\n\r\n\r\nbroadcast_scalar(element, src=0, device=device)\r\n```\r\n\r\nRun it with following command:\r\n`python -u -m torch.distributed.launch --nproc_per_node 2 test.py`\r\n\r\nThis has been tested on 2 GPUs.\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/327",
        "Issue title": "Segmentation fault when dividing by zero with integer tensors",
        "Bug description": "\r\n\r\nIn version 1.2.0, NCCL backend doesn't support `torch.bool` datatype. Broadcasting a tensor of this type throws error \"RuntimeError: Unsupported data type for NCCL process group\".\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nCreate a file test.py with following contents:\r\n```py\r\nimport torch\r\nimport argparse\r\nfrom torch import distributed as dist\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument(\"--local_rank\", type=int)\r\n\r\nargs = parser.parse_args()\r\n\r\ntorch.distributed.init_process_group(\"nccl\")\r\n\r\nlocal_rank = args.local_rank\r\n\r\ndevice = torch.device(local_rank)\r\n\r\nif local_rank == 0:\r\n    element = False\r\nelse:\r\n    element = True\r\n\r\n\r\ndef broadcast_scalar(scalar, src=0, device=\"cpu\"):\r\n    scalar_tensor = torch.tensor(scalar).to(device)\r\n    with torch.no_grad():\r\n        scalar_tensor = dist.broadcast(scalar_tensor, src)\r\n    return scalar_tensor.item()\r\n\r\n\r\nbroadcast_scalar(element, src=0, device=device)\r\n```\r\n\r\nRun it with following command:\r\n`python -u -m torch.distributed.launch --nproc_per_node 2 test.py`\r\n\r\nThis has been tested on 2 GPUs.\r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n\r\nCreate a file test.py with following contents:\r\n```py\r\nimport torch\r\nimport argparse\r\nfrom torch import distributed as dist\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument(\"--local_rank\", type=int)\r\n\r\nargs = parser.parse_args()\r\n\r\ntorch.distributed.init_process_group(\"nccl\")\r\n\r\nlocal_rank = args.local_rank\r\n\r\ndevice = torch.device(local_rank)\r\n\r\nif local_rank == 0:\r\n    element = False\r\nelse:\r\n    element = True\r\n\r\n\r\ndef broadcast_scalar(scalar, src=0, device=\"cpu\"):\r\n    scalar_tensor = torch.tensor(scalar).to(device)\r\n    with torch.no_grad():\r\n        scalar_tensor = dist.broadcast(scalar_tensor, src)\r\n    return scalar_tensor.item()\r\n\r\n\r\nbroadcast_scalar(element, src=0, device=device)\r\n```\r\n\r\nRun it with following command:\r\n`python -u -m torch.distributed.launch --nproc_per_node 2 test.py`\r\n\r\nThis has been tested on 2 GPUs.\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/38764",
        "Issue title": "max_pool1d creates illegal memory access for large kernel sizes",
        "Bug description": "\r\n\r\nIn version 1.2.0, NCCL backend doesn't support `torch.bool` datatype. Broadcasting a tensor of this type throws error \"RuntimeError: Unsupported data type for NCCL process group\".\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nCreate a file test.py with following contents:\r\n```py\r\nimport torch\r\nimport argparse\r\nfrom torch import distributed as dist\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument(\"--local_rank\", type=int)\r\n\r\nargs = parser.parse_args()\r\n\r\ntorch.distributed.init_process_group(\"nccl\")\r\n\r\nlocal_rank = args.local_rank\r\n\r\ndevice = torch.device(local_rank)\r\n\r\nif local_rank == 0:\r\n    element = False\r\nelse:\r\n    element = True\r\n\r\n\r\ndef broadcast_scalar(scalar, src=0, device=\"cpu\"):\r\n    scalar_tensor = torch.tensor(scalar).to(device)\r\n    with torch.no_grad():\r\n        scalar_tensor = dist.broadcast(scalar_tensor, src)\r\n    return scalar_tensor.item()\r\n\r\n\r\nbroadcast_scalar(element, src=0, device=device)\r\n```\r\n\r\nRun it with following command:\r\n`python -u -m torch.distributed.launch --nproc_per_node 2 test.py`\r\n\r\nThis has been tested on 2 GPUs.\r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n\r\nCreate a file test.py with following contents:\r\n```py\r\nimport torch\r\nimport argparse\r\nfrom torch import distributed as dist\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument(\"--local_rank\", type=int)\r\n\r\nargs = parser.parse_args()\r\n\r\ntorch.distributed.init_process_group(\"nccl\")\r\n\r\nlocal_rank = args.local_rank\r\n\r\ndevice = torch.device(local_rank)\r\n\r\nif local_rank == 0:\r\n    element = False\r\nelse:\r\n    element = True\r\n\r\n\r\ndef broadcast_scalar(scalar, src=0, device=\"cpu\"):\r\n    scalar_tensor = torch.tensor(scalar).to(device)\r\n    with torch.no_grad():\r\n        scalar_tensor = dist.broadcast(scalar_tensor, src)\r\n    return scalar_tensor.item()\r\n\r\n\r\nbroadcast_scalar(element, src=0, device=device)\r\n```\r\n\r\nRun it with following command:\r\n`python -u -m torch.distributed.launch --nproc_per_node 2 test.py`\r\n\r\nThis has been tested on 2 GPUs.\r\n\r\n## ",
        "API Signature": "\n torch.nn.functional. max_pool1d ( input ,  kernel_size ,  stride ,  padding ,  dilation ,  ceil_mode ,  return_indices ) \u00b6",
        "Bug fix": ""
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/63b1ae69831cd21bc4d6059a5854bc1155a152c9",
        "Bug description": "Fix overflow in torch.remainder when dividend is very large (#37758)\n\nSummary:\nThis will fix the GPU implementation in https://github.com/pytorch/pytorch/issues/37743 and https://github.com/pytorch/pytorch/issues/24861. Please also check my [comment](https://github.com/pytorch/pytorch/issues/37743#issuecomment-623285707).\n\nThe fixed `remainder_kernel` follows the similar implementation in numpy. See https://github.com/numpy/numpy/blob/79d7bc276afbe89c746e462d28d4bfbb4fc56148/numpy/core/src/npymath/npy_math_internal.h.src#L649-L658\n\nI also slightly update the doc for `torch.remainder`, to make it similar to `torch.fmod`.\n\nI'm not sure how to modify the Vec256 code of CPU remainder_kernel, so I just leave it there.\nPull Request resolved: https://github.com/pytorch/pytorch/pull/37758\n\nDifferential Revision: D21388417\n\nPulled By: ngimel\n\nfbshipit-source-id: 770ba5801cf34619b2b68b8b0cf95d8cfa52e6f6",
        "Sample Code": "",
        "API Signature": "\n torch. remainder ( input ,  other ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": [
            "@@ -77,7 +77,9 @@ void remainder_kernel_cuda(TensorIterator& iter) {\n     AT_DISPATCH_FLOATING_TYPES_AND_HALF(iter.dtype(), \"remainder_cuda\", [&]() {\n       gpu_kernel_with_scalars(iter,\n         []GPU_LAMBDA(scalar_t a, scalar_t b) __ubsan_ignore_float_divide_by_zero__ -> scalar_t {\n-          return a - b * static_cast<scalar_t>(std::floor(a / b));\n+          auto mod = ::fmod(a, b);\n+          if ((mod != 0) && ((b < 0) != (mod < 0))) mod += b;\n+          return mod;\n         });\n     });\n   }\n",
            "@@ -15449,6 +15449,27 @@ scipy_lobpcg  | {:10.2e}  | {:10.2e}  | {:6} | N/A\n                 long_res1 = long_m1.clone()\n                 long_res1.remainder_(long_qs.unsqueeze(0).expand_as(long_res1))\n \n+    # remove onlyCUDA after CPU impl of remainder_kernel be fixed\n+    @onlyCUDA\n+    @dtypes(torch.float, torch.double)\n+    def test_remainder_fmod_large_dividend(self, device, dtype):\n+        alarge = 1e9\n+        pi = 3.14159265358979\n+        for avalue in [alarge, -alarge]:\n+            for bvalue in [pi, -pi]:\n+                a = torch.tensor([avalue], dtype=dtype, device=device)\n+                b = torch.tensor([bvalue], dtype=dtype, device=device)\n+                c = torch.remainder(a, b)\n+                d = torch.fmod(a, b)\n+                self.assertTrue((b[0] > 0) == (c[0] > 0))  # remainder has same sign as divisor\n+                self.assertTrue((a[0] > 0) == (d[0] > 0))  # fmod has same sign as dividend\n+                self.assertTrue(abs(c[0]) < abs(b[0]))     # remainder is within range of divisor\n+                self.assertTrue(abs(d[0]) < abs(b[0]))     # fmod is within range of divisor\n+                if ((a[0] > 0) == (b[0] > 0)):\n+                    self.assertTrue(c[0] == d[0])   # remainder is same as fmod\n+                else:\n+                    self.assertTrue(abs(c[0] - d[0]) == abs(b[0]))  # differ by one divisor\n+\n     @dtypes(torch.int64, torch.float64)\n     def test_remainder_edge_cases(self, device, dtype):\n         # Test variations of negative values used as input\n",
            "@@ -4902,8 +4902,8 @@ remainder(input, other, out=None) -> Tensor\n \n Computes the element-wise remainder of division.\n \n-The divisor and dividend may contain both for integer and floating point\n-numbers. The remainder has the same sign as the divisor.\n+The dividend and divisor may contain both for integer and floating point\n+numbers. The remainder has the same sign as the divisor :attr:`other`.\n \n When :attr:`other` is a tensor, the shapes of :attr:`input` and\n :attr:`other` must be :ref:`broadcastable <broadcasting-semantics>`.\n"
        ]
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/7aec364bdf9ed7297b77e8445a6a6d4116265dde",
        "Bug description": "extend gather shape check to handle incorrectly sized outputs (#37102)\n\nSummary:\nFixes a safety issue (Nonsense values and segfaults) introduced by https://github.com/pytorch/pytorch/pull/36875 when in-place gather tries to use incorrect shapes.\n\nConsider the following block of code:\n```\nk0 = 8\nk1 = 8\nm = 100\n\nx = torch.rand((k0, k1))\nind = torch.randint(0, k0, (m, k1))\noutput = torch.empty((m, k1))\n\nprint(torch.gather(x, 0, ind, out=output))\nprint(torch.gather(x, 1, ind, out=output))\n```\n\nThe first gather is legal, the second is not. (`ind` and `output` need to be transposed) Previously this was caught when the kernel tried to restride inputs for TensorIterator, but we can no longer rely on those checks and must test explicitly. If `m` is small the second gather returns gibberish; if it is large enough to push the read out of memory block the program segfaults.\nPull Request resolved: https://github.com/pytorch/pytorch/pull/37102\n\nDifferential Revision: D21190580\n\nPulled By: robieta\n\nfbshipit-source-id: 80175620d24ad3380d78995f7ec7dbf2627d2998",
        "Sample Code": "",
        "API Signature": "\n torch. gather ( input ,  dim ,  index ,  * ,  sparse_grad ,  out )   \u2192 \u00b6",
        "Bug fix": [
            "@@ -9,23 +9,37 @@ namespace {\n \n // Used for `gather`-like methods\n // Test:\n-// 1. index.size(d) == self.size(d) for all d != dim\n-void gather_shape_check(const Tensor& self, int64_t dim, const Tensor& index) {\n+// 1. index.size(d) == src.size(d) for all d != dim\n+// 2. index.size(d) == self.size(d) for all d\n+void gather_shape_check(const Tensor& self, int64_t dim, const Tensor& index, const Tensor& src) {\n   auto self_dims = ensure_nonempty_dim(self.dim());\n+  auto src_dims = ensure_nonempty_dim(src.dim());\n \n   TORCH_CHECK(self_dims == ensure_nonempty_dim(index.dim()),\n     \"Index tensor must have the same number of dimensions as input tensor\"\n   );\n \n+  TORCH_CHECK(src_dims == ensure_nonempty_dim(index.dim()),\n+    \"Index tensor must have the same number of dimensions as output tensor\"\n+  );\n+\n   for (int64_t i = 0; i < self_dims; ++i) {\n+    auto index_size = ensure_nonempty_size(index, i);\n     if (i != dim) {\n       TORCH_CHECK(\n-        ensure_nonempty_size(index, i) == ensure_nonempty_size(self, i),\n-        \"Size does not match at dimension \", i,\n-        \" get \", ensure_nonempty_size(self, i),\n+        index_size == ensure_nonempty_size(src, i),\n+        \"Output size does not match at dimension \", i,\n+        \" get \", ensure_nonempty_size(src, i),\n         \" vs \", ensure_nonempty_size(index, i)\n       );\n     }\n+    TORCH_CHECK(\n+      index_size == ensure_nonempty_size(self, i),\n+      \"Input size does not match at dimension \", i,\n+      \" get \", ensure_nonempty_size(self, i),\n+      \" vs \", ensure_nonempty_size(index, i)\n+    );\n+\n   }\n }\n \n@@ -131,7 +145,7 @@ struct cpu_scatter_gather_base_kernel {\n       scatter_shape_check(self, dim, index, src);\n     }\n     else {\n-      gather_shape_check(self, dim, index);\n+      gather_shape_check(self, dim, index, src);\n     }\n \n     auto iter = TensorIterator();\n",
            "@@ -2534,6 +2534,9 @@ class _TestTorchMixin(object):\n                     expected[i, j, k] = src[tuple(ii)]\n         self.assertEqual(actual, expected, 0)\n \n+        bad_src = torch.randn(*[i - 1 for i in idx_size])\n+        self.assertRaises(RuntimeError, lambda: torch.gather(bad_src, dim, idx))\n+\n         if test_bounds:\n             idx[0][0][0] = 23\n             self.assertRaises(RuntimeError, lambda: torch.gather(src, dim, idx))\n"
        ]
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/33300",
        "Issue title": "segfaults on .numpy() on cuda tensor",
        "Bug description": " of what the bug is. -->\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. torch.zeros((7, ), device=\"cuda\").numpy()\r\n\r\nproduces segfaults.\r\n\r\nWith stacktrace include raising the exception with message to call .cpu method:\r\nhttps://our.intern.facebook.com/intern/diffusion/FBS/browse/master/fbcode/caffe2/torch/csrc/utils/tensor_numpy.cpp?commit=cea4fcd5898cf33ec83ebd2eac23eb035047fe27&lines=78-80\r\n\r\n## Expected behavior\r\n\r\nruntime error with message about having to call .cpu first.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): trunk\r\n - OS (e.g., Linux):\r\n - How you installed PyTorch (`conda`, `pip`, source):\r\n - Build command you used (if compiling from source):\r\n - Python version:\r\n - CUDA/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @ezyang @gchanan @zou3519",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. torch.zeros((7, ), device=\"cuda\").numpy()\r\n\r\nproduces segfaults.\r\n\r\nWith stacktrace include raising the exception with message to call .cpu method:\r\nhttps://our.intern.facebook.com/intern/diffusion/FBS/browse/master/fbcode/caffe2/torch/csrc/utils/tensor_numpy.cpp?commit=cea4fcd5898cf33ec83ebd2eac23eb035047fe27&lines=78-80\r\n\r\n## Expected behavior\r\n\r\nruntime error with message about having to call .cpu first.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): trunk\r\n - OS (e.g., Linux):\r\n - How you installed PyTorch (`conda`, `pip`, source):\r\n - Build command you used (if compiling from source):\r\n - Python version:\r\n - CUDA/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/33001",
        "Issue title": "Segfault when indexing with single element array",
        "Bug description": " of what the bug is. -->\r\n\r\n## To Reproduce\r\n\r\nWe are trying to use PyTorch on a Rapsberry PI 4 on Buster, but get a segfault with a very simple test program:\r\n\r\n```python\r\n$ python\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n>>> v = torch.FloatTensor(1, 135).fill_(0)\r\n>>> v[0, [1]] += 2\r\nSegmentation fault\r\n```\r\n\r\nThe issue seems to only occur when we index `v` using a single element array (whether python list, numpy array or pytorch tensor). Using a multi-element list or `:`, or a single value did not seem to have the issue in our limited testing.\r\n\r\nFollowing is the gdb trace:\r\n\r\n```\r\n$ gdb --args python\r\nGNU gdb (Raspbian 8.2.1-2) 8.2.1\r\nCopyright (C) 2018 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\nType \"show copying\" and \"show warranty\" for details.\r\nThis GDB was configured as \"arm-linux-gnueabihf\".\r\nType \"show configuration\" for configuration details.\r\nFor bug reporting instructions, please see:\r\n<http://www.gnu.org/software/gdb/bugs/>.\r\nFind the GDB manual and other documentation resources online at:\r\n    <http://www.gnu.org/software/gdb/documentation/>.\r\n\r\nFor help, type \"help\".\r\nType \"apropos word\" to search for commands related to \"word\"...\r\nReading symbols from python...(no debugging symbols found)...done.\r\n(gdb) run\r\nStarting program: /home/pi/pytorch1.3/bin/python \r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/arm-linux-gnueabihf/libthread_db.so.1\".\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n[New Thread 0xb5067460 (LWP 26627)]\r\n[New Thread 0xb40c6460 (LWP 26628)]\r\n[New Thread 0xb1125460 (LWP 26629)]\r\n[Thread 0xb1125460 (LWP 26629) exited]\r\n[Thread 0xb40c6460 (LWP 26628) exited]\r\n[Thread 0xb5067460 (LWP 26627) exited]\r\n[Detaching after fork from child process 26631]\r\n>>> v = torch.FloatTensor(1, 135).fill_(0)\r\n>>> v[0, 1] += 2\r\n>>> v[0, [1]] += 2\r\n\r\nThread 1 \"python\" received signal SIGSEGV, Segmentation fault.\r\n0xac0f2868 in at::detail::computeStride(c10::ArrayRef<long long>, c10::ArrayRef<long long>, c10::ArrayRef<long long>) ()\r\n   from /home/pi/pytorch1.3/lib/python3.7/site-packages/torch/lib/libtorch.so\r\n```\r\n\r\n\r\n## Environment\r\n\r\nI compiled pytorch on that pi (in a virtual env), using pytorch v1.3.1 and v1.4.0 from github and both had the same issue. The basic steps was:\r\n\r\n* Install apt deps (e.g. `libatlas-base-dev`).\r\n* Checkout pytorch and submodules from github (`git clone --recursive https://github.com/pytorch/pytorch --branch=v1.3.1`).\r\n* `git submodule update --remote third_party/protobuf` to fix a bug in the current version.\r\n* Export env variables:\r\n  ```\r\n  export NO_CUDA=1\r\n  export NO_DISTRIBUTED=1\r\n  export NO_MKLDNN=1 \r\n  export NO_NNPACK=1\r\n  export NO_QNNPACK=1\r\n  export USE_NUMPY=1\r\n  ```\r\n* Install pip deps (numpy, pyyaml, etc.).\r\n* `python3 setup.py build`.\r\n* `python3 setup.py install`.\r\n\r\n```\r\nCollecting environment information...\r\nPyTorch version: 1.3.0a0+ee77ccb\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Raspbian GNU/Linux 10 (buster)\r\nGCC version: (Raspbian 8.3.0-6+rpi1) 8.3.0\r\nCMake version: version 3.13.4\r\n\r\nPython version: 3.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.1\r\n[pip3] torch==1.3.0a0+ee77ccb\r\n[conda] Could not collect\r\n```\n\ncc @ezyang @gchanan @zou3519",
        "Sample Code": "\r\n\r\nWe are trying to use PyTorch on a Rapsberry PI 4 on Buster, but get a segfault with a very simple test program:\r\n\r\n```python\r\n$ python\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n>>> v = torch.FloatTensor(1, 135).fill_(0)\r\n>>> v[0, [1]] += 2\r\nSegmentation fault\r\n```\r\n\r\nThe issue seems to only occur when we index `v` using a single element array (whether python list, numpy array or pytorch tensor). Using a multi-element list or `:`, or a single value did not seem to have the issue in our limited testing.\r\n\r\nFollowing is the gdb trace:\r\n\r\n```\r\n$ gdb --args python\r\nGNU gdb (Raspbian 8.2.1-2) 8.2.1\r\nCopyright (C) 2018 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\nType \"show copying\" and \"show warranty\" for details.\r\nThis GDB was configured as \"arm-linux-gnueabihf\".\r\nType \"show configuration\" for configuration details.\r\nFor bug reporting instructions, please see:\r\n<http://www.gnu.org/software/gdb/bugs/>.\r\nFind the GDB manual and other documentation resources online at:\r\n    <http://www.gnu.org/software/gdb/documentation/>.\r\n\r\nFor help, type \"help\".\r\nType \"apropos word\" to search for commands related to \"word\"...\r\nReading symbols from python...(no debugging symbols found)...done.\r\n(gdb) run\r\nStarting program: /home/pi/pytorch1.3/bin/python \r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/arm-linux-gnueabihf/libthread_db.so.1\".\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n[New Thread 0xb5067460 (LWP 26627)]\r\n[New Thread 0xb40c6460 (LWP 26628)]\r\n[New Thread 0xb1125460 (LWP 26629)]\r\n[Thread 0xb1125460 (LWP 26629) exited]\r\n[Thread 0xb40c6460 (LWP 26628) exited]\r\n[Thread 0xb5067460 (LWP 26627) exited]\r\n[Detaching after fork from child process 26631]\r\n>>> v = torch.FloatTensor(1, 135).fill_(0)\r\n>>> v[0, 1] += 2\r\n>>> v[0, [1]] += 2\r\n\r\nThread 1 \"python\" received signal SIGSEGV, Segmentation fault.\r\n0xac0f2868 in at::detail::computeStride(c10::ArrayRef<long long>, c10::ArrayRef<long long>, c10::ArrayRef<long long>) ()\r\n   from /home/pi/pytorch1.3/lib/python3.7/site-packages/torch/lib/libtorch.so\r\n```\r\n\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/a64d0ffe81b250889a3e6670daa9c7d07d946e32",
        "Bug description": "Use int64 in pdist kernel to handle batches >= 46342 #30583 (#31593)\n\nSummary:\nCurrently `torch.pdist` yields an illegal CUDA memory access for batch sizes >= 46342 as reported by SsnL in https://github.com/pytorch/pytorch/issues/30583.\nThanks for the minimal code reproduction, btw! ;)\n\nReason for this bug:\nThe calculation if `i` in the [`pdist_kerne_cuda_impl`](https://github.com/pytorch/pytorch/blob/46ad80c8395379be5ba17624fd5dbad8e7a8e8d2/aten/src/ATen/native/cuda/DistanceKernel.cu#L112) might overflow, if a tensor with a `batch size >= 46342` is passed to `torch.pdist`.\n\nDetailed description:\n* `result` is resizes as ` n * (n - 1) / 2 = 1073767311` ([line of code](https://github.com/pytorch/pytorch/blob/46ad80c8395379be5ba17624fd5dbad8e7a8e8d2/aten/src/ATen/native/Distance.cpp#L140))\n* `grid` is initialized as `result.numel()` ([line of code](https://github.com/pytorch/pytorch/blob/46ad80c8395379be5ba17624fd5dbad8e7a8e8d2/aten/src/ATen/native/cuda/DistanceKernel.cu#L246))\n* `k` is assigned to the `blockIdx.x` as an `int32` ([line of code](https://github.com/pytorch/pytorch/blob/46ad80c8395379be5ba17624fd5dbad8e7a8e8d2/aten/src/ATen/native/cuda/DistanceKernel.cu#L108))\n* `i` is calculated using `2 * k >= 2147534622` ([line of code](https://github.com/pytorch/pytorch/blob/46ad80c8395379be5ba17624fd5dbad8e7a8e8d2/aten/src/ATen/native/cuda/DistanceKernel.cu#L112)), which overflows, since `2147534622 > 2147483647 (int32_max)`.\n\nUsing `const int64_t k = blockIdx.x;` would solve the illegal memory access. This seems also be done for [`cdist_kernel_cuda_impl`](https://github.com/pytorch/pytorch/blob/46ad80c8395379be5ba17624fd5dbad8e7a8e8d2/aten/src/ATen/native/cuda/DistanceKernel.cu#L198-L201).\n\nHowever, we might expect a slowdown, so I've timed the current PyTorch master vs. this PR:\n(tested with `x = torch.randn(x.size(0), 128)` on a V100)\n\n |x.size(0) | int32 idx | int64 idx | slowdown |\n |----------|-----------|-----------|----------|\n| 50000 | -              | 4.4460 | - |\n| 25000 | 1.02522 | 1.10869 | 7.53% |\n| 12500 | 0.25182 | 0.27277 | 7.68% |\n| 6250 | 0.06291 | 0.06817 | 7.72% |\n| 3125 | 0.01573 | 0.01704 | 7.69% |\n| 1562 | 0.00393 | 0.00426 | 7.75% |\n\nWhile checking the backward kernel, it seems I'm triggering another error with a size limit of\n```python\nx = torch.randn(1449, 1, device='cuda', requires_grad=True)\nout = torch.pdist(x)\nout.mean().backward()\n> RuntimeError: CUDA error: invalid configuration argument\n```\n, while `[<=1448, 1]` works.\n\nI'll take another look at this issue. Let me know, if the potential fix should go into this PR or if I should open a new issue.\n\nCC ngimel, csarofeen\nPull Request resolved: https://github.com/pytorch/pytorch/pull/31593\n\nDifferential Revision: D19825571\n\nPulled By: ngimel\n\nfbshipit-source-id: ace9ccab49f3cf0ce894cdb6daef0795e2e8ec03",
        "Sample Code": "",
        "API Signature": "\n torch.nn.functional. pdist ( input ,  p )   \u2192 \u00b6",
        "Bug fix": [
            "@@ -105,7 +105,7 @@ __device__ static inline scalar_t reduce_agg(scalar_t agg) {\n template <typename scalar_t, typename F>\n __global__ static void pdist_kernel_cuda_impl(scalar_t * result, const scalar_t * self, const int64_t n, const int64_t m, const scalar_t p,\n                                               const double n2, const double n2_squared_minus_1) {\n-  const int k = blockIdx.x;\n+  const int64_t k = blockIdx.x;\n   const int stride = blockDim.x;\n \n   // The -1 accounts for floating point truncation issues\n@@ -162,9 +162,9 @@ __global__ static void cdist_backward_kernel_cuda_impl(scalar_t * buffer, const\n template <typename scalar_t, typename F>\n __global__ static void pdist_backward_kernel_cuda_impl(scalar_t * buffer, const scalar_t * grad, const scalar_t * self, const scalar_t * dist, int64_t gs, const int64_t n, const int64_t m, const int64_t combs, const scalar_t p,\n                                                        const double n2, const double n2_squared_minus_1) {\n-  const int k = blockIdx.y * blockDim.y + threadIdx.y;\n-  const int init = blockIdx.x * blockDim.x + threadIdx.x;\n-  const int stride = blockDim.x * gridDim.x;\n+  const int64_t k = blockIdx.x * blockDim.x + threadIdx.x;\n+  const int init = blockIdx.y * blockDim.y + threadIdx.y;\n+  const int stride = blockDim.y * gridDim.y;\n \n   if (k >= combs) {\n     return;\n@@ -276,13 +276,12 @@ void pdist_backward_kernel_impl(Tensor& result, const Tensor& grad, const Tensor\n \n   const int64_t n = result.size(0);\n   int64_t m = self.size(1);\n-  const int block_x = 64;\n+  const int block_x = 16;\n   // NB: be careful with changing block_y; as it's currently written, grid_y is limited to be 2^16.\n-  // From binary search, block_y of 16 gives us max pdist dim0 of 1449,\n-  //                     block_y of  4 gives us max pdist dim0 of  725.\n-  const int block_y = 16;\n-  const int grid_x = (m + block_x * 8 - 1) / (block_x * 8);\n-  const int grid_y = (dist.numel() + block_y - 1) / block_y;\n+  // block_y of 64 gives us max pdist dim1 of 2**24\n+  const int block_y = 64;\n+  const int grid_x = (dist.numel() + block_x - 1) / block_x;\n+  const int grid_y = (m + block_y * 8 - 1) / (block_y * 8);\n   const dim3 grid(grid_x, grid_y);\n   const dim3 block(block_x, block_y);\n   // https://github.com/pytorch/pytorch/issues/15511 demonstrated we need to do\n",
            "@@ -25,8 +25,8 @@ from torch.testing._internal.common_methods_invocations import tri_tests_args, r\n from torch.testing._internal.common_utils import TestCase, iter_indices, TEST_NUMPY, TEST_SCIPY, TEST_MKL, \\\n     TEST_LIBROSA, TEST_WITH_ROCM, run_tests, skipIfNoLapack, suppress_warnings, \\\n     IS_WINDOWS, PY3, NO_MULTIPROCESSING_SPAWN, do_test_dtypes, do_test_empty_full, \\\n-    IS_SANDCASTLE, load_tests, brute_pdist, brute_cdist, slowTest, \\\n-    skipCUDANonDefaultStreamIf, skipCUDAMemoryLeakCheckIf, BytesIOContext\n+    IS_SANDCASTLE, load_tests, pdist_single, brute_cdist, slowTest, \\\n+    skipCUDANonDefaultStreamIf, skipCUDAMemoryLeakCheckIf, BytesIOContext, skipIfRocm\n from multiprocessing.reduction import ForkingPickler\n from torch.testing._internal.common_device_type import instantiate_device_type_tests, \\\n     skipCPUIfNoLapack, skipCUDAIfNoMagma, skipCUDAIfRocm, onlyCUDA, onlyCPU, \\\n@@ -10960,26 +10960,35 @@ class TestTorchDeviceType(TestCase):\n         nz = x.nonzero()\n         self.assertFalse(nz.requires_grad)\n \n-    def test_pdist_norm(self, device):\n-        def test_pdist_single(shape, device, p, dtype, trans):\n-            x = torch.randn(shape, dtype=dtype, device=device)\n-            if trans:\n-                x.transpose_(-2, -1)\n-            actual = torch.pdist(x, p=p)\n-            expected = brute_pdist(x, p=p)\n-            self.assertEqual(expected.shape, actual.shape)\n-            self.assertTrue(torch.allclose(expected, actual))\n-\n-        for shape in [(4, 5), (3, 2), (2, 1)]:\n+    def test_pdist_norm_forward(self, device):\n+        for shape in [(4, 5), (3, 2), (2, 1), (1500, 1)]:\n             for p in [0, 1, 2, 3, 1.5, 2.5, float('inf')]:\n                 for trans in [False, True]:\n                     for dtype in [torch.float32, torch.float64]:\n-                        test_pdist_single(shape, device, p, dtype, trans)\n+                        pdist_single(self, shape, device, p, dtype, trans, grad_check=False)\n \n         # do a simplified comparison with big inputs, see:\n         # https://github.com/pytorch/pytorch/issues/15511\n         for dtype in [torch.float32, torch.float64]:\n-            test_pdist_single((1000, 2), device, 2, dtype, False)\n+            pdist_single(self, (1000, 2), device, 2, dtype, trans=False, grad_check=False)\n+\n+    @skipIfRocm\n+    def test_pdist_norm_backward(self, device):\n+        for shape in [(4, 5), (3, 2), (2, 1), (1500, 1)]:\n+            for p in [0, 1, 2, 3, 1.5, 2.5, float('inf')]:\n+                for trans in [False, True]:\n+                    pdist_single(self, shape, device, p, torch.float64, trans, grad_check=True)\n+\n+    @skipIfRocm\n+    def test_pdist_norm_large(self, device):\n+        # use dim0>=46342 for forward, see:\n+        # https://github.com/pytorch/pytorch/issues/30583\n+        # Compare output using GPU with the CPU implementation, as brute_pdist uses too much memory\n+        if 'cuda' in device:\n+            x = torch.randn(50000, 1, dtype=torch.float32)\n+            expected_cpu = torch.pdist(x, p=2)\n+            actual_gpu = torch.pdist(x.to(device), p=2)\n+            self.assertTrue(torch.allclose(expected_cpu, actual_gpu.cpu()))\n \n     def test_atan2(self, device):\n         def _test_atan2_with_size(size, device):\n",
            "@@ -1319,6 +1319,26 @@ def brute_pdist(inp, p=2):\n     return unroll[..., inds.cumsum(0)]\n \n \n+def pdist_single(self, shape, device, p, dtype, trans, grad_check=False):\n+    x = torch.randn(shape, dtype=dtype, device=device)\n+    if trans:\n+        x.transpose_(-2, -1)\n+    if grad_check:\n+        x.requires_grad_()\n+        y = x.detach().clone().requires_grad_()\n+    else:\n+        y = x\n+    actual = torch.pdist(x, p=p)\n+    expected = brute_pdist(y, p=p)\n+    self.assertEqual(expected.shape, actual.shape)\n+    self.assertTrue(torch.allclose(expected, actual))\n+    if grad_check and expected.size() != torch.Size([0]):\n+        g0 = torch.rand_like(actual)\n+        actual.backward(g0)\n+        expected.backward(g0)\n+        self.assertTrue(torch.allclose(x.grad, y.grad))\n+\n+\n def brute_cdist(x, y, p=2):\n     r1 = x.shape[-2]\n     r2 = y.shape[-2]\n"
        ]
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/ddff014b79303e5239d5cb876ba97143cad6405a",
        "Bug description": "fixed scale_factor calculation for uint8 tensor (#31778)\n\nSummary:\nWhen calling the add_images() method on the tensorboard SummaryWriter with a uint8 NCHW tensor, the tensor is incorrectly scaled, resulting in overflow behavior. This leads to incorrect images being displayed in tensorboard.\n\nIssue: https://github.com/pytorch/pytorch/issues/31459\n\nLocal Testing (ran this code with and without the PR changes and printed scale_factor):\n\nimport torch\nimport torchvision\nfrom torch.utils.tensorboard import SummaryWriter\n\nwriter = SummaryWriter()\nx=torch.tensor([[[[1, 2, 3], [4, 5, 6]]]], dtype=torch.uint8)\nwriter.add_images(\"images\", x)\n\nBefore- scale_factor: 255, After- scale_factor: 1\nPull Request resolved: https://github.com/pytorch/pytorch/pull/31778\n\nDifferential Revision: D19289189\n\nPulled By: anjali411\n\nfbshipit-source-id: 350a1650337244deae4fd8f8b7fb0e354ae6986b",
        "Sample Code": "",
        "API Signature": null,
        "Bug fix": [
            "@@ -171,6 +171,16 @@ class TestTensorBoardUtils(BaseTestCase):\n         converted = convert_to_HWC(test_image, 'hw')\n         self.assertEqual(converted.shape, (32, 32, 3))\n \n+    def test_convert_to_HWC_dtype_remains_same(self):\n+        # test to ensure convert_to_HWC restores the dtype of input np array and\n+        # thus the scale_factor calculated for the image is 1\n+        test_image = torch.tensor([[[[1, 2, 3], [4, 5, 6]]]], dtype=torch.uint8)\n+        tensor = make_np(test_image)\n+        tensor = convert_to_HWC(tensor, 'NCHW')\n+        scale_factor = summary._calc_scale_factor(tensor)\n+        self.assertEqual(scale_factor, 1, 'Values are already in [0, 255], scale factor should be 1')\n+\n+\n     def test_prepare_video(self):\n         # At each timeframe, the sum over all other\n         # dimensions of the video should be the same.\n",
            "@@ -79,7 +79,7 @@ def make_grid(I, ncols=8):\n     W = I.shape[3]\n     ncols = min(nimg, ncols)\n     nrows = int(np.ceil(float(nimg) / ncols))\n-    canvas = np.zeros((3, H * nrows, W * ncols))\n+    canvas = np.zeros((3, H * nrows, W * ncols), dtype=I.dtype)\n     i = 0\n     for y in range(nrows):\n         for x in range(ncols):\n"
        ]
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/136bb07a93b779acbc84ff341bc397551a8cfcc2",
        "Bug description": "torch.histc added a finite range check to resolve segfaults if tensor has inf. also added checks for nan values, min>max (#27712)\n\nSummary:\nhttps://github.com/pytorch/pytorch/issues/27464\nPull Request resolved: https://github.com/pytorch/pytorch/pull/27712\n\nDifferential Revision: D18064544\n\nPulled By: anjali411\n\nfbshipit-source-id: c9c6d8eb4d55f2b5320409ba238bf44b0be8902e",
        "Sample Code": "",
        "API Signature": "\n torch. histc ( input ,  bins ,  min ,  max ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": [
            "@@ -2,6 +2,8 @@\n #include <ATen/cuda/CUDAContext.h>\n #include <ATen/cuda/CUDAApplyUtils.cuh>\n \n+#include <THC/THCNumerics.cuh>\n+\n namespace at {\n namespace cuda {\n #define THRESH_NUMBER_BINS_FOR_MULTI_BLOCK_MEM 100\n@@ -323,6 +325,29 @@ Tensor _histc_cuda_template(\n     maxvalue = maxvalue + 1;\n   }\n \n+#ifndef __HIP_PLATFORM_HCC__\n+  TORCH_CHECK(\n+      !(THCNumerics<input_t>::isinf(minvalue) ||\n+        THCNumerics<input_t>::isinf(maxvalue) ||\n+        THCNumerics<input_t>::isnan(minvalue) ||\n+        THCNumerics<input_t>::isnan(maxvalue)),\n+      \"range of [\",\n+      minvalue,\n+      \", \",\n+      maxvalue,\n+      \"] is not finite\");\n+#else\n+  TORCH_CHECK(\n+      !(std::isinf(minvalue) || std::isinf(maxvalue) || std::isnan(minvalue) ||\n+        std::isnan(maxvalue)),\n+      \"range of [\",\n+      minvalue,\n+      \", \",\n+      maxvalue,\n+      \"] is not finite\");\n+#endif\n+  TORCH_CHECK(minvalue < maxvalue, \"max must be larger than min\");\n+\n   auto ret = cuda::CUDA_tensor_histogram<input_t, input_t, false>(\n     output, self, Tensor(), nbins, minvalue, maxvalue);\n   return output;\n",
            "@@ -1283,6 +1283,9 @@ void THTensor_(histc)(THTensor *hist, THTensor *tensor, int64_t nbins, scalar_t\n     maxval = maxval + 1;\n   }\n \n+  TORCH_CHECK(!(std::isinf(minval) || std::isinf(maxval) || std::isnan(minval) || std::isnan(maxval)), \"range of [\", minval, \", \", maxval, \"] is not finite\");\n+  TORCH_CHECK(minval < maxval, \"max must be larger than min\");\n+\n   h_data = hist->data<scalar_t>();\n \n   TH_TENSOR_APPLY(scalar_t, tensor,\n",
            "@@ -9983,6 +9983,27 @@ class TestTorchDeviceType(TestCase):\n         self.assertEqual(\n             torch.tensor([1], dtype=torch.float, device=device),\n             actual)\n+        # tensors with inf; min, max not provided -- should throw a RuntimeError\n+        with self.assertRaisesRegex(RuntimeError, r'range of \\[inf, inf\\] is not finite'):\n+            torch.histc(torch.tensor([float(\"inf\")], dtype=torch.float, device=device))\n+        with self.assertRaisesRegex(RuntimeError, r'range of \\[1, inf\\] is not finite'):\n+            torch.histc(torch.tensor([1., 2., float(\"inf\")], dtype=torch.float, device=device))\n+        # tensors with inf; min, max provided\n+        self.assertEqual(\n+            torch.histc(torch.tensor([float(\"inf\")], dtype=torch.float, device=device),\n+                        bins=1, min=0, max=3),\n+            torch.tensor([0], dtype=torch.float, device=device))\n+        self.assertEqual(\n+            torch.histc(torch.tensor([1., 2., float(\"inf\")], dtype=torch.float, device=device),\n+                        bins=4, max=3),\n+            torch.tensor([0, 1, 1, 0], dtype=torch.float, device=device))\n+        # tensor with nan -- should throw a RuntimeError\n+        with self.assertRaisesRegex(RuntimeError, r'range of \\[nan, nan\\] is not finite'):\n+            torch.histc(torch.tensor([float(\"nan\")], dtype=torch.float, device=device))\n+        # tensors with min > max -- should throw a RuntimeError\n+        with self.assertRaisesRegex(RuntimeError, \"max must be larger than min\"):\n+            torch.histc(torch.tensor([1., 2., 3.], dtype=torch.float, device=device),\n+                        bins=4, min=5, max=1)\n \n         # test against numpy.histogram()\n         def test_against_np(tensor, bins=100, min=0, max=0):\n"
        ]
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/ec8e75ea92ae2b5ea73b4aeb3ec7cb39e9f95db9",
        "Bug description": "Fix int32 overflow in SummaryOps.cu getBin #25747 (#25748)\n\nSummary:\nFixes issue https://github.com/pytorch/pytorch/issues/25747 by upcasting to int64 before multiplication. Should be good enough for all reasonable nbins\nPull Request resolved: https://github.com/pytorch/pytorch/pull/25748\n\nDifferential Revision: D17269111\n\nPulled By: ezyang\n\nfbshipit-source-id: 484be39080571203264a1bb9898ecf23d1aeafab",
        "Sample Code": "",
        "API Signature": "\n torch. sum ( input ,  * ,  dtype )   \u2192 \u00b6",
        "Bug fix": [
            "@@ -17,7 +17,7 @@ namespace cuda {\n enum class CUDAHistogramMemoryType { SHARED, MULTI_BLOCK, GLOBAL };\n namespace {\n   template<typename input_t, typename IndexType>\n-  __device__ static IndexType getBin(input_t bVal, input_t minvalue, input_t maxvalue, int nbins) {\n+  __device__ static IndexType getBin(input_t bVal, input_t minvalue, input_t maxvalue, int64_t nbins) {\n     IndexType bin = (int)((bVal - minvalue) * nbins / (maxvalue - minvalue));\n     // (only applicable for histc)\n     // while each bin is inclusive at the lower end and exclusive at the higher, i.e. [start, end)\n@@ -47,7 +47,7 @@ __global__ void kernelHistogram1D(\n     detail::TensorInfo<output_t, IndexType> a, /* output */\n     detail::TensorInfo<output_t, IndexType> p, /* partial output */\n     detail::TensorInfo<input_t, IndexType> b, /* input */\n-    int nbins,\n+    int64_t nbins,\n     input_t minvalue,\n     input_t maxvalue,\n     IndexType totalElements,\n",
            "@@ -2847,6 +2847,13 @@ class TestCuda(TestCase):\n         self.assertEqual(t.cpu().bincount(), t.bincount())\n         self.assertEqual(t.cpu().bincount(w_cpu), t.bincount(w))\n \n+        t = torch.zeros([10], dtype=torch.int32, device='cuda')\n+        # 35488 * 65536 as int32 would cause overflow to negative value\n+        # giving negative bin offset\n+        t[0] = 35488\n+        counted = t.bincount(minlength=65536)\n+        self.assertEqual(torch.sum(counted), 10)\n+\n     def test_tiny_half_norm_(self):\n         a = torch.arange(25).cuda().float()\n         a /= 100000000\n"
        ]
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/24309",
        "Issue title": "Illegal memory access occurs when using nn.AvgPool2d ",
        "Bug description": " of what the bug is. -->\r\n\r\n## To Reproduce\r\n\r\nWe are trying to use PyTorch on a Rapsberry PI 4 on Buster, but get a segfault with a very simple test program:\r\n\r\n```python\r\n$ python\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n>>> v = torch.FloatTensor(1, 135).fill_(0)\r\n>>> v[0, [1]] += 2\r\nSegmentation fault\r\n```\r\n\r\nThe issue seems to only occur when we index `v` using a single element array (whether python list, numpy array or pytorch tensor). Using a multi-element list or `:`, or a single value did not seem to have the issue in our limited testing.\r\n\r\nFollowing is the gdb trace:\r\n\r\n```\r\n$ gdb --args python\r\nGNU gdb (Raspbian 8.2.1-2) 8.2.1\r\nCopyright (C) 2018 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\nType \"show copying\" and \"show warranty\" for details.\r\nThis GDB was configured as \"arm-linux-gnueabihf\".\r\nType \"show configuration\" for configuration details.\r\nFor bug reporting instructions, please see:\r\n<http://www.gnu.org/software/gdb/bugs/>.\r\nFind the GDB manual and other documentation resources online at:\r\n    <http://www.gnu.org/software/gdb/documentation/>.\r\n\r\nFor help, type \"help\".\r\nType \"apropos word\" to search for commands related to \"word\"...\r\nReading symbols from python...(no debugging symbols found)...done.\r\n(gdb) run\r\nStarting program: /home/pi/pytorch1.3/bin/python \r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/arm-linux-gnueabihf/libthread_db.so.1\".\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n[New Thread 0xb5067460 (LWP 26627)]\r\n[New Thread 0xb40c6460 (LWP 26628)]\r\n[New Thread 0xb1125460 (LWP 26629)]\r\n[Thread 0xb1125460 (LWP 26629) exited]\r\n[Thread 0xb40c6460 (LWP 26628) exited]\r\n[Thread 0xb5067460 (LWP 26627) exited]\r\n[Detaching after fork from child process 26631]\r\n>>> v = torch.FloatTensor(1, 135).fill_(0)\r\n>>> v[0, 1] += 2\r\n>>> v[0, [1]] += 2\r\n\r\nThread 1 \"python\" received signal SIGSEGV, Segmentation fault.\r\n0xac0f2868 in at::detail::computeStride(c10::ArrayRef<long long>, c10::ArrayRef<long long>, c10::ArrayRef<long long>) ()\r\n   from /home/pi/pytorch1.3/lib/python3.7/site-packages/torch/lib/libtorch.so\r\n```\r\n\r\n\r\n## Environment\r\n\r\nI compiled pytorch on that pi (in a virtual env), using pytorch v1.3.1 and v1.4.0 from github and both had the same issue. The basic steps was:\r\n\r\n* Install apt deps (e.g. `libatlas-base-dev`).\r\n* Checkout pytorch and submodules from github (`git clone --recursive https://github.com/pytorch/pytorch --branch=v1.3.1`).\r\n* `git submodule update --remote third_party/protobuf` to fix a bug in the current version.\r\n* Export env variables:\r\n  ```\r\n  export NO_CUDA=1\r\n  export NO_DISTRIBUTED=1\r\n  export NO_MKLDNN=1 \r\n  export NO_NNPACK=1\r\n  export NO_QNNPACK=1\r\n  export USE_NUMPY=1\r\n  ```\r\n* Install pip deps (numpy, pyyaml, etc.).\r\n* `python3 setup.py build`.\r\n* `python3 setup.py install`.\r\n\r\n```\r\nCollecting environment information...\r\nPyTorch version: 1.3.0a0+ee77ccb\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Raspbian GNU/Linux 10 (buster)\r\nGCC version: (Raspbian 8.3.0-6+rpi1) 8.3.0\r\nCMake version: version 3.13.4\r\n\r\nPython version: 3.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.1\r\n[pip3] torch==1.3.0a0+ee77ccb\r\n[conda] Could not collect\r\n```\n\ncc @ezyang @gchanan @zou3519",
        "Sample Code": "\r\n\r\nWe are trying to use PyTorch on a Rapsberry PI 4 on Buster, but get a segfault with a very simple test program:\r\n\r\n```python\r\n$ python\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n>>> v = torch.FloatTensor(1, 135).fill_(0)\r\n>>> v[0, [1]] += 2\r\nSegmentation fault\r\n```\r\n\r\nThe issue seems to only occur when we index `v` using a single element array (whether python list, numpy array or pytorch tensor). Using a multi-element list or `:`, or a single value did not seem to have the issue in our limited testing.\r\n\r\nFollowing is the gdb trace:\r\n\r\n```\r\n$ gdb --args python\r\nGNU gdb (Raspbian 8.2.1-2) 8.2.1\r\nCopyright (C) 2018 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\nType \"show copying\" and \"show warranty\" for details.\r\nThis GDB was configured as \"arm-linux-gnueabihf\".\r\nType \"show configuration\" for configuration details.\r\nFor bug reporting instructions, please see:\r\n<http://www.gnu.org/software/gdb/bugs/>.\r\nFind the GDB manual and other documentation resources online at:\r\n    <http://www.gnu.org/software/gdb/documentation/>.\r\n\r\nFor help, type \"help\".\r\nType \"apropos word\" to search for commands related to \"word\"...\r\nReading symbols from python...(no debugging symbols found)...done.\r\n(gdb) run\r\nStarting program: /home/pi/pytorch1.3/bin/python \r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/arm-linux-gnueabihf/libthread_db.so.1\".\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n[New Thread 0xb5067460 (LWP 26627)]\r\n[New Thread 0xb40c6460 (LWP 26628)]\r\n[New Thread 0xb1125460 (LWP 26629)]\r\n[Thread 0xb1125460 (LWP 26629) exited]\r\n[Thread 0xb40c6460 (LWP 26628) exited]\r\n[Thread 0xb5067460 (LWP 26627) exited]\r\n[Detaching after fork from child process 26631]\r\n>>> v = torch.FloatTensor(1, 135).fill_(0)\r\n>>> v[0, 1] += 2\r\n>>> v[0, [1]] += 2\r\n\r\nThread 1 \"python\" received signal SIGSEGV, Segmentation fault.\r\n0xac0f2868 in at::detail::computeStride(c10::ArrayRef<long long>, c10::ArrayRef<long long>, c10::ArrayRef<long long>) ()\r\n   from /home/pi/pytorch1.3/lib/python3.7/site-packages/torch/lib/libtorch.so\r\n```\r\n\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/74828be4a7d0d2dba3f0ec3f6e79265cdfae5329",
        "Bug description": "fix segfault in `cat` on CPU with tensors that can't be indexed with 32-bit ints. (#21530)\n\nSummary:\nShould be self-explanatory. This `int` variable is overflowing.\n\nReported in #21526\nPull Request resolved: https://github.com/pytorch/pytorch/pull/21530\n\nDifferential Revision: D15719275\n\nPulled By: umanwizard\n\nfbshipit-source-id: 24e917a00a5b78bc3af29ef3b8b72eea7e89d5d5",
        "Sample Code": "",
        "API Signature": "\n torch. cat ( tensors ,  dim ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": [
            "@@ -799,7 +799,7 @@ void THTensor_(catArray)(THTensor *result, THTensor **inputs, int numInputs, int\n         if (!should_skip(inputs[j])) {\n           THTensor* input0 = inputs[j];\n           scalar_t* input0_data = THStorage_(data)(THTensor_getStoragePtr(input0)) + input0->storage_offset();\n-          int local_inner = inner * input0->size(dimension);\n+          int64_t local_inner = inner * input0->size(dimension);\n           if (local_inner != 0) {\n             memcpy(result_data + offset, input0_data + o*local_inner, local_inner*sizeof(scalar_t));\n           } // input0_size != 0\n",
            "@@ -4948,6 +4948,16 @@ class _TestTorchMixin(object):\n     def test_cat_empty(self):\n         self._test_cat_empty(self)\n \n+    @slowTest\n+    def test_cat_big(self):\n+        SIZE1 = 6500\n+        SIZE2 = 4500\n+        concat_list = []\n+        concat_list.append(torch.ones((SIZE1, 1024 * 512), dtype=torch.uint8))\n+        concat_list.append(torch.ones((SIZE2, 1024 * 512), dtype=torch.uint8))\n+        result = torch.cat(concat_list)\n+        self.assertEqual(result.size(0), SIZE1 + SIZE2)\n+\n     def test_narrow(self):\n         x = torch.Tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n         self.assertEqual(x.narrow(0, 0, 1), torch.Tensor([[0, 1, 2]]))\n"
        ]
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/071971476d7431a24e527bdc181981678055a95d",
        "Bug description": "Fix Binomimal overflow when logits is large (#20679)\n\nSummary:\nThis PR fixes  #17843. In addition (test locally), this still maintains the continuity of log_prob which is addressed in https://github.com/pytorch/pytorch/pull/15962\n\ncc neerajprad\nPull Request resolved: https://github.com/pytorch/pytorch/pull/20679\n\nDifferential Revision: D15413311\n\nPulled By: ezyang\n\nfbshipit-source-id: 4fc0ca755ae6a85aa7deb2206dab675f82f9aa25",
        "Sample Code": "",
        "API Signature": null,
        "Bug fix": [
            "@@ -953,6 +953,18 @@ class TestDistributions(TestCase):\n             logits = probs_to_logits(probs, is_binary=True)\n             self._check_log_prob(Binomial(total_count, logits=logits), ref_log_prob)\n \n+    def test_binomial_stable(self):\n+        logits = torch.tensor([-100., 100.], dtype=torch.float)\n+        total_count = 1.\n+        x = torch.tensor([0., 0.], dtype=torch.float)\n+        log_prob = Binomial(total_count, logits=logits).log_prob(x)\n+        self.assertTrue(torch.isfinite(log_prob).all())\n+\n+        # make sure that the grad at logits=0, value=0 is 0.5\n+        x = torch.tensor(0., requires_grad=True)\n+        y = Binomial(total_count, logits=x).log_prob(torch.tensor(0.))\n+        self.assertEqual(grad(y, x)[0], torch.tensor(-0.5))\n+\n     @unittest.skipIf(not TEST_NUMPY, \"NumPy not found\")\n     def test_binomial_log_prob_vectorized_count(self):\n         probs = torch.tensor([0.2, 0.7, 0.9])\n",
            "@@ -5,6 +5,11 @@ from torch.distributions.distribution import Distribution\n from torch.distributions.utils import broadcast_all, probs_to_logits, lazy_property, logits_to_probs\n \n \n+def _clamp_by_zero(x):\n+    # works like clamp(x, min=0) but has grad at 0 is 0.5\n+    return (x.clamp(min=0) + x - x.clamp(max=0)) / 2\n+\n+\n class Binomial(Distribution):\n     r\"\"\"\n     Creates a Binomial distribution parameterized by :attr:`total_count` and\n@@ -113,9 +118,15 @@ class Binomial(Distribution):\n         log_factorial_n = torch.lgamma(self.total_count + 1)\n         log_factorial_k = torch.lgamma(value + 1)\n         log_factorial_nmk = torch.lgamma(self.total_count - value + 1)\n-        # Note that: torch.log1p(-self.probs)) = - torch.log1p(self.logits.exp()))\n-        return (log_factorial_n - log_factorial_k - log_factorial_nmk +\n-                value * self.logits - self.total_count * torch.log1p(self.logits.exp()))\n+        # k * log(p) + (n - k) * log(1 - p) = k * (log(p) - log(1 - p)) + n * log(1 - p)\n+        #     (case logit < 0)              = k * logit - n * log1p(e^logit)\n+        #     (case logit > 0)              = k * logit - n * (log(p) - log(1 - p)) + n * log(p)\n+        #                                   = k * logit - n * logit - n * log1p(e^-logit)\n+        #     (merge two cases)             = k * logit - n * max(logit, 0) - n * log1p(e^-|logit|)\n+        normalize_term = (self.total_count * _clamp_by_zero(self.logits)\n+                          + self.total_count * torch.log1p(torch.exp(-torch.abs(self.logits)))\n+                          - log_factorial_n)\n+        return value * self.logits - log_factorial_k - log_factorial_nmk - normalize_term\n \n     def enumerate_support(self, expand=True):\n         total_count = int(self.total_count.max())\n"
        ]
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/071971476d7431a24e527bdc181981678055a95d",
        "Bug description": "Fix Binomimal overflow when logits is large (#20679)\n\nSummary:\nThis PR fixes  #17843. In addition (test locally), this still maintains the continuity of log_prob which is addressed in https://github.com/pytorch/pytorch/pull/15962\n\ncc neerajprad\nPull Request resolved: https://github.com/pytorch/pytorch/pull/20679\n\nDifferential Revision: D15413311\n\nPulled By: ezyang\n\nfbshipit-source-id: 4fc0ca755ae6a85aa7deb2206dab675f82f9aa25",
        "Sample Code": "",
        "API Signature": null,
        "Bug fix": [
            "@@ -953,6 +953,18 @@ class TestDistributions(TestCase):\n             logits = probs_to_logits(probs, is_binary=True)\n             self._check_log_prob(Binomial(total_count, logits=logits), ref_log_prob)\n \n+    def test_binomial_stable(self):\n+        logits = torch.tensor([-100., 100.], dtype=torch.float)\n+        total_count = 1.\n+        x = torch.tensor([0., 0.], dtype=torch.float)\n+        log_prob = Binomial(total_count, logits=logits).log_prob(x)\n+        self.assertTrue(torch.isfinite(log_prob).all())\n+\n+        # make sure that the grad at logits=0, value=0 is 0.5\n+        x = torch.tensor(0., requires_grad=True)\n+        y = Binomial(total_count, logits=x).log_prob(torch.tensor(0.))\n+        self.assertEqual(grad(y, x)[0], torch.tensor(-0.5))\n+\n     @unittest.skipIf(not TEST_NUMPY, \"NumPy not found\")\n     def test_binomial_log_prob_vectorized_count(self):\n         probs = torch.tensor([0.2, 0.7, 0.9])\n",
            "@@ -5,6 +5,11 @@ from torch.distributions.distribution import Distribution\n from torch.distributions.utils import broadcast_all, probs_to_logits, lazy_property, logits_to_probs\n \n \n+def _clamp_by_zero(x):\n+    # works like clamp(x, min=0) but has grad at 0 is 0.5\n+    return (x.clamp(min=0) + x - x.clamp(max=0)) / 2\n+\n+\n class Binomial(Distribution):\n     r\"\"\"\n     Creates a Binomial distribution parameterized by :attr:`total_count` and\n@@ -113,9 +118,15 @@ class Binomial(Distribution):\n         log_factorial_n = torch.lgamma(self.total_count + 1)\n         log_factorial_k = torch.lgamma(value + 1)\n         log_factorial_nmk = torch.lgamma(self.total_count - value + 1)\n-        # Note that: torch.log1p(-self.probs)) = - torch.log1p(self.logits.exp()))\n-        return (log_factorial_n - log_factorial_k - log_factorial_nmk +\n-                value * self.logits - self.total_count * torch.log1p(self.logits.exp()))\n+        # k * log(p) + (n - k) * log(1 - p) = k * (log(p) - log(1 - p)) + n * log(1 - p)\n+        #     (case logit < 0)              = k * logit - n * log1p(e^logit)\n+        #     (case logit > 0)              = k * logit - n * (log(p) - log(1 - p)) + n * log(p)\n+        #                                   = k * logit - n * logit - n * log1p(e^-logit)\n+        #     (merge two cases)             = k * logit - n * max(logit, 0) - n * log1p(e^-|logit|)\n+        normalize_term = (self.total_count * _clamp_by_zero(self.logits)\n+                          + self.total_count * torch.log1p(torch.exp(-torch.abs(self.logits)))\n+                          - log_factorial_n)\n+        return value * self.logits - log_factorial_k - log_factorial_nmk - normalize_term\n \n     def enumerate_support(self, expand=True):\n         total_count = int(self.total_count.max())\n"
        ]
    },
    {
        "Commit link": "https://api.github.com/repos/pytorch/pytorch/commits/d4712ee218cd6af3c2096ca7a76fef350173b703",
        "Bug description": "Added correct isinf handling for Integral tensors (#15489)\n\nSummary:\nCurrently torch.isinf on integral tensor will raise RuntimeError: value cannot be converted to type int16_t without overflow: inf.\nThis pr will suppress the error and return false(0) for all integral tensors. The behavior will also be consistent with np.isinf\nPull Request resolved: https://github.com/pytorch/pytorch/pull/15489\n\nReviewed By: zou3519\n\nDifferential Revision: D13540786\n\nPulled By: flashhack\n\nfbshipit-source-id: e730dea849da6a59f3752d347bcfbadfd12c6483",
        "Sample Code": "",
        "API Signature": "\n torch. isinf ( input )   \u2192 \u00b6",
        "Bug fix": [
            "@@ -938,6 +938,9 @@ class TestCuda(TestCase):\n     def test_neg(self):\n         _TestTorchMixin._test_neg(self, lambda t: t.cuda())\n \n+    def test_isinf(self):\n+        _TestTorchMixin._test_isinf(self, lambda t: t.cuda())\n+\n     @unittest.skipIf(not TEST_LARGE_TENSOR, \"not enough memory\")\n     def test_arithmetic_large_tensor(self):\n         x = torch.empty(2**30, device='cuda')\n",
            "@@ -5316,9 +5316,23 @@ class _TestTorchMixin(object):\n         x = torch.tensor([1, 2, 3])\n         self.assertEqual(torch.isfinite(x), torch.ByteTensor([1, 1, 1]))\n \n+    @staticmethod\n+    def _test_isinf(self, cast):\n+        t1 = cast(torch.Tensor([1, inf, 2, -inf, nan]))\n+        t2 = cast(torch.ByteTensor([1, 2, 3]))\n+        t3 = cast(torch.CharTensor([1, 2, 3]))\n+        t4 = cast(torch.ShortTensor([1, 2, 3]))\n+        t5 = cast(torch.IntTensor([1, 2, 3]))\n+        t6 = cast(torch.LongTensor([1, 2, 3]))\n+        self.assertEqual(torch.isinf(t1), cast(torch.ByteTensor([0, 1, 0, 1, 0])))\n+        self.assertEqual(torch.isinf(t2), cast(torch.ByteTensor([0, 0, 0])))\n+        self.assertEqual(torch.isinf(t3), cast(torch.ByteTensor([0, 0, 0])))\n+        self.assertEqual(torch.isinf(t4), cast(torch.ByteTensor([0, 0, 0])))\n+        self.assertEqual(torch.isinf(t5), cast(torch.ByteTensor([0, 0, 0])))\n+        self.assertEqual(torch.isinf(t6), cast(torch.ByteTensor([0, 0, 0])))\n+\n     def test_isinf(self):\n-        x = torch.Tensor([1, inf, 2, -inf, nan])\n-        self.assertEqual(torch.isinf(x), torch.ByteTensor([0, 1, 0, 1, 0]))\n+        self._test_isinf(self, lambda t: t)\n \n     def test_isnan(self):\n         x = torch.Tensor([1, nan, 2])\n",
            "@@ -240,6 +240,8 @@ def isinf(tensor):\n     \"\"\"\n     if not isinstance(tensor, torch.Tensor):\n         raise ValueError(\"The argument is not a tensor\", str(tensor))\n+    if tensor.dtype in [torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64]:\n+        return torch.zeros_like(tensor, dtype=torch.uint8)\n     return tensor.abs() == inf\n \n \n"
        ]
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/13324",
        "Issue title": "torch.nn.utils.rnn.pack_padded_sequence segment fault if not in decreasing order",
        "Bug description": "\r\n\r\nInstead of raising an exception, the function `torch.nn.utils.rnn.pack_padded_sequence` forces python environment to shut down due to a segmentation fault if the input is not in decreasing order.\r\n\r\n\r\n## To Reproduce\r\n\r\n```python \r\nimport torch\r\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\r\na = torch.ones(25, 300)\r\nb = torch.ones(22, 300)\r\nb_a = pad_sequence([b, a])\r\npack_padded_sequence(b_a, [22, 25])\r\n>>> 31906 abort (core dumped)  ipython\r\na_b = pad_sequence([a, b])\r\npack_padded_sequence(a_b, [25, 22]) # it works!\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n```python \r\nimport torch\r\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\r\na = torch.ones(25, 300)\r\nb = torch.ones(22, 300)\r\nb_a = pad_sequence([b, a])\r\npack_padded_sequence(b_a, [22, 25])\r\n>>> 31906 abort (core dumped)  ipython\r\na_b = pad_sequence([a, b])\r\npack_padded_sequence(a_b, [25, 22]) # it works!\r\n```\r\n\r\n## ",
        "API Signature": "\n torch.nn.utils.rnn. pack_padded_sequence ( input ,  lengths ,  batch_first ,  enforce_sorted ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/9264",
        "Issue title": "Dilated Conv3d segfaults (cpu)",
        "Bug description": "\r\n\r\nInstead of raising an exception, the function `torch.nn.utils.rnn.pack_padded_sequence` forces python environment to shut down due to a segmentation fault if the input is not in decreasing order.\r\n\r\n\r\n## To Reproduce\r\n\r\n```python \r\nimport torch\r\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\r\na = torch.ones(25, 300)\r\nb = torch.ones(22, 300)\r\nb_a = pad_sequence([b, a])\r\npack_padded_sequence(b_a, [22, 25])\r\n>>> 31906 abort (core dumped)  ipython\r\na_b = pad_sequence([a, b])\r\npack_padded_sequence(a_b, [25, 22]) # it works!\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n```python \r\nimport torch\r\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\r\na = torch.ones(25, 300)\r\nb = torch.ones(22, 300)\r\nb_a = pad_sequence([b, a])\r\npack_padded_sequence(b_a, [22, 25])\r\n>>> 31906 abort (core dumped)  ipython\r\na_b = pad_sequence([a, b])\r\npack_padded_sequence(a_b, [25, 22]) # it works!\r\n```\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/3498",
        "Issue title": "Memory Leak in autograd using ndarray[None]",
        "Bug description": "\r\n\r\nInstead of raising an exception, the function `torch.nn.utils.rnn.pack_padded_sequence` forces python environment to shut down due to a segmentation fault if the input is not in decreasing order.\r\n\r\n\r\n## To Reproduce\r\n\r\n```python \r\nimport torch\r\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\r\na = torch.ones(25, 300)\r\nb = torch.ones(22, 300)\r\nb_a = pad_sequence([b, a])\r\npack_padded_sequence(b_a, [22, 25])\r\n>>> 31906 abort (core dumped)  ipython\r\na_b = pad_sequence([a, b])\r\npack_padded_sequence(a_b, [25, 22]) # it works!\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n```python \r\nimport torch\r\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\r\na = torch.ones(25, 300)\r\nb = torch.ones(22, 300)\r\nb_a = pad_sequence([b, a])\r\npack_padded_sequence(b_a, [22, 25])\r\n>>> 31906 abort (core dumped)  ipython\r\na_b = pad_sequence([a, b])\r\npack_padded_sequence(a_b, [25, 22]) # it works!\r\n```\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/86326",
        "Issue title": "`torch.special.round` doesn't support the same dtypes as `torch.round`",
        "Bug description": "\r\n\r\nInstead of raising an exception, the function `torch.nn.utils.rnn.pack_padded_sequence` forces python environment to shut down due to a segmentation fault if the input is not in decreasing order.\r\n\r\n\r\n## To Reproduce\r\n\r\n```python \r\nimport torch\r\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\r\na = torch.ones(25, 300)\r\nb = torch.ones(22, 300)\r\nb_a = pad_sequence([b, a])\r\npack_padded_sequence(b_a, [22, 25])\r\n>>> 31906 abort (core dumped)  ipython\r\na_b = pad_sequence([a, b])\r\npack_padded_sequence(a_b, [25, 22]) # it works!\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n`torch.special.round` is declared as an alias of `torch.round` in the `OpInfo`. But they behave differently (due to a bug?):\r\n\r\n```py\r\nIn [2]: torch.special.round(torch.tensor([2], dtype=torch.short))\r\nRuntimeError: \"round_vml_cpu\" not implemented for 'Short'\r\n\r\nIn [3]: torch.round(torch.tensor([2], dtype=torch.short))\r\nOut[3]: tensor([2], dtype=torch.int16)\r\n\r\nIn [4]: torch.tensor([2], dtype=torch.short).round()\r\nOut[4]: tensor([2], dtype=torch.int16)\r\n```\r\n\r\nThe error message is from `AT_DISPATCH_SWITCH`. I haven't looked into why it happens.\r\n\r\nAliases are tested in `test_variant_consistency_eager`, but that test only checks against `torch.float` and `torch.cfloat` (see `_variant_ops`). So we didn't notice. If I allow testing for all dtypes there, I get the same error:\r\n\r\n```py\r\n# old:\r\n# _variant_ops = partial(\r\n#     ops, dtypes=OpDTypes.supported, allowed_dtypes=(torch.float, torch.cfloat)\r\n# )\r\n# new:\r\n_variant_ops = partial(\r\n    ops, dtypes=OpDTypes.supported\r\n)\r\n```\r\n\r\n```bash\r\n# run after allowing all types in _variant_ops\r\npython -m pytest test/test_ops.py -k test_variant_consistency_eager_round -vv  --capture=no \r\n```\r\n\r\noutput:\r\n```\r\nFAILED test/test_ops.py::TestCommonCPU::test_variant_consistency_eager_round_cpu_int16 - RuntimeError: \"round_vml_cpu\" not implemented for 'Short'\r\nFAILED test/test_ops.py::TestCommonCPU::test_variant_consistency_eager_round_cpu_int32 - RuntimeError: \"round_vml_cpu\" not implemented for 'Int'\r\nFAILED test/test_ops.py::TestCommonCPU::test_variant_consistency_eager_round_cpu_int64 - RuntimeError: \"round_vml_cpu\" not implemented for 'Long'\r\nFAILED test/test_ops.py::TestCommonCPU::test_variant_consistency_eager_round_cpu_int8 - RuntimeError: \"round_vml_cpu\" not implemented for 'Char'\r\nFAILED test/test_ops.py::TestCommonCPU::test_variant_consistency_eager_round_cpu_uint8 - RuntimeError: \"round_vml_cpu\" not implemented for 'Byte'\r\n\r\nFAILED test/test_ops.py::TestCommonCUDA::test_variant_consistency_eager_round_cuda_int16 - RuntimeError: \"round_cuda\" not implemented for 'Short'\r\nFAILED test/test_ops.py::TestCommonCUDA::test_variant_consistency_eager_round_cuda_int32 - RuntimeError: \"round_cuda\" not implemented for 'Int'\r\nFAILED test/test_ops.py::TestCommonCUDA::test_variant_consistency_eager_round_cuda_int64 - RuntimeError: \"round_cuda\" not implemented for 'Long'\r\nFAILED test/test_ops.py::TestCommonCUDA::test_variant_consistency_eager_round_cuda_int8 - RuntimeError: \"round_cuda\" not implemented for 'Char'\r\nFAILED test/test_ops.py::TestCommonCUDA::test_variant_consistency_eager_round_cuda_uint8 - RuntimeError: \"round_cuda\" not implemented for 'Byte'\r\n```\r\n\r\n### ",
        "API Signature": "\n torch. round ( input ,  * ,  decimals ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/86279",
        "Issue title": "`torch.multinomial` on MPS crashes with `Error: total bytes of NDArray > 2**32'`",
        "Bug description": "\r\n\r\nInstead of raising an exception, the function `torch.nn.utils.rnn.pack_padded_sequence` forces python environment to shut down due to a segmentation fault if the input is not in decreasing order.\r\n\r\n\r\n## To Reproduce\r\n\r\n```python \r\nimport torch\r\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\r\na = torch.ones(25, 300)\r\nb = torch.ones(22, 300)\r\nb_a = pad_sequence([b, a])\r\npack_padded_sequence(b_a, [22, 25])\r\n>>> 31906 abort (core dumped)  ipython\r\na_b = pad_sequence([a, b])\r\npack_padded_sequence(a_b, [25, 22]) # it works!\r\n```\r\n\r\n## ",
        "Sample Code": "\n\nAfter https://github.com/pytorch/pytorch/pull/80760 added MPS version of multinomial op, operations with replacement fails for arrays of more than 32K elements with non-recoverable error:\r\n```\r\n % python -c \"import torch;print(torch.multinomial(torch.ones(1, 32768, device='mps'), 2, replacement=True))\"\r\n/AppleInternal/Library/BuildRoots/4883e71d-37bd-11ed-b0ef-b25c5e9b9057/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:724: failed assertion `[MPSNDArray initWithDevice:descriptor:] Error: total bytes of NDArray > 2**32'\r\nzsh: abort      python -c \r\n```\n\n### ",
        "API Signature": "\n torch. multinomial ( input ,  num_samples ,  replacement ,  * ,  generator ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/86162",
        "Issue title": "torch.nn.functional.one_hot only works for int64",
        "Bug description": "\r\n\r\nInstead of raising an exception, the function `torch.nn.utils.rnn.pack_padded_sequence` forces python environment to shut down due to a segmentation fault if the input is not in decreasing order.\r\n\r\n\r\n## To Reproduce\r\n\r\n```python \r\nimport torch\r\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\r\na = torch.ones(25, 300)\r\nb = torch.ones(22, 300)\r\nb_a = pad_sequence([b, a])\r\npack_padded_sequence(b_a, [22, 25])\r\n>>> 31906 abort (core dumped)  ipython\r\na_b = pad_sequence([a, b])\r\npack_padded_sequence(a_b, [25, 22]) # it works!\r\n```\r\n\r\n## ",
        "Sample Code": "\n\nTried applying torch.nn.functional.one_hot to an int32 and int16 tensor, got \"[RuntimeError: one_hot is only applicable to index tensor.](https://github.com/pytorch/pytorch/blob/8d1ff9fc5dc70bdc65a83748c01cddf187728452/aten/src/ATen/native/Onehot.cpp#L6)\"\r\n\r\nIt seems that it only works with int64 tensors. Is this behaviour expected? If so, why?\r\n\r\nThanks!\n\n### ",
        "API Signature": "\n torch.nn.functional. one_hot ( tensor ,  num_classes )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/86074",
        "Issue title": "torch.remainder and torch.fmod produce wrong results",
        "Bug description": "\n\nFor some inputs, torch.remainder and torch.fmod produce wrong results, especially for integer datatype. When converting the int32 input to float32, they can produce correct results.\r\n\r\nI suspect this might be caused by type promotion.\r\n\r\nReproduce ",
        "Sample Code": "\n\nFor some inputs, torch.remainder and torch.fmod produce wrong results, especially for integer datatype. When converting the int32 input to float32, they can produce correct results.\r\n\r\nI suspect this might be caused by type promotion.\r\n\r\nReproduce code:\r\n```\r\nimport torch\r\nimport numpy as np\r\n\r\ninput = torch.tensor(1693446850, dtype=torch.int32)\r\nother = torch.tensor([7285], dtype=torch.int16)\r\n\r\n# test the apis with int input (wrong results)\r\nr = torch.remainder(input, other)\r\nprint(r)\r\nr = torch.fmod(input, other)\r\nprint(r)\r\nr = np.fmod(input.numpy(), other.numpy())\r\nprint(r)\r\n\r\ninput = input.to(torch.float32)\r\n\r\n# test the apis with float input (correct results)\r\nr = torch.remainder(input, other)\r\nprint(r)\r\nr = torch.fmod(input, other)\r\nprint(r)\r\nr = np.fmod(input.numpy(), other.numpy())\r\nprint(r)\r\n```\r\nOutput:\r\n```\r\ntensor([3895], dtype=torch.int16)\r\ntensor([-3390], dtype=torch.int16)\r\n[4890]\r\ntensor([4952.])\r\ntensor([4952.])\r\n[4952.]\r\n```\n\n### ",
        "API Signature": "\n torch. remainder ( input ,  other ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/85852",
        "Issue title": "`torch.mm` produces wrong result on cpu when using in-place computation",
        "Bug description": "\r\n\r\nIf I use `out` to specify the output tensor to be the same as the input tensor, `torch.mm` gives wrong result on cpu. Using`torch.mm`  on cpu w/o `out` or on cuda gives the same correct result.\r\n\r\nHere is the minimized ",
        "Sample Code": "\r\n\r\nIf I use `out` to specify the output tensor to be the same as the input tensor, `torch.mm` gives wrong result on cpu. Using`torch.mm`  on cpu w/o `out` or on cuda gives the same correct result.\r\n\r\nHere is the minimized code to reproduce the bug:\r\n```\r\nimport torch\r\ntorch.manual_seed(420)\r\ntorch.cuda.manual_seed_all(420)\r\nA = torch.rand(50, 50)\r\nB = torch.clone(A).cuda()\r\nC = torch.clone(A)\r\ntorch.mm(C, C, out=C)\r\nprint(\"cpu in place:\", C)  # CPU (in place) gives wrong results\r\nD = torch.mm(A, A)\r\nprint(\"cpu:\", D)\r\nprint(torch.allclose(C, D)) # False\r\n\r\ntorch.mm(B, B, out=B)\r\nprint(\"GPU in place:\", B)  # GPU gives right answer\r\nprint(torch.allclose(B.cpu(), D)) # True\r\n\r\n\r\n```\r\noutputs:\r\n```\r\ncpu in place: tensor([[1.2465e+01, 1.1267e+01, 1.2204e+01,  ..., 8.7870e+02, 1.0072e+04,\r\n         1.0345e+04],\r\n        [1.2971e+01, 1.1560e+01, 1.1516e+01,  ..., 8.3331e+02, 9.5578e+03,\r\n         9.8192e+03],\r\n        [1.3755e+01, 1.3913e+01, 1.3279e+01,  ..., 9.6774e+02, 1.1126e+04,\r\n         1.1423e+04],\r\n        ...,\r\n        [1.2447e+01, 1.1978e+01, 1.1767e+01,  ..., 8.3779e+02, 9.6226e+03,\r\n         9.8825e+03],\r\n        [1.2835e+01, 1.0712e+01, 1.0594e+01,  ..., 7.8456e+02, 8.9946e+03,\r\n         9.2391e+03],\r\n        [1.1591e+01, 9.3684e+00, 1.0208e+01,  ..., 7.8547e+02, 9.0087e+03,\r\n         9.2529e+03]])\r\ncpu: tensor([[12.4649, 11.2666, 12.2036,  ..., 10.9338, 12.4515, 11.9901],\r\n        [12.9706, 11.5600, 11.5161,  ..., 10.0883, 11.9705, 11.6685],\r\n        [13.7549, 13.9132, 13.2790,  ..., 11.9514, 16.0034, 13.1333],\r\n        ...,\r\n        [12.4474, 11.9785, 11.7670,  ...,  9.8250, 13.5130, 10.8965],\r\n        [12.8352, 10.7118, 10.5938,  ...,  9.0758, 12.7024, 10.3281],\r\n        [11.5908,  9.3684, 10.2079,  ...,  9.5821, 11.1185,  9.8437]])\r\nFalse\r\nGPU in place: tensor([[12.4649, 11.2666, 12.2036,  ..., 10.9338, 12.4515, 11.9901],\r\n        [12.9706, 11.5600, 11.5161,  ..., 10.0883, 11.9705, 11.6685],\r\n        [13.7549, 13.9132, 13.2790,  ..., 11.9514, 16.0034, 13.1333],\r\n        ...,\r\n        [12.4474, 11.9785, 11.7670,  ...,  9.8250, 13.5130, 10.8965],\r\n        [12.8352, 10.7118, 10.5938,  ...,  9.0758, 12.7024, 10.3281],\r\n        [11.5908,  9.3684, 10.2079,  ...,  9.5821, 11.1185,  9.8437]],\r\n       device='cuda:0')\r\nTrue\r\n```\r\n\r\n### ",
        "API Signature": "\n torch. mm ( input ,  mat2 ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/85217",
        "Issue title": "Segmentation fault in native_batch_norm",
        "Bug description": "\n\nSegmentation fault in `native_batch_norm`.\r\n\r\n### ",
        "Sample Code": "\n\nSegmentation fault in `native_batch_norm`.\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\ninput = torch.full((5, 5,), 1, dtype=torch.float64, requires_grad=False)\r\nweight = torch.full((14, 9, 12, 0, 6, 0, 15, 0, 0, 0,), -1.5e+300, dtype=torch.float64, requires_grad=False)\r\nbias = torch.full((5,), 1, dtype=torch.float64, requires_grad=False)\r\nrunning_mean = torch.full((0,), 1, dtype=torch.float64, requires_grad=False)\r\nrunning_var = torch.full((0,), 1, dtype=torch.float64, requires_grad=False)\r\ntraining = True\r\nmomentum = 0\r\neps = 0\r\ntorch.native_batch_norm(input, weight, bias, running_mean, running_var, training, momentum, eps)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using fuzz testing.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/85216",
        "Issue title": "Segmentation fault in _mkldnn_transpose",
        "Bug description": "\n\nSegmentation fault in `_mkldnn_transpose`.\r\n\r\n### ",
        "Sample Code": "\n\nSegmentation fault in `_mkldnn_transpose`.\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\nself = torch.full((3, 4, 5,), 1, dtype=torch.float32, requires_grad=False).to_mkldnn()\r\ndim0 = 1250999896764\r\ndim1 = 0\r\ntorch._mkldnn_transpose(self, dim0, dim1)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using fuzz testing.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/85214",
        "Issue title": "Segmentation fault in mkldnn_reorder_conv2d_weight and mkldnn_reorder_conv3d_weight",
        "Bug description": "\n\nSegmentation fault in `mkldnn_reorder_conv2d_weight` and  `mkldnn_reorder_conv3d_weight`.\r\n\r\n### ",
        "Sample Code": "\n\nSegmentation fault in `mkldnn_reorder_conv2d_weight` and  `mkldnn_reorder_conv3d_weight`.\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\nself = torch.full((3, 3, 1, 1,), 1, dtype=torch.float32, requires_grad=False).to_mkldnn()\r\npadding = []\r\nstride = [65534, 65534]\r\ndilation = [65534, 65534]\r\ngroups = 0\r\ntorch._C._nn.mkldnn_reorder_conv2d_weight(self, padding, stride, dilation, groups)\r\n\r\n\r\nimport torch\r\n\r\nself = torch.full((32, 3, 3, 3, 3,), 1, dtype=torch.float32, requires_grad=False).to_mkldnn()\r\npadding = []\r\nstride = [1250999896764, 1250999896764, 1250999896764]\r\ndilation = [1250999896764, 1250999896764, 1250999896764]\r\ngroups = 0\r\ntorch._C._nn.mkldnn_reorder_conv3d_weight(self, padding, stride, dilation, groups)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using fuzz testing.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/85213",
        "Issue title": "Segmentation fault in embedding_bag",
        "Bug description": "\n\nSegmentation fault in `embedding_bag`, `_embedding_bag` and `_embedding_bag_forward_only`.\r\n\r\n### ",
        "Sample Code": "\n\nSegmentation fault in `embedding_bag`, `_embedding_bag` and `_embedding_bag_forward_only`.\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\ntensor_0 = torch.full((8, 8, 0, 0, 0,), 1.5e+300, dtype=torch.float64, requires_grad=False)\r\ntensor_1 = torch.full((8, 8, 0, 0, 0,), 1, dtype=torch.int64, requires_grad=False)\r\ntensor_2 = torch.full((8, 8, 0, 0, 0, 14, 13, 0, 0, 6,), 1, dtype=torch.int64, requires_grad=False)\r\nbool_3 = True\r\nint_4 = 0\r\nbool_5 = True\r\ntensor_6 = torch.full((4,), 1, dtype=torch.int64, requires_grad=False)\r\nbool_7 = True\r\nint_8 = 0\r\ntorch.embedding_bag(tensor_0, tensor_1, tensor_2, bool_3, int_4, bool_5, tensor_6, bool_7)\r\n\r\nimport torch\r\n\r\nweight = torch.full((2, 0, 0, 6, 6,), 0, dtype=torch.float64, requires_grad=False)\r\nindices = torch.full((2, 0, 0, 6, 6,), 2, dtype=torch.int64, requires_grad=False)\r\noffsets = torch.full((2, 0, 0, 6, 6, 8, 6, 8, 0, 6, 0, 11, 0, 0, 0,), 65534, dtype=torch.int64, requires_grad=False)\r\nscale_grad_by_freq = True\r\nmode = 0\r\nsparse = True\r\nper_sample_weights = torch.full((1, 1, 1, 1, 1, 1, 1, 1, 1, 1,), 3.5e+35, dtype=torch.float64, requires_grad=False)\r\ninclude_last_offset = True\r\npadding_idx = 0\r\ntorch._embedding_bag(weight, indices, offsets, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset, padding_idx)\r\n\r\n\r\nimport torch\r\n\r\nweight = torch.full((2, 0, 0, 6, 6,), 0, dtype=torch.float64, requires_grad=False)\r\nindices = torch.full((2, 0, 0, 6, 6,), 2, dtype=torch.int64, requires_grad=False)\r\noffsets = torch.full((2, 0, 0, 6, 6, 8, 6, 8, 0, 6, 0, 11, 0, 0, 0,), 65534, dtype=torch.int64, requires_grad=False)\r\nscale_grad_by_freq = True\r\nmode = 0\r\nsparse = True\r\nper_sample_weights = torch.full((1, 1, 1, 1, 1, 1, 1, 1, 1, 1,), 3.5e+35, dtype=torch.float64, requires_grad=False)\r\ninclude_last_offset = True\r\npadding_idx = 0\r\ntorch._embedding_bag_forward_only(weight, indices, offsets, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset, padding_idx)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using fuzz testing.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/85072",
        "Issue title": "Segmentation fault in `torch.jit.wait`",
        "Bug description": "\n\nPassing `None` to `torch.jit.wait` can cause a Segmentation fault.\r\n\r\n## ",
        "Sample Code": "\n\nPassing `None` to `torch.jit.wait` can cause a Segmentation fault.\r\n\r\n## code\r\n\r\n```python\r\nimport torch\r\n\r\ntorch.jit.wait(None)\r\n```\r\n## output\r\n```bash\r\nSegmentation fault (core dumped)\r\n```\n\n### ",
        "API Signature": "\n torch.jit. wait ( future ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/84990",
        "Issue title": "Segmentation fault in `torch.futures.collect_all`",
        "Bug description": "\r\n\r\nIn `torch.futures.collect_all` when `futures` got invalid input, it causes a Segmentation fault.\r\n\r\n## ",
        "Sample Code": "\r\n\r\nIn `torch.futures.collect_all` when `futures` got invalid input, it causes a Segmentation fault.\r\n\r\n## code\r\n\r\n```python\r\nimport torch\r\n\r\ninput = (None,)\r\n\r\ntorch.futures.collect_all(futures=input)\r\n```\r\n\r\n## output\r\n```bash\r\nSegmentation fault (core dumped)\r\n```\r\n\r\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/84979",
        "Issue title": "torch.nn.functional.pad generates incomplete ONNX without explicit padding value",
        "Bug description": "\r\n\r\nIn `torch.futures.collect_all` when `futures` got invalid input, it causes a Segmentation fault.\r\n\r\n## ",
        "Sample Code": "\r\n\r\nWhen I tried to export pytorch model which includes torch.nn.functional.pad to ONNX, it works without any problem.\r\nConverted model works correctly and output is same with original pytorch model. \r\nThe model without explicit padding value and the model with padding value 0 is shown below, respectively. \r\n![padding_problem](https://user-images.githubusercontent.com/34959032/190045012-e33d447f-f633-449a-a19c-9870de309098.png)\r\nThe official document (https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html) say torch.nn.functional.pad has default padding value of 0. However, the default padding value does not included in ONNX. \r\nThis incomplete ONNX can occur problems when the model is converted to other formats like OpenVINO, TFlite, etc.\r\n\r\n```python\r\nimport torch\r\nimport onnx\r\nfrom onnxsim import simplify\r\n\r\nclass simple_padding(nn.Module):\r\n\r\n    def __init__(self):\r\n        super().__init__()\r\n\r\n    def forward(self, x):\r\n\r\n        pad_shape = [1, 1, 1, 1]\r\n   \r\n        # return torch.nn.functional.pad(x, pad_shape)\r\n        return torch.nn.functional.pad(x, pad_shape, value=0)\r\n\r\ndef padding_export_check():\r\n\r\n    onnx_save_path = \"padding.onnx\"\r\n    simplified_save_path = \"opt_paddingonnx\"\r\n\r\n    model = simple_padding()\r\n\r\n    dummy_input = torch.rand(3, 224, 224, device='cpu')\r\n\r\n    torch.onnx.export(model,\r\n                      args=(dummy_input),\r\n                      f=onnx_save_path,\r\n                      input_names=[\"input\"],\r\n                      opset_version=11)\r\n\r\n    # onnx simplify\r\n    saved_onnx = onnx.load(onnx_save_path)\r\n    onnx_simplified, check = simplify(saved_onnx)\r\n    assert check, \"Simplified ONNX model could not be validated\"\r\n    onnx.save(onnx.shape_inference.infer_shapes(onnx_simplified), simplified_save_path)\r\n```\r\n\r\n\r\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/83585",
        "Issue title": "Segfault when profiling with_stack=True on model with jit.optimize_for_inference",
        "Bug description": "\r\n\r\nIn `torch.futures.collect_all` when `futures` got invalid input, it causes a Segmentation fault.\r\n\r\n## ",
        "Sample Code": "\n\nThe Python process segfaults whenever I run the pytorch profiler using with_stack=True on a model that has had torch.jit.optimize_for_inference() called on it. \r\n\r\n```python\r\nimport torch\r\nimport torchvision.models as models\r\nfrom torch.profiler import profile, record_function, ProfilerActivity\r\nmodel = models.resnet18().cuda()\r\ninputs = torch.randn(5, 3, 224, 224).cuda()\r\nmodel = torch.jit.script(model)\r\nmodel = torch.jit.optimize_for_inference(model)\r\n\r\nwith profile(activities=[ProfilerActivity.CPU], with_stack=True) as prof:\r\n    model(inputs)\r\n```\r\n\r\n```\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nThe .crash file in /var/crash is 605MB and this should be easy to reproduce, so I haven't attached that, but let me know if there's anything else you need.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/83494",
        "Issue title": "`torch.pinverse` produces wrong output!",
        "Bug description": "\r\n\r\nIn `torch.futures.collect_all` when `futures` got invalid input, it causes a Segmentation fault.\r\n\r\n## ",
        "Sample Code": "\n\n`torch.pinverse` produces wrong output for a 3*3 tensor! \r\nAccording to the [documentation](https://pytorch.org/docs/stable/generated/torch.pinverse.html), `torch.pinverse` is an alias for [`torch.linalg.pinv()`](https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv), and computes the pseudoinverse (Moore-Penrose inverse) of a matrix. Algebraically, the output of `torch.pinverse(A)`, denoted as `Apinv`, should satisfy:\r\n`A  Apinv A = A`\r\nHowever, for this input `A`, `torch.pinverse(A)` fails to generate correct result:\r\n```\r\nimport torch\r\nA  = torch.tensor([[0.0, 1.0, -1.0], [1.0, -1.0, 0.0], [-1.0, 1.0, 0.0]])\r\nApinv = torch.pinverse(A)\r\nprint(A @ Apinv @ A)\r\nprint(torch.dist(A @ Apinv @ A, A))\r\n```\r\nOutputs:\r\n```\r\ntensor([[ 0.0000e+00,  1.0000e+00, -1.0000e+00],\r\n        [ 0.0000e+00, -2.9802e-08,  2.9802e-08],\r\n        [ 0.0000e+00,  2.9802e-08, -2.9802e-08]])\r\ntensor(2.)\r\n```\r\nOn the other hand, `torch.linalg.pinv` and `numpy.linalg.pinv` can generate correct pseudo inverse given the same input matrix `A`.\r\n```\r\nimport torch\r\nA  = torch.tensor([[0.0, 1.0, -1.0], [1.0, -1.0, 0.0], [-1.0, 1.0, 0.0]])\r\nApinv2 = torch.linalg.pinv(A)\r\nprint(A @ Apinv2 @ A)\r\nprint(torch.dist(A @ Apinv2 @ A, A))\r\n\r\n\r\nimport numpy as np\r\nApinv_np = np.linalg.pinv(A)\r\nprint(A @ Apinv_np @ A)\r\nprint(torch.dist(A @ Apinv_np @ A, A))\r\n```\r\nOutputs\r\n```\r\ntensor([[-1.4901e-07,  1.0000e+00, -1.0000e+00],\r\n        [ 1.0000e+00, -1.0000e+00,  2.9802e-08],\r\n        [-1.0000e+00,  1.0000e+00, -2.9802e-08]])\r\ntensor(5.5516e-07)\r\ntensor([[ 8.9407e-08,  1.0000e+00, -1.0000e+00],\r\n        [ 1.0000e+00, -1.0000e+00, -2.9802e-08],\r\n        [-1.0000e+00,  1.0000e+00,  2.9802e-08]])\r\ntensor(2.8430e-07)\r\n```\n\n### ",
        "API Signature": "\n torch. pinverse ( input ,  rcond )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/83328",
        "Issue title": "torch.nn.Conv2d will segfault when the type of input tensor is float16",
        "Bug description": "\n\n```\r\nresults = dict()\r\nimport torch\r\narg_class = torch.nn.Conv2d(512,2048,1)\r\narg_1 = torch.rand([128, 512, 16, 16], dtype=torch.float16)\r\nresults[\"time_low\"] = arg_class(arg_1)\r\n```\r\nThe above ",
        "Sample Code": "\n\n```\r\nresults = dict()\r\nimport torch\r\narg_class = torch.nn.Conv2d(512,2048,1)\r\narg_1 = torch.rand([128, 512, 16, 16], dtype=torch.float16)\r\nresults[\"time_low\"] = arg_class(arg_1)\r\n```\r\nThe above code hangs, I have to kill the program. I think it's expected that if dtype is float16, it will output 'float16 is not supported'.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/83229",
        "Issue title": "torch.nn.MaxUnpool2d get negative size tensor",
        "Bug description": "\n\n```\r\nresults = dict()\r\nimport torch\r\narg_class = torch.nn.Conv2d(512,2048,1)\r\narg_1 = torch.rand([128, 512, 16, 16], dtype=torch.float16)\r\nresults[\"time_low\"] = arg_class(arg_1)\r\n```\r\nThe above ",
        "Sample Code": "\n\nWhen the kernel_size is negative, torch.nn.MaxUnpool2d will output negative size tensor.\r\nIn torch.nn.MaxUnpool3d, if the kernel_size is <=0, the program will die, ctrl+c cannot quit and have to force to kill the program.\r\n```\r\nimport torch\r\nresults={}\r\narg_1 = -100\r\narg_2 = False\r\narg_class = torch.nn.MaxUnpool2d(arg_1,stride=arg_2,)\r\narg_3_0 = torch.rand([1, 1, 2, 2], dtype=torch.float32)\r\narg_3_1 = torch.randint(-1,64,[1, 1, 2, 2], dtype=torch.int64)\r\narg_3 = [arg_3_0,arg_3_1,]\r\nresults['res'] = arg_class(*arg_3)\r\nprint(results['res'].shape)\r\n#torch.Size([1, 1, -100, -100])\r\n```\r\n\r\n```\r\nimport torch\r\npool = torch.nn.MaxPool3d(3, stride=2, return_indices=True)\r\nunpool = torch.nn.MaxUnpool3d(-3, stride=2)\r\noutput, indices = pool(torch.randn(20, 16, 51, 33, 15))\r\nunpooled_output = unpool(output, indices)\r\nprint(unpooled_output.size())\r\n#program die\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/83221",
        "Issue title": "torch.nn.InstanceNorm{1|2|3}d doesn't verify the value type of parameter num_features",
        "Bug description": "\r\n\r\nParameter 'num_features' is the number of features or channels C of the input. However, I found that num_features can be set to negative integral / string / list and other type value. torch.nn.InstanceNorm1d doesn't verify whether the value of num_features and input channels are equal. \r\n```\r\nimport torch\r\nresults={}\r\narg_1 = 'max'\r\narg_2 = False\r\narg_class = torch.nn.InstanceNorm1d(arg_1,affine=arg_2,)\r\narg_3 = torch.rand([20, 100, 40], dtype=torch.float32)\r\nresults['res'] = arg_class(arg_3)\r\n```\r\nAbove ",
        "Sample Code": "\r\n\r\nParameter 'num_features' is the number of features or channels C of the input. However, I found that num_features can be set to negative integral / string / list and other type value. torch.nn.InstanceNorm1d doesn't verify whether the value of num_features and input channels are equal. \r\n```\r\nimport torch\r\nresults={}\r\narg_1 = 'max'\r\narg_2 = False\r\narg_class = torch.nn.InstanceNorm1d(arg_1,affine=arg_2,)\r\narg_3 = torch.rand([20, 100, 40], dtype=torch.float32)\r\nresults['res'] = arg_class(arg_3)\r\n```\r\nAbove code works.\r\n\r\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/83175",
        "Issue title": "torch.nn.GRU runs long time, when num_layers is large",
        "Bug description": "\r\n\r\nParameter 'num_features' is the number of features or channels C of the input. However, I found that num_features can be set to negative integral / string / list and other type value. torch.nn.InstanceNorm1d doesn't verify whether the value of num_features and input channels are equal. \r\n```\r\nimport torch\r\nresults={}\r\narg_1 = 'max'\r\narg_2 = False\r\narg_class = torch.nn.InstanceNorm1d(arg_1,affine=arg_2,)\r\narg_3 = torch.rand([20, 100, 40], dtype=torch.float32)\r\nresults['res'] = arg_class(arg_3)\r\n```\r\nAbove ",
        "Sample Code": "\n\nWhen num_layers is 100000, torch.nn.GRU runs more than 5 minutes. Program hangs and doesn't return result.\r\n```\r\nimport torch\r\nresults={}\r\narg_1 = 10\r\narg_2 = 20\r\narg_3 = 100000\r\narg_class = torch.nn.GRU(arg_1,arg_2,arg_3,)\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/83152",
        "Issue title": "When padding is big int, torch.nn.functional.fold runs too long and can't return result",
        "Bug description": "\n\nWhen I run the ",
        "Sample Code": "\n\nWhen I run the code, there is no error information reports. After 5 mins running, there is no response and I can't stop the cmd, I have to kill the cmd.\r\n\r\n```\r\nimport torch\r\nresults={}\r\narg_1_tensor = torch.rand([1, 12, 12], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = [4,5,]\r\narg_3 = [2,2,]\r\narg_4 = 1\r\narg_5 = 36028797018963968\r\narg_6 = 1\r\nresults['res'] = torch.nn.functional.fold(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,)\r\n```\n\n### ",
        "API Signature": "\n torch.nn.functional. fold ( input ,  output_size ,  kernel_size ,  dilation ,  padding ,  stride ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/82635",
        "Issue title": "[Torchscript] torch.min returns wrong gradient when inputs are equal",
        "Bug description": "\n\nThe same issue applies to torch.max()\r\n\r\nSteps ",
        "Sample Code": "\n\nThe same issue applies to torch.max()\r\n\r\nSteps To Reproduce: \r\n```py\r\nimport torch\r\n\r\n# input\r\nx = torch.ones([10]).requires_grad_()\r\ny = torch.ones([10]).requires_grad_()\r\ngrad_output = torch.ones_like(x)\r\n\r\ndef minimum(x, y):\r\n    return torch.minimum(x, y) * x\r\n\r\ndef min(x, y):\r\n    return torch.min(x, y) * x\r\n\r\ndef test(func, func_script):\r\n    # we need a few iterations to trigger the fused kernel\r\n    for i in range(5):\r\n        # forward\r\n        result = func(x, y)\r\n        result_script = func_script(x, y)\r\n        # derivative\r\n        (result_grad,) = torch.autograd.grad(result, x, grad_output, create_graph=True)\r\n        (result_script_grad,) = torch.autograd.grad(result_script, x, grad_output, create_graph=True)\r\n        # check result\r\n        assert torch.allclose(result, result_script), f\"results do not match:\\n a: {result}\\n b: {result_script}\"\r\n        assert torch.allclose(result_grad, result_script_grad), f\"grads do not match:\\n a: {result_grad}\\n b: {result_script_grad}\"\r\n\r\nminimum_script = torch.jit.script(minimum)\r\nmin_script = torch.jit.script(min)\r\n\r\ntest(minimum, minimum_script)\r\nprint(\"minimum pass\")\r\ntest(min, min_script)\r\nprint(\"min pass\")\r\n```\r\n\r\noutput: \r\n```\r\noutput:\r\nminimum pass\r\nTraceback (most recent call last):\r\n  File \"torch_min_torchscript_grad_bug.py\", line 36, in <module>\r\n    test(min, min_script)\r\n  File \"torch_min_torchscript_grad_bug.py\", line 28, in test\r\n    assert torch.allclose(result_grad, result_script_grad), f\"grads do not match:\\n a: {result_grad}\\n b: {result_script_grad}\"\r\nAssertionError: grads do not match:\r\n a: tensor([1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\r\n        1.5000], grad_fn=<AddBackward0>)\r\n b: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<AddBackward0>)\r\n```\n\n### ",
        "API Signature": "\n torch. min ( input )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/82282",
        "Issue title": "`torch.matrix_exp` doesn't handle NaN properly",
        "Bug description": "\n\nThe same issue applies to torch.max()\r\n\r\nSteps ",
        "Sample Code": "\n\nWhen calling `torch.matrix_exp`  on a value containing `nan` values, the result is strange and different on CPU and on CUDA with the same input.\r\n\r\nBased on similar discussion in https://github.com/pytorch/pytorch/issues/61251 , I think `torch.matrix_exp` should also check input for `nan`.\r\n\r\n```\r\nimport torch\r\ntorch.random.manual_seed(420)\r\ninput = torch.randn(3, 3, dtype=torch.float32)\r\nprint(\"Intermediate: \", torch.log(input * 2 - 1)) # Contains nan\r\noutput = torch.matrix_exp(torch.log(input * 2 - 1))\r\nprint(\"cpu output: \", output)\r\ninput = input.cuda()\r\noutput = torch.matrix_exp(torch.log(input * 2 - 1))\r\nprint(\"gpu output: \", output) \r\n```\r\n\r\nOutputs:\r\n```\r\nIntermediate:  tensor([[    nan, -1.2915,     nan],\r\n        [    nan,  0.7102,     nan],\r\n        [-0.3755,     nan,     nan]])\r\ncpu output:  tensor([[ 7.2619e+11,  0.0000e+00, -8.4379e-01],\r\n        [-1.8280e+00,  2.0343e+00, -9.0547e-01],\r\n        [ 6.8693e-01, -1.4521e+00, -9.3093e-01]])\r\ngpu output:  tensor([[-4.3953,  0.2749, -0.8438],\r\n        [-1.8280,  2.0343, -0.9055],\r\n        [ 0.6869, -1.4521, -0.9309]], device='cuda:0')\r\n```\n\n### ",
        "API Signature": "\n torch. matrix_exp ( A )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/81409",
        "Issue title": "Segmentation fault is raised when torch._C._nn.adaptive_avg_pool2d is called with some parameters",
        "Bug description": "\r\n\r\nThe segmentation fault appears when `torch._C._nn.adaptive_avg_pool2d` is called for some combinations of input and output shapes.\r\n\r\n#### ",
        "Sample Code": "\r\n\r\nHere is the python script named `test.py`.\r\n\r\n``` python:test.py\r\nfrom __future__ import annotations\r\nimport sys\r\nimport torch\r\n\r\nif __name__ == '__main__':\r\n    assert len(sys.argv) == 5\r\n    Ih, Iw, Oh, Ow = map(int, sys.argv[1:])\r\n    _input_size = (Ih, Iw)\r\n    _output_size = (Oh, Ow)\r\n\r\n    torch.manual_seed(0)  # it seems seed value is irrelevant as far as I checked\r\n    imgs = torch.randint(low=0, high=256, size=(1,)+_input_size).type(torch.float32)\r\n    imgs_ = torch._C._nn.adaptive_avg_pool2d(imgs, _output_size)\r\n```\r\n\r\n",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/81195",
        "Issue title": "torch._weight_norm with specified dim returns wrong output",
        "Bug description": "\r\n`torch._weight_norm` outputs wrong result from torch 1.12\r\n\r\nThough `torch._weight_norm` is an undocumented API, I report this issue since the API is made public.\r\n\r\n#### ",
        "Sample Code": "\n\n# Problem\r\n`torch._weight_norm` outputs wrong result from torch 1.12\r\n\r\nThough `torch._weight_norm` is an undocumented API, I report this issue since the API is made public.\r\n\r\n#### torch 1.11 and before\r\n```python3\r\n$ python3\r\nPython 3.8.10 (default, Mar 15 2022, 12:22:08) \r\n[GCC 9.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n>>> a = torch.Tensor([[1,2],[3,4]])\r\n>>> b = torch.Tensor([[5],[6]])\r\n>>> torch._weight_norm(a,b,dim=1)\r\ntensor([[1.5811, 2.2361],\r\n        [5.6921, 5.3666]])\r\n```\r\n\r\n\r\n#### torch 1.12\r\n```python3\r\n$ python3\r\nPython 3.8.10 (default, Mar 15 2022, 12:22:08) \r\n[GCC 9.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n>>> a = torch.Tensor([[1,2],[3,4]])\r\n>>> b = torch.Tensor([[5],[6]])\r\n>>> torch._weight_norm(a,b,dim=1)\r\ntensor([[1.5811, 2.6833],\r\n        [4.7434, 5.3666]])\r\n```\r\n\r\n#### manual computation\r\n```python3\r\n>>> def weight_norm_dim1(a, b):\r\n...     norm = a.norm(2, [0], True)\r\n...     return a * b / norm\r\n... \r\n>>> weight_norm_dim1(a, b)\r\ntensor([[1.5811, 2.2361],\r\n        [5.6921, 5.3666]])\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/80946",
        "Issue title": "torch.nn.functional.linear fails for multi-dimensional bias from torch 1.12",
        "Bug description": "\r\n`torch._weight_norm` outputs wrong result from torch 1.12\r\n\r\nThough `torch._weight_norm` is an undocumented API, I report this issue since the API is made public.\r\n\r\n#### ",
        "Sample Code": "\r\n\r\n~As [docs](https://pytorch.org/docs/1.12/generated/torch.nn.functional.linear.html?highlight=linear#torch.nn.functional.linear) explains, `torch.nn.functional.linear` supports inputs of~\r\n\r\n```\r\ninput: (*, in_features)\r\nweight: (out_features, in_features)\r\nbias: (*, out_features)\r\n```\r\n\r\n(UPD  9 July 2022: This is a never-documented behaviour  https://github.com/pytorch/pytorch/issues/80946#issuecomment-1178272323)\r\n\r\n, but torch 1.12 seems to raise error for multi-dimensional inputs.\r\n\r\n```python\r\n>>> import torch.nn.functional as F\r\n>>> import torch\r\n>>> F.linear(torch.randn(2,3,5),torch.randn(7,5),torch.randn(2,3,7))\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nRuntimeError: expand(torch.FloatTensor{[2, 3, 7]}, size=[6, 7]): the number of sizes provided (2) must be greater or equal to the number of dimensions in the tensor (3)\r\n```\r\n\r\nWith torch 1.11,\r\n```python\r\n>>> import torch.nn.functional as F\r\n>>> import torch\r\n>>> F.linear(torch.randn(2,3,5),torch.randn(7,5),torch.randn(2,3,7))\r\ntensor([[[ 1.5270e+00, -1.6008e+00,  1.0397e+00, -1.7440e-01, -1.2764e+00,\r\n           1.1950e-01, -1.8383e+00],\r\n         [-3.3737e+00,  1.9518e+00,  8.4368e-01, -5.5560e+00,  6.5014e-01,\r\n          -8.5247e-01, -3.3299e+00],\r\n         [ 5.3961e-01,  1.1424e+00,  9.3576e-01,  3.1827e-01, -6.9256e-01,\r\n           1.6097e+00,  7.8738e-01]],\r\n\r\n        [[-6.2245e-01, -2.4926e+00, -1.8944e+00, -1.0425e+00,  2.6903e+00,\r\n          -5.9798e+00, -4.5269e-03],\r\n         [-6.0497e-01, -2.6881e+00, -1.4605e+00, -1.7330e+00,  1.9412e-01,\r\n          -3.6541e+00, -1.1137e+00],\r\n         [ 2.1674e+00, -5.5175e+00, -4.5325e+00,  5.0340e+00,  5.5341e-01,\r\n          -4.4188e+00,  5.1751e-01]]])\r\n```\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. linear ( input ,  weight ,  bias )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/80805",
        "Issue title": "torch.einsum results in segfault",
        "Bug description": "\r\n`torch._weight_norm` outputs wrong result from torch 1.12\r\n\r\nThough `torch._weight_norm` is an undocumented API, I report this issue since the API is made public.\r\n\r\n#### ",
        "Sample Code": "\n\nI experience a segfault when running a simple script like:\r\n```python\r\nimport torch\r\n\r\nAs = torch.randn(3, 2, 5)\r\nBs = torch.randn(3, 5, 4)\r\n\r\ntorch.einsum(\"bij,bjk->bik\", As, Bs)\r\n```\r\nRunning this results in:\r\n```console\r\n$ python test.py \r\nSegmentation fault: 11\r\n```\r\nEven if I add `-X faulthandler` I don't seem to get any kind of stacktrace to help locate the issue. If someone can give me instructions for how to use gdb I can try to get a backtrace.\n\n### ",
        "API Signature": "\n torch. einsum ( equation ,  * )   \u2192 [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/80804",
        "Issue title": "`torch.renorm` gives wrong gradient for 0-valued input when `p` is even and `maxnorm=0`.",
        "Bug description": "\r\n`torch._weight_norm` outputs wrong result from torch 1.12\r\n\r\nThough `torch._weight_norm` is an undocumented API, I report this issue since the API is made public.\r\n\r\n#### ",
        "Sample Code": "\n\n`torch.renorm` gives wrong gradient for 0-valued input when `p` is even and `maxnorm=0`.\r\n\r\n```py\r\nimport torch\r\n\r\ndef fn(input):\r\n    p = 2\r\n    dim = -1\r\n    maxnorm = 0\r\n    fn_res = torch.renorm(input, p, dim, maxnorm, )\r\n    return fn_res\r\ninput = torch.tensor([[0.1, 0.], [0., 0.]], dtype=torch.float64, requires_grad=True)\r\n\r\ntorch.autograd.gradcheck(fn, (input))\r\n```\r\n\r\n```\r\nGradcheckError: Jacobian mismatch for output 0 with respect to input 0,\r\nnumerical:tensor([[0., 0., 0., 0.],\r\n        [0., 0., 0., 0.],\r\n        [0., 0., 0., 0.],\r\n        [0., 0., 0., 0.]], dtype=torch.float64)\r\nanalytical:tensor([[1., 0., 0., 0.],\r\n        [0., 1., 0., 0.],\r\n        [0., 0., 1., 0.],\r\n        [0., 0., 0., 1.]], dtype=torch.float64)\r\n```\r\n\r\nBecause `p=2` and `maxnorm=0`, this function should be `f(x) = 0` for every element. Therefore, it should return 0 as the gradient.\n\n### ",
        "API Signature": "\n torch. renorm ( input ,  p ,  dim ,  maxnorm ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/80588",
        "Issue title": "Semi-reproducible random torch.baddbmm NaNs",
        "Bug description": "\r\n\r\nThe following ",
        "Sample Code": "\r\n\r\nThe following code snippet appears to cause `torch.baddbmm` to randomly generate NaNs when run *on CPU*\r\n\r\n```\r\nfor i in range(10000):\r\n    out = torch.baddbmm(\r\n        torch.zeros([1, 1, 1], dtype=torch.float32),\r\n        torch.FloatTensor([[[1]]]),\r\n        torch.FloatTensor([[[1]]]),\r\n        beta=0,\r\n    )\r\n    assert not torch.isnan(out).any(), i\r\n# AssertionError: 9886\r\n# (or some other number)\r\n```\r\n\r\nDespite running the same calculation each time, it often fails not on the first try, but many tries in.\r\n\r\n(Sometimes I need to run the loop several times before it actually encounters a NaN, which seems odd to me.)\r\n\r\nI've tried this on two different hardware setups and encountered the same issue.\r\n\r\nHope I'm not just doing something silly!\r\n\r\n### ",
        "API Signature": "\n torch. baddbmm ( input ,  batch1 ,  batch2 ,  * ,  beta ,  alpha ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/80488",
        "Issue title": "Negative values still produced by torch.nn.functional.kl_div",
        "Bug description": "\n\n## \ud83d\udc1b Bug\r\nDespite a fix in https://github.com/pytorch/pytorch/issues/32520, kl_div in torch.nn.functional still outputs negative values. \r\n## ",
        "Sample Code": "\n\n## \ud83d\udc1b Bug\r\nDespite a fix in https://github.com/pytorch/pytorch/issues/32520, kl_div in torch.nn.functional still outputs negative values. \r\n## To Reproduce\r\nSay we have outputs with the same values:\r\n```python\r\na = torch.tensor([[1,2,3], [5.0, 5.0, 5.0]])\r\nb = torch.tensor([[1,2,3], [5.0, 5.0, 5.0]])\r\ntorch.nn.functional.kl_div(torch.nn.functional.log_softmax(a, 1), torch.nn.functional.softmax(b, 1), reduction=\"none\")\r\ntensor([[ 0.0000e+00,  0.0000e+00, -1.9826e-08],\r\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])\r\n```\r\nOr, say we have outputs with arbitrarily-chosen different values. https://github.com/pytorch/pytorch/issues/32520 attempts to resolve negative outputs by allowing for a target in log-space, however this has no effect here:\r\n```python\r\na = torch.tensor([[1,2,3], [5.0, 5.0, 5.0]])\r\nb = torch.tensor([[8,10,6], [5.0, 5.0, 5.0]])\r\ntorch.nn.functional.kl_div(torch.nn.functional.log_softmax(a, 1), torch.nn.functional.log_softmax(b, 1), reduction=\"none\", log_target=True)\r\ntensor([[ 0.0310,  1.0962, -0.0593],\r\n        [ 0.0000,  0.0000,  0.0000]])\r\n```\r\nor with a log-space target:\r\n```python\r\na = torch.tensor([[1,2,3], [5.0, 5.0, 5.0]])\r\nb = torch.tensor([[8,10,6], [5.0, 5.0, 5.0]])\r\ntorch.nn.functional.kl_div(torch.nn.functional.log_softmax(a, 1), torch.nn.functional.softmax(b, 1), reduction=\"none\")\r\ntensor([[ 0.0310,  1.0962, -0.0593],\r\n        [ 0.0000,  0.0000,  0.0000]])\r\n```\r\n## Expected Behavior\r\nOutputs with values >= 0.\n\n### ",
        "API Signature": "\n torch.nn.functional. kl_div ( input ,  target ,  size_average ,  reduce ,  reduction ,  log_target ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/78153",
        "Issue title": "`pack_sequence` crash",
        "Bug description": "\n\n## \ud83d\udc1b Bug\r\nDespite a fix in https://github.com/pytorch/pytorch/issues/32520, kl_div in torch.nn.functional still outputs negative values. \r\n## ",
        "Sample Code": "\n\n`pack_sequence` crash\r\n\r\n```python\r\nimport torch\r\nsequences_0 = torch.rand([1, 16, 86], dtype=torch.float32)\r\nsequences_1 = torch.rand([1, 85, 0], dtype=torch.float16)\r\nsequences_2 = torch.randint(0, 2, [2, 84, 85], dtype=torch.bool)\r\nsequences_3 = torch.randint(-8, 2, [0, 4, 85], dtype=torch.int8)\r\nsequences = [sequences_0,sequences_1,sequences_2,sequences_3,]\r\nenforce_sorted = 0\r\ntorch.nn.utils.rnn.pack_sequence(sequences, enforce_sorted=enforce_sorted, )\r\n# Segmentation fault (core dumped)\r\n```\n\n### ",
        "API Signature": "\n torch.nn.utils.rnn. pack_sequence ( sequences ,  enforce_sorted ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/78131",
        "Issue title": "Segfault in _pad_packed_sequence",
        "Bug description": "\n\n\r\nFunction `torch._pad_packed_sequence` contains segmentation fault.\r\n\r\n### ",
        "Sample Code": "\n\n\r\nFunction `torch._pad_packed_sequence` contains segmentation fault.\r\n\r\n### Example to reproduce\r\n\r\n```\r\nimport torch\r\n\r\ndata = torch.full([1, 1, 1, 1], -10000, dtype=torch.float16, requires_grad=False)\r\nbatch_sizes = torch.full([0], 978, dtype=torch.int64, requires_grad=False)\r\nbatch_first = True\r\npadding_value = False\r\ntotal_length = torch.full([], -9937, dtype=torch.int64, requires_grad=False)\r\ntorch._pad_packed_sequence(data, batch_sizes, batch_first, padding_value, total_length)\r\n```\r\n\r\n### Result\r\n\r\nSegmentation fault\r\n\r\n### Expected Behavior\r\n\r\nThrowing a Python Exception\r\n\r\n### Notes\r\n\r\nThis bug was discovered using [Atheris](https://github.com/google/atheris).\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/78130",
        "Issue title": "Segfault in _grid_sampler_2d_cpu_fallback",
        "Bug description": "\n\n\r\nFunction `torch._grid_sampler_2d_cpu_fallback` contains segmentation fault.\r\n\r\n### ",
        "Sample Code": "\n\n\r\nFunction `torch._grid_sampler_2d_cpu_fallback` contains segmentation fault.\r\n\r\n### Example to reproduce\r\n\r\n```\r\nimport torch\r\n\r\ninput = torch.full([3, 3, 3, 2], 9490, dtype=torch.float32, requires_grad=False)\r\ngrid = torch.full([0, 3, 8, 2, 4, 1], -9545, dtype=torch.float32, requires_grad=False)\r\ninterpolation_mode = 8330\r\npadding_mode = 5934\r\nalign_corners = False\r\ntorch._grid_sampler_2d_cpu_fallback(input, grid, interpolation_mode, padding_mode, align_corners)\r\n```\r\n\r\n### Result\r\n\r\nSegmentation fault\r\n\r\n### Expected Behavior\r\n\r\nThrowing a Python Exception\r\n\r\n### Notes\r\n\r\nThis bug was discovered using [Atheris](https://github.com/google/atheris).\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/78129",
        "Issue title": "Segfault in _embedding_bag_forward_only",
        "Bug description": "\n\nFunction `torch._embedding_bag_forward_only` contains segmentation fault.\r\n\r\n### ",
        "Sample Code": "\n\nFunction `torch._embedding_bag_forward_only` contains segmentation fault.\r\n\r\n### Example to reproduce\r\n\r\n```\r\nimport torch\r\n\r\nweight = torch.full([2, 2, 5, 3, 3], -8670, dtype=torch.float64, requires_grad=False)\r\nindices = torch.full([3, 0, 1], -4468, dtype=torch.int32, requires_grad=False)\r\noffsets = torch.full([7, 1, 0], -7226, dtype=torch.int64, requires_grad=False)\r\nscale_grad_by_freq = True\r\nmode = torch.full([], 6318, dtype=torch.int64, requires_grad=False)\r\nsparse = False\r\nper_sample_weights = torch.full([3], -8750, dtype=torch.int64, requires_grad=False)\r\ninclude_last_offset = False\r\npadding_idx = torch.full([], 6383, dtype=torch.int64, requires_grad=False)\r\ntorch._embedding_bag_forward_only(weight, indices, offsets, scale_grad_by_freq, mode,\r\n                                  sparse, per_sample_weights, include_last_offset, padding_idx)\r\n```\r\n\r\n### Result\r\n\r\nSegmentation fault\r\n\r\n### Expected Behavior\r\n\r\nThrowing a Python Exception\r\n\r\n### Notes\r\n\r\nThis bug was discovered using [Atheris](https://github.com/google/atheris).\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/78128",
        "Issue title": "Segfault in torch._C._nn.thnn_conv2d",
        "Bug description": "\r\n\r\nFunction `torch._C._nn.thnn_conv2d` contains segmentation fault.\r\n\r\n### ",
        "Sample Code": "\r\n\r\nFunction `torch._C._nn.thnn_conv2d` contains segmentation fault.\r\n\r\n### Example to reproduce\r\n\r\n```\r\nimport torch\r\n\r\ntensor_0 = torch.full([3, 3, 3], -4398, dtype=torch.float64, requires_grad=False)\r\ntensor_1 = torch.full([6, 7], -4532, dtype=torch.int32, requires_grad=False)\r\nintarrayref_2 = -10000\r\ntensor_3 = torch.full([3, 3, 3, 6, 7], -2321, dtype=torch.float16, requires_grad=False)\r\nintarrayref_4 = -2807\r\nintarrayref_5 = []\r\ntorch._C._nn.thnn_conv2d(tensor_0, tensor_1, intarrayref_2, tensor_3, intarrayref_4, intarrayref_5)\r\n```\r\n\r\n### Result\r\n\r\nSegmentation fault\r\n\r\n### Expected Behavior\r\n\r\nThrowing a Python Exception\r\n\r\n### Notes\r\n\r\nThis bug was discovered using [Atheris](https://github.com/google/atheris).\r\n\r\n\r\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/78127",
        "Issue title": "Segfault in torch._C._nn.reflection_pad2d",
        "Bug description": "\n\n\r\nFunction `torch._C._nn.reflection_pad2d` contains segmentation fault.\r\n\r\n### ",
        "Sample Code": "\n\n\r\nFunction `torch._C._nn.reflection_pad2d` contains segmentation fault.\r\n\r\n### Example to reproduce\r\n\r\n```\r\nimport torch\r\n\r\ntensor_0 = torch.full([6, 5, 7], -8754, dtype=torch.int32, requires_grad=False)\r\nintarrayref_1 = []\r\ntorch._C._nn.reflection_pad2d(tensor_0, intarrayref_1)\r\n```\r\n\r\n### Result\r\n\r\nSegmentation fault\r\n\r\n### Expected Behavior\r\n\r\nThrowing a Python Exception\r\n\r\n### Notes\r\n\r\nThis bug was discovered using [Atheris](https://github.com/google/atheris).\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/78126",
        "Issue title": "Segfault in max_unpool3d",
        "Bug description": "\n\n\r\nFunction `torch.max_unpool3d` contains segmentation fault.\r\n\r\n### ",
        "Sample Code": "\n\n\r\nFunction `torch.max_unpool3d` contains segmentation fault.\r\n\r\n### Example to reproduce\r\n\r\n```\r\nimport torch\r\n\r\ntensor_0 = torch.full([], -10000, dtype=torch.int64, requires_grad=False)\r\ntensor_1 = torch.full([7, 7, 7, 4, 4, 4, 7, 7], -8695, dtype=torch.float16, requires_grad=False)\r\nintarrayref_2 = []\r\nintarrayref_3 = 7052\r\nintarrayref_4 = -9995\r\ntorch._C._nn.max_unpool3d(tensor_0, tensor_1, intarrayref_2, intarrayref_3, intarrayref_4)\r\n```\r\n\r\n### Result\r\n\r\nSegmentation fault\r\n\r\n### Expected Behavior\r\n\r\nThrowing a Python Exception\r\n\r\n### Notes\r\n\r\nThis bug was discovered using [Atheris](https://github.com/google/atheris).\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/78125",
        "Issue title": "Segfault in grid_sampler_3d",
        "Bug description": "\n\n\r\nFunction `torch.grid_sampler_3d` contains segmentation fault.\r\n\r\n### ",
        "Sample Code": "\n\n\r\nFunction `torch.grid_sampler_3d` contains segmentation fault.\r\n\r\n### Example to reproduce\r\n\r\n```\r\nimport torch\r\n\r\ninput = torch.full([4, 2, 0, 0, 4, 0, 0, 3], -1480, dtype=torch.float64, requires_grad=False)\r\ngrid = torch.full([1, 6, 3, 5, 3, 4, 0, 6], -2024, dtype=torch.float64, requires_grad=False)\r\ninterpolation_mode = -3278\r\npadding_mode = -1469\r\nalign_corners = True\r\ntorch.grid_sampler_3d(input, grid, interpolation_mode, padding_mode, align_corners)\r\n```\r\n\r\n### Result\r\n\r\nSegmentation fault\r\n\r\n### Expected Behavior\r\n\r\nThrowing a Python Exception\r\n\r\n### Notes\r\n\r\nThis bug was discovered using [Atheris](https://github.com/google/atheris).\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/78123",
        "Issue title": "Segfault in choose_qparams_optimized",
        "Bug description": "\n\n\r\nFunction `torch.choose_qparams_optimized` contains segmentation fault.\r\n\r\n### ",
        "Sample Code": "\n\n\r\nFunction `torch.choose_qparams_optimized` contains segmentation fault.\r\n\r\n### Example to reproduce\r\n\r\n```\r\nimport torch\r\n\r\ninput = torch.full([7, 7, 4, 6, 3, 1, 2], -7124, dtype=torch.float32, requires_grad=False)\r\nnumel = -8192\r\nn_bins = 1255\r\nratio = -9185\r\nbit_width = -4519\r\ntorch.choose_qparams_optimized(input, numel, n_bins, ratio, bit_width)\r\n```\r\n\r\n### Result\r\n\r\nSegmentation fault\r\n\r\n### Expected Behavior\r\n\r\nThrowing a Python Exception\r\n\r\n### Notes\r\n\r\nThis bug was discovered using [Atheris](https://github.com/google/atheris).\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/78122",
        "Issue title": "Segfault in bincount",
        "Bug description": "\n\nFunction `torch.bincount` contains segmentation fault.\r\n\r\n### ",
        "Sample Code": "\n\nFunction `torch.bincount` contains segmentation fault.\r\n\r\n### Example to reproduce\r\n\r\n```\r\nimport torch\r\n\r\nself = torch.full([3], 2550, dtype=torch.int64, requires_grad=False)\r\nweights = torch.full([3, 1, 3, 0, 0, 0, 1, 1], -4620, dtype=torch.int64, requires_grad=False)\r\nminlength = 9711\r\ntorch.bincount(self, weights, minlength)\r\n```\r\n\r\n### Result\r\n\r\nSegmentation fault\r\n\r\n### Expected Behavior\r\n\r\nThrowing a Python Exception\r\n\r\n### Notes\r\n\r\nThis bug was discovered using [Atheris](https://github.com/google/atheris).\r\n\n\n### ",
        "API Signature": "\n torch. bincount ( input ,  weights ,  minlength )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/77893",
        "Issue title": "Segmentation fault in _remove_batch_dim",
        "Bug description": "\r\n\r\nSegmentation fault in `_remove_batch_dim`.\r\n\r\n### ",
        "Sample Code": "\r\n\r\nSegmentation fault in `_remove_batch_dim`.\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\nself = torch.full((5, 5, 5, 5, 5,), 1, dtype=torch.float64, requires_grad=False)\r\nlevel = 0\r\nbatch_size = 0\r\nout_dim = 1250999896764\r\ntorch._remove_batch_dim(self, level, batch_size, out_dim)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using IvySyn, a fuzz testing tool which is currently being developed at Secure Systems Labs at Brown University.\r\n\r\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/77493",
        "Issue title": "forward AD fails in `torch.pow`",
        "Bug description": "\r\n\r\nSegmentation fault in `_remove_batch_dim`.\r\n\r\n### ",
        "Sample Code": "\n\nforward AD fails in `torch.pow` when input and exponent has different dtype. By contrast, backward AD will word successfully. I think maybe forward AD for `torch.pow` doesn't consider broadcasting.\r\n\r\n```python\r\nimport torch\r\nfrom torch.autograd import forward_ad\r\n\r\ninput_tensor = torch.rand([5, 4, 5], dtype=torch.bfloat16)\r\nexponent_tensor = torch.rand([1], dtype=torch.float64)\r\n\r\n# backward\r\ninput = input_tensor.clone().requires_grad_()\r\nexponent = exponent_tensor.clone()\r\ntorch.pow(input, exponent).sum().backward()\r\nprint(\"backward PASS\")\r\n\r\n# forward\r\ninput = input_tensor.clone().requires_grad_()\r\nexponent = exponent_tensor.clone()\r\nwith forward_ad.dual_level():\r\n    tangent = torch.rand_like(input)\r\n    dual_input = forward_ad.make_dual(input, tangent)\r\n    dual_output = torch.pow(dual_input, exponent)\r\n\r\n# backward PASS\r\n# RuntimeError: expected scalar type c10::BFloat16 but found double\r\n```\n\n### ",
        "API Signature": "\n torch. pow ( input ,  exponent ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/77231",
        "Issue title": "`torch.scatter_add` will succeed when the `index` is a complex tensor",
        "Bug description": "\r\n\r\nSegmentation fault in `_remove_batch_dim`.\r\n\r\n### ",
        "Sample Code": "\n\n`torch.scatter_add` will succeed when the `index` is a complex tensor without any elements.\r\n\r\n```python\r\nimport torch\r\n\r\ninput_tensor = torch.rand([10, 5], dtype=torch.float64)\r\nindex_tensor = torch.rand([13, 0], dtype=torch.complex128)\r\nsrc_tensor = torch.rand([10, 2], dtype=torch.float64)\r\n\r\ndef fn(input, index, src):\r\n    dim = -1\r\n    fn_res = torch.scatter_add(input, dim, index, src, )\r\n    return fn_res\r\n\r\nfn(input_tensor, index_tensor, src_tensor)\r\n# tensor([[0.9610, 0.2629, 0.8555, 0.7965, 0.3472],\r\n#         [0.7140, 0.6187, 0.4872, 0.3589, 0.7170],\r\n#         [0.3184, 0.3303, 0.8061, 0.6865, 0.5176],\r\n#         [0.6451, 0.1152, 0.4974, 0.0535, 0.0350],\r\n#         [0.1497, 0.7439, 0.7563, 0.8654, 0.6401],\r\n#         [0.1090, 0.9057, 0.2156, 0.3272, 0.6849],\r\n#         [0.8402, 0.4956, 0.4937, 0.9882, 0.1275],\r\n#         [0.0889, 0.8429, 0.3421, 0.1373, 0.1697],\r\n#         [0.1318, 0.0984, 0.1662, 0.4122, 0.1132],\r\n#         [0.9094, 0.2276, 0.8924, 0.3781, 0.7588]], dtype=torch.float64)\r\n```\r\n\r\nHowever, when trying to compute the gradient\r\n\r\n```python\r\nimport torch\r\nfrom torch.autograd import gradcheck\r\n\r\ninput_tensor = torch.rand([10, 5], dtype=torch.float64, requires_grad=True)\r\nindex_tensor = torch.rand([13, 0], dtype=torch.complex128, requires_grad=True)\r\nsrc_tensor = torch.rand([10, 2], dtype=torch.float64, requires_grad=True)\r\n\r\ndef fn(input, index, src):\r\n    dim = -1\r\n    fn_res = torch.scatter_add(input, dim, index, src, )\r\n    return fn_res\r\n\r\ngradcheck(fn, (input_tensor, index_tensor, src_tensor))\r\n# RuntimeError: Function ScatterAddBackward0 returned an invalid gradient at index 1 - got [13, 0] but expected shape compatible with [10, 2]\r\n```\n\n### ",
        "API Signature": "\n torch. scatter_add ( input ,  dim ,  index ,  src )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/76778",
        "Issue title": "`torch.addmv` backward fails",
        "Bug description": "\r\n\r\nSegmentation fault in `_remove_batch_dim`.\r\n\r\n### ",
        "Sample Code": "\n\n`torch.addmv` backward fails when `input` is `float64`, `mat` and `vec` are `complex128`\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([2], dtype=torch.float64, requires_grad=True)\r\nmat = torch.rand([2, 3], dtype=torch.complex128, requires_grad=True)\r\nvec = torch.rand([3], dtype=torch.complex128, requires_grad=True)\r\n\r\nres = torch.addmv(input, mat, vec)\r\nprint(\"addmv SUCCEED!\")\r\n\r\nres_2 = res.sum()\r\nprint(\"sum SUCCEED!\")\r\n\r\nres_2.backward()\r\n# addmv SUCCEED!\r\n# sum SUCCEED!\r\n# RuntimeError: Expected isFloatingType(grad.scalar_type()) || (input_is_complex == grad_is_complex) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\r\n```\r\n\r\nHowever, when `input` is `complex128`, `mat` and `vec` are `float64`, it will succeed to backward\n\n### ",
        "API Signature": "\n torch. addmv ( input ,  mat ,  vec ,  * ,  beta ,  alpha ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/76571",
        "Issue title": "torch.unique() nondeterministic behavior on nan inputs (on GPU)",
        "Bug description": "\r\n\r\nSegmentation fault in `_remove_batch_dim`.\r\n\r\n### ",
        "Sample Code": "\n\n```python\r\nimport torch\r\n\r\ndef unique(x):\r\n    return torch.unique(x, sorted=False, return_inverse=False, return_counts=True)\r\n\r\ns = torch.tensor(0.).cuda()\r\nx = torch.tensor(float('nan')).cuda()\r\n\r\nprint(unique(s))\r\nprint(unique(x)) # <- these two calls have different outputs\r\nprint(unique(x)) # <-\r\n```\r\n\r\noutput:\r\n```\r\n(tensor([0.], device='cuda:0'), tensor([1], device='cuda:0'))\r\n(tensor([0., 0.], device='cuda:0'), tensor([1, 0], device='cuda:0'))\r\n(tensor([0., 0.], device='cuda:0'), tensor([0, 0], device='cuda:0'))\r\n```\r\n\r\nTwo issues:\r\n* a) the last two results output a tensor with two elements, despite the fact that there's only one unique value (and only one element in the input tensor)\r\n* b) the last two results are different, despite having the same input.\n\n### ",
        "API Signature": "\n torch. unique ( input ,  sorted ,  return_inverse ,  return_counts ,  dim )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/75171",
        "Issue title": "torch.jit.load fails when path contains non-ascii characters",
        "Bug description": "\r\n\r\nSegmentation fault in `_remove_batch_dim`.\r\n\r\n### ",
        "Sample Code": "\r\n\r\nhttps://github.com/openai/CLIP/pull/227\r\n\r\n`torch.jit.load` fails when path contains non-ascii characters\r\n\r\n\r\n```py\r\nimport torch\r\n\r\ntorch.jit.load('C:\\\\Users\\\\\u6d41\u661f\u66b4\u96e8/.cache/clip\\\\ViT-B-16.pt', \"cpu\")\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"[C:\\Users\\]()\u6d41\u661f\u66b4\u96e8\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\jit\\_serialization.py\", line 161, in load\r\n    cpp_module = torch._C.import_ir_module(cu, str(f), map_location, _extra_files)\r\nRuntimeError: open file failed, file path: [C:\\Users\\]()\u6d41\u661f\u66b4\u96e8/.cache/clip\\ViT-B-16.pt\r\n```\r\n\r\nRelated issues: https://github.com/pytorch/pytorch/issues/47422\r\n\r\n### ",
        "API Signature": "\n torch.jit. load ( f ,  map_location ,  _extra_files ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/74809",
        "Issue title": "Incorrect results for `torch.distributed.gather` for tensor created from permuted NumPy array",
        "Bug description": "\n\nHi,\r\n\r\nWhen creating a tensor from a non-contiguous NumPy array, e.g.\r\n```python\r\nmy_array = np.reshape(np.arange(10), (2, 5))\r\nmy_array = np.transpose(my_array, (1, 0))\r\nmy_tensor = torch.from_numpy(my_array)\r\n```\r\nand then using `torch.distributed.gather`, the tensor on the destination rank is not correct.\r\n\r\n**Expected behaviour**: either the tensor on the destination rank is equal to the tensor on the source rank, **or**, `torch.distributed.gather` throws an exception to let the user know that the tensor must be contiguous. This silent error is very hard to be aware of.\r\n\r\n\r\n## ",
        "Sample Code": "\n\nHi,\r\n\r\nWhen creating a tensor from a non-contiguous NumPy array, e.g.\r\n```python\r\nmy_array = np.reshape(np.arange(10), (2, 5))\r\nmy_array = np.transpose(my_array, (1, 0))\r\nmy_tensor = torch.from_numpy(my_array)\r\n```\r\nand then using `torch.distributed.gather`, the tensor on the destination rank is not correct.\r\n\r\n**Expected behaviour**: either the tensor on the destination rank is equal to the tensor on the source rank, **or**, `torch.distributed.gather` throws an exception to let the user know that the tensor must be contiguous. This silent error is very hard to be aware of.\r\n\r\n\r\n## Minimal example\r\n\r\nThe following code\r\n```python\r\nimport os\r\nimport time\r\nimport torch\r\nimport numpy as np\r\nimport torch.distributed as dist\r\nimport torch.multiprocessing as mp \r\n\r\n\r\ndef worker_fn(rank):\r\n    print(f\"Hello from rank {rank}\")\r\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\r\n    os.environ['MASTER_PORT'] = '29500'\r\n    dist.init_process_group(backend='gloo', rank=rank, world_size=2)\r\n    dist.barrier()\r\n\r\n    if rank == 0:\r\n        # Source rank\r\n        my_array = np.reshape(np.arange(10), (2, 5))\r\n        my_array = np.transpose(my_array, (1, 0))\r\n        my_tensor = torch.from_numpy(my_array).to(torch.float32)\r\n        dist.gather(my_tensor, dst=1)\r\n        print(\"Sent tensor     = \" + str(my_tensor.tolist()))\r\n    elif rank == 1:\r\n        # Destination rank\r\n        not_used = torch.zeros((5, 2))\r\n        results = [torch.zeros((5, 2)) for _ in range(2)]\r\n        dist.gather(not_used, gather_list=results, dst=1)\r\n        # Printing tensor from rank 0\r\n        print(\"Received tensor = \" + str(results[0].tolist()))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    processes = []\r\n    mp.set_start_method(\"spawn\")\r\n    for rank in range(2):\r\n        p = mp.Process(target=worker_fn, args=(rank,))\r\n        p.start()\r\n        processes.append(p)\r\n    for p in processes:\r\n        p.join()\r\n```\r\nleads to the following CLI output under torch 1.11.0, tested on two different systems:\r\n\r\n```\r\nHello from rank 1\r\nHello from rank 0\r\nSent tensor     = [[0.0, 5.0], [1.0, 6.0], [2.0, 7.0], [3.0, 8.0], [4.0, 9.0]]\r\nReceived tensor = [[0.0, 1.0], [2.0, 3.0], [4.0, 5.0], [6.0, 7.0], [8.0, 9.0]]\r\n```\r\n\r\nThe received tensor does not have the same permutation as the sent tensor.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/73196",
        "Issue title": "`torch.pow` errors out on specific input",
        "Bug description": "\n\nHi,\r\n\r\nWhen creating a tensor from a non-contiguous NumPy array, e.g.\r\n```python\r\nmy_array = np.reshape(np.arange(10), (2, 5))\r\nmy_array = np.transpose(my_array, (1, 0))\r\nmy_tensor = torch.from_numpy(my_array)\r\n```\r\nand then using `torch.distributed.gather`, the tensor on the destination rank is not correct.\r\n\r\n**Expected behaviour**: either the tensor on the destination rank is equal to the tensor on the source rank, **or**, `torch.distributed.gather` throws an exception to let the user know that the tensor must be contiguous. This silent error is very hard to be aware of.\r\n\r\n\r\n## ",
        "Sample Code": "\n\nrunning into the issue with the scripts below:\r\n\r\n```\r\nimport torch\r\n\r\nx = torch.tensor(0, device=\"cuda\", dtype=torch.int32)\r\ny = torch.tensor(-1)\r\no = torch.pow(x, y)\r\n\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-10-bc9daa4bd4d3> in <module>\r\n----> 1 o = torch.pow(x, y)\r\n\r\nRuntimeError: \"reciprocal_cuda\" not implemented for 'Long'\r\n```\r\n\n\n### ",
        "API Signature": "\n torch. pow ( input ,  exponent ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/73191",
        "Issue title": "Segmentation fault in max_pool3d",
        "Bug description": "\n\nSegmentation fault in `max_pool3d` when containing large arguments (`kernel_size`, `dilation`).\r\n\r\n### ",
        "Sample Code": "\n\nSegmentation fault in `max_pool3d` when containing large arguments (`kernel_size`, `dilation`).\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\nself = torch.full((1, 1, 1, 1, 1,), 1.5e+300, dtype=torch.float64, requires_grad=False)\r\nkernel_size = [536870912, 536870912, 536870912]\r\nstride = [1, 1, 1]\r\npadding = [0, 0, 0]\r\ndilation = [1879048192, 1879048192, 1879048192]\r\nceil_mode = True\r\ntorch.max_pool3d(self, kernel_size, stride, padding, dilation, ceil_mode)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using fuzz testing.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/73190",
        "Issue title": "Segmentation fault in max_pool1d",
        "Bug description": "\n\nSegmentation fault in `max_pool1d` when `kernel_size`, `stride` and `dilation` are large.\r\n\r\n### ",
        "Sample Code": "\n\nSegmentation fault in `max_pool1d` when `kernel_size`, `stride` and `dilation` are large.\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\nself = torch.full((2, 10, 4,), 0.5, dtype=torch.float64, requires_grad=False)\r\nkernel_size = [1250999896764]\r\nstride = [1250999896764]\r\npadding = [0]\r\ndilation = [1250999896764]\r\nceil_mode = True\r\ntorch.max_pool1d(self, kernel_size, stride, padding, dilation, ceil_mode)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using fuzz testing.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/73186",
        "Issue title": "Segmentation fault in fractional_max_pool3d",
        "Bug description": "\n\nSegmentation fault in `fractional_max_pool3d` when `output_size` contains 0s.\r\n\r\n### ",
        "Sample Code": "\n\nSegmentation fault in `fractional_max_pool3d` when `output_size` contains 0s.\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\nself = torch.full((2, 4, 5, 5, 5,), 1, dtype=torch.float64, requires_grad=False)\r\nkernel_size = [0, 0, 0]\r\noutput_size = [0, 0, 0]\r\nrandom_samples = torch.full((2, 4, 5, 5, 5,), 1, dtype=torch.float64, requires_grad=False)\r\ntorch._C._nn.fractional_max_pool3d(self, kernel_size, output_size, random_samples)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using fuzz testing.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/73185",
        "Issue title": "Segmentation fault in fractional_max_pool2d",
        "Bug description": "\n\nSegmentation fault in `fractional_max_pool2d` when `output_size` contains 0s.\r\n\r\n### ",
        "Sample Code": "\n\nSegmentation fault in `fractional_max_pool2d` when `output_size` contains 0s.\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\nself = torch.full((1, 3, 7, 6,), 1, dtype=torch.float64, requires_grad=False)\r\nkernel_size = [0, 0]\r\noutput_size = [0, 0]\r\nrandom_samples = torch.full((1, 3, 7, 6,), 1, dtype=torch.float64, requires_grad=False)\r\ntorch._C._nn.fractional_max_pool2d(self, kernel_size, output_size, random_samples)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using fuzz testing.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/73182",
        "Issue title": "Segmentation fault in _sobol_engine_scramble_",
        "Bug description": "\r\n\r\nSegmentation fault in `_sobol_engine_scramble_` when `dimension` is large.\r\n\r\n### ",
        "Sample Code": "\r\n\r\nSegmentation fault in `_sobol_engine_scramble_` when `dimension` is large.\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\nself = torch.full((100, 30,), 1, dtype=torch.int64, requires_grad=False)\r\nltm = torch.full((100, 30, 30,), 1, dtype=torch.int64, requires_grad=False)\r\ndimension = 1250999896764\r\ntorch._sobol_engine_scramble_(self, ltm, dimension)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using fuzz testing.\r\n\r\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/73181",
        "Issue title": "Segmentation fault in _sobol_engine_initialize_state_",
        "Bug description": "\n\nSegmentation fault in `_sobol_engine_initialize_state_` when `dimension` is large.\r\n\r\n### ",
        "Sample Code": "\n\nSegmentation fault in `_sobol_engine_initialize_state_` when `dimension` is large.\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\nself = torch.full((2, 30,), 1, dtype=torch.int64, requires_grad=False)\r\ndimension = 1250999896764\r\ntorch._sobol_engine_initialize_state_(self, dimension)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using fuzz testing.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/73180",
        "Issue title": "Segmentation fault in _sobol_engine_ff_",
        "Bug description": "\n\nSegmentation fault in `_sobol_engine_ff_` when `n` and `dimension` are large.\r\n\r\n### ",
        "Sample Code": "\n\nSegmentation fault in `_sobol_engine_ff_` when `n` and `dimension` are large.\r\n\r\n### Example to reproduce\r\n\r\n```python\r\nimport torch\r\n\r\nself = torch.full((2,), 1, dtype=torch.int64, requires_grad=False)\r\nn = 1250999896764\r\nsobolstate = torch.full((2, 30,), 1, dtype=torch.int64, requires_grad=False)\r\ndimension = 1250999896764\r\nnum_generated = 0\r\ntorch._sobol_engine_ff_(self, n, sobolstate, dimension, num_generated)\r\n```\r\n\r\n### Result\r\n```segmentation fault```\r\n\r\n### Expected behavior\r\nGraceful termination or a RuntimeError to be thrown.\r\n\r\n### Note\r\nThis bug was discovered using fuzz testing.\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71689",
        "Issue title": "torch.distributions.categorical.Categorical does not work with 0 batch size",
        "Bug description": "\n\nSegmentation fault in `_sobol_engine_ff_` when `n` and `dimension` are large.\r\n\r\n### ",
        "Sample Code": "\n\nInitializing a `Categorical` with `logits` that have a batch dimension of 0 raises an error. I would expect this to work and result in probabilities/entropies/... with batch dimension 0.\r\n\r\n```\r\nPython 3.8.10 (default, Nov 26 2021, 20:14:08)\r\n[GCC 9.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from torch.distributions.categorical import Categorical\r\n>>> import torch\r\n>>> Categorical(logits=torch.zeros((2, 5)))\r\nCategorical(logits: torch.Size([2, 5]))\r\n>>> Categorical(logits=torch.zeros((0, 5)))\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/clemens/.cache/pypoetry/virtualenvs/incubator-Qe8CM38i-py3.8/lib/python3.8/site-packages/torch/distributions/categorical.py\", line 64, in __init__\r\n    super(Categorical, self).__init__(batch_shape, validate_args=validate_args)\r\n  File \"/home/clemens/.cache/pypoetry/virtualenvs/incubator-Qe8CM38i-py3.8/lib/python3.8/site-packages/torch/distributions/distribution.py\", line 53, in __init__\r\n    valid = constraint.check(value)\r\n  File \"/home/clemens/.cache/pypoetry/virtualenvs/incubator-Qe8CM38i-py3.8/lib/python3.8/site-packages/torch/distributions/constraints.py\", line 206, in check\r\n    result = result.reshape(result.shape[:result.dim() - self.reinterpreted_batch_ndims] + (-1,))\r\nRuntimeError: cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71678",
        "Issue title": "torch.bmm backward with sparse input",
        "Bug description": "\n\nSegmentation fault in `_sobol_engine_ff_` when `n` and `dimension` are large.\r\n\r\n### ",
        "Sample Code": "\r\n\r\nBased on the torch.sparse documentation it sounds like `torch.bmm` supports forward and backward for sparse tensors (but the gradients themselves will be dense). During the backward pass I'm getting the error shown below. Is this expected (in which case this is a feature request) or is this a bug?\r\n\r\n```python\r\nimport torch\r\na = torch.rand(2, 3, 3).to_sparse().requires_grad_(True)\r\nb = torch.rand(2, 3, 3)\r\nc = torch.bmm(a, b)\r\nloss = c.sum()\r\nloss.backward()\r\n```\r\n\r\ngives\r\n\r\n```text\r\nTraceback (most recent call last):\r\n  File \"/home/test_bmm.py\", line 7, in <module>\r\n    loss.backward()\r\n  File \"/home/cmccarth/.conda/envs/test/lib/python3.8/site-packages/torch/_tensor.py\", line 255, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\r\n  File \"/home/cmccarth/.conda/envs/test/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 147, in backward\r\n    Variable._execution_engine.run_backward(\r\nRuntimeError: Function BmmBackward0 returned an invalid gradient at index 0 - expected type TensorOptions(dtype=float, device=cpu, layout=Sparse, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)) but got TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt))\r\n```\r\n\r\nThank you for your help!\r\n\r\n### ",
        "API Signature": "\n torch. bmm ( input ,  mat2 ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71636",
        "Issue title": "`torch.median` will return -2147483648 when input is an empty tensor",
        "Bug description": "\n\nSegmentation fault in `_sobol_engine_ff_` when `n` and `dimension` are large.\r\n\r\n### ",
        "Sample Code": "\n\n`torch.median` will return -2147483648 when input is an empty tensor with `int32`. By contrast, `torch.min` will raise an error, which I think is a better behavior.\r\n\r\n```python\r\nimport torch\r\ninput = torch.randint(-2,2,[0], dtype=torch.int32)\r\nprint(torch.median(input))\r\n# tensor(-2147483648, dtype=torch.int32)\r\ntorch.min(input)\r\n# RuntimeError: min(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\r\n```\n\n### ",
        "API Signature": "\n torch. median ( input )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71477",
        "Issue title": "`torch.cum{min,max}, torch.sort, argsort` do not check the `dim` when the input is 0-d tensor",
        "Bug description": "\n\nSegmentation fault in `_sobol_engine_ff_` when `n` and `dimension` are large.\r\n\r\n### ",
        "Sample Code": "\r\n\r\n`torch.cummin`, `torch.cummax`, `torch.sort` and `torch.argsort` do not check the `dim` when the input is 0-d tensor\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([], dtype=torch.float64)\r\ndim = 100\r\ntorch.cummin(input, dim)\r\n# torch.return_types.cummin(\r\n# values=tensor(0.8172, dtype=torch.float64),\r\n# indices=tensor(0))\r\n```\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([1], dtype=torch.float64)\r\ndim = 100\r\ntorch.cummin(input, dim)\r\n# IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 100)\r\n```\r\n\r\n### ",
        "API Signature": "\n torch. cummin ( input ,  dim ,  * ,  out ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71477",
        "Issue title": "`torch.cum{min,max}, torch.sort, argsort` do not check the `dim` when the input is 0-d tensor",
        "Bug description": "\n\nSegmentation fault in `_sobol_engine_ff_` when `n` and `dimension` are large.\r\n\r\n### ",
        "Sample Code": "\r\n\r\n`torch.cummin`, `torch.cummax`, `torch.sort` and `torch.argsort` do not check the `dim` when the input is 0-d tensor\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([], dtype=torch.float64)\r\ndim = 100\r\ntorch.cummin(input, dim)\r\n# torch.return_types.cummin(\r\n# values=tensor(0.8172, dtype=torch.float64),\r\n# indices=tensor(0))\r\n```\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([1], dtype=torch.float64)\r\ndim = 100\r\ntorch.cummin(input, dim)\r\n# IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 100)\r\n```\r\n\r\n### ",
        "API Signature": "\n torch. cummax ( input ,  dim ,  * ,  out ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71477",
        "Issue title": "`torch.cum{min,max}, torch.sort, argsort` do not check the `dim` when the input is 0-d tensor",
        "Bug description": "\n\nSegmentation fault in `_sobol_engine_ff_` when `n` and `dimension` are large.\r\n\r\n### ",
        "Sample Code": "\r\n\r\n`torch.cummin`, `torch.cummax`, `torch.sort` and `torch.argsort` do not check the `dim` when the input is 0-d tensor\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([], dtype=torch.float64)\r\ndim = 100\r\ntorch.cummin(input, dim)\r\n# torch.return_types.cummin(\r\n# values=tensor(0.8172, dtype=torch.float64),\r\n# indices=tensor(0))\r\n```\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([1], dtype=torch.float64)\r\ndim = 100\r\ntorch.cummin(input, dim)\r\n# IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 100)\r\n```\r\n\r\n### ",
        "API Signature": "\n torch. sort ( input ,  dim ,  descending ,  stable ,  * ,  out ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71477",
        "Issue title": "`torch.cum{min,max}, torch.sort, argsort` do not check the `dim` when the input is 0-d tensor",
        "Bug description": "\n\nSegmentation fault in `_sobol_engine_ff_` when `n` and `dimension` are large.\r\n\r\n### ",
        "Sample Code": "\r\n\r\n`torch.cummin`, `torch.cummax`, `torch.sort` and `torch.argsort` do not check the `dim` when the input is 0-d tensor\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([], dtype=torch.float64)\r\ndim = 100\r\ntorch.cummin(input, dim)\r\n# torch.return_types.cummin(\r\n# values=tensor(0.8172, dtype=torch.float64),\r\n# indices=tensor(0))\r\n```\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([1], dtype=torch.float64)\r\ndim = 100\r\ntorch.cummin(input, dim)\r\n# IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 100)\r\n```\r\n\r\n### ",
        "API Signature": "\n torch. argsort ( input ,  dim ,  descending ,  stable )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71470",
        "Issue title": "torch.jit.script failed to compile nn.MultiheadAttention when specifying the kdim and vdim parameters.",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum code to reproduce the behavior:\r\n\r\n```\r\nimport torch\r\n\r\n\r\nmha0 = torch.nn.MultiheadAttention(256, 4)\r\nscript_mha0 = torch.jit.script(mha0)\r\nprint(\"Successful compiled mha0\")\r\n\r\nmha1 = torch.nn.MultiheadAttention(256, 4, kdim=128, vdim=128)\r\nscript_mha1 = torch.jit.script(mha1)\r\nprint(\"Successful compiled mha1\")\r\n```\r\n\r\nFull error stack:\r\n\r\n```\r\nSuccessful compiled mha0\r\nTraceback (most recent call last):\r\n  File \"tests/bin/jit_mha.py\", line 9, in <module>\r\n    script_mha1 = torch.jit.script(mha1)\r\n  File \"/storage09/yuxinyuan02/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/jit/_script.py\", line 1097, in script\r\n    obj, torch.jit._recursive.infer_methods_to_compile\r\n  File \"/storage09/yuxinyuan02/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/jit/_recursive.py\", line 412, in create_script_module\r\n    return create_script_module_impl(nn_module, concrete_type, stubs_fn)\r\n  File \"/storage09/yuxinyuan02/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/jit/_recursive.py\", line 478, in create_script_module_impl\r\n    create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)\r\n  File \"/storage09/yuxinyuan02/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/jit/_recursive.py\", line 355, in create_methods_and_properties_from_stubs\r\n    concrete_type._create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)\r\nRuntimeError: \r\n\r\nmulti_head_attention_forward(Tensor query, Tensor key, Tensor value, int embed_dim_to_check, int num_heads, Tensor in_proj_weight, Tensor? in_proj_bias, Tensor? bias_k, Tensor? bias_v, bool add_zero_attn, float dropout_p, Tensor out_proj_weight, Tensor? out_proj_bias, bool training=True, Tensor? key_padding_mask=None, bool need_weights=True, Tensor? attn_mask=None, bool use_separate_proj_weight=False, Tensor? q_proj_weight=None, Tensor? k_proj_weight=None, Tensor? v_proj_weight=None, Tensor? static_k=None, Tensor? static_v=None) -> ((Tensor, Tensor?)):\r\nExpected a value of type 'Tensor' for argument 'in_proj_weight' but instead found type 'NoneType'.\r\n:\r\n  File \"/storage09/yuxinyuan02/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/activation.py\", line 1020\r\n    \r\n        if not self._qkv_same_embed_dim:\r\n            attn_output, attn_output_weights = F.multi_head_attention_forward(\r\n                                               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n                query, key, value, self.embed_dim, self.num_heads,\r\n                self.in_proj_weight, self.in_proj_bias,\r\n```\n\n### ",
        "API Signature": "\n torch.jit. script ( obj ,  optimize ,  _frames_up ,  _rcb ,  example_inputs ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71204",
        "Issue title": "`torch.diag` unexpectedly fails",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\r\n\r\nBased on the documentation, `torch.diag` and `torch.diagonal` should have the same behavior when the input is 2-d and `dim1` and `dim2` are default value.\r\n```python\r\nimport torch\r\na = torch.tensor([[0, 1], [2, 3]])\r\nfor i in [0, 1, 2]:\r\n    assert(torch.equal(torch.diag(a, i), torch.diagonal(a, i)))\r\ntorch.diagonal(a, 3)\r\ntorch.diag(a, 3)\r\n# RuntimeError: [enforce fail at CPUAllocator.cpp:50] ((ptrdiff_t)nbytes) >= 0. alloc_cpu() seems to have been called with negative number: 18446744073709551608\r\n```\r\nFor a 2-d tensor, when `diagonal<=2`, their output are the same. But when `diagonal>=3`, `torch.diagonal` still returns an empty tensor but `torch.diag` raise an error that it allocates negative memory. It seems strange because `diagonal=2` is the first value beyond the range but `torch.diag` just return an empty tensor. \r\n\r\nIn my view, `torch.diag` should succeed when `diagonal >= 2`.\r\n\r\n### ",
        "API Signature": "\n torch. diag ( input ,  diagonal ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71204",
        "Issue title": "`torch.diag` unexpectedly fails",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\r\n\r\nBased on the documentation, `torch.diag` and `torch.diagonal` should have the same behavior when the input is 2-d and `dim1` and `dim2` are default value.\r\n```python\r\nimport torch\r\na = torch.tensor([[0, 1], [2, 3]])\r\nfor i in [0, 1, 2]:\r\n    assert(torch.equal(torch.diag(a, i), torch.diagonal(a, i)))\r\ntorch.diagonal(a, 3)\r\ntorch.diag(a, 3)\r\n# RuntimeError: [enforce fail at CPUAllocator.cpp:50] ((ptrdiff_t)nbytes) >= 0. alloc_cpu() seems to have been called with negative number: 18446744073709551608\r\n```\r\nFor a 2-d tensor, when `diagonal<=2`, their output are the same. But when `diagonal>=3`, `torch.diagonal` still returns an empty tensor but `torch.diag` raise an error that it allocates negative memory. It seems strange because `diagonal=2` is the first value beyond the range but `torch.diag` just return an empty tensor. \r\n\r\nIn my view, `torch.diag` should succeed when `diagonal >= 2`.\r\n\r\n### ",
        "API Signature": "\n torch. diagonal ( input ,  offset ,  dim1 ,  dim2 )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71082",
        "Issue title": "`torch.combinations` will allocate large memory when `r` is greater than the length of input",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\n\n`torch.combinations` will malloc large memory when `r` is greater than the length of input. In fact, it will an empty tensor since `r` is greater than the length. Therefore, I think it should not allocate a very large memory.\r\n\r\n```python\r\nimport torch\r\ninput_tensor = torch.randint(-1,1,[3], dtype=torch.int64)\r\ninput = input_tensor.clone()\r\nr = 100\r\nprint(torch.combinations(input, r=r))\r\n# killed\r\n```\n\n### ",
        "API Signature": "\n torch. combinations ( input ,  r ,  with_replacement )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71078",
        "Issue title": "`torch.nn.{Constant,Zero}Pad` unexpectedly fail",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\n\n`torch.nn.{Constant,Zero}Pad` unexpectedly fail when trying to create a zero dimension tensor. Instead, `torch.nn.{Reflection,Replication}Pad` will succeed\r\n\r\n```\r\nimport torch\r\npadding = [-1, -2, 1, 1]\r\nc1 = torch.nn.ReflectionPad2d(padding)\r\nc2 = torch.nn.ReplicationPad2d(padding)\r\nc3 = torch.nn.ConstantPad2d(padding, 0)\r\nc4 = torch.nn.ZeroPad2d(padding)\r\ninput = torch.rand([1, 1, 3, 3], dtype=torch.float32)\r\n\r\nprint(c1(input))\r\nprint(c2(input))\r\nc3(input)\r\n# RuntimeError: The input size 3, plus negative padding -1 and -2 resulted in a negative output size, which is invalid. Check dimension 3 of your input.\r\nc4(input)\r\n# RuntimeError: The input size 3, plus negative padding -1 and -2 resulted in a negative output size, which is invalid. Check dimension 3 of your input.\r\n```\r\n\r\n3-3=0, it is not negative\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71078",
        "Issue title": "`torch.nn.{Constant,Zero}Pad` unexpectedly fail",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\n\n`torch.nn.{Constant,Zero}Pad` unexpectedly fail when trying to create a zero dimension tensor. Instead, `torch.nn.{Reflection,Replication}Pad` will succeed\r\n\r\n```\r\nimport torch\r\npadding = [-1, -2, 1, 1]\r\nc1 = torch.nn.ReflectionPad2d(padding)\r\nc2 = torch.nn.ReplicationPad2d(padding)\r\nc3 = torch.nn.ConstantPad2d(padding, 0)\r\nc4 = torch.nn.ZeroPad2d(padding)\r\ninput = torch.rand([1, 1, 3, 3], dtype=torch.float32)\r\n\r\nprint(c1(input))\r\nprint(c2(input))\r\nc3(input)\r\n# RuntimeError: The input size 3, plus negative padding -1 and -2 resulted in a negative output size, which is invalid. Check dimension 3 of your input.\r\nc4(input)\r\n# RuntimeError: The input size 3, plus negative padding -1 and -2 resulted in a negative output size, which is invalid. Check dimension 3 of your input.\r\n```\r\n\r\n3-3=0, it is not negative\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71059",
        "Issue title": "`torch.scatter` will return random value when `input` is empty tensor",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\n\n`torch.scatter` will return random value when `input` is empty tensor\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([])\r\ndim = 0\r\nindex = torch.tensor([]) # or torch.tensor([0])\r\nsrc = torch.rand([])\r\ntorch.scatter(input, dim, index, src)\r\n# random value like tensor(6.7333e+22)\r\n```\n\n### ",
        "API Signature": "\n torch. scatter ( input ,  dim ,  index ,  src )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/71058",
        "Issue title": "`torch.Tensor.where` cannot work when `y` is float",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\n\nBased on the [documentation](https://pytorch.org/docs/stable/generated/torch.Tensor.where.html?highlight=where#torch.Tensor.where) of `torch.Tensor.where`, `self.where(condition, y)` is equivalent to `torch.where(condition, self, y)`. However, `torch.where` will succeed when `y` is a float but `Tensor.where` will raise an error.\r\n\r\n```python\r\nimport torch\r\ncondition= torch.randint(0,2,[2, 2], dtype=torch.bool)\r\nx= torch.rand([2, 2], dtype=torch.float64)\r\ny = 0.0\r\nprint( torch.where(condition, x, y) )\r\n# tensor([[0.0000, 0.6290],\r\n#        [0.0000, 0.0000]], dtype=torch.float64)\r\nprint( x.where(condition, y) )\r\n# TypeError: where(): argument 'other' (position 2) must be Tensor, not float\r\n```\n\n### ",
        "API Signature": "\n torch. where ( condition ,  x ,  y )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/70901",
        "Issue title": "Accuracy problem of `torch.batch_norm_gather_stats_with_counts` when `running_mean` is half tensor",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\r\n\r\nIt looks like `n + count` in the `batch_norm_reduce_statistics_kernel` function may overflow when `count` is half type. For example:\r\n\r\n```python\r\nimport torch\r\ni = torch.rand([5,4,10,10], dtype=torch.float).cuda()\r\nc = torch.rand((150,), dtype=torch.half).fill_(500).cuda()\r\nm = torch.rand([150, 4], dtype=torch.float).cuda()\r\nrm = torch.rand([4], dtype=torch.half).cuda()\r\nv = torch.rand([150, 4], dtype=torch.float).cuda()\r\nv += 0.0001\r\nrv = torch.rand([4], dtype=torch.half).cuda()\r\nrv += 0.0001\r\nmea, inv = torch.batch_norm_gather_stats_with_counts(i, m, v, rm, rv, 1.2, 0.001, c)\r\nprint(mea)\r\n```\r\noutput :\r\n\r\n```python\r\n# The value of output tensor \"mea\" should not be zero. \r\ntensor([0., 0., 0., 0.], device='cuda:0')  \r\n```\r\nAm I right? This is easy to fix and I wouldn't mind submitting a PR to do so.\r\n\r\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/70672",
        "Issue title": "`torch.as_strided` can create a tensor with negative dimension",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\n\n`torch.as_strided` can create a tensor with negative dimension\r\n\r\n```python\r\nimport torch\r\na = torch.rand([3, 3])\r\nb = torch.as_strided(a, [1, -1], [1, 1])\r\nprint(b.shape)\r\n# torch.Size([1, -1])\r\n```\n\n### ",
        "API Signature": "\n torch. as_strided ( input ,  size ,  stride ,  storage_offset )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/70398",
        "Issue title": "`torch.broadcast_to` can create tensor with negative dimension.",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\r\n\r\n`torch.broadcast_to` can create tensor with negative dimension. Though it is a view of tensor, I think it should do the dimension check since tensor cannot have negative dimension.\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([3])\r\nshape = [-2, 3]\r\nres = torch.broadcast_to(input,shape,)\r\nprint(res.shape)\r\n# torch.Size([-2, 3])\r\nprint(torch.sum(res))\r\n# tensor(0.)\r\ntorch.all(res)\r\n# RuntimeError: Trying to create tensor with negative dimension -2: [-2, 3]\r\n```\r\n\r\nBy the way, `tensor.expand` also has the same issue.\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([3])\r\nshape = [-2, 3]\r\nres = input.expand(shape)\r\nprint(res.shape)\r\nprint(torch.sum(res))\r\ntorch.all(res)\r\n```\r\n\r\ncc @ezyang @gchanan @zou3519 @bdhirsh @mruberry @albanD @soulitzer \r\n\r\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/70398",
        "Issue title": "`torch.broadcast_to` can create tensor with negative dimension.",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\r\n\r\n`torch.broadcast_to` can create tensor with negative dimension. Though it is a view of tensor, I think it should do the dimension check since tensor cannot have negative dimension.\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([3])\r\nshape = [-2, 3]\r\nres = torch.broadcast_to(input,shape,)\r\nprint(res.shape)\r\n# torch.Size([-2, 3])\r\nprint(torch.sum(res))\r\n# tensor(0.)\r\ntorch.all(res)\r\n# RuntimeError: Trying to create tensor with negative dimension -2: [-2, 3]\r\n```\r\n\r\nBy the way, `tensor.expand` also has the same issue.\r\n\r\n```python\r\nimport torch\r\ninput = torch.rand([3])\r\nshape = [-2, 3]\r\nres = input.expand(shape)\r\nprint(res.shape)\r\nprint(torch.sum(res))\r\ntorch.all(res)\r\n```\r\n\r\ncc @ezyang @gchanan @zou3519 @bdhirsh @mruberry @albanD @soulitzer \r\n\r\n### ",
        "API Signature": "\n torch. broadcast_to ( input ,  shape )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/70397",
        "Issue title": "`torch.empty_strided` works when the stride is negative!",
        "Bug description": "\n\nnn.MultiheadAttention cannot be correctly compiled by torch.jit.script when kdim and vdim are specified. Minimum ",
        "Sample Code": "\r\n\r\n`torch.empty_strided` works when the stride is negative! We can get the shape or even `torch.sum` the result tensor. But when we try printing the result tensor, it fails.\r\n\r\n```python\r\nimport torch\r\nsize = [2, 3]\r\nstride = [-1, 2]\r\nres = torch.empty_strided(size,stride,)\r\nprint(torch.sum(res))\r\n# tensor(nan)\r\nprint(res.shape)\r\n# torch.Size([2, 3])\r\nprint(res)\r\n# RuntimeError: setStorage: sizes [6], strides [2], storage offset 0, and itemsize 4 requiring a storage size of 44 are out of bounds for storage of size 16\r\n```\r\n\r\n### ",
        "API Signature": "\n torch. empty_strided ( size ,  stride ,  * ,  dtype ,  layout ,  device ,  requires_grad ,  pin_memory )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/69433",
        "Issue title": "`torch.transpose` should raise an error when indexing 0 for 0 dimensional tensor.",
        "Bug description": "\r\n\r\n`torch.transpose` should raise an error when indexing 0 for 0 dimensional tensor. Because you cannot index 0 for a 0 dimensional tensor.\r\n\r\n## To Reproduce\r\n\r\n```python\r\nimport torch\r\ntensor = torch.rand(torch.Size([]))\r\nres1 = torch.transpose(tensor, 0, 0)\r\n```\r\nIt will succeed. But when you index 0 for this tensor it will fail\r\n```\r\ntensor[0]\r\n# IndexError: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n```python\r\nimport torch\r\ntensor = torch.rand(torch.Size([]))\r\nres1 = torch.transpose(tensor, 0, 0)\r\n```\r\nIt will succeed. But when you index 0 for this tensor it will fail\r\n```\r\ntensor[0]\r\n# Index",
        "API Signature": "\n torch. transpose ( input ,  dim0 ,  dim1 )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/69408",
        "Issue title": "`torch.hstack` should raise an error when tensor is 0 dimensional",
        "Bug description": "\r\n\r\n`torch.hstack` should raise an error when tensor is 0 dimensional like `torch.cat` based on the document that \"This is equivalent to concatenation along the first axis for 1-D tensors, and along the second axis for all other tensors.\"\r\n\r\n## To Reproduce\r\n\r\n```python\r\nimport torch\r\ntensor_0 = torch.rand(torch.Size([]))\r\ntensor_1 = torch.rand(torch.Size([3]))\r\ntensors = [tensor_0, tensor_1]\r\nres1 = torch.hstack(tensors)\r\n# succeed\r\nres2 = torch.cat(tensors, dim=0)\r\n# RuntimeError: zero-dimensional tensor (at position 0) cannot be concatenated\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n```python\r\nimport torch\r\ntensor_0 = torch.rand(torch.Size([]))\r\ntensor_1 = torch.rand(torch.Size([3]))\r\ntensors = [tensor_0, tensor_1]\r\nres1 = torch.hstack(tensors)\r\n# succeed\r\nres2 = torch.cat(tensors, dim=0)\r\n# Runtime",
        "API Signature": "\n torch. hstack ( tensors ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/68610",
        "Issue title": "`torch.unique_consecutive`: passing positional optional arguments results in empty tensors",
        "Bug description": "\r\n\r\nPassing `True` for either `return_inverse` or `return_counts` (but not both!) as **a positional argument** to `torch.unique_consecutive` results in an empty second return value.\r\n\r\n",
        "Sample Code": "\r\n\r\n``` python3\r\n>>> torch.unique_consecutive(torch.ones(5), True)\r\n(tensor([1.]), tensor([], dtype=torch.int64))\r\n>>> torch.unique_consecutive(torch.ones(5), False, True)\r\n(tensor([1.]), tensor([], dtype=torch.int64))\r\n```\r\n",
        "API Signature": "\n torch. unique_consecutive ( * ,  ** ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/67081",
        "Issue title": "DLPack no longer works on Boolean tensors after 1.10+",
        "Bug description": "\r\n\r\n`torch.utils.dlpack.to_dlpack` no longer works for Boolean Tensor.\r\n\r\n## To Reproduce\r\n\r\n```python\r\ntorch.utils.dlpack.to_dlpack(torch.BoolTensor([False, True]))   # Bool type is not supported by dlpack\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n```python\r\ntorch.utils.dlpack.to_dlpack(torch.BoolTensor([False, True]))   # Bool type is not supported by dlpack\r\n```\r\n\r\n## Expected behavior\r\n\r\nShould work.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.10 RC and nightly\r\n - OS (e.g., Linux): Linux\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.8.3\r\n - CUDA/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/65683",
        "Issue title": "`torch.nn.functional.l1_loss` fails gradgradcheck for complex inputs",
        "Bug description": "\r\n\r\n`torch.utils.dlpack.to_dlpack` no longer works for Boolean Tensor.\r\n\r\n## To Reproduce\r\n\r\n```python\r\ntorch.utils.dlpack.to_dlpack(torch.BoolTensor([False, True]))   # Bool type is not supported by dlpack\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n```python\r\ntorch.utils.dlpack.to_dlpack(torch.BoolTensor([False, True]))   # Bool type is not supported by dlpack\r\n```\r\n\r\n## Expected behavior\r\n\r\nShould work.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.10 RC and nightly\r\n - OS (e.g., Linux): Linux\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.8.3\r\n - CUDA/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n## ",
        "API Signature": "\n torch.nn.functional. l1_loss ( input ,  target ,  size_average ,  reduce ,  reduction )   \u2192 [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/65400",
        "Issue title": "torch.sparse.sum on scalar sparse tensor fails when dim is specified",
        "Bug description": "\r\n\r\nAs in the title.\r\n\r\n## To Reproduce\r\n\r\n```python\r\n>>> import torch\r\n>>> t = torch.tensor(1).to_sparse()\r\n>>> torch.sparse.sum(t, dim=0)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/pearu/git/pearu/pytorch/torch/sparse/__init__.py\", line 152, in sum\r\n    return torch._sparse_sum(input, dim)\r\nRuntimeError: Trying to create tensor with negative dimension -1: [-1, 1]\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n```python\r\n>>> import torch\r\n>>> t = torch.tensor(1).to_sparse()\r\n>>> torch.sparse.sum(t, dim=0)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/pearu/git/pearu/pytorch/torch/sparse/__init__.py\", line 152, in sum\r\n    return torch._sparse_sum(input, dim)\r\nRuntimeError: Trying to create tensor with negative dimension -1: [-1, 1]\r\n```\r\n\r\n## Expected behavior\r\n\r\ntorch.sparse.sum should not fail on scalar input (see additional context):\r\n```python\r\n>>> torch.sparse.sum(t, dim=0)\r\ntensor(1)\r\n```\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): 1.10.0a0\r\n\r\n## ",
        "API Signature": "\n torch.sparse. sum ( input ,  dim ,  dtype ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/65050",
        "Issue title": "torch.cross precision problem",
        "Bug description": "\r\n\r\n`torch.cross` can encounter precision problem when two input vectors are the same.\r\n\r\n## To Reproduce\r\n\r\nThe following code can reproduce the problem.\r\n\r\n```python\r\na = torch.Tensor([0.7533, 0.6123, -0.2404])\r\nb = torch.Tensor([0.7533, 0.6123, -0.2404])\r\nc = torch.cross(a, b)\r\nprint(c)\r\n```\r\n\r\nThe output is:\r\n\r\n```python\r\ntensor([ 2.9772e-09, -3.4915e-09, 1.4205e-08])\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\nThe following code can reproduce the problem.\r\n\r\n```python\r\na = torch.Tensor([0.7533, 0.6123, -0.2404])\r\nb = torch.Tensor([0.7533, 0.6123, -0.2404])\r\nc = torch.cross(a, b)\r\nprint(c)\r\n```\r\n\r\nThe output is:\r\n\r\n```python\r\ntensor([ 2.9772e-09, -3.4915e-09, 1.4205e-08])\r\n```\r\n\r\n## ",
        "API Signature": "\n torch. cross ( input ,  other ,  dim ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/64978",
        "Issue title": "ONNX export of torch.nn.functional.linear with weight dimension 1",
        "Bug description": "\r\ntorch.nn.functional.linear function doesn't validate weight dimension == 2. \r\nIt only asserts  weight.t() expects a tensor with <= 2 dimension.\r\n\r\nFrom doc: https://pytorch.org/docs/stable/generated/torch.nn.functional.linear.html#torch.nn.functional.linear\r\n```\r\n Weight: (out_features,in_features)\r\n```\r\n\r\nFor example, it works with weight 1-d\r\n```\r\n>>> import torch\r\n>>> a = torch.ones([1,1,10])\r\n>>> b = torch.ones([10])   # weight is 1-d\r\n>>> c = torch.nn.functional.linear(a, b)\r\n>>> c\r\ntensor([[10.]])\r\n```\r\nBut, **onnx.export** is fail on torch v1.9.0, otherwise torch v1.8.0 ~ v1.4.0 works. \r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nclass Net(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n\r\n    def forward(self, a):\r\n        b = torch.ones([10])\r\n        return F.linear(a, b)\r\n\r\nnet = Net()\r\na = torch.ones([1,1,10])\r\nout = net(a)\r\nprint(out)\r\ntorch.onnx.export(net, (a,), \"tmp.onnx\")\r\n```\r\n\r\nstdout:\r\n```\r\ntensor([[10.]])\r\n[W shape_type_inference.cpp:419] Warning: Constant folding in symbolic shape inference fails: number of dims don't match in permute\r\nException raised from permute at /pytorch/aten/src/ATen/native/TensorShape.cpp:934 (most recent call first):\r\nframe #0: c10::",
        "API Signature": "\n torch.nn.functional. linear ( input ,  weight ,  bias )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/64079",
        "Issue title": "torch.equal does not support sparse tensors",
        "Bug description": "\r\n\r\ntorch.equal(input,other) does not support sparse tensors.\r\n\r\n## To Reproduce\r\n\r\n```python\r\nif __name__ == \"__main__\":\r\n    x = torch.rand(4, 4).to_sparse()\r\n    assert torch.equal(x, x)\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"benchmarks/distributed/rpc/parameter_server/test.py\", line 82, in <module>\r\n    assert torch.equal(x, y)\r\nNotImplementedError: Could not run 'aten::equal' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::equal' is only available for these backends: [CPU, CUDA, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\r\n\r\nCPU: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterCPU.cpp:22545 [kernel]\r\nCUDA: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterCUDA.cpp:30514 [kernel]\r\nQuantizedCPU: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:1060 [kernel]\r\nBackendSelect: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\r\nPython: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:38 [backend fallback]\r\nNamed: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\r\nConjugate: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/ConjugateFallback.cpp:26 [backend fallback]\r\nNegative: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/native/NegateFallback.cpp:26 [backend fallback]\r\nADInplaceOrView: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\r\nAutogradOther: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradCPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradCUDA: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradXLA: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradLazy: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradXPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradMLC: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradHPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradNestedTensor: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse1: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse2: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse3: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nTracer: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:11391 [kernel]\r\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/autocast_mode.cpp:455 [backend fallback]\r\nAutocast: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/autocast_mode.cpp:294 [backend fallback]\r\nBatched: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\r\nVmapMode: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\n```\r\n\r\n```python\r\nif __name__ == \"__main__\":\r\n    x = torch.rand(4, 4).to_sparse_csr()\r\n    assert torch.equal(x, x)\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 81, in <module>\r\n    assert torch.equal(x, x)\r\nNotImplementedError: Could not run 'aten::equal' with arguments from the 'SparseCsrCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::equal' is only available for these backends: [CPU, CUDA, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\r\n\r\nCPU: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterCPU.cpp:22545 [kernel]\r\nCUDA: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterCUDA.cpp:30514 [kernel]\r\nQuantizedCPU: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:1060 [kernel]\r\nBackendSelect: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\r\nPython: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:38 [backend fallback]\r\nNamed: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\r\nConjugate: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/ConjugateFallback.cpp:26 [backend fallback]\r\nNegative: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/native/NegateFallback.cpp:26 [backend fallback]\r\nADInplaceOrView: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\r\nAutogradOther: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradCPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradCUDA: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradXLA: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradLazy: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradXPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradMLC: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradHPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradNestedTensor: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse1: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse2: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse3: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nTracer: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:11391 [kernel]\r\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/autocast_mode.cpp:455 [backend fallback]\r\nAutocast: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/autocast_mode.cpp:294 [backend fallback]\r\nBatched: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\r\nVmapMode: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n```python\r\nif __name__ == \"__main__\":\r\n    x = torch.rand(4, 4).to_sparse()\r\n    assert torch.equal(x, x)\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"benchmarks/distributed/rpc/parameter_server/test.py\", line 82, in <module>\r\n    assert torch.equal(x, y)\r\nNotImplementedError: Could not run 'aten::equal' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::equal' is only available for these backends: [CPU, CUDA, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\r\n\r\nCPU: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterCPU.cpp:22545 [kernel]\r\nCUDA: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterCUDA.cpp:30514 [kernel]\r\nQuantizedCPU: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:1060 [kernel]\r\nBackendSelect: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\r\nPython: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:38 [backend fallback]\r\nNamed: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\r\nConjugate: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/ConjugateFallback.cpp:26 [backend fallback]\r\nNegative: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/native/NegateFallback.cpp:26 [backend fallback]\r\nADInplaceOrView: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\r\nAutogradOther: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradCPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradCUDA: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradXLA: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradLazy: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradXPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradMLC: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradHPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradNestedTensor: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse1: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse2: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse3: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nTracer: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:11391 [kernel]\r\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/autocast_mode.cpp:455 [backend fallback]\r\nAutocast: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/autocast_mode.cpp:294 [backend fallback]\r\nBatched: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\r\nVmapMode: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\n```\r\n\r\n```python\r\nif __name__ == \"__main__\":\r\n    x = torch.rand(4, 4).to_sparse_csr()\r\n    assert torch.equal(x, x)\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 81, in <module>\r\n    assert torch.equal(x, x)\r\nNotImplementedError: Could not run 'aten::equal' with arguments from the 'SparseCsrCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::equal' is only available for these backends: [CPU, CUDA, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\r\n\r\nCPU: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterCPU.cpp:22545 [kernel]\r\nCUDA: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterCUDA.cpp:30514 [kernel]\r\nQuantizedCPU: registered at /fsx/users/gcramer/work/pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:1060 [kernel]\r\nBackendSelect: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\r\nPython: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:38 [backend fallback]\r\nNamed: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\r\nConjugate: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/ConjugateFallback.cpp:26 [backend fallback]\r\nNegative: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/native/NegateFallback.cpp:26 [backend fallback]\r\nADInplaceOrView: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\r\nAutogradOther: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradCPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradCUDA: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradXLA: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradLazy: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradXPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradMLC: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradHPU: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradNestedTensor: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse1: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse2: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nAutogradPrivateUse3: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12635 [autograd kernel]\r\nTracer: registered at /fsx/users/gcramer/work/pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:11391 [kernel]\r\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/autocast_mode.cpp:455 [backend fallback]\r\nAutocast: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/autocast_mode.cpp:294 [backend fallback]\r\nBatched: registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\r\nVmapMode: fallthrough registered at /fsx/users/gcramer/work/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\n```\r\n\r\n## Expected behavior\r\n\r\ntorch.equal(input, other) evaluates the sparse tensors and returns a result.\r\n\r\n## Environment\r\n\r\n```\r\nCollecting environment information...\r\nPyTorch version: 1.10.0a0+git6f899c1\r\nIs debug build: False\r\nCUDA used to build PyTorch: 11.1\r\nROCM used to build PyTorch: N/A\r\n\r\nOS: Ubuntu 18.04.5 LTS (x86_64)\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nClang version: Could not collect\r\nCMake version: version 3.21.1\r\n\r\nPython version: 3.6 (64-bit runtime)\r\nIs CUDA available: True\r\nCUDA runtime version: 11.1.105\r\nGPU models and configuration: \r\nGPU 0: A100-SXM4-40GB\r\nGPU 1: A100-SXM4-40GB\r\nGPU 2: A100-SXM4-40GB\r\nGPU 3: A100-SXM4-40GB\r\nGPU 4: A100-SXM4-40GB\r\nGPU 5: A100-SXM4-40GB\r\nGPU 6: A100-SXM4-40GB\r\nGPU 7: A100-SXM4-40GB\r\n\r\nNvidia driver version: 450.119.03\r\ncuDNN version: Probably one of the following:\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudnn.so.7.6.5\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn.so.7.6.5\r\n/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudnn.so.8.0.5\r\n/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8.0.5\r\n/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudnn_adv_train.so.8.0.5\r\n/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8.0.5\r\n/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8.0.5\r\n/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8.0.5\r\n/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudnn_ops_train.so.8.0.5\r\n/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn.so.8.0.5\r\n/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8.0.5\r\n/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_adv_train.so.8.0.5\r\n/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8.0.5\r\n/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8.0.5\r\n/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8.0.5\r\n/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_ops_train.so.8.0.5\r\nHIP runtime version: N/A\r\nMIOpen runtime version: N/A\r\n```\r\n\r\n## ",
        "API Signature": "\n torch. equal ( input ,  other )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/59439",
        "Issue title": "NaN values on torch.nn.functional.conv2d (aarch64)",
        "Bug description": "\r\nNaN values randomly introduced on torch.nn.functional.conv2d\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nimport torch\r\nimport torch.nn.functional as F\r\nF.conv2d(torch.ones(1,3,160,240).cpu(), torch.ones(1,3,3,3).cpu())\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nimport torch\r\nimport torch.nn.functional as F\r\nF.conv2d(torch.ones(1,3,160,240).cpu(), torch.ones(1,3,3,3).cpu())\r\n```\r\n\r\n## ",
        "API Signature": "\n torch.nn.functional. conv2d ( input ,  weight ,  bias ,  stride ,  padding ,  dilation ,  groups )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/54638",
        "Issue title": "torch.jit.trace() fails on a GCN with sparse inputs and dense layers",
        "Bug description": " of what the bug is. -->\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Construct a basic gcn (example code below)\r\n```\r\nimport torch\r\n\r\n### LAYER and GCN DEFINITION\r\n\r\nclass HiddenLayerSparse(torch.nn.Module):\r\n    def __init__(self, dimf_in, dimf_out):\r\n        super().__init__()\r\n        self.weights = torch.nn.Parameter(torch.rand(dimf_in, dimf_out, dtype=float))\r\n\r\n    def forward(self, adj, x):\r\n        x = torch.mm(x, self.weights)\r\n        x = torch.mm(adj, x)\r\n        return x\r\n\r\nclass ExampleSparseGCN(torch.nn.Module):\r\n    def __init__(self, sizes):\r\n        super().__init__()\r\n        self.sizes = sizes\r\n        self.hidden_layers = torch.nn.ModuleList([HiddenLayerSparse(sizes[i], sizes[i+1]) for i in range(len(sizes)-1)])\r\n        self.nonlinear = torch.nn.ReLU()\r\n        self.softmax = torch.nn.Softmax(dim=1)\r\n\r\n    def forward(self, adj, x):\r\n        for h in self.hidden_layers:\r\n            x = self.nonlinear(h(adj, x))\r\n        return self.softmax(x)\r\n\r\n### EXAMPLE SPARSE INPUTS\r\n\r\nadjacency = torch.tensor([[1,0],[0,1]], dtype=float).to_sparse()\r\nfeatures = torch.tensor([[1,0,0,1,0],[0,1,0,0,1]],dtype=float).to_sparse()\r\nlabels = torch.tensor([[1,0,0], [0,1,0]],dtype=float)\r\ninputs = (adjacency, features)\r\n\r\nmodel = ExampleSparseGCN([5, 4, 3]) # training does not fail with [5,3]\r\nloss_fn =  torch.nn.L1Loss()\r\noptimizer = torch.optim.SGD(model.parameters(), lr=0.05)\r\n\r\n_train = False      # FLAG TO ENABLE TRAINING\r\n_trace = True      # FLAG TO ENABLE TRACING\r\n\r\n# TRAINING \r\nif _train:\r\n    model.train()\r\n    for t in range(50):\r\n        optimizer.zero_grad()\r\n        output = model(*inputs)\r\n        loss = loss_fn(output, labels)\r\n        loss.backward()\r\n        optimizer.step() \r\n    print('Train Complete')\r\n\r\n# TRACING\r\nif _trace:\r\n    model.eval()\r\n    with torch.no_grad():\r\n        #torch.onnx.export(model, inputs, path, do_constant_folding=True, verbose=True, export_params=True)\r\n        traced = torch.jit.trace(model, inputs)\r\n    print('Trace Complete')\r\n```\r\n2. Attempt to trace a model without training. (`python example.py`)\r\n3. Attempt to trace a model with training (set `_train = True`)\r\n\r\nAny GCN with sparse inputs **or** dense inputs with `torch.sparse.mm` fails to trace. Using `torch.sparse.mm` breaks training with exception:\r\n```\r\nTraceback (most recent call last):\r\n  File \".\\minimum_example.py\", line 46, in <module>\r\n    loss.backward()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\", line 221, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 130, in backward\r\n    Variable._execution_engine.run_backward(\r\nRuntimeError: sparse_.is_sparse() INTERNAL ASSERT FAILED at \"..\\\\torch\\\\csrc\\\\autograd\\\\FunctionsManual.cpp\":560, please report a bug to PyTorch.\r\n```\r\n\r\n## Expected behavior\r\n\r\nI expect the model to train and trace without triggering any exceptions using `torch.sparse.mm`. Currently tracing always fails, and using `torch.sparse.mm` causes training to fail in the backward pass (which can be alleviated by using `torch.mm`.)\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 1.7.1+cpu\r\nIs debug build: False\r\nCUDA used to build PyTorch: Could not collect\r\nROCM used to build PyTorch: N/A\r\n\r\nOS: Microsoft Windows 10 Education\r\nGCC version: Could not collect\r\nClang version: Could not collect\r\nCMake version: Could not collect\r\n\r\nPython version: 3.8 (64-bit runtime)\r\nIs CUDA available: False\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce RTX 2070\r\nNvidia driver version: 456.71\r\ncuDNN version: Could not collect\r\nHIP runtime version: N/A\r\nMIOpen runtime version: N/A\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.5\r\n[pip3] numpydoc==1.1.0\r\n[pip3] torch==1.7.1\r\n[conda] blas                      1.0                         mkl\r\n[conda] mkl                       2020.1                      216\r\n[conda] mkl-service               2.3.0            py38hb782905_0\r\n[conda] mkl_fft                   1.1.0            py38h45dec08_0\r\n[conda] mkl_random                1.1.1            py38h47e9c7a_0\r\n[conda] numpy                     1.18.5           py38h6530119_0\r\n[conda] numpy-base                1.18.5           py38hc3f5095_0\r\n[conda] numpydoc                  1.1.0                      py_0\r\n[conda] torch                     1.7.1                    pypi_0    pypi\r\n```\r\n\r\n## Additional context\r\n\r\nPlease let me know if more context/information/support is needed from my end.\r\n\n\ncc @gmagogsfm",
        "Sample Code": "**.\r\n\r\nTracing gives the following warnings:\r\n```\r\n[W pybind_utils.h:521] Warning: Using sparse tensors in TorchScript is experimental. Many optimization pathways have not been thoroughly tested with sparse tensors. Please include the fact that the network is running sparse tensors in any bug reports submitted. (function operator ())\r\n[W pybind_utils.h:851] Warning: Using sparse tensors in TorchScript is experimental. Many optimization pathways have not been thoroughly tested with sparse tensors. Please include the fact that the network is running sparse tensors in any bug reports submitted. (function operator ())\r\n```\r\nbefore failing with the following exception:\r\n```\r\nTraceback (most recent call last):\r\n  File \".\\minimum_example.py\", line 55, in <module>\r\n    traced = torch.jit.trace(model, inputs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\_trace.py\", line 733, in trace\r\n    return trace_module(\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\_trace.py\", line 958, in trace_module\r\n    _check_trace(\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 26, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\_trace.py\", line 327, in _check_trace\r\n    copied_dict[name] = _clone_inputs(data)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\_trace.py\", line 158, in _clone_inputs\r\n    return function._nested_map(\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\function.py\", line 282, in _map\r\n    return type(obj)(mapped)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\function.py\", line 278, in <genexpr>\r\n    mapped = (_map(x) for x in obj)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\function.py\", line 274, in _map\r\n    return fn(obj)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\_trace.py\", line 148, in clone_input\r\n    a.detach()\r\nRuntimeError: unsupported memory format option Preserve\r\n```\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Construct a basic gcn (example code below)\r\n```\r\nimport torch\r\n\r\n### LAYER and GCN DEFINITION\r\n\r\nclass HiddenLayerSparse(torch.nn.Module):\r\n    def __init__(self, dimf_in, dimf_out):\r\n        super().__init__()\r\n        self.weights = torch.nn.Parameter(torch.rand(dimf_in, dimf_out, dtype=float))\r\n\r\n    def forward(self, adj, x):\r\n        x = torch.mm(x, self.weights)\r\n        x = torch.mm(adj, x)\r\n        return x\r\n\r\nclass ExampleSparseGCN(torch.nn.Module):\r\n    def __init__(self, sizes):\r\n        super().__init__()\r\n        self.sizes = sizes\r\n        self.hidden_layers = torch.nn.ModuleList([HiddenLayerSparse(sizes[i], sizes[i+1]) for i in range(len(sizes)-1)])\r\n        self.nonlinear = torch.nn.ReLU()\r\n        self.softmax = torch.nn.Softmax(dim=1)\r\n\r\n    def forward(self, adj, x):\r\n        for h in self.hidden_layers:\r\n            x = self.nonlinear(h(adj, x))\r\n        return self.softmax(x)\r\n\r\n### EXAMPLE SPARSE INPUTS\r\n\r\nadjacency = torch.tensor([[1,0],[0,1]], dtype=float).to_sparse()\r\nfeatures = torch.tensor([[1,0,0,1,0],[0,1,0,0,1]],dtype=float).to_sparse()\r\nlabels = torch.tensor([[1,0,0], [0,1,0]],dtype=float)\r\ninputs = (adjacency, features)\r\n\r\nmodel = ExampleSparseGCN([5, 4, 3]) # training does not fail with [5,3]\r\nloss_fn =  torch.nn.L1Loss()\r\noptimizer = torch.optim.SGD(model.parameters(), lr=0.05)\r\n\r\n_train = False      # FLAG TO ENABLE TRAINING\r\n_trace = True      # FLAG TO ENABLE TRACING\r\n\r\n# TRAINING \r\nif _train:\r\n    model.train()\r\n    for t in range(50):\r\n        optimizer.zero_grad()\r\n        output = model(*inputs)\r\n        loss = loss_fn(output, labels)\r\n        loss.backward()\r\n        optimizer.step() \r\n    print('Train Complete')\r\n\r\n# TRACING\r\nif _trace:\r\n    model.eval()\r\n    with torch.no_grad():\r\n        #torch.onnx.export(model, inputs, path, do_constant_folding=True, verbose=True, export_params=True)\r\n        traced = torch.jit.trace(model, inputs)\r\n    print('Trace Complete')\r\n```\r\n2. Attempt to trace a model without training. (`python example.py`)\r\n3. Attempt to trace a model with training (set `_train = True`)\r\n\r\nAny GCN with sparse inputs **or** dense inputs with `torch.sparse.mm` fails to trace. Using `torch.sparse.mm` breaks training with exception:\r\n```\r\nTraceback (most recent call last):\r\n  File \".\\minimum_example.py\", line 46, in <module>\r\n    loss.backward()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\", line 221, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 130, in backward\r\n    Variable._execution_engine.run_backward(\r\nRuntimeError: sparse_.is_sparse() INTERNAL ASSERT FAILED at \"..\\\\torch\\\\csrc\\\\autograd\\\\FunctionsManual.cpp\":560, please report a bug to PyTorch.\r\n```\r\n\r\n## Expected behavior\r\n\r\nI expect the model to train and trace without triggering any exceptions using `torch.sparse.mm`. Currently tracing always fails, and using `torch.sparse.mm` causes training to fail in the backward pass (which can be alleviated by using `torch.mm`.)\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 1.7.1+cpu\r\nIs debug build: False\r\nCUDA used to build PyTorch: Could not collect\r\nROCM used to build PyTorch: N/A\r\n\r\nOS: Microsoft Windows 10 Education\r\nGCC version: Could not collect\r\nClang version: Could not collect\r\nCMake version: Could not collect\r\n\r\nPython version: 3.8 (64-bit runtime)\r\nIs CUDA available: False\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce RTX 2070\r\nNvidia driver version: 456.71\r\ncuDNN version: Could not collect\r\nHIP runtime version: N/A\r\nMIOpen runtime version: N/A\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.5\r\n[pip3] numpydoc==1.1.0\r\n[pip3] torch==1.7.1\r\n[conda] blas                      1.0                         mkl\r\n[conda] mkl                       2020.1                      216\r\n[conda] mkl-service               2.3.0            py38hb782905_0\r\n[conda] mkl_fft                   1.1.0            py38h45dec08_0\r\n[conda] mkl_random                1.1.1            py38h47e9c7a_0\r\n[conda] numpy                     1.18.5           py38h6530119_0\r\n[conda] numpy-base                1.18.5           py38hc3f5095_0\r\n[conda] numpydoc                  1.1.0                      py_0\r\n[conda] torch                     1.7.1                    pypi_0    pypi\r\n```\r\n\r\n## ",
        "API Signature": "\n torch.jit. trace ( func ,  example_inputs ,  optimize=None ,  check_trace=True ,  check_inputs=None ,  check_tolerance=1e-05 ,  strict=True ,  _force_outplace=False ,  _module_class=None ,  _compilation_unit=<torch.jit.CompilationUnit ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/54620",
        "Issue title": "torch.pow(tensor, tensor) throws RuntimeError for dtype bool ",
        "Bug description": "\r\n\r\n`torch.pow(tensor, tensor)` doesn't work for dtype `bool`, although its method variant works.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Try `torch.pow(tensor, tensor)` for `bool` tensor.\r\n2. On CPU, the runtime error is:\r\n   `RuntimeError: \"pow\" not implemented for 'Bool'`.\r\n   On CUDA, the runtime error is:\r\n  `RuntimeError: \"pow_cuda\" not implemented for 'Bool'`\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Try `torch.pow(tensor, tensor)` for `bool` tensor.\r\n2. On CPU, the runtime error is:\r\n   `Runtime",
        "API Signature": "\n torch. pow ( input ,  exponent ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/54499",
        "Issue title": "Caught an integer overflow or wraparound in torch.nn.MaxPool1d",
        "Bug description": "\r\n\r\nThe `MaxPool1d` takes an integer as its first argument. However, when I pass a big number to this function, I got an Runtime Errror. This error is quit normal but the log is interesting.\r\n`RuntimeError: Given input size: (16x1x50). Calculated output size: (16x1x-272823246). Output size is too small`\r\nthe calculated out put size, has a negative number. I think it meets an integer overflow. But I can't figure out what function going wrong right now.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n`import torch `\r\n`m=torch.nn.MaxPool1d(545646544,stride=2)`\r\n`input=input=torch.randn(20,16,50)`.\r\n`m(input)`\r\n\r\nthen I got the runtime error.\r\n`Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 651, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/modules/pooling.py\", line 76, in forward\r\n    self.return_indices)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/_jit_internal.py\", line 209, in fn\r\n    return if_false(*args, **kwargs)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/functional.py\", line 496, in _max_pool1d\r\n    input, kernel_size, stride, padding, dilation, ceil_mode)\r\nRuntimeError: Given input size: (16x1x50). Calculated output size: (16x1x-272823246). Output size is too small\r\n`\r\n\r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n`import torch `\r\n`m=torch.nn.MaxPool1d(545646544,stride=2)`\r\n`input=input=torch.randn(20,16,50)`.\r\n`m(input)`\r\n\r\nthen I got the runtime error.\r\n`Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 651, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/modules/pooling.py\", line 76, in forward\r\n    self.return_indices)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/_jit_internal.py\", line 209, in fn\r\n    return if_false(*args, **kwargs)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/functional.py\", line 496, in _max_pool1d\r\n    input, kernel_size, stride, padding, dilation, ceil_mode)\r\nRuntime",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/53407",
        "Issue title": "torch.matmul doesn't handle zero-sized inputs in some cases, leading to batched grad failures",
        "Bug description": "\r\n\r\nI am getting the following error when running batched grad and gradgrad checks through OpInfo with empty input tensors\r\n\r\n```\r\nRuntimeError: While computing batched gradients, got: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n`import torch `\r\n`m=torch.nn.MaxPool1d(545646544,stride=2)`\r\n`input=input=torch.randn(20,16,50)`.\r\n`m(input)`\r\n\r\nthen I got the runtime error.\r\n`Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 651, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/modules/pooling.py\", line 76, in forward\r\n    self.return_indices)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/_jit_internal.py\", line 209, in fn\r\n    return if_false(*args, **kwargs)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/functional.py\", line 496, in _max_pool1d\r\n    input, kernel_size, stride, padding, dilation, ceil_mode)\r\nRuntime",
        "API Signature": "\n torch. matmul ( input ,  other ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/53391",
        "Issue title": "torch.empty_strided doesn't test if strides are negative",
        "Bug description": "\r\n\r\nI am getting the following error when running batched grad and gradgrad checks through OpInfo with empty input tensors\r\n\r\n```\r\nRuntimeError: While computing batched gradients, got: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n`import torch `\r\n`m=torch.nn.MaxPool1d(545646544,stride=2)`\r\n`input=input=torch.randn(20,16,50)`.\r\n`m(input)`\r\n\r\nthen I got the runtime error.\r\n`Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 651, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/modules/pooling.py\", line 76, in forward\r\n    self.return_indices)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/_jit_internal.py\", line 209, in fn\r\n    return if_false(*args, **kwargs)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/functional.py\", line 496, in _max_pool1d\r\n    input, kernel_size, stride, padding, dilation, ceil_mode)\r\nRuntime",
        "API Signature": "\n torch. empty_strided ( size ,  stride ,  * ,  dtype ,  layout ,  device ,  requires_grad ,  pin_memory )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/53358",
        "Issue title": "[bug] torch.cumsum: behaviour for `bool` input",
        "Bug description": "\r\n\r\nI am getting the following error when running batched grad and gradgrad checks through OpInfo with empty input tensors\r\n\r\n```\r\nRuntimeError: While computing batched gradients, got: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n`import torch `\r\n`m=torch.nn.MaxPool1d(545646544,stride=2)`\r\n`input=input=torch.randn(20,16,50)`.\r\n`m(input)`\r\n\r\nthen I got the runtime error.\r\n`Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 651, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/modules/pooling.py\", line 76, in forward\r\n    self.return_indices)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/_jit_internal.py\", line 209, in fn\r\n    return if_false(*args, **kwargs)\r\n  File \"/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/functional.py\", line 496, in _max_pool1d\r\n    input, kernel_size, stride, padding, dilation, ceil_mode)\r\nRuntime",
        "API Signature": "\n torch. cumsum ( input ,  dim ,  * ,  dtype ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/51911",
        "Issue title": "torch.nn.functional.grid_sample outputs NaN",
        "Bug description": "\r\n\r\n`torch.nn.functional.grid_sample` outputs NaN if `grid` contains large value\r\n\r\n## To Reproduce\r\n~~~python\r\nimport torch\r\ntorch.nn.functional.grid_sample(input=torch.ones([1,1,1,5]), grid=torch.tensor([[[[ 2.9839e+38, -3.2406e+38]]]]))\r\n~~~\r\n\r\nOutput:\r\n~~~python\r\ntensor([[[[nan]]]])\r\n~~~\r\n## ",
        "Sample Code": "\r\n~~~python\r\nimport torch\r\ntorch.nn.functional.grid_sample(input=torch.ones([1,1,1,5]), grid=torch.tensor([[[[ 2.9839e+38, -3.2406e+38]]]]))\r\n~~~\r\n\r\n",
        "API Signature": "\n torch.nn.functional. grid_sample ( input ,  grid ,  mode ,  padding_mode ,  align_corners ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/51906",
        "Issue title": "torch.nn.functional.binary_cross_entropy(_with_logits) outputs NaN",
        "Bug description": "\r\n\r\n`torch.nn.functional.binary_cross_entropy_with_logits` outputs NaN when input is empty or large\r\n`torch.nn.functional.binary_cross_entropy` outputs NaN when input is empty\r\n\r\n\r\n## To Reproduce\r\n~~~python\r\nimport torch\r\ntorch.nn.functional.binary_cross_entropy(input=torch.tensor([]), target=torch.tensor([]))\r\n~~~\r\nOutput:\r\n~~~python\r\ntensor(nan)\r\n~~~\r\n\r\n~~~python\r\nimport torch\r\ntorch.nn.functional.binary_cross_entropy_with_logits(input=torch.tensor([]), target=torch.tensor([]))\r\n~~~\r\nOutput:\r\n~~~python\r\ntensor(nan)\r\n~~~\r\n\r\n~~~python\r\nimport torch\r\ntorch.nn.functional.binary_cross_entropy_with_logits(input=torch.tensor([-2.3135e+307,  6.6756e+307]), target=torch.ones((2)))\r\n~~~\r\n\r\nOutput:\r\n~~~python\r\ntensor(nan)\r\n~~~\r\n\r\n\r\n\r\n## ",
        "Sample Code": "\r\n~~~python\r\nimport torch\r\ntorch.nn.functional.binary_cross_entropy(input=torch.tensor([]), target=torch.tensor([]))\r\n~~~\r\n",
        "API Signature": "\n torch.nn.functional. binary_cross_entropy_with_logits ( input ,  target ,  weight ,  size_average ,  reduce ,  reduction ,  pos_weight ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/51906",
        "Issue title": "torch.nn.functional.binary_cross_entropy(_with_logits) outputs NaN",
        "Bug description": "\r\n\r\n`torch.nn.functional.binary_cross_entropy_with_logits` outputs NaN when input is empty or large\r\n`torch.nn.functional.binary_cross_entropy` outputs NaN when input is empty\r\n\r\n\r\n## To Reproduce\r\n~~~python\r\nimport torch\r\ntorch.nn.functional.binary_cross_entropy(input=torch.tensor([]), target=torch.tensor([]))\r\n~~~\r\nOutput:\r\n~~~python\r\ntensor(nan)\r\n~~~\r\n\r\n~~~python\r\nimport torch\r\ntorch.nn.functional.binary_cross_entropy_with_logits(input=torch.tensor([]), target=torch.tensor([]))\r\n~~~\r\nOutput:\r\n~~~python\r\ntensor(nan)\r\n~~~\r\n\r\n~~~python\r\nimport torch\r\ntorch.nn.functional.binary_cross_entropy_with_logits(input=torch.tensor([-2.3135e+307,  6.6756e+307]), target=torch.ones((2)))\r\n~~~\r\n\r\nOutput:\r\n~~~python\r\ntensor(nan)\r\n~~~\r\n\r\n\r\n\r\n## ",
        "Sample Code": "\r\n~~~python\r\nimport torch\r\ntorch.nn.functional.binary_cross_entropy(input=torch.tensor([]), target=torch.tensor([]))\r\n~~~\r\n",
        "API Signature": "\n torch.nn.functional. binary_cross_entropy_with_logits ( input ,  target ,  weight ,  size_average ,  reduce ,  reduction ,  pos_weight ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/51803",
        "Issue title": "torch.fx.symbolic_trace fails on torch.arange with input-dependent size",
        "Bug description": "\r\n\r\nI'm trying to use torch.fx.symbolic_trace to trace an `arange` call where the first argument to `arange` is part of the size of the input tensor:\r\n```\r\nl = x.size(1)\r\ntorch.arange(l, dtype=torch.long, device='cuda')\r\n```\r\nAnd it fails.\r\n\r\n## To Reproduce\r\n\r\n```\r\nimport torch\r\nfrom torch.fx import symbolic_trace\r\ndef test(x):\r\n    l = x.size(1)\r\n    return torch.arange(l, dtype=torch.long, device='cuda')\r\ntraced = symbolic_trace(test)\r\n```\r\nTrace:\r\n```\r\nTraceback (most recent call last):\r\n  File \"repro.py\", line 6, in <module>\r\n    traced = symbolic_trace(test)\r\n  File \"/opt/pytorch/pytorch/torch/fx/symbolic_trace.py\", line 606, in symbolic_trace\r\n    graph = tracer.trace(root, concrete_args)\r\n  File \"/opt/pytorch/pytorch/torch/fx/symbolic_trace.py\", line 355, in trace\r\n    self.create_node('output', 'output', (self.create_arg(fn(*args)),), {},\r\n  File \"repro.py\", line 5, in test\r\n    return torch.arange(l, dtype=torch.long, device='cuda')\r\nTypeError: arange() received an invalid combination of arguments - got (Proxy, device=str, dtype=torch.dtype), but expected one of:\r\n * (Number end, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\r\n * (Number start, Number end, Number step, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\r\n *\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n```\r\nimport torch\r\nfrom torch.fx import symbolic_trace\r\ndef test(x):\r\n    l = x.size(1)\r\n    return torch.arange(l, dtype=torch.long, device='cuda')\r\ntraced = symbolic_trace(test)\r\n```\r\nTrace:\r\n```\r\nTraceback (most recent call last):\r\n  File \"repro.py\", line 6, in <module>\r\n    traced = symbolic_trace(test)\r\n  File \"/opt/pytorch/pytorch/torch/fx/symbolic_trace.py\", line 606, in symbolic_trace\r\n    graph = tracer.trace(root, concrete_args)\r\n  File \"/opt/pytorch/pytorch/torch/fx/symbolic_trace.py\", line 355, in trace\r\n    self.create_node('output', 'output', (self.create_arg(fn(*args)),), {},\r\n  File \"repro.py\", line 5, in test\r\n    return torch.arange(l, dtype=torch.long, device='cuda')\r\nType",
        "API Signature": "\n torch.nn.functional. binary_cross_entropy ( input ,  target ,  weight ,  size_average ,  reduce ,  reduction ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/51732",
        "Issue title": "torch.nn.functional.ctc_loss crash(segfault) ",
        "Bug description": "\r\n\r\n`torch.nn.functional.ctc_loss`  crash(segfault) when `input_lengths` contains large negative number.\r\n\r\n## To Reproduce\r\n~~~python\r\nimport torch \r\ntorch.nn.functional.ctc_loss(log_probs=torch.ones((1,2,1)), targets=torch.ones((2,1)), input_lengths=torch.tensor([-5570080269274466818, -1]), target_lengths=torch.tensor((1,1)))\r\n~~~\r\n\r\nOutput:\r\n~~~python\r\nSegmentation fault (core dumped)\r\n~~~\r\n\r\n## ",
        "Sample Code": "\r\n~~~python\r\nimport torch \r\ntorch.nn.functional.ctc_loss(log_probs=torch.ones((1,2,1)), targets=torch.ones((2,1)), input_lengths=torch.tensor([-5570080269274466818, -1]), target_lengths=torch.tensor((1,1)))\r\n~~~\r\n\r\n",
        "API Signature": "\n torch.nn.functional. ctc_loss ( log_probs ,  targets ,  input_lengths ,  target_lengths ,  blank ,  reduction ,  zero_infinity ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/51134",
        "Issue title": "segmentation fault in torch.nn.ReplicationPad3d/2d when padding is large",
        "Bug description": "\r\n\r\nsegmentation fault in `torch.nn.ReplicationPad3d` and `torch.nn.ReplicationPad2d` when `padding` is large\r\n\r\n## To Reproduce\r\n~~~python\r\nimport torch\r\nlayer = torch.nn.ReplicationPad3d(padding=498444555)\r\nmodel_input = torch.ones([1, 1, 1, 1, 1])\r\nlayer(model_input)\r\n~~~\r\n\r\n~~~python\r\nimport torch\r\nlayer = torch.nn.ReplicationPad2d(padding=1012756988)\r\nmodel_input = torch.ones([2,2,2,2])\r\nlayer(model_input)\r\n~~~\r\n\r\nOutput:\r\n~~~python\r\nSegmentation fault (core dumped)\r\n~~~\r\n\r\n## ",
        "Sample Code": "\r\n~~~python\r\nimport torch\r\nlayer = torch.nn.ReplicationPad3d(padding=498444555)\r\nmodel_input = torch.ones([1, 1, 1, 1, 1])\r\nlayer(model_input)\r\n~~~\r\n\r\n~~~python\r\nimport torch\r\nlayer = torch.nn.ReplicationPad2d(padding=1012756988)\r\nmodel_input = torch.ones([2,2,2,2])\r\nlayer(model_input)\r\n~~~\r\n\r\n",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/49520",
        "Issue title": "Segfault in torch.bincount",
        "Bug description": " of what the bug is. -->\r\n\r\n## To Reproduce\r\n~~~python\r\nimport torch\r\ntorch.bincount(input =torch.tensor([9223372036854775807]))\r\n~~~\r\n\r\nThe code snippet gives \r\n~~~\r\nSegmentation fault (core dumped)\r\n~~~\r\n\r\n## Expected behavior\r\nexpect no crash\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.5.0\r\nIs debug build: False\r\nCUDA used to build PyTorch: 10.1\r\nROCM used to build PyTorch: N/A\r\n\r\nOS: Ubuntu 18.04.4 LTS (x86_64)\r\nGCC version: Could not collect\r\nClang version: Could not collect\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.7 (64-bit runtime)\r\nIs CUDA available: False\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\nHIP runtime version: N/A\r\nMIOpen runtime version: N/A",
        "Sample Code": "\r\n~~~python\r\nimport torch\r\ntorch.bincount(input =torch.tensor([9223372036854775807]))\r\n~~~\r\n\r\nThe code snippet gives \r\n~~~\r\nSegmentation fault (core dumped)\r\n~~~\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/47610",
        "Issue title": "Input dimension check for `torch.gather`",
        "Bug description": "\r\n\r\nThe input dimension check was dropped somewhere between PyTorch 1.5.1 and 1.6.\r\n\r\n## To Reproduce\r\n\r\nThe following code runs successfully. However, the `index` argument has incompatible dimensions and should raise an exception.\r\n\r\n```python\r\nimport torch\r\ntorch.manual_seed(0)\r\ninput = torch.rand(4, 2)\r\nindex = torch.randint(2, size=(4,)).unsqueeze(0)  # intended to be unsqueeze(1)\r\ndim = 1\r\noutput = torch.gather(input, dim, index)\r\nprint(\"input = \", input)\r\nprint(\"index = \", index)\r\nprint(\"output = \", output)\r\n```\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## ",
        "Sample Code": "\r\n\r\nThe following code runs successfully. However, the `index` argument has incompatible dimensions and should raise an exception.\r\n\r\n```python\r\nimport torch\r\ntorch.manual_seed(0)\r\ninput = torch.rand(4, 2)\r\nindex = torch.randint(2, size=(4,)).unsqueeze(0)  # intended to be unsqueeze(1)\r\ndim = 1\r\noutput = torch.gather(input, dim, index)\r\nprint(\"input = \", input)\r\nprint(\"index = \", index)\r\nprint(\"output = \", output)\r\n```\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n`torch.gather` should raise an exception on receiving and index with incompatible dimension.\r\n\r\n## Environment\r\n\r\n```\r\nCollecting environment information...\r\nPyTorch version: 1.5.1\r\nIs debug build: False\r\nCUDA used to build PyTorch: 10.2\r\nROCM used to build PyTorch: N/A\r\n\r\nOS: Ubuntu 18.04.5 LTS (x86_64)\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nClang version: Could not collect\r\nCMake version: version 3.10.2\r\n\r\nPython version: 3.8 (64-bit runtime)\r\nIs CUDA available: True\r\nCUDA runtime version: 10.2.89\r\nGPU models and configuration:\r\nGPU 0: GeForce RTX 2080\r\nGPU 1: GeForce RTX 2080\r\n\r\nNvidia driver version: 440.100\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn.so.7.6.5\r\nHIP runtime version: N/A\r\nMIOpen runtime version: N/A\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.19.0\r\n[pip3] pytorch-lightning==0.9.0rc5\r\n[pip3] torch==1.5.1\r\n[pip3] torchvision==0.6.0a0+35d732a\r\n[conda] blas                      1.0                         mkl\r\n[conda] cudatoolkit               10.2.89              hfd86e86_1\r\n[conda] mkl                       2019.4                      243\r\n[conda] mkl-service               2.3.0            py38h516909a_0    conda-forge\r\n[conda] mkl_fft                   1.1.0            py38hc1659b7_1    conda-forge\r\n[conda] mkl_random                1.1.0            py38hb3f55d8_0    conda-forge\r\n[conda] numpy                     1.19.0                    <pip>\r\n[conda] numpy                     1.18.5           py38ha1c710e_0\r\n[conda] numpy-base                1.18.5           py38hde5b4d6_0\r\n[conda] pytorch                   1.5.1           py3.8_cuda10.2.89_cudnn7.6.5_0    pytorch\r\n[conda] pytorch-lightning         0.9.0rc5                  <pip>\r\n[conda] torchvision               0.6.1                py38_cu102    pytorch\r\n```\r\n## ",
        "API Signature": "\n torch. gather ( input ,  dim ,  index ,  * ,  sparse_grad ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/46225",
        "Issue title": "torch.mode when input has nans",
        "Bug description": " of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\nOutput of `collect_env.py`:\r\n```\r\nCollecting environment information...\r\nPyTorch version: 1.6.0\r\nIs debug build: False\r\nCUDA used to build PyTorch: 10.2\r\nROCM used to build PyTorch: N/A\r\n\r\nOS: Ubuntu 18.04.3 LTS (x86_64)\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nClang version: Could not collect\r\nCMake version: version 3.10.2\r\n\r\nPython version: 3.7 (64-bit runtime)\r\nIs CUDA available: True\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration:\r\nGPU 0: TITAN RTX\r\nGPU 1: TITAN RTX\r\nGPU 2: GeForce RTX 2080 Ti\r\nGPU 3: GeForce GTX 1080 Ti\r\n\r\nNvidia driver version: 440.64.00\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\nHIP runtime version: N/A\r\nMIOpen runtime version: N/A\r\n\r\nVersions of relevant libraries:\r\n[pip3] msgpack-numpy==0.4.4.3\r\n[pip3] numpy==1.16.1\r\n[pip3] numpy-quaternion==2020.10.2.17.17.31\r\n[pip3] numpy-stl==2.10.1\r\n[pip3] torch==1.6.0\r\n[pip3] torchvision==0.6.0\r\n[conda] msgpack-numpy             0.4.4.3                  pypi_0    pypi\r\n[conda] numpy                     1.16.1                   pypi_0    pypi\r\n[conda] numpy-quaternion          2020.10.2.17.17.31          pypi_0    pypi\r\n[conda] numpy-stl                 2.10.1                   pypi_0    pypi\r\n[conda] torch                     1.6.0                    pypi_0    pypi\r\n[conda] torchvision               0.6.0                    pypi_0    pypi\r\n```\r\n\r\n\n\ncc @brianjo @mruberry @rgommers @heitorschueroff @ezyang @gchanan @zou3519 @bdhirsh @ejguan @jlin27",
        "Sample Code": "\r\n\r\n```python\r\ndef test(device):\r\n    x = torch.rand(1000).mul(5).long().to(device)\r\n    s = torch.bincount(x, minlength=5).argsort(descending=True)\r\n    \r\n    mode =  x.mode().values\r\n    print(f'w/o nans, got {mode}, expected {s[0]}')\r\n\r\n    y = x.clone().float()\r\n    y[y == mode] = np.nan\r\n    mode =  y.mode().values.long()\r\n    print(f'w nans, got {mode}, expected {s[1]}')\r\n```\r\n\r\nWhen running `test(\"cpu\")`, both lines always give the expected result:\r\n```\r\nIn [17]: test('cpu')\r\nw/o nans, got 3, expected 3\r\nw nans, got 0, expected 0\r\n```\r\n\r\nwhereas when running `test(\"cuda\")`, the first line always gives the expected result, but the second line gives something seemingly random:\r\n```\r\nIn [26]: test('cuda')\r\nw/o nans, got 2, expected 2\r\nw nans, got 4, expected 0\r\n```\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\n",
        "API Signature": "\n torch. mode ( input ,  dim ,  keepdim ,  * ,  out ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/43567",
        "Issue title": "`torch.svd()` CUDA gives incorrect results when input contains `nan`",
        "Bug description": "\r\n\r\nIn at least one case, `torch.svd()`'s CUDA implementation gives an incorrect result when the input contains a `nan` value.\r\n\r\nThis issue shows up when the input is `torch.tensor([[float('nan'), 1.0]])`.\r\n\r\n## To Reproduce\r\n\r\n```\r\n>>> import torch\r\n>>> torch.svd(torch.tensor([[float('nan'), 1.0]]))\r\ntorch.return_types.svd(\r\nU=tensor([[1.]]),\r\nS=tensor([nan]),\r\nV=tensor([[nan],\r\n        [nan]]))\r\n>>> torch.svd(torch.tensor([[float('nan'), 1.0]]).cuda())\r\ntorch.return_types.svd(\r\nU=tensor([[1.]], device='cuda:0'),\r\nS=tensor([1.4142], device='cuda:0'),\r\nV=tensor([[nan],\r\n        [nan]], device='cuda:0'))\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n\r\n```\r\n>>> import torch\r\n>>> torch.svd(torch.tensor([[float('nan'), 1.0]]))\r\ntorch.return_types.svd(\r\nU=tensor([[1.]]),\r\nS=tensor([nan]),\r\nV=tensor([[nan],\r\n        [nan]]))\r\n>>> torch.svd(torch.tensor([[float('nan'), 1.0]]).cuda())\r\ntorch.return_types.svd(\r\nU=tensor([[1.]], device='cuda:0'),\r\nS=tensor([1.4142], device='cuda:0'),\r\nV=tensor([[nan],\r\n        [nan]], device='cuda:0'))\r\n```\r\n\r\n## Expected behavior\r\n\r\nIn the above code snippet, the CUDA result is `S=1.4142`, but it should be `S=nan`. The CPU result is correct.\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.7.0a0+5ff1ce3\r\nIs debug build: False\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Ubuntu 18.04.3 LTS (x86_64)\r\nGCC version: (crosstool-NG 1.24.0.123_1667d2b) 7.5.0\r\nClang version: Could not collect\r\nCMake version: version 3.18.0\r\n\r\nPython version: 3.8 (64-bit runtime)\r\nIs CUDA available: True\r\nCUDA runtime version: 10.2.89\r\nGPU models and configuration: \r\nGPU 0: TITAN RTX\r\nGPU 1: TITAN RTX\r\n\r\nNvidia driver version: 440.33.01\r\ncuDNN version: /usr/local/cuda-10.2.89/targets/x86_64-linux/lib/libcudnn.so.7\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.19.1\r\n[pip3] torch==1.7.0a0+5ff1ce3\r\n[conda] magma-cuda101             2.5.2                         1    pytorch\r\n[conda] mkl                       2020.2                      256    conda-forge\r\n[conda] mkl-include               2020.2                      256    conda-forge\r\n[conda] numpy                     1.19.1           py38h8854b6b_0    conda-forge\r\n[conda] torch                     1.7.0a0+5ff1ce3           dev_0    <develop>\r\n\r\n## ",
        "API Signature": "\n torch. svd ( input ,  some ,  compute_uv ,  * ,  out ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/43115",
        "Issue title": "torch.multinomial with replacement=True produces inaccurate results for large number of categories",
        "Bug description": "\r\n\r\n`torch.multinomial` with `replacement=True` produces very inaccurate results when number of categories is large (and/or probabilities have very different values)\r\n\r\n## ",
        "Sample Code": "\r\nOne of the ways to reproduce (there could be multiple ways to construct adversarial examples):\r\n```\r\nimport torch\r\nfor ncat in (2**8, 2**22, 2**24):\r\n    probs=torch.empty(ncat) \r\n    half = ncat//2    \r\n    probs[half:]=1\r\n    probs[:half-1]=2\r\n    out=torch.multinomial(probs, num_samples=10**5, replacement=True) \r\n    print(\"number of categories {:10}, number of samples in upper half {:8} \".format(ncat, (out>=half).sum().item())) #would expect 1/3 (~33333) of generated values to be >=half, true for ncat 2**8, 2**22, 0 for ncat 2**24\r\n```\r\n## ",
        "API Signature": "\n torch. multinomial ( input ,  num_samples ,  replacement ,  * ,  generator ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/37556",
        "Issue title": "torch.cartesian_prod(*tensors) error when you have tensors with [x,y]",
        "Bug description": "\r\n\r\n`torch.multinomial` with `replacement=True` produces very inaccurate results when number of categories is large (and/or probabilities have very different values)\r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n```\r\na = [[1,1], [2,3], [3,5]]\r\n\r\nb = [[4, 5], [3,6]]\r\n\r\nprint(list(itertools.product(a, b)))\r\n\r\ntensor_a = torch.tensor(a)\r\n\r\ntensor_b = torch.tensor(b)\r\n\r\n#torch.cartesian_prod(tensor_a, tensor_b)\r\n\r\ntorch.cartesian_prod(tensor_a, tensor_b)\r\n\r\n```\r\n\r\n## Error:\r\n\r\n```\r\n[([1, 1], [4, 5]), ([1, 1], [3, 6]), ([2, 3], [4, 5]), ([2, 3], [3, 6]), ([3, 5], [4, 5]), ([3, 5], [3, 6])]\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-346-78fb1274668d> in <module>\r\n      4 tensor_a = torch.tensor(a)\r\n      5 tensor_b = torch.tensor(b)\r\n----> 6 torch.cartesian_prod(tensor_a, tensor_b)\r\n\r\nc:\\users\\hbb9279\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\functional.py in cartesian_prod(*tensors)\r\n    603                 [3, 5]])\r\n    604     \"\"\"\r\n--> 605     return torch._C._VariableFunctions.cartesian_prod(tensors)\r\n    606 \r\n    607 \r\n\r\nRuntimeError: Expect a 1D vector, but got shape [3, 2]\r\n```\r\n\r\n## Expected behavior\r\n\r\n`torch.cartesian_prod` does not work like itertools.product when you have more than one dimension\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n Collecting environment information...\r\nPyTorch version: 1.3.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Microsoft Windows 10 Enterprise\r\nGCC version: Could not collect\r\nCMake version: Could not collect\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration: GPU 0: Quadro P6000\r\nNvidia driver version: 426.00\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.17.3\r\n[pip3] pytorch-transformers==1.2.0\r\n[pip3] torch==1.3.0\r\n[pip3] torchvision==0.4.1\r\n[conda] Could not collect\r\n\r\n## ",
        "API Signature": "\n torch. cartesian_prod ( * ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/29372",
        "Issue title": "torch.std() returns nan for single item tensors.",
        "Bug description": "\r\n\r\nnp.std(4) returns 0 whereas torch.std(torch.tensor(4)) returns NaN. This causes numerical instabilities in certain situations.\r\n\r\n## To Reproduce\r\n\r\nimport numpy as np\r\nnp.std(4)  # returns 0\r\n\r\nimport torch\r\ntorch.std(torch.tensor(4.))  # returns NaN\r\n\r\n## ",
        "Sample Code": "\r\n\r\nimport numpy as np\r\nnp.std(4)  # returns 0\r\n\r\nimport torch\r\ntorch.std(torch.tensor(4.))  # returns NaN\r\n\r\n## ",
        "API Signature": "\n torch. std ( input ,  dim ,  unbiased ,  keepdim ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/25648",
        "Issue title": "Torch.jit.trace unexpected error with `torch.cat(\u2026, dim=-1)` ",
        "Bug description": "\r\n\r\nnp.std(4) returns 0 whereas torch.std(torch.tensor(4)) returns NaN. This causes numerical instabilities in certain situations.\r\n\r\n## To Reproduce\r\n\r\nimport numpy as np\r\nnp.std(4)  # returns 0\r\n\r\nimport torch\r\ntorch.std(torch.tensor(4.))  # returns NaN\r\n\r\n## ",
        "Sample Code": "\r\n\r\nimport numpy as np\r\nnp.std(4)  # returns 0\r\n\r\nimport torch\r\ntorch.std(torch.tensor(4.))  # returns NaN\r\n\r\n## ",
        "API Signature": "\n torch. cat ( tensors ,  dim ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/24823",
        "Issue title": "Problematic handling of NaN and inf in grid_sample, causing segfaults, corrupted CUDA memory, and incorrect results",
        "Bug description": "\r\n\r\nThe `grid_sample` function does not have proper handling of `NaN` values for in its grid input.\r\n\r\nThe 2D CPU version segfaults under certain conditions and parameters, as described in https://github.com/pytorch/pytorch/issues/19826, and with simplified examples below.\r\n\r\nThe other `grid_sample` kernels (3D CPU, and 2D/3D CUDA) do not segfault, but produce incorrect results under certain conditions when the grid contains a `NaN` value.\r\n\r\nProper handling would place a `NaN` in the output for every grid location that has a `NaN`.\r\n\r\n### ",
        "Sample Code": "\r\n\r\nThis is covered and diagnosed by @SsnL at https://github.com/pytorch/pytorch/issues/19826, but I want to provide a simple example to reproduce the segfault behavior, and expand on the exact conditions in which it occurs.\r\n\r\n- Here is a simple example to reproduce the segmentation fault:\r\n```python\r\n>>> image = torch.rand(1, 1, 3, 3, device='cpu')\r\n>>> grid = torch.rand(1, 3, 3, 2, device='cpu')\r\n>>> grid[:,1,1,0] = float('nan')\r\n>>> torch.nn.functional.grid_sample(image, grid, padding_mode='border')\r\nSegmentation fault (core dumped)\r\n```\r\n\r\n- This segfault does not, however, happen if both components of a grid point are `NaN`.\r\nExample:\r\n```python\r\n>>> image = torch.rand(1, 1, 3, 3, device='cpu')\r\n>>> grid = torch.rand(1, 3, 3, 2, device='cpu')\r\n>>> grid[:,1,1,:] = float('nan')\r\n>>> torch.nn.functional.grid_sample(image, grid, padding_mode='border')\r\ntensor([[[[0.2587, 0.1807, 0.2114],\r\n          [0.1993,    nan, 0.2673],\r\n          [0.2065, 0.1258, 0.2002]]]])\r\n```\r\nwhich is, in fact, the correct and desired behavior.\r\n\r\n- The segfault occurs for padding modes `border` and `reflection`, but not for `zeros` (where it works correctly).\r\n\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. grid_sample ( input ,  grid ,  mode ,  padding_mode ,  align_corners ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/24823",
        "Issue title": "Problematic handling of NaN and inf in grid_sample, causing segfaults, corrupted CUDA memory, and incorrect results",
        "Bug description": "\r\n\r\nThe `grid_sample` function does not have proper handling of `NaN` values for in its grid input.\r\n\r\nThe 2D CPU version segfaults under certain conditions and parameters, as described in https://github.com/pytorch/pytorch/issues/19826, and with simplified examples below.\r\n\r\nThe other `grid_sample` kernels (3D CPU, and 2D/3D CUDA) do not segfault, but produce incorrect results under certain conditions when the grid contains a `NaN` value.\r\n\r\nProper handling would place a `NaN` in the output for every grid location that has a `NaN`.\r\n\r\n### ",
        "Sample Code": "\r\n\r\nThis is covered and diagnosed by @SsnL at https://github.com/pytorch/pytorch/issues/19826, but I want to provide a simple example to reproduce the segfault behavior, and expand on the exact conditions in which it occurs.\r\n\r\n- Here is a simple example to reproduce the segmentation fault:\r\n```python\r\n>>> image = torch.rand(1, 1, 3, 3, device='cpu')\r\n>>> grid = torch.rand(1, 3, 3, 2, device='cpu')\r\n>>> grid[:,1,1,0] = float('nan')\r\n>>> torch.nn.functional.grid_sample(image, grid, padding_mode='border')\r\nSegmentation fault (core dumped)\r\n```\r\n\r\n- This segfault does not, however, happen if both components of a grid point are `NaN`.\r\nExample:\r\n```python\r\n>>> image = torch.rand(1, 1, 3, 3, device='cpu')\r\n>>> grid = torch.rand(1, 3, 3, 2, device='cpu')\r\n>>> grid[:,1,1,:] = float('nan')\r\n>>> torch.nn.functional.grid_sample(image, grid, padding_mode='border')\r\ntensor([[[[0.2587, 0.1807, 0.2114],\r\n          [0.1993,    nan, 0.2673],\r\n          [0.2065, 0.1258, 0.2002]]]])\r\n```\r\nwhich is, in fact, the correct and desired behavior.\r\n\r\n- The segfault occurs for padding modes `border` and `reflection`, but not for `zeros` (where it works correctly).\r\n\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. grid_sample ( input ,  grid ,  mode ,  padding_mode ,  align_corners ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/23159",
        "Issue title": "Can't `torch.sum(tensor, dim)` where `dim >= 64`",
        "Bug description": "\r\n\r\nCan't use TensorIterator reduction functions if the dimension to be reduced over is > 64.\r\n\r\n## To Reproduce\r\n\r\n```\r\nIn [1]: import torch\r\n\r\nIn [2]: sizes = [1]*65\r\n\r\nIn [3]: x = torch.randn(sizes)\r\n\r\nIn [4]: x.sum(0)\r\nOut[4]: tensor([[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[-0.2885]]]]]]]]]]]]]]]]\r\n]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]])\r\n\r\nIn [5]: x.sum(65)\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-5-cfca9db78f16> in <module>()\r\n----> 1 x.sum(65)\r\n\r\nIndexError: Dimension out of range (expected to be in range of [-65, 64], but got 65)\r\n\r\nIn [6]: x.sum(64)\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-6-6375767cd187> in <module>()\r\n----> 1 x.sum(64)\r\n\r\nRuntimeError: bitset::set: __position (which is 64) >= _Nb (which is 64)\r\n```\r\n\r\n# ",
        "Sample Code": "\r\n\r\n```\r\nIn [1]: import torch\r\n\r\nIn [2]: sizes = [1]*65\r\n\r\nIn [3]: x = torch.randn(sizes)\r\n\r\nIn [4]: x.sum(0)\r\nOut[4]: tensor([[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[-0.2885]]]]]]]]]]]]]]]]\r\n]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]])\r\n\r\nIn [5]: x.sum(65)\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-5-cfca9db78f16> in <module>()\r\n----> 1 x.sum(65)\r\n\r\nIndex",
        "API Signature": "\n torch. sum ( input ,  * ,  dtype )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/23061",
        "Issue title": "The speed of `torch.einsum` and `torch.matmul` when using `fp16` is slow",
        "Bug description": "\r\n\r\nI found that the speed of `torch.einsum` when using fp16 is much slower than using fp32.\r\n\r\nwhen the shapes of inputs are (a,b,c) and (a,c,d), `matmul` became much slower as well.\r\n\r\n## To Reproduce\r\n```python\r\nimport os\r\nos.environ['CUDA_VISIBLE_DEVICES']='0'\r\nimport torch\r\nfrom time import time\r\n\r\na = torch.empty(24,32,40,48, dtype=torch.float32).to('cuda')\r\nb = torch.empty(64,32,40,48, dtype=torch.float32).to('cuda')\r\nc = torch.empty(40,80,24, dtype=torch.float32).to('cuda')\r\nd = torch.empty(40,24,16, dtype=torch.float32).to('cuda')\r\n\r\nst = time()\r\nfor _ in range(1000):\r\n    c.matmul(d)\r\nprint(time()-st)\r\n\r\nst = time()\r\nfor _ in range(1000):\r\n    torch.einsum('ibnd,jbnd->ijbn', a, b)\r\nprint(time()-st)\r\n\r\na = torch.empty(24,32,40,48, dtype=torch.float16).to('cuda')\r\nb = torch.empty(64,32,40,48, dtype=torch.float16).to('cuda')\r\nc = torch.empty(40,80,24, dtype=torch.float16).to('cuda')\r\nd = torch.empty(40,24,16, dtype=torch.float16).to('cuda')\r\n\r\nst = time()\r\nfor _ in range(1000):\r\n    torch.matmul(c,d)\r\nprint(time()-st)\r\n\r\nst = time()\r\nfor _ in range(1000):\r\n    torch.einsum('ibnd,jbnd->ijbn', a, b)\r\nprint(time()-st)\r\n```\r\nSteps to reproduce the behavior:\r\n\r\njust run it\r\n\r\n\r\n## ",
        "Sample Code": "\r\n```python\r\nimport os\r\nos.environ['CUDA_VISIBLE_DEVICES']='0'\r\nimport torch\r\nfrom time import time\r\n\r\na = torch.empty(24,32,40,48, dtype=torch.float32).to('cuda')\r\nb = torch.empty(64,32,40,48, dtype=torch.float32).to('cuda')\r\nc = torch.empty(40,80,24, dtype=torch.float32).to('cuda')\r\nd = torch.empty(40,24,16, dtype=torch.float32).to('cuda')\r\n\r\nst = time()\r\nfor _ in range(1000):\r\n    c.matmul(d)\r\nprint(time()-st)\r\n\r\nst = time()\r\nfor _ in range(1000):\r\n    torch.einsum('ibnd,jbnd->ijbn', a, b)\r\nprint(time()-st)\r\n\r\na = torch.empty(24,32,40,48, dtype=torch.float16).to('cuda')\r\nb = torch.empty(64,32,40,48, dtype=torch.float16).to('cuda')\r\nc = torch.empty(40,80,24, dtype=torch.float16).to('cuda')\r\nd = torch.empty(40,24,16, dtype=torch.float16).to('cuda')\r\n\r\nst = time()\r\nfor _ in range(1000):\r\n    torch.matmul(c,d)\r\nprint(time()-st)\r\n\r\nst = time()\r\nfor _ in range(1000):\r\n    torch.einsum('ibnd,jbnd->ijbn', a, b)\r\nprint(time()-st)\r\n```\r\nSteps to reproduce the behavior:\r\n\r\njust run it\r\n\r\n\r\n## ",
        "API Signature": "\n torch. einsum ( equation ,  * )   \u2192 [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/22788",
        "Issue title": "Pytorch deadlock from distributed multiprocessing",
        "Bug description": "\r\n\r\nPytorch hangs indefinitely when using distributed multiprocessing with Pytorch 1.1.0 after 77k iterations (77939 and 77940 iterations). In Pytorch 1.0.1.post2, there is no such bug.\r\n\r\nIt appears to be deadlock.\r\n\r\nThe following distributed modules combine together in a very nasty way for some reason:\r\n```\r\nimport torch.distributed as dist\r\ntrain_sampler = torch.utils.data.distributed.DistributedSampler(train_data)\r\ndist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size, rank=args.rank)\r\napex.parallel.DistributedDataParallel(model)\r\nmodel, optimizer = apex.amp.initialize(model.cuda(), optimizer, opt_level=args.opt_level, keep_batchnorm_fp32=args.keep_batchnorm_fp32, loss_scale=args.loss_scale)\r\n model = apex.parallel.DistributedDataParallel(model)\r\n```\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Clone the following repo: [semseg](https://github.com/hszhao/semseg)\r\n2. Use the following config:\r\n3. Run the training script [train.py](https://github.com/hszhao/semseg/blob/master/tool/train.py)\r\n4. Observe that Pytorch will hang indefinitely after the 77,939th iteration. \r\n\r\n## ",
        "Sample Code": "\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Clone the following repo: [semseg](https://github.com/hszhao/semseg)\r\n2. Use the following config:\r\n3. Run the training script [train.py](https://github.com/hszhao/semseg/blob/master/tool/train.py)\r\n4. Observe that Pytorch will hang indefinitely after the 77,939th iteration. \r\n\r\n## Expected behavior\r\n\r\nPytorch should not hang.\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.1.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.0.130\r\n\r\nOS: Ubuntu 18.04.2 LTS\r\nGCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\nCMake version: version 3.10.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration: many\r\nNvidia driver version: \r\ncuDNN version: \r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.16.3\r\n[pip] torch==1.1.0\r\n[pip] torchvision==0.3.0\r\n[conda] blas                      1.0                         mkl\r\n[conda] mkl                       2019.3                      199\r\n[conda] mkl_fft                   1.0.12           py36ha843d7b_0\r\n[conda] mkl_random                1.0.2            py36hd81dba3_0\r\n[conda] pytorch                   1.1.0           py3.6_cuda10.0.130_cudnn7.5.1_0    pytorch\r\n[conda] torchvision               0.3.0           py36_cu10.0.130_1    pytorch\r\n\r\n## ",
        "API Signature": "\n torch. matmul ( input ,  other ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/22105",
        "Issue title": "Memory leak when utilizing pandas indices",
        "Bug description": "\r\n\r\nThere is a memory leak when utilizing pandas.Int64Index + pytorch on windows (haven't tested Linux + mac)\r\n\r\n## ",
        "Sample Code": "\r\n```\r\nimport numpy as np\r\nimport torch\r\nimport pandas as pd\r\n\r\n\r\nidx = pd.core.indexes.numeric.Int64Index(np.arange(10000))\r\narr = torch.zeros(len(idx))\r\n\r\nwhile True:\r\n    arr[idx]\r\n```\r\n\r\n## ",
        "API Signature": "\n torch. zeros ( *size ,  * ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/17897",
        "Issue title": "CUDA large matrix-vector product (torch.mv) causes illegal memory access",
        "Bug description": "\r\n\r\n`torch.mv` causes an \"illegal memory access\" when multiplying a matrix with more than 2^31-1 elements. Note that each dim of the first matrix can fit in an `int`.\r\n\r\nThis is likely a bug in cuBLAS. Either cuBLAS should be fixed or PyTorch should issue multiple calls to `cublasSgemv`.\r\n\r\n## ",
        "Sample Code": "\r\n\r\nNote: you need ~10 GB on your GPU to run this example\r\n\r\n```python\r\nx = torch.ones(35783, 65133, device='cuda')\r\ny = torch.randn(65133, device='cuda')\r\nz = torch.mv(x, y)\r\ntorch.cuda.synchronize()  # report asynchronous error\r\n```\r\n\r\n## ",
        "API Signature": "\n torch. mv ( input ,  vec ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/17350",
        "Issue title": "torch.nn.CrossEntropyLoss with \"reduction\" sum/mean is not deterministic on segmentation outputs / labels",
        "Bug description": "\r\ntorch.nn.CrossEntropyLoss doesn't output deterministic results on segmentation outputs / labels, when using reduction other than 'none'.\r\nHappens only on GPU. CPU does give a consistent behavior. \r\n\r\n## To Reproduce\r\n```\r\nimport numpy as np\r\nimport torch\r\n\r\noutputs = np.random.rand(16, 1, 256, 256)\r\noutputs = np.hstack((outputs, 1.0 - outputs))\r\ntargets = np.random.randint(2, size=(16, 256, 256))\r\n\r\nseed = 0\r\ntorch.backends.cudnn.deterministic = True\r\ntorch.backends.cudnn.benchmark = False\r\n\r\nfor reduction in ['none', 'sum', 'mean']:\r\n    print(reduction)\r\n\r\n    for i in range(10):\r\n        torch.manual_seed(seed)\r\n        np.random.seed(seed)\r\n\r\n        outputs_t, targets_t = torch.from_numpy(outputs), torch.from_numpy(targets)\r\n        outputs_t, targets_t = outputs_t.cuda(0), targets_t.cuda(0)\r\n\r\n        loss_fn = torch.nn.CrossEntropyLoss(reduction=reduction)\r\n        loss_fn = loss_fn.cuda(0)\r\n\r\n        loss = loss_fn(outputs_t, targets_t)\r\n        loss = loss.detach().cpu().numpy()\r\n        print(i, outputs.sum(), targets.sum(), outputs.mean(), targets.mean(), loss.sum(), loss.mean())\r\n```\r\n## Output\r\n```\r\nnone\r\n0 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n1 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n2 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n3 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n4 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n5 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n6 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n7 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n8 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n9 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\nsum\r\n0 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n1 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n2 1048576.0 524341 0.5 0.5000505447387695 769533.4950007757 769533.4950007757\r\n3 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n4 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n5 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n6 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n7 1048576.0 524341 0.5 0.5000505447387695 769533.4950007754 769533.4950007754\r\n8 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n9 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\nmean\r\n0 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n1 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n2 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n3 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n4 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n5 1048576.0 524341 0.5 0.5000505447387695 0.7338843297965769 0.7338843297965769\r\n6 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n7 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n8 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n9 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n```\r\n\r\n## ",
        "Sample Code": "\r\n```\r\nimport numpy as np\r\nimport torch\r\n\r\noutputs = np.random.rand(16, 1, 256, 256)\r\noutputs = np.hstack((outputs, 1.0 - outputs))\r\ntargets = np.random.randint(2, size=(16, 256, 256))\r\n\r\nseed = 0\r\ntorch.backends.cudnn.deterministic = True\r\ntorch.backends.cudnn.benchmark = False\r\n\r\nfor reduction in ['none', 'sum', 'mean']:\r\n    print(reduction)\r\n\r\n    for i in range(10):\r\n        torch.manual_seed(seed)\r\n        np.random.seed(seed)\r\n\r\n        outputs_t, targets_t = torch.from_numpy(outputs), torch.from_numpy(targets)\r\n        outputs_t, targets_t = outputs_t.cuda(0), targets_t.cuda(0)\r\n\r\n        loss_fn = torch.nn.CrossEntropyLoss(reduction=reduction)\r\n        loss_fn = loss_fn.cuda(0)\r\n\r\n        loss = loss_fn(outputs_t, targets_t)\r\n        loss = loss.detach().cpu().numpy()\r\n        print(i, outputs.sum(), targets.sum(), outputs.mean(), targets.mean(), loss.sum(), loss.mean())\r\n```\r\n## Output\r\n```\r\nnone\r\n0 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n1 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n2 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n3 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n4 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n5 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n6 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n7 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n8 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\n9 1048576.0 524341 0.5 0.5000505447387695 769533.4950007759 0.7338843297965774\r\nsum\r\n0 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n1 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n2 1048576.0 524341 0.5 0.5000505447387695 769533.4950007757 769533.4950007757\r\n3 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n4 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n5 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n6 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n7 1048576.0 524341 0.5 0.5000505447387695 769533.4950007754 769533.4950007754\r\n8 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\n9 1048576.0 524341 0.5 0.5000505447387695 769533.4950007756 769533.4950007756\r\nmean\r\n0 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n1 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n2 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n3 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n4 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n5 1048576.0 524341 0.5 0.5000505447387695 0.7338843297965769 0.7338843297965769\r\n6 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n7 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n8 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n9 1048576.0 524341 0.5 0.5000505447387695 0.733884329796577 0.733884329796577\r\n```\r\n\r\n## Expected behavior\r\nI believe the expected behavior of the reduction='sum' and 'mean' should be as consistent as the 'none' option (where I use numpy for reduction).\r\n\r\n## Environment\r\n```\r\nPyTorch version: 1.0.1.post2\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration: GPU 0: Tesla K80\r\nNvidia driver version: 384.111\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.16.1\r\n[pip3] torch==1.0.1.post2\r\n[conda] mkl                       2018.0.0             hb491cac_4\r\n[conda] mkl-service               1.1.2            py36h17a0993_4\r\n[conda] torch                     0.4.0                     <pip>\r\n```\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/15728",
        "Issue title": "torch.load() large tensor return 'invalid memory size'",
        "Bug description": "\r\n\r\nHello,\r\n\r\nI'm having a problem of loading a serialized tensor from a file.\r\nMy tensor shape is [309000001, 2, 5] the dtype is torch.int8\r\nWhen I deserialize the tensor using torch.load(), it yell \"invalid memory size\".\r\nThe line that it complain is:\r\nhttps://github.com/pytorch/pytorch/blob/b740b92f3600840e09d4c93f3138333838d1e474/torch/serialization.py#L528-L529\r\nIt seem like the variable it used is destructured from here:\r\nhttps://github.com/pytorch/pytorch/blob/b740b92f3600840e09d4c93f3138333838d1e474/torch/serialization.py#L525\r\nWhich also came from here:\r\nhttps://github.com/pytorch/pytorch/blob/b740b92f3600840e09d4c93f3138333838d1e474/torch/serialization.py#L517\r\nSo I insert `print(saved_id)` where it yell:\r\nNow, it print:\r\n`('storage', <class 'torch.CharStorage'>, '2149339138576', 'cpu', -1204967286, None)`\r\n\r\nIt seem that size is negative.\r\n\r\n## To Reproduce\r\n```\r\nimport torch\r\n\r\ntorch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\ntorch.load('./sample.pt')\r\n```\r\nIt can only be reproduce in MS.Windows environment.\r\nMy Windows version is:\r\n10.0.17134.472\r\nMy Python version is:\r\n3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)]\r\nSteps to reproduce the behavior:\r\n1. Run above code in MS. Windows\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-2-1e8f41ee3715> in <module>\r\n      2 \r\n      3 torch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\n----> 4 torch.load('./sample.pt')\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in load(f, map_location, pickle_module)\r\n    365         f = open(f, 'rb')\r\n    366     try:\r\n--> 367         return _load(f, map_location, pickle_module)\r\n    368     finally:\r\n    369         if new_fd:\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in _load(f, map_location, pickle_module)\r\n    538     unpickler = pickle_module.Unpickler(f)\r\n    539     unpickler.persistent_load = persistent_load\r\n--> 540     result = unpickler.load()\r\n    541 \r\n    542     deserialized_storage_keys = pickle_module.load(f)\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in persistent_load(saved_id)\r\n    504                 print(data_type, size)\r\n    505                 deserialized_objects[root_key] = restore_location(\r\n--> 506                     data_type(size), location)\r\n    507             storage = deserialized_objects[root_key]\r\n    508             if view_metadata is not None:\r\n\r\nRuntimeError: $ Torch: invalid memory size -- maybe an overflow? at ..\\aten\\src\\TH\\THGeneral.cpp:188\r\n\r\n## ",
        "Sample Code": "\r\n```\r\nimport torch\r\n\r\ntorch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\ntorch.load('./sample.pt')\r\n```\r\nIt can only be reproduce in MS.Windows environment.\r\nMy Windows version is:\r\n10.0.17134.472\r\nMy Python version is:\r\n3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)]\r\nSteps to reproduce the behavior:\r\n1. Run above code in MS. Windows\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-2-1e8f41ee3715> in <module>\r\n      2 \r\n      3 torch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\n----> 4 torch.load('./sample.pt')\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in load(f, map_location, pickle_module)\r\n    365         f = open(f, 'rb')\r\n    366     try:\r\n--> 367         return _load(f, map_location, pickle_module)\r\n    368     finally:\r\n    369         if new_fd:\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in _load(f, map_location, pickle_module)\r\n    538     unpickler = pickle_module.Unpickler(f)\r\n    539     unpickler.persistent_load = persistent_load\r\n--> 540     result = unpickler.load()\r\n    541 \r\n    542     deserialized_storage_keys = pickle_module.load(f)\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in persistent_load(saved_id)\r\n    504                 print(data_type, size)\r\n    505                 deserialized_objects[root_key] = restore_location(\r\n--> 506                     data_type(size), location)\r\n    507             storage = deserialized_objects[root_key]\r\n    508             if view_metadata is not None:\r\n\r\nRuntimeError: $ Torch: invalid memory size -- maybe an overflow? at ..\\aten\\src\\TH\\THGeneral.cpp:188\r\n\r\n## Expected behavior\r\n\r\nTensor is loaded without error.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.0\r\n - OS (e.g., Linux): Windows 10\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.6.7\r\n - CUDA/cuDNN version: N/A\r\n - GPU models and configuration: N/A\r\n - Any other relevant information: No problem on Linux\r\n\r\n## ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/7343",
        "Issue title": "[memory leak] [PyTorch] .backward(create_graph=True)",
        "Bug description": "\r\n\r\nHello,\r\n\r\nI'm having a problem of loading a serialized tensor from a file.\r\nMy tensor shape is [309000001, 2, 5] the dtype is torch.int8\r\nWhen I deserialize the tensor using torch.load(), it yell \"invalid memory size\".\r\nThe line that it complain is:\r\nhttps://github.com/pytorch/pytorch/blob/b740b92f3600840e09d4c93f3138333838d1e474/torch/serialization.py#L528-L529\r\nIt seem like the variable it used is destructured from here:\r\nhttps://github.com/pytorch/pytorch/blob/b740b92f3600840e09d4c93f3138333838d1e474/torch/serialization.py#L525\r\nWhich also came from here:\r\nhttps://github.com/pytorch/pytorch/blob/b740b92f3600840e09d4c93f3138333838d1e474/torch/serialization.py#L517\r\nSo I insert `print(saved_id)` where it yell:\r\nNow, it print:\r\n`('storage', <class 'torch.CharStorage'>, '2149339138576', 'cpu', -1204967286, None)`\r\n\r\nIt seem that size is negative.\r\n\r\n## To Reproduce\r\n```\r\nimport torch\r\n\r\ntorch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\ntorch.load('./sample.pt')\r\n```\r\nIt can only be reproduce in MS.Windows environment.\r\nMy Windows version is:\r\n10.0.17134.472\r\nMy Python version is:\r\n3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)]\r\nSteps to reproduce the behavior:\r\n1. Run above code in MS. Windows\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-2-1e8f41ee3715> in <module>\r\n      2 \r\n      3 torch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\n----> 4 torch.load('./sample.pt')\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in load(f, map_location, pickle_module)\r\n    365         f = open(f, 'rb')\r\n    366     try:\r\n--> 367         return _load(f, map_location, pickle_module)\r\n    368     finally:\r\n    369         if new_fd:\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in _load(f, map_location, pickle_module)\r\n    538     unpickler = pickle_module.Unpickler(f)\r\n    539     unpickler.persistent_load = persistent_load\r\n--> 540     result = unpickler.load()\r\n    541 \r\n    542     deserialized_storage_keys = pickle_module.load(f)\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in persistent_load(saved_id)\r\n    504                 print(data_type, size)\r\n    505                 deserialized_objects[root_key] = restore_location(\r\n--> 506                     data_type(size), location)\r\n    507             storage = deserialized_objects[root_key]\r\n    508             if view_metadata is not None:\r\n\r\nRuntimeError: $ Torch: invalid memory size -- maybe an overflow? at ..\\aten\\src\\TH\\THGeneral.cpp:188\r\n\r\n## ",
        "Sample Code": "\r\n```\r\nimport torch\r\n\r\ntorch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\ntorch.load('./sample.pt')\r\n```\r\nIt can only be reproduce in MS.Windows environment.\r\nMy Windows version is:\r\n10.0.17134.472\r\nMy Python version is:\r\n3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)]\r\nSteps to reproduce the behavior:\r\n1. Run above code in MS. Windows\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-2-1e8f41ee3715> in <module>\r\n      2 \r\n      3 torch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\n----> 4 torch.load('./sample.pt')\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in load(f, map_location, pickle_module)\r\n    365         f = open(f, 'rb')\r\n    366     try:\r\n--> 367         return _load(f, map_location, pickle_module)\r\n    368     finally:\r\n    369         if new_fd:\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in _load(f, map_location, pickle_module)\r\n    538     unpickler = pickle_module.Unpickler(f)\r\n    539     unpickler.persistent_load = persistent_load\r\n--> 540     result = unpickler.load()\r\n    541 \r\n    542     deserialized_storage_keys = pickle_module.load(f)\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in persistent_load(saved_id)\r\n    504                 print(data_type, size)\r\n    505                 deserialized_objects[root_key] = restore_location(\r\n--> 506                     data_type(size), location)\r\n    507             storage = deserialized_objects[root_key]\r\n    508             if view_metadata is not None:\r\n\r\nRuntimeError: $ Torch: invalid memory size -- maybe an overflow? at ..\\aten\\src\\TH\\THGeneral.cpp:188\r\n\r\n## Expected behavior\r\n\r\nTensor is loaded without error.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.0\r\n - OS (e.g., Linux): Windows 10\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.6.7\r\n - CUDA/cuDNN version: N/A\r\n - GPU models and configuration: N/A\r\n - Any other relevant information: No problem on Linux\r\n\r\n## ",
        "API Signature": "\n torch.autograd. grad ( outputs ,  inputs ,  grad_outputs ,  retain_graph ,  create_graph ,  only_inputs ,  allow_unused ,  is_grads_batched ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/7343",
        "Issue title": "[memory leak] [PyTorch] .backward(create_graph=True)",
        "Bug description": "\r\n\r\nHello,\r\n\r\nI'm having a problem of loading a serialized tensor from a file.\r\nMy tensor shape is [309000001, 2, 5] the dtype is torch.int8\r\nWhen I deserialize the tensor using torch.load(), it yell \"invalid memory size\".\r\nThe line that it complain is:\r\nhttps://github.com/pytorch/pytorch/blob/b740b92f3600840e09d4c93f3138333838d1e474/torch/serialization.py#L528-L529\r\nIt seem like the variable it used is destructured from here:\r\nhttps://github.com/pytorch/pytorch/blob/b740b92f3600840e09d4c93f3138333838d1e474/torch/serialization.py#L525\r\nWhich also came from here:\r\nhttps://github.com/pytorch/pytorch/blob/b740b92f3600840e09d4c93f3138333838d1e474/torch/serialization.py#L517\r\nSo I insert `print(saved_id)` where it yell:\r\nNow, it print:\r\n`('storage', <class 'torch.CharStorage'>, '2149339138576', 'cpu', -1204967286, None)`\r\n\r\nIt seem that size is negative.\r\n\r\n## To Reproduce\r\n```\r\nimport torch\r\n\r\ntorch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\ntorch.load('./sample.pt')\r\n```\r\nIt can only be reproduce in MS.Windows environment.\r\nMy Windows version is:\r\n10.0.17134.472\r\nMy Python version is:\r\n3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)]\r\nSteps to reproduce the behavior:\r\n1. Run above code in MS. Windows\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-2-1e8f41ee3715> in <module>\r\n      2 \r\n      3 torch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\n----> 4 torch.load('./sample.pt')\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in load(f, map_location, pickle_module)\r\n    365         f = open(f, 'rb')\r\n    366     try:\r\n--> 367         return _load(f, map_location, pickle_module)\r\n    368     finally:\r\n    369         if new_fd:\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in _load(f, map_location, pickle_module)\r\n    538     unpickler = pickle_module.Unpickler(f)\r\n    539     unpickler.persistent_load = persistent_load\r\n--> 540     result = unpickler.load()\r\n    541 \r\n    542     deserialized_storage_keys = pickle_module.load(f)\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in persistent_load(saved_id)\r\n    504                 print(data_type, size)\r\n    505                 deserialized_objects[root_key] = restore_location(\r\n--> 506                     data_type(size), location)\r\n    507             storage = deserialized_objects[root_key]\r\n    508             if view_metadata is not None:\r\n\r\nRuntimeError: $ Torch: invalid memory size -- maybe an overflow? at ..\\aten\\src\\TH\\THGeneral.cpp:188\r\n\r\n## ",
        "Sample Code": "\r\n```\r\nimport torch\r\n\r\ntorch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\ntorch.load('./sample.pt')\r\n```\r\nIt can only be reproduce in MS.Windows environment.\r\nMy Windows version is:\r\n10.0.17134.472\r\nMy Python version is:\r\n3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)]\r\nSteps to reproduce the behavior:\r\n1. Run above code in MS. Windows\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-2-1e8f41ee3715> in <module>\r\n      2 \r\n      3 torch.save(torch.zeros([309237982, 2, 5], dtype=torch.int8), './sample.pt')\r\n----> 4 torch.load('./sample.pt')\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in load(f, map_location, pickle_module)\r\n    365         f = open(f, 'rb')\r\n    366     try:\r\n--> 367         return _load(f, map_location, pickle_module)\r\n    368     finally:\r\n    369         if new_fd:\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in _load(f, map_location, pickle_module)\r\n    538     unpickler = pickle_module.Unpickler(f)\r\n    539     unpickler.persistent_load = persistent_load\r\n--> 540     result = unpickler.load()\r\n    541 \r\n    542     deserialized_storage_keys = pickle_module.load(f)\r\n\r\nc:\\users\\nattapong\\workspace\\lstm_nlp\\lib\\site-packages\\torch\\serialization.py in persistent_load(saved_id)\r\n    504                 print(data_type, size)\r\n    505                 deserialized_objects[root_key] = restore_location(\r\n--> 506                     data_type(size), location)\r\n    507             storage = deserialized_objects[root_key]\r\n    508             if view_metadata is not None:\r\n\r\nRuntimeError: $ Torch: invalid memory size -- maybe an overflow? at ..\\aten\\src\\TH\\THGeneral.cpp:188\r\n\r\n## Expected behavior\r\n\r\nTensor is loaded without error.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.0\r\n - OS (e.g., Linux): Windows 10\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.6.7\r\n - CUDA/cuDNN version: N/A\r\n - GPU models and configuration: N/A\r\n - Any other relevant information: No problem on Linux\r\n\r\n## ",
        "API Signature": "\n torch.autograd. grad ( outputs ,  inputs ,  grad_outputs ,  retain_graph ,  create_graph ,  only_inputs ,  allow_unused ,  is_grads_batched ) [source] \u00b6",
        "Bug fix": ""
    }
]
