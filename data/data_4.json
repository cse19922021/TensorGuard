[{
    "Id": 1,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/0a7eef9bcf6d1f8b5531102342ffc21f24beb58d",
    "Violation": "unnecessary",
    "Bug report": "[BE] Remove stale CUDA version check from cpp_extension.py. As at least CUDA-11.x is needed to build PyTorch on latest trunk. But still skip `--generate-dependencies-with-compile` if running on ROCm",
    "Number of deleted lines": 5,
    "Deleted lines": "        compile_rule.append('  depfile = $out.d')\n        compile_rule.append('  deps = gcc')\n\n    if with_cuda:\n        cuda_compile_rule = ['rule cuda_compile']\n        nvcc_gendeps = ''\n        # --generate-dependencies-with-compile was added in CUDA 10.2.\n        # Compilation will work on earlier CUDA versions but header file\n        # dependencies are not correctly computed.\n        required_cuda_version = '11.0'\n        if torch.version.cuda is not None and TorchVersion(torch.version.cuda) >= required_cuda_version:\n            cuda_compile_rule.append('  depfile = $out.d')\n            cuda_compile_rule.append('  deps = gcc')\n            # Note: non-system deps with nvcc are only supported\n            # on Linux so use --generate-dependencies-with-compile\n            # to make this work on Windows too.\n            nvcc_gendeps = '--generate-dependencies-with-compile --dependency-output $out.d'\n        cuda_compile_rule.append(\n            f'  command = $nvcc {nvcc_gendeps} $cuda_cflags -c $in -o $out $cuda_post_cflags')"
},
{
    "Id": 2,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/93cea394dee1315c7a85ead7bb7af21363157c4f",
    "Violation": "improper",
    "Bug report": "Currently we compare `CUDA_INCLUDE_DIRS` and expect exact equality with `CUDAToolkit_INCLUDE_DIR` however this fails in the presense of symbolic links or for split installs where there are multiple include paths.",
    "Number of deleted lines": 4,
    "Deleted lines": "endif()\n\nfind_package(CUDAToolkit REQUIRED)\n\ncmake_policy(POP)\n\nif(NOT CMAKE_CUDA_COMPILER_VERSION STREQUAL CUDAToolkit_VERSION OR\n    NOT CUDA_INCLUDE_DIRS STREQUAL CUDAToolkit_INCLUDE_DIR)\n  message(FATAL_ERROR \"Found two conflicting CUDA installs:\\n\"\n                      \"V${CMAKE_CUDA_COMPILER_VERSION} in '${CUDA_INCLUDE_DIRS}' and\\n\"\n                      \"V${CUDAToolkit_VERSION} in '${CUDAToolkit_INCLUDE_DIR}'\")\nendif()\n\nif(NOT TARGET CUDA::nvToolsExt)\n  message(FATAL_ERROR \"Failed to find nvToolsExt\")\nendif()\n\nmessage(STATUS \"Caffe2: CUDA detected: \" ${CUDA_VERSION})\nmessage(STATUS \"Caffe2: CUDA nvcc is: \" ${CUDA_NVCC_EXECUTABLE})"
},
{
    "Id": 3,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/6b4c686b9a33a1503a4a4133f9067dd31e0822f7",
    "Violation": "improper",
    "Bug report": "Forward fix a performance regression caused by #110510. When a model is run once, all those kernel pointers are initialized and removing the if-nullptr check will cause those loadKernel be unnecessarily executed again when we rerun the foward function.",
    "Number of deleted lines": 2,
    "Deleted lines": "\n    @functools.lru_cache(None)\n    def generate_load_kernel_once(\n        self, name: str, mangled_name: str, cubin_path: str, shared_mem: int\n    ):\n        if V.graph.aot_mode:\n            self.writeline(\n                f\"\"\"kernels.{name} = loadKernel(\"{cubin_path}\", \"{mangled_name}\", {shared_mem}, this->cubin_dir_);\"\"\"\n            )\n        else:\n            self.writeline(\n                f\"\"\"{name} = loadKernel(\"{cubin_path}\", \"{mangled_name}\", {shared_mem});\"\"\"\n            )\n\n    def generate_args_decl(self, call_args):\n        dynamic_symbols = V.graph.sizevars.free_symbols()\n        # TODO: only works for constant now, need type info\n        new_args = []\n        for arg in call_args:\n            var_name = f\"var_{next(self.arg_var_id)}\"\n            if isinstance("
},
{
    "Id": 4,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/45296f87ec865a7a500a6fd98353035c040d0cb7",
    "Violation": "insufficient",
    "Bug report": "Prior to this change ROCm was not exiting check_cuda, causing an exception at packaging.version.parse(torch.version.cuda),",
    "Number of deleted lines": 1,
    "Deleted lines": "    return packaging.version.parse(hip_str_version)\n\n\ndef check_cuda():\n    import torch\n\n    if not torch.cuda.is_available():\n        return None\n\n    torch_cuda_ver = packaging.version.parse(torch.version.cuda)\n\n    # check if torch cuda version matches system cuda version\n    cuda_ver = get_cuda_version()\n    if cuda_ver != torch_cuda_ver:\n        # raise VerifyDynamoError("
},
{
    "Id": 5,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/bede7d999523d02e636a8981c0dff233b67f1a62",
    "Violation": "improper",
    "Bug report": "It does not check if `kind` variable fits in array of pointer called `names`",
    "Number of deleted lines": 1,
    "Deleted lines": "                                \"ts\",\n                                \"g\",\n                                \"gs\",\n                                \"ty\",\n                                \"tys\",\n                                \"ival\"};\n  AT_ASSERT(size_t(kind) < sizeof(names) / sizeof(AttributeKind));\n  return names[int(kind)];\n}\n\nstruct AttributeValue {\n  AttributeValue(Symbol name) : name(name) {}\n  using Ptr = std::unique_ptr<AttributeValue>;\n  Symbol name;\n  virtual AttributeKind kind() const = 0;"
},
{
    "Id": 6,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/f6639359357452de8bfc691430396ded98ea399c",
    "Violation": "improper",
    "Bug report": "`TORCH_CHECK(i<UINT32_MAX)` is always false, it should be `TORCH_CHECK(iterShape[i] < UINT32_MAX)`",
    "Number of deleted lines": 3,
    "Deleted lines": "  uint32_t numThreads = iter.numel();\n  const uint32_t nDim = iter.ndim();\n  const IntArrayRef& iterShape = iter.shape();\n  std::vector<uint32_t> iterShapeData(iterShape.size());\n  std::vector<std::array<uint32_t, nOffsets>> strides(nDim);\n  TORCH_INTERNAL_ASSERT(iter.ntensors() >= nOffsets);\n\n  for (const auto i : c10::irange(iterShape.size())) {\n    TORCH_CHECK(i <= UINT32_MAX);\n    iterShapeData[i] = (uint32_t)(iterShape[i]);\n  }\n\n  for (const auto i : c10::irange(nDim)) {\n    for (const auto offset : c10::irange(nOffsets)) {\n      strides[i][offset] = iter.strides(offset)[i];\n    }\n  }\n\n  id<MTLComputePipelineState> kernelDataOffsetsPSO = MPSDevice::getInstance()->metalIndexingPSO(\"kernel_index_offsets\");\n  id<MTLBuffer> kernelDataOffsets = (id<MTLBuffer>)getIMPSAllocator()->allocate(numThreads * sizeof(simd_uint3)).get();\n\n  [commandEncoder setComputePipelineState:kernelDataOffsetsPSO];\n  [commandEncoder setBytes:strides.data() length:sizeof(uint32_t) * nDim * nOffsets atIndex:0];"
},
{
    "Id": 7,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/175ccfc4c8443bcc65c87d9c942272d3ebf16b0b",
    "Violation": "missing",
    "Bug report": "flatbuffer module fields are not initialized",
    "Number of deleted lines": 2,
    "Deleted lines": "  all_types_.clear();\n  storages_.clear();\n  storage_loaded_.clear();\n  module_parsed_ = false;\n\n  const auto* ivalues = module->ivalues();\n  TORCH_CHECK(ivalues != nullptr, \"Corrupted ivalues field\")\n  TORCH_CHECK(\n      reinterpret_cast<const char*>(ivalues) < end, \"Corrupted ivalues field\")\n  all_ivalues_.resize(ivalues->size());\n  all_types_.resize(module->object_types()->size());\n  storages_.resize(module->storage_data_size());\n  storage_loaded_.resize(module->storage_data_size(), false);\n\n  mobile_ivalue_size_ = module_->mobile_ivalue_size();\n  if (mobile_ivalue_size_ == 0) {\n    mobile_ivalue_size_ = ivalues->size();"
},
{
    "Id": 8,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/bde7b81f34925491fbcbb9e355697eb594e36923",
    "Violation": "improper",
    "Bug report": "Back out \"[PyTorch] Don't do extra numel() check in TensorImpl::data()",
    "Number of deleted lines": 1,
    "Deleted lines": "    auto* data = get_data();\n    static_assert(\n        sizeof(*data) == 1, \"get_data must return a byte-addressed pointer.\");\n    // Computing an offset into an empty tensor would be UB, since an empty\n    // tensor's storage will be nullptr, and adding a nonzero offset to nullptr\n    // is UB.  So we skip the offset computation in this case.\n    if (data == nullptr) {\n      return nullptr;\n    }\n    return data + data_type_.itemsize() * storage_offset_;\n  }\n\n public:\n  /**\n   * Returns the TypeMeta of a tensor, which describes what data type"
},
{
    "Id": 9,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/2e224d62b6afecc78d885d0a4e160354950f6424",
    "Violation": "missing",
    "Bug report": "We have environment variable USE_CUDNN with self-explanatory name. However cpp code is compiled based on cpp macro definition AT_CUDNN_ENABLED, even if USE_CUDNN is set to 0, cpp is compiled with cuDNN if cmake finds cuDNN in the system.",
    "Number of deleted lines": 2,
    "Deleted lines": "    message(\"disabling CUDA because NOT USE_CUDA is set\")\n    SET(AT_CUDA_ENABLED 0)\n  else()\n    SET(AT_CUDA_ENABLED 1)\n  endif()\n\n  IF (NOT AT_CUDA_ENABLED OR NOT CUDNN_FOUND)\n    MESSAGE(STATUS \"CuDNN not found. Compiling without CuDNN support\")\n    set(AT_CUDNN_ENABLED 0)\n  ELSE()\n    include_directories(SYSTEM ${CUDNN_INCLUDE_PATH})\n    set(AT_CUDNN_ENABLED 1)\n  ENDIF()\n\n  IF (NOT USE_ROCM)\n    message(\"disabling ROCM because NOT USE_ROCM is set\")"
},
{
    "Id": 10,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/30e1c74dc19ae2b622b46ebcdb7972c42775ac80",
    "Violation": "improper",
    "Bug report": "Update cuda amp to also check xla device ",
    "Number of deleted lines": 1,
    "Deleted lines": "        if self.device == 'cuda':\n            self.fast_dtype = torch.get_autocast_gpu_dtype()\n        elif self.device == 'cpu':\n            self.fast_dtype = torch.get_autocast_cpu_dtype()\n        else:\n            raise RuntimeError('User specified autocast device_type must be \\'cuda\\' or \\'cpu\\'')\n        if not torch.cuda.is_available() and self.device == 'cuda':\n            warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n            enabled = False\n        for key, value in kwargs.items():\n            if key == 'fast_dtype':\n                self.fast_dtype = value\n            if not (key == 'fast_dtype'):\n                raise RuntimeError('Unrecognized optional argument supplied to autocast context manager: ' + str(key))\n"
},
{
    "Id": 11,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/5a63c452e638dad8e077887ad8d2c94ff0e23917",
    "Violation": "missing",
    "Bug report": "This is because there are some hard-to-detect edge cases that will throw exceptions with cudnn 8.0.5 on Nvidia A40 GPU.",
    "Number of deleted lines": 0,
    "Deleted lines": "        return ((bsize % 16 == 0 && bsize != 80 && bsize !=112) || bsize == 8) &&\n               ((tensors.seq_length >=40 && bsize <=128) ||\n                (tensors.seq_length >=20 && bsize <=96) ||\n                (tensors.seq_length >=10 && bsize <=32));\n      }\n    } else if (prop->major >= 8) {\n      // Based on tests by Vasily Volkov and xwang233.  Vasily only tried bsize <= 128,\n      // so conservatively enable persistence for bsize <= 128 only.\n      // TODO:  Run more tests for bsize > 128.\n      if (rnn.mode == CUDNN_GRU) {\n        // Persistent GRU performance is flakier than other RNN types.  Exclude them for now.\n        // TODO:  Write a more refined GRU heuristic.\n        return false;\n      } else if (rnn.mode == CUDNN_LSTM) {"
},
{
    "Id": 12,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/611080a118fff166c85f3200d860f3b059abac6f",
    "Violation": "improper",
    "Bug report": "uda 11.0.x doesn't support sm86.",
    "Number of deleted lines": 2,
    "Deleted lines": "if(CUDA_VERSION VERSION_GREATER \"10.5\")\n  list(APPEND CUDA_KNOWN_GPU_ARCHITECTURES \"Ampere\")\n  list(APPEND CUDA_COMMON_GPU_ARCHITECTURES \"8.0\")\n  list(APPEND CUDA_ALL_GPU_ARCHITECTURES \"8.0\")\n\n  if(CUDA_VERSION VERSION_LESS \"11.1\")\n    set(CUDA_LIMIT_GPU_ARCHITECTURE \"8.6\")\n    list(APPEND CUDA_COMMON_GPU_ARCHITECTURES \"8.0+PTX\")\n  endif()\nendif()\n\nif(CUDA_VERSION VERSION_GREATER \"11.0\")\n  list(APPEND CUDA_COMMON_GPU_ARCHITECTURES \"8.6\" \"8.6+PTX\")\n  list(APPEND CUDA_ALL_GPU_ARCHITECTURES \"8.6\")\n\n  if(CUDA_VERSION VERSION_LESS \"12.0\")\n    set(CUDA_LIMIT_GPU_ARCHITECTURE \"9.0\")\n  endif()\nendif()\n\n################################################################################################\n# A function for automatic detection of GPUs installed  (if autodetection is enabled)"
},
{
    "Id": 13,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/563bbeb8905f4cea0bc5353dc12518c61113128e",
    "Violation": "insufficient",
    "Bug report": "undefined CUDA_VERSION warning",
    "Number of deleted lines": 1,
    "Deleted lines": ""
},
{
    "Id": 14,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/8198474eb763c8d526ede3418211479c2f4cbd30",
    "Violation": "missing",
    "Bug report": "Previous to this PR, we only checked TorchScript nodes for scope compatibility, skipping their parent's scope reference check.",
    "Number of deleted lines": 1,
    "Deleted lines": "    NameFunc name_func) {\n  std::string out = (*name_func)(scope);\n  if (scope->isRoot()) {\n    return out;\n  }\n  auto parent = scope->parent();\n  while (!parent->isRoot()) {\n    out = std::string((*name_func)(parent)).append(layer_separator).append(out);\n    parent = parent->parent();\n  }\n  return out;\n}\n\nstd::pair<std::string, std::string> parseNameFromScope(\n    torch::jit::ScopePtr scope) {"
},
{
    "Id": 15,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/37dea0454dd310cfe443859f717862657df6b753",
    "Violation": "missing",
    "Bug report": "add checking for number of args checking observer in same graph",
    "Number of deleted lines": 1,
    "Deleted lines": "    \"\"\" Check if observer in same graph\n    when the node output is not fp32 and input is 'placeholder'\n    the input is assumed to be quantized, so it is observed\n    in a different place rather than not observed.\n    \"\"\"\n    node_output_dtype = get_arg_target_dtype_as_output(node, modules, node_name_to_target_dtype)\n    if isinstance(node.args[0], Node):\n        if node_output_dtype == torch.quint8 and node.args[0].op == 'placeholder':\n            return False\n    return True\n\ndef is_pattern_dtype_config_supported_by_backend(\n    pattern: Optional[Pattern],\n    matched_node_pattern: Optional[NodePattern],\n    node_name_to_target_dtype: Dict[str, Dict[str, Optional[Union[torch.dtype, type]]]],"
},
{
    "Id": 16,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/bdbd3ed312e0fc81e75302239ea78b3445fe95e7",
    "Violation": "insufficient",
    "Bug report": "Although `len(compiler.captured_graphs)` is 2, no error was thrown during the compilation. This observation conflicts with `nopython=True`. After some digging, I found a check is missed before making graph break. This PR adds it.",
    "Number of deleted lines": 1,
    "Deleted lines": "        def wrapper(self: \"InstructionTranslatorBase\", inst: Instruction):\n            state = self.copy_graphstate()\n            reason = None\n            try:\n                return inner_fn(self, inst)\n            except Unsupported as excp:\n                if self.has_backedge():\n                    msg = \"Skipping frame because there is a graph break in a for/while loop\"\n                    log.debug(msg)\n                    raise exc.SkipFrame(msg) from excp\n\n                if not self.should_compile_partial_graph():\n                    raise\n\n                log.debug(\"break_graph_if_unsupported triggered compile\", exc_info=True)"
},
{
    "Id": 17,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/7e9bf2ed860b8b60d252eead4cc457c3fe5f1667",
    "Violation": "insufficient",
    "Bug report": "Although `len(compiler.captured_graphs)` is 2, no error was thrown during the compilation. This observation conflicts with `nopython=True`. After some digging, I found a check is missed before making graph break. This PR adds it.",
    "Number of deleted lines": 1,
    "Deleted lines": "        def wrapper(self: \"InstructionTranslatorBase\", inst: Instruction):\n            state = self.copy_graphstate()\n            reason = None\n            try:\n                return inner_fn(self, inst)\n            except Unsupported as excp:\n                if self.has_backedge():\n                    msg = \"Skipping frame because there is a graph break in a for/while loop\"\n                    log.debug(msg)\n                    raise exc.SkipFrame(msg) from excp\n\n                if not self.should_compile_partial_graph():\n                    raise\n\n                log.debug(\"break_graph_if_unsupported triggered compile\", exc_info=True)"
},
{
    "Id": 18,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/9234f5026dbaf09a41b82bb6cf5f10ad4eeb03f2",
    "Violation": "improper",
    "Bug report": "at::cuda::CUDAEvent is \"lazy\" and only creates an event when it's first recorded. Until then, at::cuda::CUDAEvent is empty. If we use at::cuda::CUDAEvent::query() this is taken into account (an empty event is always ready), but WorkNCCL extracts the raw cudaEvent_t value from at::cuda::CUDAEvent and calls cudaEventQuery manually and doesn't check this. This could cause a failure. It's unclear if this is ever supposed to happen, but we're seeing that failure, and we want to sort it out in order to see if there's something \"deeper\" going on.",
    "Number of deleted lines": 5,
    "Deleted lines": "  return finishedGPUExecutionInternal();\n}\n\nbool ProcessGroupNCCL::WorkNCCL::finishedGPUExecutionInternal() const {\n  for (size_t i = 0; i < devices_.size(); ++i) {\n    // Checking the work's corresponding CUDA events' status\n    auto ret = cudaEventQuery((*cudaEvents_)[i]);\n    if (ret != cudaSuccess && ret != cudaErrorNotReady) {\n      AT_CUDA_CHECK(ret);\n    }\n    if (ret == cudaErrorNotReady) {\n      return false;\n    }\n  }\n  return true;\n}\n\nvoid ProcessGroupNCCL::WorkNCCL::checkAndThrowException() {\n  // Set the appropriate exception if found."
},
{
    "Id": 19,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/e9c1ccee2247a7746fde202067a7d47b72809968",
    "Violation": "improper",
    "Bug report": "Bug fix: allow std 0 in the meta definition of normal_. All other `normal` variants allow 0.  Looks like a mistake made while copying the check. ",
    "Number of deleted lines": 1,
    "Deleted lines": "\nTensor& normal_(Tensor& self, double mean, double std, c10::optional<Generator> gen) {\n  return at::native::templates::normal_impl_<NormalStub, Generator>(self, mean, std, gen);\n}\n\nTensor& normal_meta_(Tensor& self, double mean, double std, c10::optional<Generator> gen) {\n  TORCH_CHECK(std > 0.0, \"normal_ expects std > 0.0, but found std=\", std);  // TODO: dedupe\n  return self;\n}\n\nTensor& normal_out(const Tensor& mean, double std, c10::optional<Generator> gen, Tensor& output) {\n  return at::native::templates::normal_out_impl<NormalStub, Generator>(output, mean, std, gen);\n}\n\nTensor& normal_out(double mean, const Tensor& std, c10::optional<Generator> gen, Tensor& output) {"
},
{
    "Id": 20,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/c99277e177cf16736262251c7e92ea5e9ba2c5c2",
    "Violation": "improper",
    "Bug report": " handle the case in acc_ops.sum when dim == 0, differentiating it from the case when dim is None. handle the case in acc_ops.sum when dim == 0, differentiating it from the case when dim is None",
    "Number of deleted lines": 1,
    "Deleted lines": "        sum_node.meta = node.meta.copy()\n        return sum_node\n\n\n@register_acc_op\ndef sum(*, input, dim=None, keepdim=False, dtype=None):\n    if dim:\n        return torch.sum(**locals())\n    else:\n        return input.sum(dtype=dtype)\n\n\n@register_acc_op_mapping(op_and_target=(\"call_function\", torch.sigmoid))\n@register_acc_op_mapping(op_and_target=(\"call_method\", \"sigmoid\"))\n@register_acc_op"
},
{
    "Id": 21,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/d72db37c4a6513c0f67f6f69870c9c45bf4880e6",
    "Violation": "unnecessary",
    "Bug report": "In file: combinatorics.py, the comparison of Collection length creates a logical short circuit. if isinstance(self.sampler, Sized) and len(self.sampler) >= 0: Here, the right side of the comparison will always return true. I suggested that the Collection length check should be removed since this is redundant.",
    "Number of deleted lines": 1,
    "Deleted lines": "\n    def __iter__(self) -> Iterator[T_co]:\n        return iter(self.sampler)\n\n    def __len__(self) -> int:\n        # Dataset has been tested as `Sized`\n        if isinstance(self.sampler, Sized) and len(self.sampler) >= 0:\n            return len(self.sampler)\n        raise TypeError(\"{} instance doesn't have valid length\".format(type(self).__name__))\n\n\n@functional_datapipe('shuffle')\nclass ShufflerIterDataPipe(IterDataPipe[T_co]):\n    r\"\"\"\n    Shuffles the input DataPipe with a buffer (functional name: ``shuffle``). The buffer"
},
{
    "Id": 22,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/c170d395de8ca441d3bedb20c9e45beb666f216c",
    "Violation": "missing",
    "Bug report": "Only check for xnnpack if torch installed. Fixes a bug where collect_env.py was not able to be run without having torch installed",
    "Number of deleted lines": 2,
    "Deleted lines": "\ndef get_cachingallocator_config():\n    ca_config = os.environ.get('PYTORCH_CUDA_ALLOC_CONF', '')\n    return ca_config\n\ndef is_xnnpack_available():\n    import torch.backends.xnnpack\n    return str(torch.backends.xnnpack.enabled)  # type: ignore[attr-defined]\n\ndef get_env_info():\n    run_lambda = run\n    pip_version, pip_list_output = get_pip_packages(run_lambda)\n\n    if TORCH_AVAILABLE:\n        version_str = torch.__version__\n        debug_mode_str = str(torch.version.debug)"
},
{
    "Id": 23,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/65faf1a7eb07129d8b1f017fac341e178620dabd",
    "Violation": "missing",
    "Bug report": "Add version check for ProfilingVerbosity bulider config",
    "Number of deleted lines": 1,
    "Deleted lines": "            cache_file = numpy.array(timing_cache)\n            cache = builder_config.create_timing_cache(cache_file.tobytes())\n        else:\n            cache = builder_config.create_timing_cache(b\"\")\n        builder_config.set_timing_cache(cache, False)\n\n        builder_config.profiling_verbosity = profiling_verbosity if profiling_verbosity else trt.ProfilingVerbosity.LAYER_NAMES_ONLY\n        if fp16_mode:\n            builder_config.set_flag(trt.BuilderFlag.FP16)\n\n        if int8_mode:\n            builder_config.set_flag(trt.BuilderFlag.INT8)\n\n        if sparse_weights:\n            assert fp16_mode or int8_mode, \"We can only enable sparsity in fp16 or int8 mode.\""
},
{
    "Id": 24,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/5fdddbbfe8ef17b2c81ed34a48f3b963944aa4c3",
    "Violation": "improper",
    "Bug report": "Fix checking of current mode in PyOperator dispatch",
    "Number of deleted lines": 3,
    "Deleted lines": "\n        if dispatch_key == torch._C.DispatchKey.FuncTorchDynamicLayerFrontMode:\n            return dispatch_functorch(self, args, kwargs)\n\n        if dispatch_key == torch._C.DispatchKey.Python:\n            # TODO(voz): We should walk all the nodes here / turn it into a list, topmode is ok for now.\n            curr_mode = type(_get_current_dispatch_mode())\n            assert (\n                curr_mode is not None\n            ), \"Illegal invocation of dispatch on torch._C.DispatchKey.Python without a mode.\"\n            assert (\n                curr_mode in self.python_key_mode_table\n            ), f\"Current active mode {curr_mode} not registered\"\n            # TODO(voz): The idea behind this is that we do not yet support dispatch by key + mode, only key.\n            return self.python_key_mode_table[curr_mode](*args, **kwargs)\n\n        assert dispatch_key in self.table, dispatch_key\n        return self.table[dispatch_key](*args, **kwargs)\n\n    def __call__(self, *args, **kwargs):\n        flat_args = _to_flat_tuple(args, kwargs)\n        if torch.overrides.has_torch_function(flat_args):\n            return torch.overrides.handle_torch_function("
},
{
    "Id": 25,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/0c0c9e743e82b398435ed07719e998aa15ac1ce1",
    "Violation": "improper",
    "Bug report": "Fix dimensions check ",
    "Number of deleted lines": 1,
    "Deleted lines": "\n  bool RunOnDevice() override {\n    const auto& input = Input(0);\n    const auto* input_data = input.template data<T>();\n    auto* Y = Output(0);\n\n    CHECK_LT(num_reduce_dims_, input.dims().size());\n    const int M = FIRSTDIMS\n        ? input.size_to_dim(num_reduce_dims_)\n        : input.size_to_dim(input.ndim() - num_reduce_dims_);\n    const int N = FIRSTDIMS\n        ? input.size_from_dim(num_reduce_dims_)\n        : input.size_from_dim(input.ndim() - num_reduce_dims_);\n\n    vector<TIndex> output_shape;"
},
{
    "Id": 26,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/4d0fbb0e6f578bea14f3f52b0a927bcc20f8b109",
    "Violation": "improper",
    "Bug report": "when adding a new axis to concatenate along, allow it to be the last axis. For example, concated 1D columns into a 2D matrix with axis=1, add_axis=1.",
    "Number of deleted lines": 1,
    "Deleted lines": "bool ConcatOp<Context>::RunOnDevice() {\n  auto* output = Output(0);\n  TensorCPU* split = OperatorBase::Output<TensorCPU>(1);\n  split->Resize(vector<TIndex>(1, InputSize()));\n  int* axis_data = split->template mutable_data<int>();\n  auto& input_zero = Input(0);\n  CAFFE_ENFORCE_LT(axis_, input_zero.ndim(), \"Axis not in input ndim range.\");\n  for (int i = 1; i < InputSize(); ++i) {\n    CAFFE_ENFORCE(\n        Input(i).meta() == input_zero.meta(),\n        \"All inputs must have the same type, expected: \",\n        input_zero.meta().name(),\n        \" but got: \",\n        Input(i).meta().name(),\n        \" for input: \","
},
{
    "Id": 27,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/b2d110447190abe5d66b0b59a775cc4881f3e30e",
    "Violation": "improper",
    "Bug report": "Fixed numpy bool check",
    "Number of deleted lines": 1,
    "Deleted lines": "        self.num_heads = num_heads\n        self.dropout = dropout\n        self.batch_first = batch_first\n        self.head_dim = embed_dim // num_heads\n        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n\n        if self._qkv_same_embed_dim is False:\n            self.q_proj_weight = Parameter(torch.empty((embed_dim, embed_dim), **factory_kwargs))\n            self.k_proj_weight = Parameter(torch.empty((embed_dim, self.kdim), **factory_kwargs))\n            self.v_proj_weight = Parameter(torch.empty((embed_dim, self.vdim), **factory_kwargs))\n            self.register_parameter('in_proj_weight', None)\n        else:\n            self.in_proj_weight = Parameter(torch.empty((3 * embed_dim, embed_dim), **factory_kwargs))\n            self.register_parameter('q_proj_weight', None)\n            self.register_parameter('k_proj_weight', None)"
},
{
    "Id": 28,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/85cbe0d8258ab06897e2f049e61f74d8aa935240",
    "Violation": "missing",
    "Bug report": "This diff is similar to D14163001. We need to handle the edge case when add_axis=1.",
    "Number of deleted lines": 1,
    "Deleted lines": "  ArgumentHelper helper(def);\n  const int axis = helper.HasArgument(\"axis\")\n      ? helper.GetSingleArgument<int>(\"axis\", -1)\n      : GetDimFromOrderString(\n            helper.GetSingleArgument<string>(\"order\", \"NCHW\"));\n  bool add_axis = helper.GetSingleArgument<int>(\"add_axis\", 0) != 0;\n  const int canonical_axis = canonical_axis_index_(axis, in[0].dims_size());\n  CAFFE_ENFORCE_GT(in.size(), 0);\n  vector<int> out_shape(in[0].dims().begin(), in[0].dims().end());\n  if (add_axis) {\n    out_shape.insert(out_shape.begin() + canonical_axis, in.size());\n  } else {\n    for (size_t i = 1; i < in.size(); ++i) {\n      out_shape[canonical_axis] += in[i].dims(canonical_axis);\n    }"
},
{
    "Id": 29,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/4f63f348aef3da8b4d53f61098f4e32bd916c221",
    "Violation": "improper",
    "Bug report": "The bounds check was too conservative by an extra one.",
    "Number of deleted lines": 1,
    "Deleted lines": "  if (tensor.numel() == 0) {\n    throw std::runtime_error(\"cannot unsqueeze empty tensor\");\n  }\n\n  std::vector<int64_t> sizes(tensor.sizes());\n  std::vector<int64_t> strides(tensor.strides());\n  int64_t new_stride = dim >= tensor.dim() - 1 ? 1 : sizes[dim] * strides[dim];\n  sizes.insert(sizes.begin() + dim, 1);\n  strides.insert(strides.begin() + dim, new_stride);\n\n  return std::make_tuple(sizes, strides);\n}\n\nTensor squeeze(const Tensor& self) {\n  auto g = inferSqueezeGeometry(self);"
},
{
    "Id": 30,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/bf32ea80942ce720b105efcd517fd11182edeb08",
    "Violation": "insufficient",
    "Bug report": " Fix dimension check in 1D instance norm, allowing 2D tensors alongsid e 3D.",
    "Number of deleted lines": 2,
    "Deleted lines": "\n    .. _`Instance Normalization: The Missing Ingredient for Fast Stylization`:\n        https://arxiv.org/abs/1607.08022\n    \"\"\"\n\n    def _check_input_dim(self, input):\n        if input.dim() != 3:\n            raise ValueError('expected 3D input (got {}D input)'\n                             .format(input.dim()))\n\n\nclass InstanceNorm2d(_InstanceNorm):\n    r\"\"\"Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs\n    with additional channel dimension) as described in the paper\n    `Instance Normalization: The Missing Ingredient for Fast Stylization`_ .\n"
},
{
    "Id": 31,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/a9deda5469a6ef73692a9dd796cc4eeba4436d6c",
    "Violation": "improper",
    "Bug report": "The at::native::_validate_sparse_coo_tensor_args only supports checking the indices on CUDA device and CPU device. To extend the function to support more device type.",
    "Number of deleted lines": 1,
    "Deleted lines": "  if (indices.numel() > 0) {\n    Tensor min_indices =\n        std::get</* values */ 0>(indices.min(/* dim */ 1, /* keepdim */ false));\n    Tensor max_indices =\n        std::get</* values */ 0>(indices.max(/* dim */ 1, /* keepdim */ false));\n    Tensor cpu_min_indices, cpu_max_indices;\n    if (indices.is_cuda()) {\n      cpu_min_indices = min_indices.to(at::DeviceType::CPU);\n      cpu_max_indices = max_indices.to(at::DeviceType::CPU);\n    } else {\n      cpu_min_indices = min_indices;\n      cpu_max_indices = max_indices;\n    }\n    auto cpu_min_indices_accessor = cpu_min_indices.accessor<int64_t, 1>();\n    auto cpu_max_indices_accessor = cpu_max_indices.accessor<int64_t, 1>();"
},
{
    "Id": 32,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/d9870d70c12dc59b0f8bce288910422bcb60b044",
    "Violation": "insufficient",
    "Bug report": "Exempt _foreach_norm from autograd_not_implemented_fallback check",
    "Number of deleted lines": 1,
    "Deleted lines": "        if (at::impl::tensor_has_dispatch(t) ||\n            at::impl::dispatch_mode_enabled())\n          return;\n        if (!is_inplace_output[idx_ret])\n          TORCH_INTERNAL_ASSERT(\n              t.use_count() <= 1, op_name); // Okay to return undefined tensor\n        if (!is_aliased_output[idx_ret] && t.has_storage())\n          TORCH_INTERNAL_ASSERT(t.storage().use_count() == 1);\n      },\n      stack,\n      stack->size() - num_returns,\n      num_returns);\n  // There should be only a single base-view pair, make sure their storage is\n  // aliased.\n  if (aliased_input_idx != -1 && aliased_output_idx != -1) {"
},
{
    "Id": 33,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/98f9ff90268ae62ab6d794cce0786121bf17edc9",
    "Violation": "improper",
    "Bug report": "Fix an assertion failure involving Slice. Before this change, exporting a model to ONNX involving Slice crashes at `axes[i]` in line 153 if C++ assertions are enabled:",
    "Number of deleted lines": 1,
    "Deleted lines": "      std::cerr\n          << \"Warning: Constant folding - Invalid 'axes' or 'ends' inputs found for opset >= 10 onnx::Slice op. \"\n          << \"Constant folding not applied.\" << std::endl;\n      return c10::nullopt;\n    }\n    auto axes_a = inputTensorValues[3].accessor<int64_t, 1>();\n    axes.reserve(inputTensorValues[3].sizes()[0]);\n    // ONNX slice accepts negative axis, fix this for aten op\n    for (const auto i : c10::irange(inputTensorValues[3].sizes()[0])) {\n      axes[i] = axes_a[i] < 0 ? axes_a[i] + inputTensorValues[0].sizes().size()\n                              : axes_a[i];\n    }\n  } else {\n    axes = std::vector<int64_t>(inputTensorValues[1].sizes()[0], 0);\n  }"
},
{
    "Id": 34,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/71af538e31547e5b1bc814c9e00323a21905baf3",
    "Violation": "insufficient",
    "Bug report": "Updated assert to remove check on 3rd dim for MHA.  Updated assert statement to remove check on 3rd dimension (features) for keys and values in MultiheadAttention / Transform. The feature dimension for keys and values can now be of different sizes",
    "Number of deleted lines": 1,
    "Deleted lines": "                need_weights=need_weights, attn_mask=attn_mask,\n                use_separate_proj_weight=use_separate_proj_weight,\n                q_proj_weight=q_proj_weight, k_proj_weight=k_proj_weight,\n                v_proj_weight=v_proj_weight, static_k=static_k, static_v=static_v)\n    tgt_len, bsz, embed_dim = query.size()\n    assert embed_dim == embed_dim_to_check\n    assert key.size() == value.size()\n\n    head_dim = embed_dim // num_heads\n    assert head_dim * num_heads == embed_dim, \"embed_dim must be divisible by num_heads\"\n    scaling = float(head_dim) ** -0.5\n\n    if not use_separate_proj_weight:\n        if torch.equal(query, key) and torch.equal(key, value):\n            # self-attention"
},
{
    "Id": 35,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/b8ab3080b1043a610ba2825a2be406a1833b1d70",
    "Violation": "improper",
    "Bug report": "If kernel sizes were specified via \"kernel_w\" and \"kernel_h\", tensor size inference was incorrect in InferShapesAndTypes(): it was checking for \"helper_w\" instead of \"kernel_w\".",
    "Number of deleted lines": 1,
    "Deleted lines": "      pads.push_back(helper.GetSingleArgument<int>(\"pad_r\", 0));\n    }\n\n    if (helper.HasArgument(\"kernel\")) {\n      kernel.resize(2, helper.GetSingleArgument<int>(\"kernel\", 1));\n    } else if (\n        helper.HasArgument(\"kernel_h\") && helper.HasArgument(\"helper_w\")) {\n      kernel.push_back(helper.GetSingleArgument<int>(\"kernel_h\", 1));\n      kernel.push_back(helper.GetSingleArgument<int>(\"kernel_w\", 1));\n    }\n\n    if (helper.HasArgument(\"stride\")) {\n      strides.resize(2, helper.GetSingleArgument<int>(\"stride\", 1));\n    } else if (\n        helper.HasArgument(\"stride_h\") && helper.HasArgument(\"stride_w\")) {"
},
{
    "Id": 36,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/be253b8ee8a104997773d11ed28928a48193217d",
    "Violation": "improper",
    "Bug report": "The existing check isn't safe for 32-bit `size_t` because the max 64-bit int will overflow.",
    "Number of deleted lines": 1,
    "Deleted lines": "#include <cstddef>\n\nnamespace at {\n\n// See TensorGeometry.h on why this is useful now that we cache is_contiguous.\nbool geometry_is_contiguous(IntArrayRef sizes, IntArrayRef strides) {\n  assert(sizes.size() < static_cast<std::size_t>(std::numeric_limits<std::int64_t>::max()));\n  auto dim = static_cast<std::int64_t>(sizes.size());\n  int64_t expected_stride = 1;\n  bool contig_if_nonempty = true;\n  for (int64_t i = dim - 1; i >= 0; i--) {\n    if (sizes[i] == 0) {\n      return true;\n    }\n    if (contig_if_nonempty) {"
},
{
    "Id": 37,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/128dd6b1502ad3687ffb79484b72d4cfafec496e",
    "Violation": "insufficient",
    "Bug report": "Relax the check that makes sure number of outs equals number of returns. We are trying to add an out variant for an existing operator, Notice the out argument is a mutable list of tensors. Given the fact that we don't support mutable tensor list as a return type and it seems not useful to add such a return type. The solution I'm proposing is to relax the constraint that the number of outs needs to be the same as the number of returns, so we can return a `void`.",
    "Number of deleted lines": 3,
    "Deleted lines": "        for ret in mutable_returns:\n            assert any([ret.annotation == arg.annotation for arg in out_and_self]), (\n                'All mutable returns must be aliased either to a keyword argument, or to \"self\". '\n                \"Did you forget to mark an out argument as keyword-only?\"\n            )\n        if self.arguments.out:\n            assert len(self.arguments.out) == len(\n                self.returns\n            ), \"Must return as many arguments as there are out arguments\"\n        if self.name.name.inplace:\n            # TODO: fixme\n            if not is_foreach_op(str(self.name)):\n                assert len(self.returns) == 1\n\n    def is_out_fn(self) -> bool:\n        # Note [is_out_fn]\n        #"
},
{
    "Id": 38,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/9c3cb6e652e6033e355cef92229fde5b0baf271b",
    "Violation": "improper",
    "Bug report": "Fix stride checks in gemm dispatch.  lda: \"When transa = 'N' or 'n', then lda must be at least max(1, m), otherwise lda must be at least max(1, k). When transb = 'N' or 'n', then ldb must be at least max(1, k), otherwise ldb must be at least max(1, n).",
    "Number of deleted lines": 2,
    "Deleted lines": "    if(n == 1)\n      ldb = k;\n  }\n\n#if defined(USE_BLAS) && (defined(TH_REAL_IS_DOUBLE) || defined(TH_REAL_IS_FLOAT))\n  if( (m <= INT_MAX) && (n <= INT_MAX) && (k <= INT_MAX) &&\n      (lda >= THMax(1, (transa_ ? m : k))) && (lda <= INT_MAX) &&\n      (ldb >= THMax(1, (transb_ ? k : n))) && (ldb <= INT_MAX) &&\n      (ldc >= THMax(1, n)) && (ldc <= INT_MAX) )\n  {\n    int i_m = (int)m;\n    int i_n = (int)n;\n    int i_k = (int)k;\n    int i_lda = (int)lda;\n    int i_ldb = (int)ldb;\n    int i_ldc = (int)ldc;"
},
{
    "Id": 39,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/7f125bca1cd42ebd8e07c97f1bd1682dff5cf387",
    "Violation": "insufficient",
    "Bug report": "Add pin_memory check in empty_strided. Add the false checking if pin_memory has been specified to `False`",
    "Number of deleted lines": 1,
    "Deleted lines": "    IntArrayRef stride,\n    optional<ScalarType> dtype,\n    optional<Layout> layout,\n    optional<Device> device,\n    optional<bool> pin_memory) {\n  TORCH_CHECK(\n      !pin_memory.has_value(),\n      \"'pin_memory' argument is incompatible with Metal tensor\");\n  MetalTensor mt{size.vec(), stride.vec()};\n  return MetalTensor::toTensor(\n      std::move(mt), at::device(at::kMetal).dtype(dtype));\n}\n\nTensor addmm(\n    const Tensor& bias,"
},
{
    "Id": 40,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/f02b7a9c36dd6182da694bc47a5c345285dfd951",
    "Violation": "improper",
    "Bug report": "don't error when unused fill value is zero. In the python version of `F.pad`, checking that the fill value was left as default was done by comparing against zero. So if someone does explicitly pass in a zero-value, then this `TORCH_CHECK` was an accidental BC-break.",
    "Number of deleted lines": 4,
    "Deleted lines": "  TORCH_CHECK(static_cast<int64_t>(pad.size()) <= input_dim * 2, \"Padding length too large\");\n  auto mode = static_cast<at::padding_mode>(mode_int);\n\n  if (mode == at::padding_mode::constant) {\n    return at::constant_pad_nd(self, pad, value.value_or(0.0));\n  }\n  TORCH_CHECK(\n      !value.has_value(), \"Padding mode \\\"\",\n      padding_mode_string(mode),\n      \"\\\" doesn't take in value argument\");\n\n  if (pad.size() == 2 && (input_dim == 2 || input_dim == 3)) {\n    switch (mode) {\n      case at::padding_mode::reflect: return at::reflection_pad1d(self, pad);\n      case at::padding_mode::replicate: return at::replication_pad1d(self, pad);\n      case at::padding_mode::circular: return at::_pad_circular(self, pad);\n      default: {}\n    }"
},
{
    "Id": 41,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/75be4f9cdb503d6eff189b2bc5c05d96bff66653",
    "Violation": "insufficient",
    "Bug report": " check tensor has storage before refer to tensor data ptr. In the exporter dedupe initializers passes, check the tensor has storage before reference to tensor's data_ptr, otherwise it will result in a crash.",
    "Number of deleted lines": 1,
    "Deleted lines": "    g->eraseInput(*it);\n  }\n}\n\nbool DeduplicateInitializersByDataPtr(at::Tensor& t1, at::Tensor& t2) {\n  return t1.sizes().equals(t2.sizes()) && t1.strides().equals(t2.strides()) &&\n      (t1.data_ptr() == t2.data_ptr());\n}\n\nbool DeduplicateInitializersByValue(at::Tensor& t1, at::Tensor& t2) {\n  if (t1.dtype() != t2.dtype() || !t1.sizes().equals(t2.sizes()) ||\n      !t1.strides().equals(t2.strides())) {\n    return false;\n  }\n"
},
{
    "Id": 42,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/a3701b674046bcefb5927a6643364b186f77dbcf",
    "Violation": "unnecessary",
    "Bug report": "fix backward bug for custom device. In the backward on some device , it may get an error to get device index because of exchange a new thread. So just set_device and check the device index in `setDevice`  func may be better for some many kinds of devices. For CUDA, the device index check is also included in `setDevice`  func",
    "Number of deleted lines": 2,
    "Deleted lines": "  // Don't use DeviceGuard here because its destructor may be called before the\n  // device is reset. This is fine because the device is thread local.\n  if (device != CPU_DEVICE) {\n    for (const auto i : c10::irange(static_cast<size_t>(\n             c10::DeviceType::COMPILE_TIME_MAX_DEVICE_TYPES))) {\n      auto* impl = c10::impl::device_guard_impl_registry[i].load();\n      if (impl && device < impl->deviceCount() &&\n          impl->getDevice().index() != device) {\n        impl->setDevice(at::Device(static_cast<c10::DeviceType>(i), device));\n      }\n    }\n  }\n  worker_device = device;\n}\n\nvoid validate_outputs("
},
{
    "Id": 43,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/6f5945e4bb1258d39a2878a08a910fcc8f659d5e",
    "Violation": "improper",
    "Bug report": "triton supports devices < 7.0, not 6.0. triton is still buggy with Pascal devices, so make the error checker reflect that. Also, this < 6.0 never worked, as the `has_triton` definition in utils.py was checking >= 7.0.",
    "Number of deleted lines": 2,
    "Deleted lines": "            from .codegen.cpp import CppScheduling\n\n            return CppScheduling(self)\n        else:\n            if not has_triton():\n                device_props = torch.cuda.get_device_properties(device)\n                if device_props.major < 6:\n                    raise RuntimeError(\n                        f\"Found {device_props.name} which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 6.0, but your device is of CUDA capability {device_props.major}.{device_props.minor}\"  # noqa: B950\n                    )\n                else:\n                    raise RuntimeError(\n                        \"Cannot find a working triton installation. More information on installing Triton can be found at https://github.com/openai/triton\"  # noqa: B950\n                    )\n            from .codegen.triton import TritonScheduling\n\n            return TritonScheduling(self)"
},
{
    "Id": 44,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/871b5caae76185cff141c522b3133e7543c8dabf",
    "Violation": "improper",
    "Bug report": "Fix hpu deserialization bug. fix hpu deserialization bug. It should check hpu model if and only if location start with hpu. Otherwise, it always raise an AssertError if hpu is not imported. This break the serialization/desirialization functionality abourt other third-party like IPEX. only assert hpu model when start with hpu",
    "Number of deleted lines": 2,
    "Deleted lines": "                           'torch.load with map_location to map your storages '\n                           'to an existing device.')\n    return device\n\n\ndef _hpu_deserialize(obj, location):\n    hpu = getattr(torch, \"hpu\", None)\n    assert hpu is not None, \"HPU device module is not loaded\"\n    if location.startswith('hpu'):\n        device = validate_hpu_device(location)\n        if getattr(obj, \"_torch_load_uninitialized\", False):\n            with hpu.device(device):\n                return torch.UntypedStorage(obj.nbytes(), device=torch.device(location))\n        else:\n            return obj.hpu(device)\n\n"
},
{
    "Id": 45,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/6592259ea52f45e1fc9a633ccb5b154ba5099334",
    "Violation": "insufficient",
    "Bug report": "As per torch.jit.load documentation, all previously saved modules, irrespective of their device, are first loaded onto CPU, and then are moved to the devices they were saved from. So far, supported devices included CPU and CUDA only. To enable torch.jit.load for HPU, additional check for HPU is introduced.",
    "Number of deleted lines": 2,
    "Deleted lines": "        tensor = at::_empty_affine_quantized({}, options, 0, 0)\n                     .set_(storage, 0, {}, {});\n      } else {\n        tensor = at::empty({0}, options).set_(storage);\n      }\n\n      if (device.is_cuda() || device.is_xpu() || device.is_meta()) {\n        tensor = tensor.to(device, tensor.scalar_type());\n      } else if (device.type() != DeviceType::CPU) {\n        AT_ERROR(\n            \"supported devices include CPU and CUDA, however got \",\n            DeviceTypeName(device.type(), false));\n      }\n      stack_.emplace_back(std::move(tensor));\n    } break;\n    default: {\n      AT_ERROR(\n          \"Unknown opcode for unpickling at \",\n          reinterpret_cast<void*>(opcode),"
},
{
    "Id": 46,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/1becd2c314f45bded8d3fbec91d785e7190b4afe",
    "Violation": "insufficient",
    "Bug report": "Align checks in _use_cudnn_ctc_loss with those in _cudnn_ctc_loss.This PR is intended to fix the following problem: When using `CTCLoss`, there is a cudnn path gated by a call to [`_use_cudnn_ctc_loss`] which checks some conditions. However, there are more checks in `_cudnn_ctc_loss`.  some of which are not present in `_use_cudnn_ctc_loss` (e.g. the check that `targets` is on CPU which will cause a RuntimeError after dispatching to `_cudnn_ctc_loss`). Instead, these checks should be in `_use_cudnn_ctc_loss` so that the normal `_ctc_loss` path will be used if the checks are not met)",
    "Number of deleted lines": 1,
    "Deleted lines": "    int64_t BLANK) {\n  auto& ctx = at::globalContext();\n\n  bool use_cudnn = ctx.userEnabledCuDNN() && (BLANK == 0) &&\n      (targets.dim() == 1) && (log_probs.scalar_type() == at::kFloat) &&\n      (targets.scalar_type() == at::kInt) &&\n      (log_probs.device().type() == at::kCUDA);\n\n  if (use_cudnn) {\n    // we don't know that input_lengths and target_lengths have the same size\n    // (they should, but we didn't check yet)\n    int64_t max_input_length = log_probs.size(0);\n    for (const auto input_length : input_lengths) {\n      use_cudnn = use_cudnn && ((input_length == max_input_length) ? 1 : 0);\n    }"
},
{
    "Id": 47,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/a076a74f1118da171cf70d00d1de4abbe27cf85d",
    "Violation": "insufficient",
    "Bug report": " Add xpu device in assertion for nested tensor creation",
    "Number of deleted lines": 2,
    "Deleted lines": "  C10_LOG_API_USAGE_ONCE(\"torch.NestedTensor\");\n  TORCH_WARN_ONCE(\n      \"The PyTorch API of nested tensors is in prototype stage and will change \"\n      \"in the near future.\");\n  auto storage_device = storage_.device();\n  TORCH_INTERNAL_ASSERT(\n      storage_device.is_cpu() || storage_device.is_cuda() || storage_device.is_privateuseone(),\n      \"NestedTensorImpl storage must be either CUDA, CPU or \", get_privateuse1_backend(), \" but got \",\n      storage_device);\n  validate_nested_tensor_metadata(nested_sizes_, nested_strides_, storage_offsets_);\n  refresh_dim();\n  set_custom_sizes_strides(c10::TensorImpl::SizesStridesPolicy::CustomSizes);\n}\n\nNestedTensorImpl::NestedTensorImpl(\n    at::Tensor buffer,"
},
{
    "Id": 48,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/097defb1608827d82b18b27adeec0a98b72a9281",
    "Violation": "insufficient",
    "Bug report": "only check when world size > num_devices per host",
    "Number of deleted lines": 1,
    "Deleted lines": "        device_handle = _get_device_handle(self.device_type)\n        # TODO: if user want to pass pg_options, offer a way to do it\n        if not default_initialized and device_handle:\n            # automatically set the current cuda/cuda-like device base on num of gpu devices available in each host\n            # NOTE: This device selection would only work for homogeneous hardware.\n            num_devices_per_host = device_handle.device_count()\n            if world_size % num_devices_per_host != 0:\n                raise RuntimeError(\n                    f\"DeviceMesh only support homogeneous hardware, but found \"\n                    f\"{world_size} ranks and {num_devices_per_host} {self.device_type} devices!\"\n                )\n            device_handle.set_device(get_rank() % num_devices_per_host)\n\n        # calculate the coordinates of the current global rank on the mesh\n        rank_coords = (self.mesh == get_rank()).nonzero()"
},
{
    "Id": 49,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/57af1ec14594a73c8f2b73bf70c04ba7efeb6eab",
    "Violation": "improper",
    "Bug report": "observers: use torch.all to check for valid min and max values. Using `torch.all` instead of `torch.sum` and length check. It's unclear whether the increase in perf (~5% for small inputs) is real, but should be a net benefit, especially for larger channel inputs.",
    "Number of deleted lines": 1,
    "Deleted lines": "\n        if min_val.dim() == 0 or max_val.dim() == 0:\n            assert min_val <= max_val, \"min {} should be less than max {}\".format(\n                min_val, max_val\n            )\n        else:\n            assert torch.sum(min_val <= max_val) == len(min_val), \"min {} should be less than max {}\".format(\n                min_val, max_val\n            )\n\n        quant_min, quant_max = self._calculate_qmin_qmax()\n        min_val_neg = torch.min(min_val, torch.zeros_like(min_val))\n        max_val_pos = torch.max(max_val, torch.zeros_like(max_val))\n\n        scale = torch.ones(min_val_neg.size(), dtype=torch.float32)"
},
{
    "Id": 50,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/07f0f383fa23e63eca164036ab58ab983e9437eb",
    "Violation": "unnecessary",
    "Bug report": "update tensor-like to check instance for torch function impl. tensor like should check the instance for a torch function impl, not the type",
    "Number of deleted lines": 1,
    "Deleted lines": "    ...     @classmethod\n    ...     def __torch_function__(cls, func, types, args, kwargs):\n    ...         return -1\n    >>> is_tensor_like(TensorLike())\n    True\n    \"\"\"\n    return type(inp) is torch.Tensor or hasattr(type(inp), \"__torch_function__\")\n\nclass TorchFunctionMode:\n    \"\"\"\n    A ``TorchFunctionMode`` allows you to override the meaning of all\n    ``__torch_function__`` overrideable functions within a dynamic scope,\n    without having to actually create a tensor subclass or manually\n    monkey-patch functions in the PyTorch API.  Some common situations\n    where you should use a mode:"
},
{
    "Id": 51,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/b90db4a78f8d760377a81a5a64d03ab4b67599de",
    "Violation": "improper",
    "Bug report": "Fix type checking to accept both Iter and Map DataPipe",
    "Number of deleted lines": 1,
    "Deleted lines": "def _sharding_worker_init_fn(worker_init_fn, world_size, rank_id, worker_id):\n    global_worker_id = worker_id\n    info = torch.utils.data.get_worker_info()\n    assert info is not None\n    total_workers = info.num_workers\n    datapipe = info.dataset\n    assert isinstance(datapipe, IterDataPipe)\n    # To distribute elements across distributed process evenly, we should shard data on distributed\n    # processes first then shard on worker processes\n    total_workers *= world_size\n    global_worker_id = global_worker_id * world_size + rank_id\n    torch.utils.data.graph_settings.apply_sharding(datapipe, total_workers, global_worker_id)\n    if worker_init_fn is not None:\n        worker_init_fn(worker_id)\n"
},
{
    "Id": 52,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/63cbdc92a750a667ffdcfbdac563d02db6fd9559",
    "Violation": "improper",
    "Bug report": "switching the exact check to isinstance check. Simplifying a type check if an object is a SymIntNode in `is_symint_node`",
    "Number of deleted lines": 2,
    "Deleted lines": "#include <string>\n#include <vector>\n\nnamespace torch {\ninline bool is_symint_node(py::handle obj) {\n  auto static tp_symn = py::type::of<c10::SymIntNodeImpl>();\n  // TODO: switch this to `isinstance`\n  if (obj.get_type().equal(tp_symn)) {\n    TORCH_CHECK(\n        !jit::tracer::isTracing(), \"JIT tracing of SymInts isn't supported!\");\n    return true;\n  }\n  return false;\n}\n} // namespace torch\n"
},
{
    "Id": 53,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/92ebb04f9206882e6d312a8b91318545f43a53c2",
    "Violation": "insufficient",
    "Bug report": "added check for NumberType",
    "Number of deleted lines": 3,
    "Deleted lines": "    }\n  }\n\n  NamedValue emitValueToTensor(\n      const NamedValue& value,\n      const NamedValue& matchTypeOf) {\n    // Add implicit conversion of int/float/bool types to tensors\n    // Used in emitSubscriptAssign to convert:\n    //   `tensor(...)[x] = 99` to `tensor(...)[x] = tensor(99)`\n    // Mirrors the `valueToTensor` behavior in python_variable_indexing.cpp\n    const auto kind = value.type()->kind();\n    if (kind == c10::TypeKind::IntType || kind == c10::TypeKind::BoolType ||\n        kind == c10::TypeKind::FloatType) {\n      auto dtype = graph->insert(prim::dtype, {matchTypeOf}, {});\n      auto device = graph->insert(prim::device, {matchTypeOf}, {});\n      auto converted = graph->insert(\n          aten::tensor,\n          {value},\n          {NamedValue(\"dtype\", dtype), NamedValue(\"device\", device)});\n      return NamedValue(value.loc(), converted);\n    }"
},
{
    "Id": 54,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/fe6aa0844466e5dd2669092eac5edde153108b28",
    "Violation": "improper",
    "Bug report": "Don't delegate to `operator=` for construction. Catch hypothetical addition of a new Scalar type via debug assertion rather than checking in prod.",
    "Number of deleted lines": 5,
    "Deleted lines": "    return i;\n  }\n\n  // Scalar, which gets encoded as either an Int, a Double or a ComplexDouble\n  IValue(const at::Scalar& s) : IValue() {\n    if (s.isFloatingPoint()) {\n      *this = s.toDouble();\n    } else if (s.isComplex()) {\n      *this = s.toComplexDouble();\n    } else if (s.isBoolean()) {\n      *this = s.toBool();\n    } else if (s.isIntegral(false)) {\n      *this = s.toLong();\n    } else {\n      TORCH_CHECK(false, \"Unknown type in Scalar\");\n    }\n  }\n\n  bool isScalar() const {\n    return isDouble() || isInt() || isComplexDouble() || isBool();\n  }\n\n  at::Scalar toScalar() const {"
},
{
    "Id": 55,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/35e7ac3fa17bc20d982ea69440d30cd9658dff25",
    "Violation": "insufficient",
    "Bug report": "This fixes a bug in singleCheckErrors introduced by #69437 (thanks Lezcano for the catch). Checking existence of a substring in a larger string is done with (name.find(text) != name.npos) but we omitted the second half of the check.",
    "Number of deleted lines": 3,
    "Deleted lines": "    } else if (name.find(\"cholesky\") != name.npos) {\n      TORCH_CHECK_LINALG(false, name, batch_string,\n          \": The factorization could not be completed because the input is not positive-definite (the leading minor of order \", info, \" is not positive-definite).\");\n    } else if (name.find(\"svd\") != name.npos) {\n      TORCH_CHECK_LINALG(false, name, batch_string,\n          \": The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated singular values (error code: \", info, \").\");\n    } else if (name.find(\"eig\") || name.find(\"syevd\")) {\n      TORCH_CHECK_LINALG(false, name, batch_string,\n          \": The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated eigenvalues (error code: \", info, \").\");\n    } else if (name.find(\"lstsq\")) {\n      TORCH_CHECK_LINALG(false, name, batch_string,\n          \": The least squares solution could not be computed because the input matrix does not have full rank (error code: \", info, \").\");\n    } else if (name.find(\"lu_factor\")) {\n      TORCH_CHECK(false, name, batch_string,\n          \": U[\", info, \",\", info, \"] is zero and using it on lu_solve would result in a division by zero. \"\n          \"If you still want to perform the factorization, consider calling linalg.lu(A, pivot) or \"\n          \"linalg.lu_factor_ex(A, pivot)\");\n    } else {\n      TORCH_INTERNAL_ASSERT(false, name, \": Unknown error code: \", info, \".\");\n    }\n  }"
},
{
    "Id": 56,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/a7cc6531399300f999a404718827e2a94c115aaf",
    "Violation": "insufficient",
    "Bug report": "Summary:GCC version check is currently being skipped when using the newly released CUDA 9.1. This will also handle other CUDA 9.x minor releases if any, reducing our work if there are such releases like 9.2. This assumes that the next major CUDA version will be 10.0, needing adjustment only after such major version is released.",
    "Number of deleted lines": 3,
    "Deleted lines": "endif()\n\n# ---[ CUDA\nif(USE_CUDA)\n  include(cmake/Cuda.cmake)\n  if(HAVE_CUDA)\n    # CUDA 9.0 requires GCC version <= 6\n    if (CUDA_VERSION VERSION_EQUAL 9.0)\n      if (CMAKE_C_COMPILER_ID STREQUAL \"GNU\" AND\n          NOT CMAKE_C_COMPILER_VERSION VERSION_LESS 7.0 AND\n          CUDA_HOST_COMPILER STREQUAL CMAKE_C_COMPILER)\n        message(FATAL_ERROR\n          \"CUDA 9.0 is not compatible with GCC version >= 7. \"\n          \"Use the following option to use another version (for example): \\n\"\n          \"  -DCUDA_HOST_COMPILER=/usr/bin/gcc-6\\n\")\n      endif()\n    # CUDA 8.0 requires GCC version <= 5\n    elseif (CUDA_VERSION VERSION_EQUAL 8.0)\n      if (CMAKE_C_COMPILER_ID STREQUAL \"GNU\" AND\n          NOT CMAKE_C_COMPILER_VERSION VERSION_LESS 6.0 AND\n          CUDA_HOST_COMPILER STREQUAL CMAKE_C_COMPILER)"
},
{
    "Id": 57,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/3f5dc95b57496c4ea938be381efcdc2ea92bb4cc",
    "Violation": "insufficient",
    "Bug report": "Some of the tests don't specify `device` in the input configs so filter by device won't work for them. This diff fixes that issue.",
    "Number of deleted lines": 1,
    "Deleted lines": "        if (self._check_keep(op_test_config.test_name, self.args.test_name) and\n            self._check_keep_list(test_case.op_bench.module_name(), operators) and\n            self._check_keep_list(test_case.framework, frameworks) and\n                (self.args.tag_filter == 'all' or\n                    self._check_keep(op_test_config.tag, self.args.tag_filter)) and\n                (not self.args.forward_only or op_test_config.run_backward != self.args.forward_only) and\n                (self.args.device == 'None' or self.args.device in op_test_config.test_name)):\n            return True\n\n        return False\n\n    def _print_test_case_info(self, test_case):\n        # Print out the test name and skip the real execution\n        if self.args.list_tests:\n            print(\"# {}\".format(test_case.test_config.test_name))"
},
{
    "Id": 58,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/1c02be1b6a0f6d02d3a0ae19c13d51a3e59a55ae",
    "Violation": "insufficient",
    "Bug report": "In PyTorch 1.5, when running `torch.cuda.reset_peak_memory_stats()` on a machine where `torch.cuda.is_available() is False`, I would get: AssertionError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from. With this patch, we get a more sensible:",
    "Number of deleted lines": 1,
    "Deleted lines": "    # add more available device types here\n    return None\n\n\ndef _get_device_attr(get_member):\n    device_type = _get_available_device_type()\n    if device_type.lower() == \"cuda\":\n        return get_member(torch.cuda)\n    # add more available device types here\n    return None\n\n\ndef _get_current_device_index():\n    # current device index\n    return _get_device_attr(lambda m: m.current_device())"
},
{
    "Id": 59,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/29b702144bf5bb96dfd8fcbd04b6562a27ca5385",
    "Violation": "improper",
    "Bug report": " Fix issue in s_addmm_out_sparse_dense_cpu only supporting CUDA device checking. ## Motivation The at::native::s_addmm_out_sparse_dense_cpu only supports the CPU tensors. But it only checks whether the tensor is on CUDA device which is not enough. ## Solution Change the tensor device type checkging from is_cuda to !is_cpu to protect other backends than the CUDA.",
    "Number of deleted lines": 4,
    "Deleted lines": "    const SparseTensor& sparse_,\n    const Tensor& dense,\n    const Scalar& beta,\n    const Scalar& alpha\n) {\n  // TODO: This error message seems awfully opaque\n  TORCH_CHECK(!t.is_cuda(),  \"Expected all tensors to be on the same device. addmm expected 't' to be CPU tensor, but got CUDA tensor\");\n  TORCH_CHECK(!r.is_cuda(), \"Expected all tensors to be on the same device. addmm: expected 'out' to be CPU tensor, but got CUDA tensor\");\n  TORCH_CHECK(!sparse_.is_cuda(), \"Expected all tensors to be on the same device. addmm: expected 'mat1' to be a CPU tensor, but got a CUDA tensor\");\n  TORCH_CHECK(!dense.is_cuda(), \"Expected all tensors to be on the same device. addmm: expected 'mat2' to be a CPU tensor, but got a CUDA tensor\");\n\n  TORCH_CHECK(sparse_.sparse_dim() == 2, \"addmm: matrices expected, got \", sparse_.sparse_dim(), \"D tensor\");\n  TORCH_CHECK(sparse_.dense_dim() == 0, \"addmm: scalar values expected, got \", sparse_.dense_dim(), \"D values\");\n  TORCH_CHECK(dense.dim() == 2, \"addmm: matrices expected, got \", dense.dim(), \"D tensor\");\n\n  // ixj * jxk = ixk\n  int64_t dim_i = sparse_.size(0);\n  int64_t dim_j = sparse_.size(1);"
},
{
    "Id": 60,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/bbc7c79b20e67da450dd9b7de70cc6b68e656714",
    "Violation": "missing",
    "Bug report": "add device checks for sparse csr",
    "Number of deleted lines": 0,
    "Deleted lines": "    TORCH_CHECK(\n        self.sizes().equals(other.sizes()),\n        \"torch.add: Expected input tensors to have the same shape, but got tensor `self` with shape \",\n        self.sizes(),\n        \" and tensor `other` with shape \",\n        other.sizes());\n\n    if (only_sparse_compressed_add_trivial_cases(self, other, alpha, out)) {\n      return out;\n    }\n\n    at::native::resize_as_sparse_compressed_(out, self);\n    sparse::impl::cuda::add_out_sparse_csr(self, other, Scalar(1), alpha, out);\n  }"
},
{
    "Id": 61,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/faa7eb81c634492b70fcc0327622bb0aa812cacd",
    "Violation": "misleading",
    "Bug report": "change error_message for XPU Autocast data type check. XPU autocast supports bf16 and fp16 data types, we are going to change the error_message for that.",
    "Number of deleted lines": 1,
    "Deleted lines": "                warnings.warn(error_message)\n                enabled = False\n        elif self.device == 'xpu':\n            supported_dtype = [torch.bfloat16, torch.float16]\n            if self.fast_dtype not in supported_dtype:\n                error_message = 'In XPU autocast, but the target dtype is not supported. Disabling autocast.\\n'\n                error_message += 'XPU Autocast only supports dtype of torch.bfloat16 currently.'\n                warnings.warn(error_message)\n                enabled = False\n        elif self.device == 'hpu':\n            supported_dtype = [torch.bfloat16, torch.float16]\n            if self.fast_dtype not in supported_dtype:\n                error_message = 'In HPU autocast, but the target dtype is not supported. Disabling autocast.\\n'\n                error_message += 'HPU Autocast only supports dtypes of torch.bfloat16 and torch.float16 currently.'\n                warnings.warn(error_message)"
},
{
    "Id": 62,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/48a49b2683ffa21eb1b472e503c129c043c18f87",
    "Violation": "misleading",
    "Bug report": "use more informative error message for ConstandPad2d/3d.  the current error message for `torch.nn.ConstantPad2d` and `torch.nn.ConstantPad3d` is misleading, this PR fixes the problem.",
    "Number of deleted lines": 1,
    "Deleted lines": "  return out;\n}\n\nTensor _pad_enum_symint(const Tensor &self, c10::SymIntArrayRef pad, int64_t mode_int, c10::optional<double> value) {\n  const auto input_dim = self.dim();\n  TORCH_CHECK(pad.size() % 2 == 0, \"Padding length must be divisible by 2\");\n  TORCH_CHECK(static_cast<int64_t>(pad.size()) <= input_dim * 2, \"Padding length too large\");\n  auto mode = static_cast<at::padding_mode>(mode_int);\n\n  if (mode == at::padding_mode::constant) {\n    return at::constant_pad_nd_symint(self, pad, value.value_or(0.0));\n  }\n  TORCH_CHECK(!value.has_value() || *value == 0,\n              \"Padding mode \\\"\", padding_mode_string(mode),\n              \"\\\" doesn't take in value argument\");"
},
{
    "Id": 63,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/4ab1588d9919bc1a62219a5c2393e0784ddaae70",
    "Violation": "misleading",
    "Bug report": "Enhance error message for dependency check, If python development library is missing when building pytorch from source cmake will raise the error like: CMake Error at cmake/Dependencies.cmake:1079 (if): if given arguments: \"VERSION_LESS\" \"3\"  Unknown arguments specified ```it's quite a misleading information that user would consider it's a syntax error or cmake version problem. This PR add a check to ensure `PYTHONLIBS_VERSION_STRING` exist before using.",
    "Number of deleted lines": 0,
    "Deleted lines": "  # These should fill in the rest of the variables, like versions, but resepct\n  # the variables we set above\n  set(Python_ADDITIONAL_VERSIONS ${PYTHON_VERSION} 3.8)\n  find_package(PythonInterp 3.0)\n  find_package(PythonLibs 3.0)\n\n  if(${PYTHONLIBS_VERSION_STRING} VERSION_LESS 3)\n    message(FATAL_ERROR\n      \"Found Python libraries version ${PYTHONLIBS_VERSION_STRING}. Python 2 has reached end-of-life and is no longer supported by PyTorch.\")\n  endif()\n  if(${PYTHONLIBS_VERSION_STRING} VERSION_LESS 3.8)\n    message(FATAL_ERROR\n      \"Found Python libraries version ${PYTHONLIBS_VERSION_STRING}. Python < 3.8 is no longer supported by PyTorch.\")\n  endif()"
},
{
    "Id": 64,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/577e90ae9bf257040acb68da3626d9a64d07bf7a",
    "Violation": "misleading",
    "Bug report": " Improve error message for missing ops. The current error message is ill formed",
    "Number of deleted lines": 2,
    "Deleted lines": "      code_.operators_[i] = *func;\n    }\n  }\n  if (should_check_operators) {\n    TORCH_CHECK(\n        unsupported_op_names.empty(),\n        \"Following ops cannot be found. Please check if the operator library is included in the build. If built with selected ops, check if these ops are in the list. If you are a Meta employee, please see fburl.com/missing_ops for a fix. Or post it in https://discuss.pytorch.org/\",\n        c10::Join(\", \", unsupported_op_names));\n  }\n  code_.initialized = all_ops_supported;\n  return all_ops_supported;\n}\n\nvoid Function::append_constant(const c10::IValue& constant) {\n  code_.constants_.push_back(constant);\n}"
},
{
    "Id": 65,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/22044c6f7cbdafdd340714bbe220b621e1927826",
    "Violation": "misleading",
    "Bug report": "Use TORCH_CHECK instead of AT_ASSERT in torch::cuda::gather(). The error message produced by AT_ASSERT() in gather() encouraged users to file a bug report (\"please report a bug to PyTorch...\"). The assertion should be a regular argument check since it can be triggered by passing tensors with different dimensionality, e.g. `torch.cuda.comm.gather([torch.rand(1, device='cuda'), torch.rand(1, 1, device='cuda')])`.",
    "Number of deleted lines": 1,
    "Deleted lines": "  const auto first_size = first.sizes();\n  std::vector<int64_t> expected_size(first_size.begin(), first_size.end());\n  bool all_channels_last = true;\n  for (const auto& tensor : tensors) {\n    TORCH_CHECK(\n        tensor.is_cuda(), \"Gather expects all inputs to have CUDA type\");\n    AT_ASSERT(tensor.ndimension() == static_cast<int64_t>(expected_size.size()));\n    expected_size[dim] = tensor.size(dim);\n    for (size_t dimension = 0; dimension < expected_size.size(); ++dimension) {\n      TORCH_CHECK(\n          expected_size[dimension] == tensor.size(dimension),\n          \"Gather got an input of invalid size: got \",\n          tensor.sizes(), \", but expected \", at::IntArrayRef(expected_size));\n    }\n    total_size += tensor.size(dim);"
},
{
    "Id": 66,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/dc0d68a1ee3800ed4024762d018f85256e80f5ad",
    "Violation": "misleading",
    "Bug report": "Print out interface mismatch for prim::ModuleDictIndex. This commit augments the module interface subtyping check that is done before the emission of the `prim::ModuleDictIndex` operator so that the error message that is printed if the subtyping check fails provides more information on which methods do not match.",
    "Number of deleted lines": 2,
    "Deleted lines": "    } else if (type_hint) {\n      // Check that all submodules comply with the type hint.\n      const auto& self_type = concreteType_->getJitType()->expect<ClassType>();\n      for (size_t i = 0; i < self_type->numAttributes(); ++i) {\n        const auto& attr_type = self_type->getAttribute(i);\n        if (attr_type->is_module()) {\n          if (!attr_type->isSubtypeOf(type_hint)) {\n            auto loc = self_->node()->sourceRange();\n            throw ErrorReport(loc)\n                << \"Attribute \" << self_type->getAttributeName(i)\n                << \" is not of annotated type \" << type_hint->annotation_str();\n          }\n        }\n      }\n\n      // Emit a prim::ModuleDictIndex operator. This is needed because it's\n      // difficult to construct a dict in the graph representing the ModuleDict\n      // and use aten::__getitem__ ops to index into it because any call to\n      // ModuleDict.setAttr would invalidate that emitted dict."
},
{
    "Id": 67,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/c9548176965557a76526ba0db23ff5c9facd3e97",
    "Violation": "misleading",
    "Bug report": "print matrix dims in torch cuda matrix multiply error.  trying to improve the error message for torch matrix multiply dimension mismatch",
    "Number of deleted lines": 1,
    "Deleted lines": "    self_ = self;\n  }\n\n  IntArrayRef mat1_sizes = mat1.sizes();\n  IntArrayRef mat2_sizes = mat2.sizes();\n  IntArrayRef self__sizes = self_.sizes();\n  TORCH_CHECK(mat1_sizes[1] == mat2_sizes[0], \"mat1 dim 1 must match mat2 dim 0\");\n  TORCH_CHECK(self__sizes[0] == mat1_sizes[0], \"self_ dim 0 must match mat1 dim 0\");\n  TORCH_CHECK(self__sizes[1] == mat2_sizes[1], \"self_ dim 1 must match mat2 dim 1\");\n\n  if (&result != &self) {\n    at::native::resize_as_(result, self_);\n    if (beta.toComplexDouble() != 0.0) {\n      at::native::copy_(result, self_);\n    }"
},
{
    "Id": 68,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/93256617c8622760181dacf03c41cc0577ac0ea6",
    "Violation": "misleading",
    "Bug report": "corrected messages for check of default options. Modified messages in the check of default options for the Adam optimizer.",
    "Number of deleted lines": 3,
    "Deleted lines": " public:\n   explicit Adam(std::vector<OptimizerParamGroup> param_groups,\n       AdamOptions defaults = {}) : Optimizer(std::move(param_groups), std::make_unique<AdamOptions>(defaults)) {\n     TORCH_CHECK(defaults.lr() >= 0, \"Invalid learning rate: \", defaults.lr());\n     TORCH_CHECK(defaults.eps() >= 0, \"Invalid epsilon value: \", defaults.eps());\n     auto betas = defaults.betas();\n     TORCH_CHECK(std::get<0>(betas) >= 0, \"Invalid learning rate: \", std::get<0>(betas));\n     TORCH_CHECK(std::get<1>(betas) >= 0, \"Invalid learning rate: \", std::get<1>(betas));\n     TORCH_CHECK(defaults.weight_decay() >= 0, \"Invalid learning rate: \", defaults.weight_decay());\n   }\n   explicit Adam(\n       std::vector<Tensor> params,\n       AdamOptions defaults = {}) : Adam({std::move(OptimizerParamGroup(params))}, defaults) {}\n\n  torch::Tensor step(LossClosure closure = nullptr) override;\n  void save(serialize::OutputArchive& archive) const override;\n  void load(serialize::InputArchive& archive) override;"
},
{
    "Id": 69,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/99f06c0cc2a907d8fbf613768356838548f1f8c0",
    "Violation": "misleading",
    "Bug report": "update errors to be more descriptive we call `_check_single_tensor` and `_check_tensor_list` as validation but don't print out the param types that were invalid",
    "Number of deleted lines": 5,
    "Deleted lines": "\n\ndef _check_single_tensor(param, param_name) -> None:\n    \"\"\"Check that the parameter ``param_name`` is a single tensor.\"\"\"\n    if not isinstance(param, torch.Tensor):\n        raise TypeError(\n            f\"Invalid function argument. Expected parameter `{param_name}` to be of type torch.Tensor.\"\n        )\n\n\ndef _check_tensor_list(param, param_name) -> None:\n    \"\"\"Check that the parameter ``param_name`` is a list of tensors.\"\"\"\n    if not isinstance(param, list) or not all(\n        isinstance(p, torch.Tensor) for p in param\n    ):\n        raise TypeError(\n            f\"Invalid function argument. Expected parameter `{param_name}` to be of type List[torch.Tensor].\"\n        )\n\ndef _as_iterable(obj) -> collections.abc.Iterable:\n    return obj if isinstance(obj, list) else (obj,)\n\ndef _ensure_all_tensors_same_dtype(*tensors) -> None:\n    last_dtype = None\n    for tensor in itertools.chain(*map(_as_iterable, tensors)):\n        tensor_dtype = tensor.dtype\n        # Mixing complex and its element type is allowed"
},
{
    "Id": 70,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/9a9eadacc6ac3b734a6d607ae6f63ec1a0d1438d",
    "Violation": "missing",
    "Bug report": "explicitly check device for grid_sampler",
    "Number of deleted lines": 0,
    "Deleted lines": "class GridSampler(Function):\n\n    @staticmethod\n    def forward(ctx, input, grid, padding_mode='zeros'):\n        ctx.save_for_backward(input, grid)\n\n        if padding_mode == 'zeros':\n            ctx.padding_mode = MODE_ZEROS\n        elif padding_mode == 'border':\n            ctx.padding_mode = MODE_BORDER\n        else:\n            raise ValueError(\"padding_mode needs to be 'zeros' or 'border', but got {}\".format(padding_mode))\n\n        grid_sz = grid.size()"
},
{
    "Id": 71,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/157d478a30f27fd9d866c1235841721a559c8d0b",
    "Violation": "improper",
    "Bug report": "Fix omission of shape in size check in index. ",
    "Number of deleted lines": 1,
    "Deleted lines": "                    k + index.ndim <= self.ndim,\n                    lambda: f\"too many indices for tensor of dimension {self.ndim}\",\n                    IndexError\n                )\n                for j in range(index.ndim):\n                    check(\n                        index[j] <= self.shape[k + j],\n                        lambda: f\"The shape of the mask {index.shape} at index {i} \"\n                                f\"does not match the shape of the indexed tensor {self.shape} at index {k + j}\",\n                        IndexError\n                    )\n                    result.append(nonzero.select(1, j))\n            else:\n                result.append(index)\n        else:"
},
{
    "Id": 72,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/f14887a63f83b931df9fc5d841c7d3829141ff58",
    "Violation": "missing",
    "Bug report": "check for exact shape match before loading. Use RuntimeError instead of ValueError to keep it consistent with other errors",
    "Number of deleted lines": 0,
    "Deleted lines": "        local_state = {k: v.data for k, v in local_name_params if v is not None}\n\n        for name, param in local_state.items():\n            key = prefix + name\n            if key in state_dict:\n                input_param = state_dict[key]\n                if isinstance(input_param, Parameter):\n                    # backwards compatibility for serialized parameters\n                    input_param = input_param.data\n                try:\n                    param.copy_(input_param)\n                except Exception:\n                    error_msgs.append('While copying the parameter named \"{}\", '\n                                      'whose dimensions in the model are {} and '"
},
{
    "Id": 73,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/02e2158e754bafda46e663052c838aeb6ab6b560",
    "Violation": "missing",
    "Bug report": " Fix for out of bounds read in mobile interpreter INTERFACE_CALL opcode handler. The INTERFACE_CALL opcode for the mobile TorchScript interpreter contained an out of bounds read issue leading to memory corruption. This change adds an explicit check that the number of inputs passed to the format method called when handling the INTERFACE_CALL opcode is a valid and within bounds of the stack.",
    "Number of deleted lines": 0,
    "Deleted lines": "        } break;\n        case INTERFACE_CALL: {\n          if (inst.X < 0 ||\n              static_cast<size_t>(inst.X) >= code.constants_.size()) {\n            TORCH_CHECK(false, \"Can't load constant with index: \", inst.X);\n          }\n          torch::jit::Function& method =\n              peek(stack, 0, inst.N)\n                  .toObject()\n                  ->type()\n                  ->getMethod(code.constants_[inst.X].toStringRef());\n          RECORD_EDGE_SCOPE_WITH_DEBUG_HANDLE_AND_INPUTS(\n              method.name(), debug_handle, stack);\n          callFunction(method, stack);"
},
{
    "Id": 74,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/4d07428edee863e7f5920f0672957a9711a9f0b5",
    "Violation": "missing",
    "Bug report": "Fix for out of bounds read in mobile interpreter FORMAT opcode handler. Summary: The FORMAT opcode for the mobile TorchScript interpreter contained an out of bounds read issue leading to memory corruption. This change adds an explicit check that the number of inputs passed to the format method called when handling the FORMAT opcode is a valid and within bounds of the stack.",
    "Number of deleted lines": 0,
    "Deleted lines": "void tupleUnpack(Stack& stack) {\n  auto tuple = pop(stack).toTuple();\n  stack.insert(stack.end(), tuple->elements().begin(), tuple->elements().end());\n}\n\nvoid format(Stack& stack, size_t num_inputs) {\n  // static const std::regex unsupported_options(\"\\\\{(.*?)\\\\}\");\n  auto format = peek(stack, 0, num_inputs).toStringRef();\n  // // Temporally comment out the warning message because of\n  // // \"StdRegexIsAwful\" internal Lint error, to prevent sev\n  // // of std::regex from PT mobile.\n  // if (std::regex_search(format, unsupported_options)) {\n  //   TORCH_WARN(\"Format options are not supported.\");\n  // }"
},
{
    "Id": 75,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/b3ace213f240dc0f0f2a738f825f46e0d0dffca4",
    "Violation": "missing",
    "Bug report": "The error occurs because there is not check in `deserialize_source` that `text_table_` size can be less than `fnameIndex`. To prevent the error the corresponding check must be located.",
    "Number of deleted lines": 0,
    "Deleted lines": "  if (!text_table_.empty()) {\n    const auto& textIndex = tup_elems[0].toIntList();\n    int64_t fnameIndex = tup_elems[1].toInt();\n    int64_t starting_line_no_ = tup_elems[2].toInt();\n    c10::optional<std::string> filename = c10::nullopt;\n\n    filename = *text_table_[fnameIndex];\n\n    std::vector<c10::string_view> pieces;\n    std::vector<std::shared_ptr<std::string>> strs;\n\n    for (int64_t i : textIndex) {\n      pieces.emplace_back(*text_table_[i]);\n      strs.emplace_back(text_table_[i]);"
},
{
    "Id": 76,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/d8466964b348b6172317f70b8e52de02402bad54",
    "Violation": "missing",
    "Bug report": "Add range check to multi margin loss target ",
    "Number of deleted lines": 0,
    "Deleted lines": "  using acc_t = at::acc_type<scalar_t, true>;\n  __shared__ acc_t buffer[MULTIMARGIN_THREADS];\n  int k = blockIdx.x;\n  scalar_t *input_k = input + k*dim;\n  scalar_t *output_k = output + k;\n  int target_k = static_cast<int>(target[k]);\n  scalar_t input_target_k = input_k[target_k];\n\n  int i_start = threadIdx.x;\n  int i_end = dim;\n  int i_step = blockDim.x;\n\n  buffer[threadIdx.x] = 0;\n  for (int i = i_start; i < i_end; i += i_step) {"
},
{
    "Id": 77,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/c22ac14969a863a00b5ebb04a3453610c7a27713",
    "Violation": "missing",
    "Bug report": "The diff sets the upper boundary on border element when presenting the error message. This is required in order to avoid unnecessary log contamination",
    "Number of deleted lines": 0,
    "Deleted lines": "            width = max(width, w)\n            if rank == root_rank:\n                root_failure_fmt = fmt\n            else:\n                other_failures_fmt.append(fmt)\n\n        return Template(_MSG_FORMAT_TEMPLATE).substitute(\n            boarder=boarder_delim * width,\n            title=title.center(width),\n            section=section_delim * width,\n            root_failure=root_failure_fmt,\n            other_failures=\"\\n\".join(other_failures_fmt or [\"  <NO_OTHER_FAILURES>\"]),\n        )\n"
},
{
    "Id": 78,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/b7bb34d7625d95e5088638721dcc07c2bc5e2ade",
    "Violation": "missing",
    "Bug report": "[MPS] Add version check Use `instancesRespondToSelector:` to test the presence of `optimizationLevel` in `MPSGraphCompilationDescriptor`",
    "Number of deleted lines": 0,
    "Deleted lines": "MPSDevice::~MPSDevice() {\n  [_mtl_device release];\n  _mtl_device = nil;\n}\n\nMPSDevice::MPSDevice(): _mtl_device(nil) {\n  NSArray* devices = [MTLCopyAllDevices() autorelease];\n  for (unsigned long i = 0 ; i < [devices count] ; i++) {\n    id<MTLDevice>  device = devices[i];\n    if(![device isLowPower]) { // exclude Intel GPUs\n      _mtl_device = [device retain];\n      break;\n    }\n  }"
},
{
    "Id": 79,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/b1f08e7426a56a323e6928365918093b65aa4fb6",
    "Violation": "missing",
    "Bug report": " Call uncheckedSetDevice in ~InlineDeviceGuard only when device index are different. Setting device could be expensive, especially when a debugger is present. We should check the device are different before we set.",
    "Number of deleted lines": 2,
    "Deleted lines": "  }\n  Device getDevice() const override {\n    int device;\n    C10_CUDA_CHECK(cudaGetDevice(&device));\n    return Device(DeviceType::CUDA, device);\n  }\n  void setDevice(Device d) const override {\n    TORCH_INTERNAL_ASSERT(d.type() == DeviceType::CUDA);\n    C10_CUDA_CHECK(cudaSetDevice(d.index()));\n  }\n  void uncheckedSetDevice(Device d) const noexcept override {\n    C10_CUDA_CHECK_WARN(cudaSetDevice(d.index()));\n  }\n  Stream getStream(Device d) const noexcept override {\n    return getCurrentCUDAStream(d.index()).unwrap();\n  }\n  Stream getDefaultStream(Device d) const override {\n    return getDefaultCUDAStream(d.index());\n  }\n  // NB: These do NOT set the current device"
},
{
    "Id": 80,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/53953316444485c8ee250022988ef87778ae1352",
    "Violation": "missing",
    "Bug report": "Stacks recorded when tensors are being freed during exit could try to acquire the GIL. Py_IsInitialized can be used to check if we are post Python exit and should not attempt to acquire the GIL.",
    "Number of deleted lines": 0,
    "Deleted lines": "\nnamespace {\nstatic std::mutex to_free_frames_mutex;\nstatic std::vector<CapturedTraceback::PyFrame> to_free_frames;\nstruct PythonTraceback : public CapturedTraceback::Python {\n  std::vector<CapturedTraceback::PyFrame> gather() override {\n    std::vector<CapturedTraceback::PyFrame> frames;\n    py::gil_scoped_acquire acquire;\n    {\n      std::lock_guard<std::mutex> lock(to_free_frames_mutex);\n      for (CapturedTraceback::PyFrame f : to_free_frames) {\n        Py_XDECREF(f.code);\n      }\n      to_free_frames.clear();"
},
{
    "Id": 81,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/8269c4f3d30ad950a873d900f7de0880cdd38878",
    "Violation": "missing",
    "Bug report": "Added nullptr check for pthradpool_get_threads_count. We get seg fault without this in using XNNPACK.",
    "Number of deleted lines": 0,
    "Deleted lines": "            function(argument, workId);\n          },\n          range);\n}\n\nsize_t pthreadpool_get_threads_count(pthreadpool_t threadpool) {\n  return reinterpret_cast<caffe2::ThreadPool*>(threadpool)->getNumThreads();\n}\n\npthreadpool_t pthreadpool_create(size_t threads_count) {\n  std::mutex thread_pool_creation_mutex_;\n  std::lock_guard<std::mutex> guard(thread_pool_creation_mutex_);\n\n  return reinterpret_cast<pthreadpool_t>(new caffe2::ThreadPool(threads_count));\n}"
},
{
    "Id": 82,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/13121598efc7d86cb7ae6e05322bb95c1d0f16bc",
    "Violation": "missing",
    "Bug report": "Bug fix to update requantization and zp parameters of input. Also sneaking in change to check for realloc failure for packed activation buffer. In dynamic quantization input's quantization scale and zero point can be different on every iterations. Thus requantization scale needs to be recomputed. Earlier bug that calculated those only at op creation time results in wrong results on subsequent runs.",
    "Number of deleted lines": 0,
    "Deleted lines": "\n      const size_t output_size = op->output_height * op->output_width;\n      const size_t k_stride = (group_input_channels + (kr - 1)) & -kr;\n      const size_t m_stride = (output_size + (mr - 1)) & -mr;\n      op->prepacked_a =\n        (uint8_t*)realloc((void*)op->prepacked_a, k_stride * m_stride);\n\n      struct q8gemm_prepackA_sparse_dq_context\n        q8gemm_prepack_sparse_dq_context = {\n          .k = group_input_channels,\n          .a = op->input,\n          .a_stride = op->input_pixel_stride,\n          .a_packed = op->prepacked_a,\n          .a_packed_stride = k_stride * mr,"
},
{
    "Id": 83,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/e8e29690ef0306da25b5f191623476001d29a18b",
    "Violation": "missing",
    "Bug report": " Add has_debug_def() check to net's debug_def() ",
    "Number of deleted lines": 2,
    "Deleted lines": "  virtual vector<OperatorBase*> GetOperators() const = 0;\n\n  const string& Name() const {\n    return name_;\n  }\n\n  inline const std::shared_ptr<const NetDef> debug_def() const {\n    return net_def_;\n  }\n\n protected:\n  virtual bool DoRunAsync() = 0;\n\n  vector<string> external_input_;\n  vector<string> external_output_;\n  string name_;"
},
{
    "Id": 84,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/eed22921237eb4c1f4399af177ce912147a885c3",
    "Violation": "missing",
    "Bug report": " check for null commonworld in DestroyCommonWorld. Summary: Check for nullptr before closing a common world.",
    "Number of deleted lines": 0,
    "Deleted lines": "  DestroyCommonWorld(const OperatorDef& operator_def, Workspace* ws)\n      : Operator<CPUContext>(operator_def, ws) {\n    cw_name_ = operator_def.input(0);\n  }\n\n  bool RunOnDevice() override {\n    const auto& context =\n        OperatorBase::Input<std::shared_ptr<::gloo::Context>>(0);\n\n    if (context) {\n      LOG(INFO) << \"Closing connections: \" << cw_name_;\n      context->closeConnections();\n    }\n    return true;"
},
{
    "Id": 85,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/d471eaeb1d2fbc7efcde6408d7d1e513b969af25",
    "Violation": "missing",
    "Bug report": "fix inline_container.cc inplace loading",
    "Number of deleted lines": 1,
    "Deleted lines": "  mz_zip_reader_extract_iter_state* iter =\n      mz_zip_reader_extract_iter_new(ar_.get(), key, 0);\n  TORCH_CHECK(\n      iter != nullptr,\n      \"Failed to create zip reader iter: \",\n      mz_zip_get_error_string(mz_zip_get_last_error(ar_.get())));\n\n  for (size_t offset = 0; offset < stat.m_uncomp_size; offset += chunk_size) {\n    size_t want_size =\n        std::min(chunk_size, (size_t)stat.m_uncomp_size - offset);\n    size_t read_size =\n        mz_zip_reader_extract_iter_read(iter, buf, want_size);\n    TORCH_CHECK(\n        read_size == want_size,\n        \"Failed to advance zip reader iter: \","
},
{
    "Id": 86,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/a5ca445f7953711bc90c111c3cad2ec87f02e74a",
    "Violation": "missing",
    "Bug report": "Check for corrupted ivalues. The error occurs because the `ivalues` field of flatbuffer module can be null, so the corresponding check must be inserted.",
    "Number of deleted lines": 0,
    "Deleted lines": "  all_types_.clear();\n  storages_.clear();\n  storage_loaded_.clear();\n  module_parsed_ = false;\n\n  const auto* ivalues = module->ivalues();\n  all_ivalues_.resize(ivalues->size());\n  all_types_.resize(module->object_types()->size());\n  storages_.resize(module->storage_data_size());\n  storage_loaded_.resize(module->storage_data_size(), false);\n\n  mobile_ivalue_size_ = module_->mobile_ivalue_size();\n  if (mobile_ivalue_size_ == 0) {\n    mobile_ivalue_size_ = ivalues->size();"
},
{
    "Id": 87,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/6cc0f1c20c2f87a6c7b0e4abd5419e5007920999",
    "Violation": "missing",
    "Bug report": "Checking for nullptr in get_model_bytecode_version . One-liner commit to check that the ptr is not null. Just had `test_jit` that had a segfault there.",
    "Number of deleted lines": 0,
    "Deleted lines": "  PyTorchStreamReader reader(std::move(rai));\n  auto bytecode_values = get_bytecode_ivalues(reader);\n  return _get_model_bytecode_version(bytecode_values);\n}\n\nuint64_t _get_model_bytecode_version_from_bytes(char* data, size_t size) {\n  TORCH_CHECK(size >= kFileFormatHeaderSize, \"Unrecognized data format\");\n  auto format = getFileFormat(data);\n  switch (format) {\n    case FileFormat::FlatbufferFileFormat: {\n      return get_bytecode_version_from_bytes(data);\n    }\n    case FileFormat::ZipFileFormat: {\n      auto rai ="
},
{
    "Id": 88,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/61b9d8fccd3361f21e1f3548c2a9538b62cc7525",
    "Violation": "improper",
    "Bug report": "It is apparently undefined behavior to do pointer arithmetic on nullptr. In the case of AppendOnlyList, `next_` will only be null if `end_` is also null and thus the `memcpy` path will only be triggered if `n == 0`. Nonetheless, it is U to `memcpy(0, 0, 0)`. The extra null check is in a `C10_LIKELY` block so the extra cost should be negligible, and indeed after dusting off the component microbenchmarks there's no observable difference.",
    "Number of deleted lines": 2,
    "Deleted lines": "  }\n\n  template <typename T0>\n  typename std::enable_if<\n      std::is_same<T0, T>::value && std::is_trivially_copyable<T>::value>::type\n  copy(c10::ArrayRef<T0> src) {\n    int n = src.size();\n    if (C10_LIKELY(next_ + n <= end_)) {\n      std::memcpy((void*)next_, (void*)src.begin(), n * sizeof(T0));\n      next_ += n;\n    } else {\n      // We could chunk this into several `memcpy`s, but because we expect this\n      // fallback to be infrequent (n << ChunkSize) the performance impact is\n      // negligible.\n      for (auto i : src) {\n        emplace_back(i);"
},
{
    "Id": 89,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/c06dfd7c26102ac2436ca25609c92fa794e972ca",
    "Violation": "missing",
    "Bug report": "Check input device in TRTModule. Add a check to ensure all the inputs are on cuda device.",
    "Number of deleted lines": 0,
    "Deleted lines": "        ), f\"Wrong number of inputs, expect {len(self.input_names)} get {len(inputs)}.\"\n        batch_size = inputs[0].shape[0]\n        contiguous_inputs: List[torch.Tensor] = [i.contiguous() for i in inputs]\n        bindings: List[Any] = [None] * (len(self.input_names) + len(self.output_names))\n\n        for i, input_name in enumerate(self.input_names):\n            idx = self.engine.get_binding_index(input_name)\n            bindings[idx] = contiguous_inputs[i].data_ptr()\n\n            if not self.engine.has_implicit_batch_dimension:\n                self.context.set_binding_shape(idx, tuple(contiguous_inputs[i].shape))\n\n        # create output tensors\n        outputs: List[torch.Tensor] = []"
},
{
    "Id": 90,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/d3de37609f2f052a7efb098ab69540458ebaaa6c",
    "Violation": "insufficient",
    "Bug report": "Support fused_dropout with XPU backend. ## Motivation Enable the fused dropout optimization on XPU devices. ## Solution Add XPU device in the fused dropout acceptable checking.",
    "Number of deleted lines": 1,
    "Deleted lines": "  for (int64_t i = 2; i < input.dim(); ++i)\n    sizes.push_back(1);\n  return at::empty(sizes, input.options());\n}\n\nbool is_fused_kernel_acceptable(const Tensor& input, double p) {\n  return input.is_cuda() && p > 0 && p < 1 && input.numel() > 0;\n}\n\n// NB: sure, we could have used different overloads here, but I would feel insecure\n// knowing that this dispatch depends only on the constness of the references\ntemplate<bool inplace>\nTensor& multiply(Tensor& input, const Tensor& noise) {\n  static_assert(inplace, \"Wrong multiply overload triggered in Dropout.cpp\");\n  return input.mul_(noise);"
},
{
    "Id": 91,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/7bf195f3608e0f28c30ffb6e2fecd74a1d4ee50a",
    "Violation": "missing",
    "Bug report": "fix kernel launch check in cross kernel",
    "Number of deleted lines": 1,
    "Deleted lines": "    auto x1 = static_cast<const scalar_t*>(iter.data_ptr(1));\n    auto x2 = static_cast<const scalar_t*>(iter.data_ptr(2));\n    constexpr int64_t int_max = std::numeric_limits<int>::max();\n    if (ostride * 2 > int_max || x1stride * 2 > int_max || x2stride * 2 > int_max) {\n      cross_kernel<<<grid, num_threads, 0, stream>>>(\n          N, out, x1, x2, offset_calculator, ostride, x1stride, x2stride);\n    } else {\n      cross_kernel<<<grid, num_threads, 0, stream>>>(\n          N, out, x1, x2, offset_calculator,\n          static_cast<int>(ostride),\n          static_cast<int>(x1stride),\n          static_cast<int>(x2stride));\n    }\n  });\n  C10_CUDA_KERNEL_LAUNCH_CHECK();\n}\n\nvoid cross_impl(Tensor& result, const Tensor& x1, const Tensor& x2, int64_t dim) {\n  const int64_t ostride = result.stride(dim);\n  const int64_t x1stride = x1.stride(dim);\n  const int64_t x2stride = x2.stride(dim);\n\n  auto iter = TensorIteratorConfig()"
},
{
    "Id": 92,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/15dbc566c57eedbd0245e786912e94586eba0fd2",
    "Violation": "missing",
    "Bug report": "Add missing cuda kernel launch check",
    "Number of deleted lines": 0,
    "Deleted lines": "                 at::cuda::getCurrentCUDAStream()>>>(\n                  output_data_ptr,\n                  lengths_data_ptr,\n                  segment_count,\n                  initial.has_value(),\n                  initial_value);\n        }\n      });\n\n  return output;\n}\n\nREGISTER_DISPATCH(_segment_reduce_stub, &_segment_reduce_cuda_kernel);\n"
},
{
    "Id": 93,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/a8653f35de02c7fb038e3c184dda6e67a12a39e2",
    "Violation": "missing",
    "Bug report": "Perf win by check which device tensors are on",
    "Number of deleted lines": 0,
    "Deleted lines": "Tensor& fill_quantized_(Tensor& self, const Scalar& value) {\n  return fill_out_quantized(self, value);\n}\n\nTensor& fill_(Tensor& self, const Tensor& value) {\n  TORCH_CHECK(value.dim() == 0, \"fill_ only supports 0-dimension value tensor but got tensor with \", value.dim(), \" dimensions.\");\n  // Check if value is a view of self and if it is we clone\n  // it to avoid overwriting self prematurely\n  if(self.is_alias_of(value)) {\n    self.copy_(value.clone());\n  } else{\n    self.copy_(value);\n  }\n  return self;"
},
{
    "Id": 94,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/8b37821813b60a3ce2ae92e7a06057183578a450",
    "Violation": "insufficient",
    "Bug report": "if we want to use dp on other device ranther than \"cuda\", this balance  check will raise error, so I make the balance check only effective for `cuda`",
    "Number of deleted lines": 1,
    "Deleted lines": "        self.dim = dim\n        self.module = module\n        self.device_ids = [_get_device_index(x, True) for x in device_ids]\n        self.output_device = _get_device_index(output_device, True)\n        self.src_device_obj = torch.device(device_type, self.device_ids[0])\n\n        _check_balance(self.device_ids)\n\n        if len(self.device_ids) == 1:\n            self.module.to(self.src_device_obj)\n\n    def forward(self, *inputs: Any, **kwargs: Any) -> Any:\n        with torch.autograd.profiler.record_function(\"DataParallel.forward\"):\n            if not self.device_ids:\n                return self.module(*inputs, **kwargs)"
},
{
    "Id": 95,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/59a3759d9787091e75d939de603981a6d32505c8",
    "Violation": "missing",
    "Bug report": "When we need to link extra libs, we should notice that 64-bit CUDA may be installed in \"lib\", not in \"lib64\".",
    "Number of deleted lines": 1,
    "Deleted lines": "        if IS_WINDOWS:\n            extra_ldflags.append(f'/LIBPATH:{_join_cuda_home(\"lib\", \"x64\")}')\n            extra_ldflags.append('cudart.lib')\n            if CUDNN_HOME is not None:\n                extra_ldflags.append(f'/LIBPATH:{os.path.join(CUDNN_HOME, \"lib\", \"x64\")}')\n        elif not IS_HIP_EXTENSION:\n            extra_ldflags.append(f'-L{_join_cuda_home(\"lib64\")}')\n            extra_ldflags.append('-lcudart')\n            if CUDNN_HOME is not None:\n                extra_ldflags.append(f'-L{os.path.join(CUDNN_HOME, \"lib64\")}')\n        elif IS_HIP_EXTENSION:\n            assert ROCM_VERSION is not None\n            extra_ldflags.append(f'-L{_join_rocm_home(\"lib\")}')\n            extra_ldflags.append('-lamdhip64' if ROCM_VERSION >= (3, 5) else '-lhip_hcc')\n    return extra_ldflags"
},
{
    "Id": 96,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/e856a4d66bead8997a83f8714547c09fcbcdc263",
    "Violation": "missing",
    "Bug report": " Add an env var to skip cudnn version compatibility check. skip the check by setting `PYTORCH_SKIP_CUDNN_COMPATIBILITY_CHECK=1`",
    "Number of deleted lines": 0,
    "Deleted lines": "                cudnn_compatible = False\n            elif runtime_major < 7 or not _cudnn.is_cuda:\n                cudnn_compatible = runtime_minor == compile_minor\n            else:\n                cudnn_compatible = runtime_minor >= compile_minor\n            if not cudnn_compatible:\n                base_error_msg = (f'cuDNN version incompatibility: '\n                                  f'PyTorch was compiled  against {compile_version} '\n                                  f'but found runtime version {runtime_version}. '\n                                  f'PyTorch already comes bundled with cuDNN. '\n                                  f'One option to resolving this error is to ensure PyTorch '\n                                  f'can find the bundled cuDNN.')\n\n                if 'LD_LIBRARY_PATH' in os.environ:"
},
{
    "Id": 97,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/0fc110cdd19363f2eb5de68b6eeb82dadc933be0",
    "Violation": "missing",
    "Bug report": "The bug in libcuda.so that required is fixed for libcuda.so versions >= 11.4.This PR changes replay() to sync after each launch only if the process's in-use libcuda.so is < 11.4. With all the \"enhanced\" and \"forward\" compatibility promises flying around, and the fact that \"driver\" sometimes means kernel-mode driver and sometimes means user-mode driver (libcuda.so), I wasn't sure if this PR's check suffices to trigger the sync iff the in-use libcuda.so is 11.4, but Cuda people say what I wrote is reasonable.",
    "Number of deleted lines": 5,
    "Deleted lines": "  }\n  offset_extragraph_.fill_(int64_t(rng_engine_inputs.offset_.val));\n\n  // graph_exec_ may be replayed in any stream.\n  AT_CUDA_CHECK(cudaGraphLaunch(graph_exec_, at::cuda::getCurrentCUDAStream()));\n\n  // Temporary workaround for bug in libcuda.so that causes replayed graphs\n  // with certain topologies to be corrupted (kernels elided, internal syncs\n  // ignored) when replayed back to back without a sync in between.\n  // I hate to use a hard sync, but it's the only surefire workaround at the moment.\n  cudaDeviceSynchronize();\n#else\n  TORCH_CHECK(false, \"CUDA graphs may only be used in Pytorch built with CUDA >= 11.0\");\n#endif\n}\n\nvoid CUDAGraph::reset() {\n#if CUDA_VERSION >= 11000\n  // I'd prefer these checks throw exceptions, not print warnings,"
},
{
    "Id": 98,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/ef44faece2cd4045f58cbbac6c74842b84ac6c45",
    "Violation": "insufficient",
    "Bug report": " check attribute existence in torch.legay.nn.SpatialFullConvolution in method type",
    "Number of deleted lines": 2,
    "Deleted lines": "            self.padW, self.padH,\n            adjW, adjH,\n            scale\n        )\n\n    def type(self, type=None, tensorCache=None):\n        if self.finput is not None:\n            self.finput = torch.Tensor()\n        if self.fgradInput is not None:\n            self.fgradInput = torch.Tensor()\n        return super(SpatialFullConvolution, self).type(type, tensorCache)\n\n    def __repr__(self):\n        s = super(SpatialFullConvolution, self).__repr__()\n        s += '({} -> {}, {}x{}'.format(self.nInputPlane, self.nOutputPlane, self.kW, self.kH)\n        if self.dW != 1 or self.dH != 1 or self.padW != 0 or self.padH != 0:\n            s += ', {}, {}'.format(self.dW, self.dH)"
},
{
    "Id": 99,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/5c93ca258bab7bd74a8ec94d64647e48c8ad8797",
    "Violation": "insufficient",
    "Bug report": "check attribute existence in SpatialFullConvolution",
    "Number of deleted lines": 4,
    "Deleted lines": "            targetTensor = input[1]\n            tDims = targetTensor.dim()\n            tH = targetTensor.size(tDims - 2)\n            tW = targetTensor.size(tDims - 1)\n            adjW = self._calculateAdj(tW, self.kW, self.padW, self.dW)\n            adjH = self._calculateAdj(tH, self.kH, self.padH, self.dH)\n            if self.finput is None:\n                self.finput = input[0].new()\n            if self.fgradInput is None:\n                self.fgradInput = input[0].new()\n        else:\n            if self.finput is None:\n                self.finput = input.new()\n            if self.fgradInput is None:\n                self.fgradInput = input.new()\n\n        inputTensor = self._makeContiguous(inputTensor)\n        self._backend.SpatialFullConvolution_updateOutput(\n            self._backend.library_state,\n            inputTensor,\n            self.output,\n            self.weight,"
},
{
    "Id": 100,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/c5fdcd85c7570b654eec45b6cba7cc75b0cf8f6b",
    "Violation": "insufficient",
    "Bug report": "check pruned attributes before deleting. I copyed a pruned model after deleteing the derived tensors. In order to be able to reparameter the model, we should check the existence of the tensors here.",
    "Number of deleted lines": 1,
    "Deleted lines": "        )  # this gets set in apply()\n\n        # to update module[name] to latest trained weights\n        weight = self.apply_mask(module)  # masked weights\n\n        # delete and reset\n        delattr(module, self._tensor_name)\n        orig = module._parameters[self._tensor_name + \"_orig\"]\n        orig.data = weight.data\n        del module._parameters[self._tensor_name + \"_orig\"]\n        del module._buffers[self._tensor_name + \"_mask\"]\n        setattr(module, self._tensor_name, orig)\n\n\nclass PruningContainer(BasePruningMethod):"
},
{
    "Id": 101,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/678c08bb55eef0c2e707a17d0cd6e50f5b9bd427",
    "Violation": "missing",
    "Bug report": "_ProcessGroupWrapper check needs to be gated on Gloo availability, this fails when gloo is not avail_ProcessGroupWrapper check needs to be gated on Gloo availability, this fails when gloo is not avail.",
    "Number of deleted lines": 4,
    "Deleted lines": "def _tensor_to_object(tensor, tensor_size):\n    buf = tensor.numpy().tobytes()[:tensor_size]\n    return _unpickler(io.BytesIO(buf)).load()\n\ndef _check_for_nccl_backend(group):\n    pg = group or _get_default_group()\n    # It is not expected for PG to be wrapped many times, but support it just\n    # in case\n    while isinstance(pg, _ProcessGroupWrapper):\n        pg = pg.wrapped_pg\n\n    return (\n        is_nccl_available() and\n        isinstance(pg, ProcessGroupNCCL)\n    )\n\ndef all_gather_object(object_list, obj, group=None):\n    \"\"\""
},
{
    "Id": 102,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/db1ac4e29b0f557711190c8d49d4afb5da1844e8",
    "Violation": "insufficient",
    "Bug report": "Summary: We should explicitly check for the gloo backend instead of relying on the shard's device, because user might pass a GPU tensor as input and a process group gloo as the pg, and expect that should work.",
    "Number of deleted lines": 1,
    "Deleted lines": "    assert group is not None\n    out_size = list(shard.size())\n    out_size[0] *= group_size\n    out_tensor = shard.new_empty(out_size)\n    assert out_tensor.is_contiguous()\n    # FIXME gloo doesn't support _allgather_base\n    if shard.is_cpu:\n        tensor_list = list(torch.chunk(out_tensor, group_size))\n        work = dist.all_gather(tensor_list, shard, group=group, async_op=True)\n    else:\n        work = dist.all_gather_into_tensor(out_tensor, shard, group=group, async_op=True)\n    _register_tensor_work(out_tensor, work)\n\n    return out_tensor\n"
},
{
    "Id": 103,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/3ef4d697df5bfdbd27dfc7a79c0679da2b87e3af",
    "Violation": "missing",
    "Bug report": "default backend need to check for nccl availability. As titled, we can only initialize nccl backend when NCCL is available",
    "Number of deleted lines": 4,
    "Deleted lines": "    def __init__(self, backend: Union[str, Backend]):\n        self.device_backend_map: Dict[torch.device, Backend] = {}\n\n        if backend == Backend.UNDEFINED:\n            # default config when backend is not specified\n            # supported since PyTorch 2.0\n            self.device_backend_map = {\n                \"cpu\": Backend.GLOO,\n                \"cuda\": Backend.NCCL,\n            }\n        elif backend.lower() in Backend.backend_list:\n            # Cases for when backend is a single string (without device types)\n            # e.g. \"nccl\", \"gloo\", \"ucc\", \"mpi\"\n            supported_devices = Backend.backend_capability[backend.lower()]\n            backend_val = Backend(backend)\n            self.device_backend_map = {\n                device : backend_val for device in supported_devices\n            }"
},
{
    "Id": 104,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/9bb1371cc20a14907dbc47bc98e3ac5de866e34b",
    "Violation": "missing",
    "Bug report": "Disable RDYNAMIC check with MSVC. Summary: When testing with clang-cl, the flag is added though it is unsupported and that generates a few warnings.",
    "Number of deleted lines": 4,
    "Deleted lines": "endif()\n\n# ---[ Checks if linker supports -rdynamic. `-rdynamic` tells linker\n# -to add all (including unused) symbols into the dynamic symbol\n# -table. We need this to get symbols when generating backtrace at\n# -runtime.\ncheck_cxx_compiler_flag(\"-rdynamic\" COMPILER_SUPPORTS_RDYNAMIC)\nif(${COMPILER_SUPPORTS_RDYNAMIC})\n  set(CMAKE_SHARED_LINKER_FLAGS \"${CMAKE_SHARED_LINKER_FLAGS} -rdynamic\")\n  set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -rdynamic\")\nendif()\n\n# ---[ If we are using msvc, set no warning flags\n# Note(jiayq): if you are going to add a warning flag, check if this is\n# totally necessary, and only add when you see fit. If it is needed due to\n# a third party library (like Protobuf), mention it in the comment as\n# \"THIRD_PARTY_NAME related\"\n# From https://docs.microsoft.com/en-us/cpp/error-messages/compiler-warnings/"
},
{
    "Id": 105,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/48e675ac7519666ed5e96d8d49c468dfc15a5d66",
    "Violation": "missing",
    "Bug report": "fx quant: fix subtle bug in BinaryOpQuantizeHanlder logic in matching. When matching a pattern to `BinaryOpQuantizeHandler`, we need to make sure we check for dtype support on the base node, instead of the current node.  This is important in cases such as `add-relu` and `mul-relu`, when the current node is `relu`, but the base node is `add|mul`.",
    "Number of deleted lines": 3,
    "Deleted lines": "                            use_copy_node = all_node_args_have_no_tensors(node, modules, cache_for_no_tensor_check)\n                            if use_copy_node:\n                                # TODO(future PR): update the pattern to quantize\n                                # handler logic to take this into account.\n                                value = CopyNodeQuantizeHandler  # type: ignore\n\n                            this_node_qconfig = self.qconfig_map[node.name]\n                            if this_node_qconfig:\n                                dtypes = get_qconfig_dtypes(this_node_qconfig)\n                                # TODO(future PR): update the pattern to quantize\n                                # handler logic to take this into account.\n                                skip_this_match = (\n                                    (node.target in binary_op_supported_dtypes) and\n                                    (dtypes not in binary_op_supported_dtypes[node.target])\n                                )\n\n                        if not skip_this_match:\n                            matched: List[Any] = []\n                            record_match(pattern, node, matched)\n                            for n in matched:\n                                match_map[n.name] = (\n                                    node, matched, pattern, value(self, node),  # type: ignore"
},
{
    "Id": 106,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/62732bdcdb8b6112e01366d4ad1c2a50e61da1ed",
    "Violation": "insufficient",
    "Bug report": "quick fix for invalid nodes. Summary: As title.Need to check whether node is valid before fusion",
    "Number of deleted lines": 0,
    "Deleted lines": "\ndef is_linear_node_can_be_fused(node):\n    input = get_arg_value(node, 0, \"input\")\n    weight = get_arg_value(node, 1, \"weight\")\n    return (\n        is_node_meta_valid(node)\n        and len(input.meta[\"example_value\"].shape) == 2\n        and len(weight.meta[\"example_value\"].shape) == 2\n    )\n\n\nclass BatchLinearFusion(BatchFusion):\n    \"\"\"\n    Batch linear fusion in pre grad pass."
},
{
    "Id": 107,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/aab55d6d0d7b958e32cfdbb69794e107cfceb6bc",
    "Violation": "missing",
    "Bug report": "Remove all the dequant nodes when the ref module has multi input args. When converting a ref module into a quant module, `_lower_static_weighted_ref_module` pass assumes the `ref_node` only has 1 input node, and only remove the first `dequant` node. We add a check in this PR to ensure this is the case for `_lower_static_weighted_ref_module` pass.",
    "Number of deleted lines": 0,
    "Deleted lines": "        q_module = q_class.from_reference(ref_module, output_scale, output_zero_point)\n        # replace reference module with quantized module\n        parent_name, module_name = _parent_name(ref_node.target)\n        setattr(modules[parent_name], module_name, q_module)\n\n        # Step 2: Reroute around dq_node, and remove q_node and its args\n        dq_node = ref_node.args[0]\n        assert(isinstance(dq_node, Node))\n        ref_node.replace_input_with(dq_node, dq_node.args[0])\n        q_node.replace_all_uses_with(ref_node)\n        model.graph.erase_node(q_node)\n        model.graph.erase_node(scale_node)\n        model.graph.erase_node(zero_point_node)\n"
},
{
    "Id": 108,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/bae895cef0c12df5f64afa155ce5462e06f0e04a",
    "Violation": "missing",
    "Bug report": "Added check for kHIP in ATen/native/Copy.cpp",
    "Number of deleted lines": 0,
    "Deleted lines": "    return self;\n  }\n\n  DeviceType device_type = iter.device_type(0);\n  if (iter.device_type(1) == kCUDA) {\n    device_type = kCUDA;\n  }\n\n  // TODO: if we need to, we can also enable this path for quantized tensor\n  if (device_type == kCPU && copy_transpose_valid(self, src) && !self.is_quantized()) {\n    copy_same_type_transpose_(self, src);\n    return self;\n  }\n"
},
{
    "Id": 109,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/cf348bcdeecfe0b47a2245d95eaa8ef37fb7b53e",
    "Violation": "missing",
    "Bug report": "tighten hasCUDA check",
    "Number of deleted lines": 0,
    "Deleted lines": "  static Context globalContext_;\n  return globalContext_;\n}\n\nbool Context::hasCUDA() const {\n#ifdef AT_CUDA_ENABLED\n  return true;\n#else\n  return false;\n#endif\n}\n\n\n}"
},
{
    "Id": 110,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/027c0d7f8e37e583c02b372df5331d73793c06b1",
    "Violation": "missing",
    "Bug report": "fixed compilations on xla tensor prin. This is done to avoid compilations during tensor printing. Torch performs some tensor operations like slicing to make the tensor readable. These operations result in compilations. Hence to avoid the compilations, copying the tensor to cpu before printing. Returning from this function would have resulted in 63 compiles, since PDB prints the value of the return output. In this case it is a xla tensor. Now with the current change, there is no compilation.",
    "Number of deleted lines": 0,
    "Deleted lines": "    # In other cases, we don't have a way to set them as default yet,\n    # and we should always print out device for them.\n    if self.device.type != torch._C._get_default_device()\\\n            or (self.device.type == 'cuda' and torch.cuda.current_device() != self.device.index):\n        suffixes.append('device=\\'' + str(self.device) + '\\'')\n\n    # TODO: add an API to map real -> complex dtypes\n    _default_complex_dtype = torch.cdouble if torch.get_default_dtype() == torch.double else torch.cfloat\n    has_default_dtype = self.dtype in (torch.get_default_dtype(), _default_complex_dtype, torch.int64, torch.bool)\n    if self.is_sparse:\n        suffixes.append('size=' + str(tuple(self.shape)))\n        suffixes.append('nnz=' + str(self._nnz()))\n        if not has_default_dtype:\n            suffixes.append('dtype=' + str(self.dtype))"
},
{
    "Id": 111,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/ee91c328da5739ce03b3127cd7c542ce505212b8",
    "Violation": "improper",
    "Bug report": "Fix cuda/cpu check on NoneType ",
    "Number of deleted lines": 1,
    "Deleted lines": "                self.out_proj.bias,\n            )\n            # We have to use list comprehensions below because TorchScript does not support\n            # generator expressions.\n            if torch.overrides.has_torch_function(tensor_args):\n                why_not_fast_path = \"some Tensor argument has_torch_function\"\n            elif not all([(x.is_cuda or 'cpu' in str(x.device)) for x in tensor_args]):\n                why_not_fast_path = \"some Tensor argument is neither CUDA nor CPU\"\n            elif torch.is_grad_enabled() and any([x.requires_grad for x in tensor_args]):\n                why_not_fast_path = (\"grad is enabled and at least one of query or the \"\n                                     \"input/output projection weights or biases requires_grad\")\n            if not why_not_fast_path:\n                merged_mask, mask_type = self.merge_masks(attn_mask, key_padding_mask, query)\n\n                return torch._native_multi_head_attention("
},
{
    "Id": 112,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/cdab6c8df9ff9331126f69ea59c23f06109f03d7",
    "Violation": "missing",
    "Bug report": "Support specifying None for obs_or_fq_ctr in target_dtype_info. It is cleaner for quantizer to say what does not need observation instead of putting fp32 observers. This diff add support for that by checking if target_dtype_info contains none for specific observers and if so skip inserting observers for those.",
    "Number of deleted lines": 0,
    "Deleted lines": "                # only add observer for first input for now, we may need to extend\n                # qconfig_dict and backend_config to support more general configurations\n                # of dynamic quantization, e.g. dynamically quantizing second input, third\n                # input etc.\n                arg_as_input_target_is_dynamic and arg is node.args[0]\n            )\n\n    else:\n        assert qconfig is not None\n        # custom flow for standalone modules\n        _, _, sm_prepare_custom_config, _ = \\\n            _get_standalone_module_configs(\n                node, named_modules, prepare_custom_config, qconfig, backend_config)\n        sm_input_quantized_idxs = sm_prepare_custom_config.input_quantized_indexes"
},
{
    "Id": 113,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/7f5737392d637a22d555a88a8546d8fc7ab31084",
    "Violation": "insufficient",
    "Bug report": "fix for fsdp exec order pre fwd record. When the sharding_strategy is set to SHARD_GRAD_OP and forward_prefetch=True, during direct validation run, self.is_first_iter will always be True (because training=False, iter+1 is not executed). Additionally, the _pre_forward_order_index of the first handle entering the record_pre_forward function is 0. This causes the handle to have a False result in the if condition at line 166 when entering the record_pre_forward function again (the expected value should be True because _pre_forward_order_index has actually been assigned a value). As a result, the first handle is repetitively added to handles_pre_forward_order, leading to incorrect prefetching order.",
    "Number of deleted lines": 1,
    "Deleted lines": "        \"\"\"\n        if not handle:\n            return\n        self._check_order(handle, is_training)\n        # Fix the order after the first iteration and only record the first\n        # usage of a handles key\n        if not self.is_first_iter or handle._pre_forward_order_index:\n            return\n        index = len(self.handles_pre_forward_order)\n        handle._pre_forward_order_index = index\n        self.handles_pre_forward_order.append(handle)\n\n    def _check_order(self, handle: FlatParamHandle, is_training: bool) -> None:\n        \"\"\"\n        Checks the forward execution order as long as ``is_training`` is"
},
{
    "Id": 114,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/dcac4dd58edefb6951a60266e53d8767dc9be002",
    "Violation": "missing",
    "Bug report": "Add int32_t range check in packed_accessor32 in PyTorch TensorBase.  Summary: As ajtulloch suggested, we can make tensor.packed_accessor32<...>() raise an exception if tensor.numel() > std::numeric_limits<uint32_t>::max(). Trade-off: run-time check overhead (one-time) when doing `packed_accessor32` accessor.",
    "Number of deleted lines": 0,
    "Deleted lines": "  }\n  template<typename T, size_t N, template <typename U> class PtrTraits = DefaultPtrTraits, typename index_t = int64_t>\n  GenericPackedTensorAccessor<T,N> generic_packed_accessor() && = delete;\n\n  template<typename T, size_t N, template <typename U> class PtrTraits = DefaultPtrTraits>\n  PackedTensorAccessor32<T,N,PtrTraits> packed_accessor32() const& {\n    return generic_packed_accessor<T,N,PtrTraits,int32_t>();\n  }\n  template<typename T, size_t N, template <typename U> class PtrTraits = DefaultPtrTraits>\n  PackedTensorAccessor32<T,N,PtrTraits> packed_accessor32() && = delete;\n\n  template<typename T, size_t N, template <typename U> class PtrTraits = DefaultPtrTraits>\n  PackedTensorAccessor64<T,N,PtrTraits> packed_accessor64() const& {\n    return generic_packed_accessor<T,N,PtrTraits,int64_t>();"
},
{
    "Id": 115,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/027e3b7910fade8950038fb5044a548319510600",
    "Violation": "insufficient",
    "Bug report": "check if source is None when using tensor out variants",
    "Number of deleted lines": 1,
    "Deleted lines": "                    for idx, name in enumerate(output_tensor_names):\n                        if name in tx.symbolic_locals:\n                            tx.symbolic_locals[name] = tensor_variable.items[idx]\n                elif isinstance(tensor_variable, TensorVariable):\n                    assert isinstance(kwargs[\"out\"], TensorVariable)\n                    if (\n                        kwargs[\"out\"] in tx.output.graphargs\n                        and kwargs[\"out\"].size != tensor_variable.size\n                    ):\n                        # It's hard to get out variants with resizing on graph inputs work\n                        # properly across dynamo/aot/inductor, just fall back.\n                        unimplemented(\"out variants with resizing on graph inputs\")\n                    name = tx.find_symbolic_locals_name(kwargs[\"out\"])\n                    if name in tx.symbolic_locals:\n                        tx.symbolic_locals[name] = tensor_variable"
},
{
    "Id": 116,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/91066559a8c8e5978ed4de722317576b222267c5",
    "Violation": "improper",
    "Bug report": "truthy check for empty string in NameScope(). As in name. LATTE translation team moving some code from Python 2 to 3 uncovered a case where comparison between unicode and str types leads NameScope('') to prepend a separator to the beginning of blob names. This fixes it.",
    "Number of deleted lines": 1,
    "Deleted lines": "@contextlib.contextmanager\ndef NameScope(prefix, reset=False):\n    global _threadlocal_scope\n    assert isinstance(prefix, basestring), \\\n        \"NameScope takes in a string as its argument.\"\n    old_scope = CurrentNameScope()\n    prefix = prefix + _NAMESCOPE_SEPARATOR if prefix is not '' else ''\n    if reset:\n        _threadlocal_scope.namescope = prefix\n    else:\n        _threadlocal_scope.namescope = _threadlocal_scope.namescope + prefix\n\n    try:\n        yield\n    finally:"
},
{
    "Id": 117,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/e3542d2c12d8aaaccf8a53873e480c20dc6b7338",
    "Violation": "missing",
    "Bug report": "avoid unnecessary call to empty_tensor_restride in empty(). Our empty benchmark makes this call unconditionally. If MemoryFormat::Contiguous is indeed a common case (or if workloads are likely to use a consistent-ish memory format), then I'd expect checking first to be a win.",
    "Number of deleted lines": 2,
    "Deleted lines": "      std::move(storage_impl), at::DispatchKey::CPU, dtype);\n  // Default TensorImpl has size [0]\n  if (size.size() != 1 || size[0] != 0) {\n    tensor.unsafeGetTensorImpl()->set_sizes_contiguous(size);\n  }\n\n  auto memory_format = memory_format_opt.value_or(MemoryFormat::Contiguous);\n  tensor.unsafeGetTensorImpl()->empty_tensor_restride(memory_format);\n\n  return tensor;\n}\n\ntemplate <typename T>\nTensor tensor_cpu(ArrayRef<T> values, const TensorOptions& options) {\n  auto result = at::empty(values.size(), options);\n  AT_ASSERT(result.is_contiguous());"
},
{
    "Id": 118,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/45d5b3248b430aca70111316accd165954464589",
    "Violation": "missing",
    "Bug report": "Fixed C++ BatchNorm pretty_print() with optional momentum. Summary : Inserted a check for the momentum and print  \"None\" in case is not defined.",
    "Number of deleted lines": 1,
    "Deleted lines": "template <size_t D, typename Derived>\nvoid BatchNormImplBase<D, Derived>::pretty_print(std::ostream& stream) const {\n  stream << std::boolalpha\n         << \"torch::nn::BatchNorm\" << D << \"d(\"\n         << this->options.num_features() << \", \"\n         << \"eps=\" << this->options.eps() << \", \"\n         << \"momentum=\" << this->options.momentum().value() << \", \"\n         << \"affine=\" << this->options.affine() << \", \"\n         << \"track_running_stats=\" << this->options.track_running_stats() << \")\";\n}\n\nvoid BatchNorm1dImpl::_check_input_dim(const Tensor& input) {\n  TORCH_CHECK(\n      input.dim() == 2 || input.dim() == 3,\n      \"expected 2D or 3D input (got \", input.dim(), \"D input)\");"
},
{
    "Id": 119,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/666ff0ae220e1a5c406b0bc5cd43283e1b18b38e",
    "Violation": "missing",
    "Bug report": "Update _create_c10d_store to check port value. Port number is int in python, but needs to be uint16_t when called for TCPStore constructor.",
    "Number of deleted lines": 0,
    "Deleted lines": "\n    If ``torchelastic_use_agent_store()`` is ``False``, then rank 0 will host\n    the TCPStore (with multi-tenancy) and it is assumed that rank 0's hostname\n    and port are correctly passed via ``hostname`` and ``port``. All\n    non-zero ranks will create and return a TCPStore client.\n    \"\"\"\n\n    if _torchelastic_use_agent_store():\n        attempt = os.environ[\"TORCHELASTIC_RESTART_COUNT\"]\n        tcp_store = TCPStore(hostname, port, world_size, False, timeout)\n        return PrefixStore(f\"/worker/attempt_{attempt}\", tcp_store)\n    else:\n        start_daemon = rank == 0\n        return TCPStore("
},
{
    "Id": 120,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/ba59d720cd5c5c81601b53d2c3397c46c1f87883",
    "Violation": "missing",
    "Bug report": "Change error message for torch.linspace(). Basically moves the error checking from the device-specific function to the native function.",
    "Number of deleted lines": 0,
    "Deleted lines": "\nTensor linspace(\n    Scalar start,\n    Scalar end,\n    int64_t steps,\n    const TensorOptions& options) {\n  Tensor result = at::empty({steps}, options);\n  return at::linspace_out(result, start, end, steps);\n}\n\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ logspace ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTensor logspace(\n    Scalar start,"
},
{
    "Id": 121,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/babb28d2a3a755424f72518bc360d9f511a24463",
    "Violation": "improper",
    "Bug report": "Change DHCECK to CAFFE_ENFORCE in softmax_with_loss_op.cc. Summary: Based on discussion on the post in Caffe2 users. Changing DCHECK that works only in debug mode to CAFFE_ENFORCE that throws exception and is a better option. Update: Also correct the check for label_data >= 0, did not check for all elements previously. Moved it to inner loop.",
    "Number of deleted lines": 5,
    "Deleted lines": "    }\n    math::Exp(N * D, Pdata, Pdata, &context_);\n  } else {\n    const float* label_data = T.data<float>();\n\n    for (int i = 0; i < N; ++i) {\n      CAFFE_ENFORCE(\n          label_data[i] >= 0,\n          \"Label prob seems incorrect: label prob value must be nonnegative: \",\n          label_data[i]);\n      float l = 0.0;\n      float total_prob = 0.0;\n      float weight = weights ? weights[i] : 1.0;\n      for (int j = 0; j < D; ++j) {\n        l += -log(std::max(Pdata[i * D + j], 1e-20f)) * label_data[i * D + j] *\n            weight;\n        total_prob += label_data[i * D + j];\n      }\n      loss_sum += l;\n      DCHECK(std::abs(total_prob - 1.) < 1e-5f);\n      weight_sum += weight;\n    }\n  }\n\n  avg_loss->Resize(vector<TIndex>());\n  float* avg_loss_data = avg_loss->mutable_data<float>();\n  if (weight_sum != 0.0) {\n    avg_loss_data[0] = loss_sum * scale_ / weight_sum;"
},
{
    "Id": 122,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/bc371a2cd03ce573f3ad4f7be141364136028905",
    "Violation": "missing",
    "Bug report": "Add additional checks when tracing back during maybe share output observer function. Summary: Currently in `maybe_make_input_output_share_observers`  we trace back from a node to find the activation_post_process of the input node, we have internal use case which would error out during tracing back, this PR is adding a guard during this process to return False early when the node doesn't have any input",
    "Number of deleted lines": 0,
    "Deleted lines": "        # set all other input observer nodes to use that module\n        for input_idx, input_arg in enumerate(first_arg):\n            if input_idx == 0:\n                continue\n            iteration_guard = 0\n            while not is_activation_post_process_node(input_arg, modules):\n                input_arg = input_arg.args[0]\n                iteration_guard += 1\n                if iteration_guard > 10000:\n                    raise AssertionError('Unable to find observer of previous node')\n\n            parent_name, name = _parent_name(input_arg.target)\n            setattr(modules[parent_name], name, obs_mod_to_use)\n"
},
{
    "Id": 123,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/3aeaa21eb02953a9cbc62b3e61215572fc28453e",
    "Violation": "missing",
    "Bug report": "Revert \"Remove parent device mesh check",
    "Number of deleted lines": 0,
    "Deleted lines": "        and all(isinstance(pg, dist.ProcessGroup) for pg in process_group)\n    )\n\n\n@no_type_check\ndef _is_valid_hybrid_shard_device_mesh(device_mesh: DeviceMesh) -> bool:\n    return isinstance(device_mesh, DeviceMesh) and device_mesh.ndim == 2\n\n\n@no_type_check\ndef _init_intra_node_process_group(num_devices_per_node: int) -> dist.ProcessGroup:\n    \"\"\"\n    Return a process group across the current node.\n"
},
{
    "Id": 124,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/5fc122bf3973504e619cd677ad4a7fc1011642cd",
    "Violation": "missing",
    "Bug report": "tensor.numpy() checks that no positional arguments are passed. * tensor.numpy() checks that no arguments are passed.",
    "Number of deleted lines": 0,
    "Deleted lines": "  npy_intp zero = 0;\n  int ndim;\n  npy_intp* sizes_ptr;\n  std::unique_ptr<npy_intp[]> sizes;\n  std::unique_ptr<npy_intp[]> strides;\n\n  // Numpy and Torch disagree on empty tensors. In Torch, an empty tensor\n  // is a tensor with zero dimensions. In Numpy, a tensor with zero dimensions\n  // is a scalar (with one element). So we'll convert an empty Torch tensor\n  // to a 1d Numpy tensor of shape [0]. Also see pushTensor in PythonToLua.cpp.\n  ndim = THTensor_(nDimension)(LIBRARY_STATE self->cdata);\n  if (ndim != 0) {\n\n    sizes.reset(new npy_intp[ndim]);"
},
{
    "Id": 125,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/647154f82ac2c57769f080c41452b3e5960ab94f",
    "Violation": "missing",
    "Bug report": "Assert tensor isn't sparse in enforce_invariants. There's no reason we can't check this, but I'm punting on implementing it for now.  But it currently segfaults, so this is an improvement",
    "Number of deleted lines": 0,
    "Deleted lines": "  if (defined()) {\n    // If it's a variable - we definitely not in C2 land\n    if (!is_variable()) {\n      AT_ASSERTM(\n          impl_->dtype_initialized(),\n          \"Partially-initialized tensor not supported by at::Tensor\");\n      AT_ASSERTM(\n          impl_->storage_initialized(),\n          \"Partially-initialized tensor not supported by at::Tensor\");\n    }\n    // Ensure LegacyTypeDispatch is initialized. In ATen it's done in tensor\n    // factory functions, but when we get a tensor from Caffe2 we might bypass\n    // those factory functions.\n    initializeLegacyTypeDispatchFor(*impl_);"
},
{
    "Id": 126,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/2c9dd886afc656a8bfe5d8bbcb601ee5877cee21",
    "Violation": "missing",
    "Bug report": "Modify torch.movedim to handle scalar as no-op. Summary: `torch.movedim` directly handle the case of a scalar tensor (0-dim) in input as a no-op by returning a view of the input tensor (after all the usual checks for the other parameters)",
    "Number of deleted lines": 0,
    "Deleted lines": "    auto duplicate = std::adjacent_find(copy.begin(), copy.end());\n    return duplicate == copy.end();\n  };\n  TORCH_CHECK(all_unique(normalized_src), \"movedim: repeated dim in `source` (\", src, \")\");\n  TORCH_CHECK(all_unique(normalized_dst), \"movedim: repeated dim in `destination` (\", dst, \")\");\n\n  // TODO: The algorithm below can probably be optimized.\n  // Reference: https://github.com/pytorch/pytorch/pull/41480#discussion_r456100505\n\n  // Algorithm Walkthrough\n  // Example Input\n  // Variable State:\n  //     normalized_src = 0, 1\n  //     normalized_dst = 2, 4"
},
{
    "Id": 127,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/52e76a305677dfaf26cd5d59bd1aa239375f833c",
    "Violation": "missing",
    "Bug report": "fix ShardedTensor.gather when shard is empty. current ShardedTensor.gather is not working as expectation when the shard is empty on any rank The root cause is identified that when a sharded tensor has no placement on a specific rank, the metadata doesn't include that rank's placement which introduces KeyError in :```shard_offset = shard_placement[shard. Metadata][1]``` It's fixed by adding an empty tensor check.",
    "Number of deleted lines": 0,
    "Deleted lines": "                # enforce_dtype is deprecated.  Do it for backward compatibility.\n                dtype = local_shards[0].tensor.dtype\n            data = torch.empty(max_rank_size, device=self._get_preferred_device(), dtype=dtype)\n\n            for shard in local_shards:\n                src = shard.tensor.flatten()\n                shard_offset = shard_placement[shard.metadata][1]\n                data[shard_offset: shard_offset + src.numel()].copy_(src)\n\n        dist.gather(\n            tensor=data,\n            gather_list=gather_list,\n            dst=dst,\n            group=self._process_group,"
},
{
    "Id": 128,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/4ee179c9528c8c6aae17a01f2b0d7e8235219219",
    "Violation": "insufficient",
    "Bug report": "Fix ConstantVariable init method if NumPy is missing. By adding `np is not None` check before `isinstance(value, np.number)`",
    "Number of deleted lines": 1,
    "Deleted lines": "    def __init__(self, value, **kwargs):\n        super().__init__(**kwargs)\n        if not ConstantVariable.is_literal(value):\n            for disallowed_type, reason in _type_to_assert_reason.items():\n                assert not isinstance(value, disallowed_type), reason\n\n        if isinstance(value, np.number):\n            self.value = value.item()\n        else:\n            self.value = value\n\n    def as_proxy(self):\n        return self.value\n\n    def __str__(self):"
},
{
    "Id": 129,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/ba766ef39a4fff2d8856e17747393d469e409775",
    "Violation": "missing",
    "Bug report": "Fix BN size check in eval mode",
    "Number of deleted lines": 3,
    "Deleted lines": "        scale_grad_by_freq, sparse\n    )\n\n\ndef batch_norm(input, running_mean, running_var, weight=None, bias=None,\n               training=False, momentum=0.1, eps=1e-5):\n    size = list(input.size())\n    if reduce(mul, size[2:], size[0]) == 1:\n        raise ValueError('Expected more than 1 value per channel, got input size {}'.format(size))\n    f = torch._C._functions.BatchNorm(running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled)\n    return f(input, weight, bias)\n\n\n# loss\n\ndef nll_loss(input, target, weight=None, size_average=True, ignore_index=-100):\n    r\"\"\"The negative log likelihood loss."
},
{
    "Id": 130,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/b287cb816c1ac52165920a121c98643c08d31ff7",
    "Violation": "insufficient",
    "Bug report": " inductor: make the vec_transpose's tiling stride doesn't depend on out_idx and tiling_idex. ",
    "Number of deleted lines": 2,
    "Deleted lines": "        self.tiling_indices = tiling_indices\n\n    def inner_itervar(self):\n        return sympy_symbol(f\"{self.itervars[self.outer_idx]}_inner\")\n\n    def need_vec_transpose(self, index):\n        return stride_at(self.itervars[self.outer_idx], index) == 1 and index.has(\n            self.itervars[self.tiling_idx]\n        )\n\n    def gen_transposed_tile_load_store(self, name, var, index, is_store):\n        # transposed tile load/store outside the kernel inner loop\n        dtype = V.graph.get_dtype(name)\n        factor = self.tiling_factor\n        src = f\"{var} + {cexpr_index(index)}\"\n        dst = \"__place_holder__\""
},
{
    "Id": 131,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/999bae0f54108ffc5b7cf2524a02a83901554b16",
    "Violation": "insufficient",
    "Bug report": "Add padding check for use_nnpack. nnp_convolution_output doesn't support the case of input padding > = kernel_size.",
    "Number of deleted lines": 1,
    "Deleted lines": "           input.device().is_cpu() &&\n           input.scalar_type() == kFloat && // only on CPU Float Tensors\n           !is_dilated() && // or dilation\n           !transposed &&   // or transposed tensors\n           input.ndimension() == 4 && // must be in NCHW format\n           weight.ndimension() == 4 &&\n           (at::symint::size<T>(weight, 2) < 17) && (at::symint::size<T>(weight, 3) < 17) // NNPACK only supports kernels up to 16x16\n#if !defined(C10_MOBILE)\n           && at::symint::size<T>(input, 0) >= 16 // ensure large enough batch size to ensure perf, tuneable\n#endif\n       ;\n#endif\n    return false;\n  }\n  bool use_xnnpack(const at::Tensor& input, const at::Tensor& weight,"
},
{
    "Id": 132,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/66b04e3cb707d30c4698b269c83cb6221848f17a",
    "Violation": "missing",
    "Bug report": "nullptr profiling name. Sometimes profiling name can be a nullptr, which throws on conversion to std::string. This adds a check.",
    "Number of deleted lines": 1,
    "Deleted lines": "    std::lock_guard<std::mutex> guard(mutex_);\n\n    auto te = Entry{\n        id_,\n        pg_id,\n        seq_id,\n        profiling_name,\n        std::move(traceback),\n        std::move(start),\n        std::move(end),\n        c10::getTime()};\n\n    for (const auto& input : inputs) {\n      c10::IntArrayRef sizes = input.sizes();\n      te.input_dims_.push_back(sizes.size());"
},
{
    "Id": 133,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/14c47fb211bc929ae4e505e7e13411faa2339f00",
    "Violation": "missing",
    "Bug report": " fix invalid-null-argument UBSAN error in math_cpu.cc. Add an if statement to check if the destination buffer is not nullptr.",
    "Number of deleted lines": 0,
    "Deleted lines": "    const void* A,\n    const int lda,\n    void* B,\n    const int ldb,\n    CPUContext* /*context*/,\n    TypeMeta::TypedCopy copy) {\n  if (lda == N && ldb == N) {\n    // can coalese to a single memcpy of size M * N\n    if (copy) {\n      copy(static_cast<const char*>(A), static_cast<char*>(B), N * M);\n    } else {\n      memcpy(\n          static_cast<char*>(B), static_cast<const char*>(A), itemsize * N * M);\n    }"
},
{
    "Id": 134,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/f77f88fbc7511b405c4e493bdd74634b633f63d1",
    "Violation": "missing",
    "Bug report": "X86 qengine always uses fbgemm kernels on OS other than Linux. X86 quantization backend (qengine) with oneDNN kernels has not been validated on OS other than Linux. So, let it fall back to fbgemm if OS is not Linux. This makes sure the behavior is the same on Windows/Mac as the previous default fbgemm qengine on x86 CPUs.",
    "Number of deleted lines": 1,
    "Deleted lines": "      // but we do not want to raise an error in this util function.\n    is_symmetric = false;\n  }\n  return is_symmetric;\n}\n\n// Check if onednn should be used w.r.t fbgemm\nstatic bool should_use_onednn_quant(\n    const at::Tensor& weight,\n    bool is_transposed_conv,\n    int groups,\n    torch::List<int64_t> output_padding) {\n  bool vnni_available = cpuinfo_has_x86_avx512vnni();\n  bool w_sym_quant =\n      is_weight_symmetric_quant(weight, is_transposed_conv);\n  bool opad_all_zero =\n      std::all_of(output_padding.begin(), output_padding.end(), [](int i) { return i==0; });\n  return vnni_available && (groups <= 100) && w_sym_quant && opad_all_zero;\n}\n\n} // onednn_utils\n\n#endif // #if AT_MKLDNN_ENABLED()\n"
},
{
    "Id": 135,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/acd51e13f727af22e6c9e579518362898f1b12e6",
    "Violation": "missing",
    "Bug report": "TorchScript add check if quantized",
    "Number of deleted lines": 0,
    "Deleted lines": "                warnings.warn(nondeterministic_ops_warning, category=TracerWarning, stacklevel=5)\n\n        def compare_outputs(original, reference, match_what):\n            all_ok = True\n            for i, (orig, ref) in enumerate(zip(original, reference)):\n                try:\n                    torch.testing.assert_allclose(orig.double(), ref.double(), rtol=check_tolerance,\n                                                  atol=torch.testing._get_default_tolerance(orig, ref)[1])\n                except AssertionError as e:\n                    maybe_warn_nondeterministic()\n                    warnings.warn('Output nr ' + str(i + 1) + '. of the traced function does not match '\n                                  'the corresponding output of the ' + match_what + '. Detailed error:\\n' + str(e),\n                                  category=TracerWarning, stacklevel=4)\n                    all_ok = False"
},
{
    "Id": 136,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/0584fd9339af7c939ab7d955db05743ba58ff86d",
    "Violation": "improper",
    "Bug report": "Only insert observers for fixed qparam ops. Fixed a condition check for fixed qparam ops, previously we were including CopyNodes as well",
    "Number of deleted lines": 1,
    "Deleted lines": "            def is_observed(input_arg):\n                if isinstance(input_arg, Node):\n                    return input_arg.name in observed_node_names_set\n                elif isinstance(input_arg, list):\n                    return all(map(is_observed, input_arg))\n\n            if activation_dtype(qconfig) == torch.float16:\n                insert_observer(\n                    node, qconfig.activation(),\n                    model, activation_post_process_map, env, observed_graph,\n                    load_arg, observed_node_names_set)\n            else:\n                # propagate observed property from input\n                if is_observed(node.args[0]):\n                    observed_node_names_set.add(node.name)"
},
{
    "Id": 137,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/97245a06e14a5b87a0bca1908d7200603aff2c8c",
    "Violation": "missing",
    "Bug report": "TORCH_INTERNAL_ASSERT_DEBUG_ONLY won't be enabled during non-debug builds, but for 1 dimension Tensors the check is cheap enough and not catching this can slow down development a lot.",
    "Number of deleted lines": 5,
    "Deleted lines": "namespace native {\nstruct NestedTensorImpl;\n\n// The following functions are used to construct nested tensors from buffers and\n// metadata.\n\ninline at::Tensor wrap_buffer(\n    at::Tensor buffer,\n    at::Tensor nested_sizes) {\n  TORCH_INTERNAL_ASSERT_DEBUG_ONLY(\n      buffer.is_contiguous(), \"Given buffer must be contiguous.\");\n  return at::detail::make_tensor<NestedTensorImpl>(\n      std::move(buffer), std::move(nested_sizes));\n}\n\n// TODO: Figure out if we need a non-moving wrap_buffer()\ninline at::Tensor wrap_buffer(\n    at::Tensor buffer,\n    at::Tensor nested_sizes,"
},
{
    "Id": 138,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/9bcb4de16878073896d8743fbd70d5abe28b595a",
    "Violation": "insufficient",
    "Bug report": "check parameter k and l ",
    "Number of deleted lines": 1,
    "Deleted lines": "  }\n  return r;\n}\n\n// Product of all dims between k and l (not including dims[k] and dims[l])\ninline int64_t size_between_dim_(int k, int l, IntArrayRef dims) {\n  TORCH_CHECK((unsigned)l < dims.size());\n  int64_t r = 1;\n  if (k < l) {\n    for (int i = k + 1; i < l; ++i) {\n      r *= dims[i];\n    }\n  } else {\n    for (int i = l + 1; i < k; ++i) {\n      r *= dims[i];"
},
{
    "Id": 139,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/65496e4e67b42e52b3428b0cf2d994e0aa1a9902",
    "Violation": "missing",
    "Bug report": "Bug fix in bound shape inferencer. Accessing dims() without boundary check is not good.",
    "Number of deleted lines": 1,
    "Deleted lines": "  int channel_acc = 0;\n  std::string input_to_infer;\n  for (const auto& i : op.input()) {\n    const auto it = shape_info_.find(i);\n    if (it != shape_info_.end()) {\n      const auto& current_input_shape = it->second;\n      channel_acc += current_input_shape.shape.dims(axis);\n    } else if (missing_shape_infos) {\n      LOG(INFO) << \"More than one missing shapes, previous one: \"\n                << input_to_infer;\n      // We can only infer one missing input shape info\n      return;\n    } else {\n      ++missing_shape_infos;\n      input_to_infer = i;"
},
{
    "Id": 140,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/260f66c3165ce0c48dd1514a916da6971d981578",
    "Violation": "missing",
    "Bug report": "Fix concat dimension check bug",
    "Number of deleted lines": 1,
    "Deleted lines": "      ArgumentHelper helper(def);\n      const int axis = helper.HasArgument(\"axis\")\n          ? helper.GetSingleArgument<int>(\"axis\", -1)\n          : GetDimFromOrderString(\n                helper.GetSingleArgument<string>(\"order\", \"NCHW\"));\n      bool add_axis = helper.GetSingleArgument<int>(\"add_axis\", 0) != 0;\n      const int canonical_axis = canonical_axis_index_(axis, in[0].dims_size());\n      CAFFE_ENFORCE_GT(in.size(), 0);\n      vector<int> split_shape(1, in.size());\n      vector<int> out_shape(in[0].dims().begin(), in[0].dims().end());\n      if (add_axis) {\n        for (int i = 1; i < in.size(); ++i) {\n          CAFFE_ENFORCE_EQ(\n              in[0].dims().size(),\n              in[i].dims().size(),"
},
{
    "Id": 141,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/dc07102b17915f21170fae9a9d52c6f2d59726ca",
    "Violation": "missing",
    "Bug report": "Check dim size preventively when doing shape inference for BatchMatMul. We check input(0) but not input(1) in BatchMatMul. This may result in a protobuf exception which won't be caught by upstream and causing termination of the program. Check that with `CAFFE_ENFORCE` will be caught by upstream inference function. Plus, it will print out clean stack tracing showing where went wrong.",
    "Number of deleted lines": 0,
    "Deleted lines": "    const vector<TensorShape>& in) {\n  ArgumentHelper helper(def);\n  bool broadcast = helper.GetSingleArgument<int>(\"broadcast\", 0);\n  if (!broadcast) {\n    const auto ndim = in[0].dims_size();\n    CAFFE_ENFORCE_GE(ndim, 2);\n    int a_dim0;\n    int b_dim1;\n    if (helper.GetSingleArgument<int>(\"trans_a\", 0)) {\n      a_dim0 = in[0].dims(ndim - 1);\n    } else {\n      a_dim0 = in[0].dims(ndim - 2);\n    }\n"
},
{
    "Id": 142,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/77523df413ff7f8a336b6481cfa47967c234a149",
    "Violation": "missing",
    "Bug report": "Add more check on softmax ONNX exporting logic. * Add more check on softmax exporting logic * Add more comments about axis and dim",
    "Number of deleted lines": 0,
    "Deleted lines": "\n    first, second = g.op('Split', input, axis_i=dim, outputs=2)\n    return g.op('Mul', first, g.op('Sigmoid', second))\n\n\ndef softmax(g, input, dim=None):\n    return g.op('Softmax', input, axis_i=dim)\n\n\ndef softplus(g, self, beta, threshold):\n    if beta != 1:\n        return _unimplemented(\"beta\", \"has to be 1\")\n    return g.op('Softplus', self)\n"
},
{
    "Id": 143,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/a53f4b0f9bbc007c0a92e4fd28dd22af027e24a8",
    "Violation": "missing",
    "Bug report": " add dimension check to NHWC2NCHW shape inference. Summary: To prevent assertion from protobuffer when accessing the dims.",
    "Number of deleted lines": 0,
    "Deleted lines": "\nOPERATOR_SCHEMA(NHWC2NCHW)\n    .NumInputs(1)\n    .NumOutputs(1)\n    .TensorInferenceFunction([](const OperatorDef& /*unused*/ /*def*/,\n                                const vector<TensorShape>& in) {\n      vector<TensorShape> out(1);\n      out[0].add_dims(in[0].dims(0));\n      out[0].add_dims(in[0].dims(3));\n      out[0].add_dims(in[0].dims(1));\n      out[0].add_dims(in[0].dims(2));\n      return out;\n    })\n    .SetDoc(R\"DOC("
},
{
    "Id": 144,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/ecd3c252b4da3056797f8a505c9ebe8d68db55c4",
    "Violation": "missing",
    "Bug report": "Suport all length one SLS op lowering: C2 part. We check the input shape of lengths and indices of SLS and add an attribute if they are the same.",
    "Number of deleted lines": 0,
    "Deleted lines": "  // GivenTensorIntFill op\n  std::unordered_set<std::string> split_infos;\n  for (auto& op : *onnxifi_net.mutable_op()) {\n    if ((op.type() == \"Concat\" || op.type() == \"Reshape\") &&\n        op.output_size() == 2) {\n      split_infos.emplace(op.output(1));\n    }\n  }\n  onnxifi_net.clear_external_output();\n  for (const auto& o : net.external_output()) {\n    if (!split_infos.count(o)) {\n      onnxifi_net.add_external_output(o);\n    }\n  }"
},
{
    "Id": 145,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/55092b1cc604fad3d70d31e71bbdd3a43a279423",
    "Violation": "missing",
    "Bug report": "Validate matching input shapes in Int8Add operator. Default engine doesn't support broadcast semantics in Int8Add operator. This patch adds a check that shapes are equivalent.",
    "Number of deleted lines": 0,
    "Deleted lines": "  bool RunOnDevice() override {\n    CAFFE_ENFORCE_EQ(Inputs().size(), 2);\n    const auto& A = Inputs()[0]->template Get<Int8TensorCPU>();\n    const auto& B = Inputs()[1]->template Get<Int8TensorCPU>();\n    auto* Y = Outputs()[0]->template GetMutable<Int8TensorCPU>();\n\n    /*\n     * Record quantization parameters for A and B inputs, because if the op is\n     * in-place, we may overwrite these parameters later, when we set\n     * quantization parameters for Y tensor.\n     */\n    const uint8_t A_zero_point = A.zero_point;\n    const uint8_t B_zero_point = B.zero_point;\n    const float A_scale = A.scale;"
},
{
    "Id": 146,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/1f819ee965894b8332cb364a67c91855c91c9dcc",
    "Violation": "missing",
    "Bug report": "Add check for no grad in transformer encoder nestedtensor conversion.  Before, we allowed inputs with grad to be converted to NestedTensors. Autograd attempts to find the size of the NestedTensor, but NestedTensor throws an exception for its size function. This causes all calls to nn.TransformerEncoder with grad enabled to fail. Fix: we add a check for no grad in transformer encoder so we do not convert tensor with grad to nestedtensor.",
    "Number of deleted lines": 3,
    "Deleted lines": "                        first_layer.linear1.weight,\n                        first_layer.linear1.bias,\n                        first_layer.linear2.weight,\n                        first_layer.linear2.bias,\n                    )\n                    if not torch.overrides.has_torch_function(tensor_args):\n                        if output.is_cuda or 'cpu' in str(output.device):\n                            convert_to_nested = True\n                            output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not())\n\n        for mod in self.layers:\n            if convert_to_nested:\n                output = mod(output, src_mask=mask)\n            else:\n                output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n\n        if convert_to_nested:"
},
{
    "Id": 147,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/dc43ad428603539a2051940c09b191825f66203d",
    "Violation": "missing",
    "Bug report": " add is_grad_enabled check in runtime_wrapper before running with torch.no_grad. We observed that `with torch.no_grad()` in runtime_wrapper introduced ~10% (0.06ms->0.066ms) inference performance regression on lennard_jones on cpu. For inference tasks in benchmark, grad has been disabled, but in the current runtime_wrapper, no_grad is set again and its time is counted into the running time. Therefore, we add `is_grad_enabled` check in runtime_wrapper before running with torch.no_grad. If grad has been disabled, there is no need to set no_grad. ",
    "Number of deleted lines": 1,
    "Deleted lines": "                )\n        else:\n            # When we have an inference graph, we run with torch.no_grad.\n            # It's possible to get an inference graph with inputs that require grad,\n            # in which case we want to make sure autograd is disabled\n            # (since e.g., inductor will generate aten.addmm.out calls which autograd will complain on)\n            with torch.no_grad():\n                all_outs = call_func_at_runtime_with_args(\n                    compiled_fn,\n                    args,\n                    disable_amp=disable_amp,\n                )\n\n        num_mutated_runtime_inps = runtime_metadata.num_mutated_inp_runtime_indices\n        num_intermediate_bases = runtime_metadata.num_intermediate_bases"
},
{
    "Id": 148,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/c1c4882367c592d49e15268a0b99631c207d662e",
    "Violation": "insufficient",
    "Bug report": "Based on discussions with Sherlock + Zhengxu in D51118067, updated the internal thrift schema to match the OSS schema.. So to bypass these failures I did the following hacks(?): Before creating the exported program in deserialization, populate nodes w/o meta[\"val\"] with meta[\"val\"] = None * Add torch.autograd.grad_mode.set_grad_enabled to the skip opset * Duplicated ExportGraphSignature into aot_export.py so that the graph signature checks will be skipped",
    "Number of deleted lines": 1,
    "Deleted lines": "\n            def _allowed_op_types() -> Tuple[Type[Any], ...]:\n                ret = self.allowed_op_types()\n                assert not any(t is object for t in ret)\n                return ret\n\n            if not isinstance(op, _allowed_op_types()):\n                if op not in _allowed_builtin_ops():\n                    raise SpecViolationError(\n                        f\"Operator '{op}' is not an allowed operator type: {_allowed_op_types()}\\n\"\n                        f\"Valid builtin ops: {_allowed_builtin_ops()}\"\n                    )\n\n            if isinstance(op, OpOverload):\n                # All ops functional\n                if not is_functional(op):\n                    raise SpecViolationError(\n                        f\"operator '{op}' is not functional\"\n                    )"
},
{
    "Id": 149,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/f3a2094065c8b4b7bae426e71c923a8a8abb74b5",
    "Violation": "insufficient",
    "Bug report": "Mitigate legacy issue that aten op as export entrance function. This is not supported any more, now the top level ```torch.export``` only support ```nn.Module```, but there are still some tests using the internal APIs and caused the ```trace_rules.check``` assertion error. This PR is going to mitigate such cases.",
    "Number of deleted lines": 0,
    "Deleted lines": "        remove_from_cache(f)\n\n        if (\n            not disable_constraint_solver\n            and (shape_env := getattr(fake_mode, \"shape_env\", None)) is not None\n            and (dim_constraints := shape_env.dim_constraints) is not None\n            and not trace_rules.check(call_to_inspect)\n        ):\n            dim_constraints.solve()\n            dim_constraints.remove_redundant_dynamic_results()\n            forced_specializations = dim_constraints.forced_specializations()\n            msg = dim_constraints.prettify_results(\n                original_signature, constraint_violation_error, forced_specializations\n            )"
},
{
    "Id": 150,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/cc6a51c9f3ee97a06ff9c0b84477e88e33e31137",
    "Violation": "missing",
    "Bug report": "added shape checking to WeightedRandomSampler",
    "Number of deleted lines": 1,
    "Deleted lines": "                num_samples <= 0:\n            raise ValueError(\"num_samples should be a positive integer \"\n                             \"value, but got num_samples={}\".format(num_samples))\n        if not isinstance(replacement, bool):\n            raise ValueError(\"replacement should be a boolean value, but got \"\n                             \"replacement={}\".format(replacement))\n        self.weights = torch.as_tensor(weights, dtype=torch.double)\n        self.num_samples = num_samples\n        self.replacement = replacement\n        self.generator = generator\n\n    def __iter__(self) -> Iterator[int]:\n        rand_tensor = torch.multinomial(self.weights, self.num_samples, self.replacement, generator=self.generator)\n        yield from iter(rand_tensor.tolist())\n"
},
{
    "Id": 151,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/8ee59280d78a4fefc4de0da04b287e067c28de0d",
    "Violation": "insufficient",
    "Bug report": "Bug - check config for dynamic",
    "Number of deleted lines": 2,
    "Deleted lines": "            for i in range(e.dim()):\n                # NB: mark dynamic has precedence over static\n                marked_dynamic = i in getattr(e, \"_dynamo_dynamic_indices\", set())\n                marked_static = i in getattr(e, \"_dynamo_static_indices\", set())\n\n                # NB: both static and dynamic have precedence over\n                automatic_dynamic = curr_sizes is None or curr_sizes[i] is None\n\n                # We will process constraints first, as they will imply that we\n                # have a dynamic dimension\n                # Precedence: export constraints > eager constraints\n                constraint = dim2constraint.get(i)\n                if constraint is None:\n                    if marked_dynamic and not config.allow_ignore_mark_dynamic:\n                        constraint = RelaxedUnspecConstraint(warn_only=False)\n                    elif not marked_static and automatic_dynamic:"
},
{
    "Id": 152,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/e9e125475e94aabfb34ee239fadc760615eef429",
    "Violation": "missing",
    "Bug report": "Add schema check to aten::repeat and fb::fast_gather",
    "Number of deleted lines": 0,
    "Deleted lines": "            padding_idx.value_or(-1));\n      };\n    });\n\n// NOLINTNEXTLINE(cppcoreguidelines-avoid-non-const-global-variables)\nREGISTER_OPERATOR_FUNCTOR(aten::repeat, aten_repeat, [](Node* n) -> SROperator {\n  return [](ProcessedNode* p_node) {\n    const auto& self = p_node->Input(0).toTensor();\n    const auto repeats = p_node->Input(1).toIntVector();\n\n    if (p_node->Output(0).isNone()) {\n      p_node->Output(0) = create_empty_from(self);\n    }\n    at::Tensor& output = p_node->Output(0).toTensor();"
},
{
    "Id": 153,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/7ea6559658a6f650363f8b96f462bbc047e29124",
    "Violation": "missing",
    "Bug report": "Add size checks to torch.stack. Checks the size of each tensor passed to `torch.stack` before calling `cat` to address #29510. This is done in the `get_stack_input` function as that is a common path. The function now compares the size of each tensor in the TensorList to the size of the first tensor and throws an exception when the sizes are not equal.",
    "Number of deleted lines": 1,
    "Deleted lines": "  TORCH_CHECK(start_idx == dim_size,\n           \"split_with_sizes expects split_sizes to sum exactly to \", dim_size,\n           \" (input tensor's size at dimension \", dim, \"), \", \"but got split_sizes=\", split_sizes);\n  return splits;\n}\n\nstatic inline std::vector<Tensor> get_stack_inputs(TensorList tensors, int64_t dim) {\n  std::vector<Tensor> inputs(tensors.size());\n  for (size_t i = 0; i < tensors.size(); ++i) {\n    inputs[i] = tensors[i].unsqueeze(dim);\n  }\n  return inputs;\n}\n\nTensor stack(TensorList tensors, int64_t dim) {\n  TORCH_CHECK(tensors.size() > 0,\n           \"stack expects a non-empty TensorList\");"
},
{
    "Id": 154,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/bbb5e106ad6228953df6c7f5c8916b26dc0cb457",
    "Violation": "improper",
    "Bug report": "Improve error checking of CUDALoops. Same change as was applied to CPU loops -- separate out checking of the inputs and outputs.",
    "Number of deleted lines": 1,
    "Deleted lines": "void gpu_kernel_impl(TensorIterator& iter, const func_t& f) {\n  using traits = function_traits<func_t>;\n  using arg0_t = typename traits::result_type;\n  constexpr int ntensors = traits::arity + 1;\n\n  TORCH_INTERNAL_ASSERT(iter.can_use_32bit_indexing());\n  TORCH_INTERNAL_ASSERT(iter.ntensors() == traits::arity + 1);\n\n  at::detail::Array<char*, ntensors> data;\n  for (int i = 0; i < ntensors; i++) {\n    data[i] = (char*)iter.data_ptr(i);\n  }\n\n  int64_t numel = iter.numel();\n"
},
{
    "Id": 155,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/d3bf6803b62c79f1dafd1eec49b4bd65d5a27697",
    "Violation": "missing",
    "Bug report": "add sanity check that we do not wrap tracked tensors ",
    "Number of deleted lines": 0,
    "Deleted lines": "                \"wrapped by this instance of Dynamo\",\n            )\n\n    def wrap_tensor(self, value: torch.Tensor):\n        source = self.get_source()\n\n        if (\n            source.guard_source().is_nn_module()\n            or get_static_address_type(value) is not None\n        ) and not source.guard_source().is_fsdp_module():\n            self.assert_not_wrapped_by_this_graph(value)\n            return self.tx.output.register_attr_or_module(\n                value,\n                self.name,"
},
{
    "Id": 156,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/794e3971ab90611b4a63166589368a737843c8bc",
    "Violation": "missing",
    "Bug report": "Add size check before calling stack_.at(dict_pos) in unpickler.cpp",
    "Number of deleted lines": 0,
    "Deleted lines": "      // At this OpCode, stack looks like\n      // | Stack Bottom |\n      // | ......       |\n      // | Dict         | -> (stack_size - 3)\n      // | Key          | -> (stack_size - 2)\n      // | Value        | -> (stack_size - 1)\n      auto stack_size = stack_.size();\n      auto dict_pos = stack_size - 3;\n      auto key_pos = stack_size - 2;\n      auto val_pos = stack_size - 1;\n      auto dict = stack_.at(dict_pos).toGenericDict();\n      dict.insert_or_assign(stack_.at(key_pos), stack_.at(val_pos));\n      stack_.erase(stack_.begin() + (key_pos), stack_.end());\n    } break;\n    default: {\n      AT_ERROR(\n          \"Unknown opcode for unpickling at \",\n          reinterpret_cast<void*>(opcode),"
},
{
    "Id": 157,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/7684044b713761abd4f51225dc5d83ce5869562a",
    "Violation": "missing",
    "Bug report": "Add size check before calling .back() in rpc/script_call.cpp",
    "Number of deleted lines": 0,
    "Deleted lines": "        \"Either builtin operator or TorchScript function name should be set.\");\n  }\n}\n\nstd::unique_ptr<ScriptCall> ScriptCall::fromIValues(\n    std::vector<at::IValue>& ivalues) {\n  // Last element in the vector is always qualifiedName for both\n  // builitin operator and TorchScript function\n  // If the qualifiedName is not a builtin operator name, then treat it\n  // as TorchScript function name\n  const std::string& qualifiedName = ivalues.back().toStringRef();\n\n  if (qualifiedName.rfind(BUILTIN_OP_NAMESPACE_) == 0) {\n    ivalues.pop_back();"
},
{
    "Id": 158,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/fb25fd6f865ed0532caf710ca130b6cc23a772a8",
    "Violation": "missing",
    "Bug report": "Replaced neg dim normalization with assert in helper. I think we can still leave the check for negative shard dimension in `compute_local_shape_and_global_offset` and replace the normalization logic with an assert. This should provide us a stack trace to see which user-facing API did not normalize the dim as expected.",
    "Number of deleted lines": 2,
    "Deleted lines": "    tensor_stride = list(tensor.stride())\n    for idx, placement in enumerate(placements):\n        mesh_dim_size = mesh.size(idx)\n        if placement.is_shard():\n            shard_placement = cast(Shard, placement)\n            if shard_placement.dim < 0:\n                # normalize shard dim to be positive\n                shard_placement.dim += len(tensor_shape)\n            shard_dim = shard_placement.dim\n\n            assert (\n                shard_dim < tensor.ndim\n            ), f\"Sharding dim {shard_dim} greater than tensor ndim {tensor.ndim} for placement number {idx}.\"\n\n            local_dim_size = tensor_shape[shard_dim]\n            tensor_shape[shard_dim] = local_dim_size * mesh_dim_size"
},
{
    "Id": 159,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/55c19a3c6d38a49fe34e008c4c566445c43810f0",
    "Violation": "missing",
    "Bug report": "Increase multiplier to 3 for Inductor AMP benchmark correctness check. we find some of the models have failed the benchmark's correctness check. However, the end-to-end model's accuracy. when comparing AMP with FP32 is within a difference of less than 0.1%. Thus, it's possible that the correctness check failures for these models are false alarms. We use multiplier of 3 instead of 2 in this PR to avoid these false alarms.",
    "Number of deleted lines": 1,
    "Deleted lines": "                if math.isnan(ref_error):\n                    log.warning(\n                        \"Found nan in reference. Consider running in higher precision.\"\n                    )\n\n                res_error = rmse(fp64_ref, res).item()\n                multiplier = 2.0\n\n                if (\n                    fp64_ref.numel() < 1000\n                    or (ref.ndim == 4 and ref.shape[-1] == ref.shape[-2] == 1)\n                    # large tol means a benchmark has been specified as REQUIRE_HIGHER_TOLERANCE\n                    or tol >= 2 * 1e-2\n                ):\n                    # In the presence of noise, noise might dominate our error"
},
{
    "Id": 160,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/6e78592cbb81138ce13ad65a5f549d65b191526c",
    "Violation": "missing",
    "Bug report": "Added type checking for ExportedProgram. Added type checking for ExportedProgram in save function. ",
    "Number of deleted lines": 0,
    "Deleted lines": "        extra_files = {'foo.txt': b'bar'.decode('utf-8')}\n        torch.export.save(ep, 'exported_program.pt2', extra_files=extra_files)\n\n    \"\"\"\n    from torch._export import save\n\n    save(ep, f, extra_files=extra_files, opset_version=opset_version)\n\n\ndef load(\n    f: Union[str, os.PathLike, io.BytesIO],\n    *,\n    extra_files: Optional[Dict[str, Any]] = None,\n    expected_opset_version: Optional[Dict[str, int]] = None,"
},
{
    "Id": 161,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/828a6a3b3943a0a0701ecacacd2bcc34fc03fe03",
    "Violation": "missing",
    "Bug report": "Use proper isnan check ",
    "Number of deleted lines": 1,
    "Deleted lines": "  REAL_SWAP(ARR(III), ARR(JJJ)); \\\n  LONG_SWAP(IDX(III), IDX(JJJ))\n\n/* Emulate NumPy behavior of putting NaNs\n * at the end of an ascending list. */\n#define GT_OR_NAN(x, y) \\\n  ((x != x && y == y) || (x > y))\n\nstatic void THTensor_(quicksortascend)(scalar_t *arr, int64_t *idx, int64_t elements, int64_t stride)\n{\n  int64_t beg[MAX_LEVELS], end[MAX_LEVELS], i, j, L, R, P, swap, pid, stack = 0, sz_right, sz_left;\n  scalar_t rswap, piv;\n  unsigned char done = 0;\n\n  /* beg[0]=0; end[0]=elements; */"
},
{
    "Id": 162,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/47c531b6e80e36282dbaec60d239ae1b9f816f43",
    "Violation": "missing",
    "Bug report": "Compare object identity first in ClassType::operator==. This check is much cheaper than anything involving actually inspecting object fields (i.e., the cost is low), and if it succeeds we can skip the expensive (e.g., it involves locking a weak_ptr and then destroying the resulting shared_ptr)  function body. It almost entirely eliminates time spent in this function during model loading according to perf.",
    "Number of deleted lines": 0,
    "Deleted lines": "      std::weak_ptr<CompilationUnit> cu,\n      bool is_module = false,\n      std::string doc_string = \"\",\n      std::vector<std::string> unresolved_class_attributes = {});\n\n  bool operator==(const Type& rhs) const override {\n    if (auto user_rhs = rhs.castRaw<ClassType>()) {\n      const auto& lhs_name = name().value();\n      const auto& rhs_name = user_rhs->name().value();\n\n      return lhs_name == rhs_name &&\n          this->compilation_unit() == user_rhs->compilation_unit();\n    }\n    return false;"
},
{
    "Id": 163,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/3611d26a25bd889627403a808ea667ac99c09904",
    "Violation": "missing",
    "Bug report": "Optimize FunctionSchema::checkArg for the Tensor case. The Tensor case is one of the most common and the existing check can be made faster. This results in a ~21% improvement on DeepAndWide model and would improve other models as well.",
    "Number of deleted lines": 0,
    "Deleted lines": "}\n\ninline void FunctionSchema::checkArg(\n    const IValue& value,\n    const Argument& argument,\n    optional<size_t> pos) const {\n  if (!value.type()->isSubtypeOf(argument.type())) {\n    TORCH_CHECK(\n        false,\n        formatTypeMismatchMsg(\n            argument, value.type()->repr_str(), pos));\n  }\n}\n"
},
{
    "Id": 164,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/324dc1623e2f91892038fb1b151450a7c6529dd9",
    "Violation": "missing",
    "Bug report": "add dtype checking for gather and scatter. in the `cpu_scatter_gather_base_kernel`, it interpret a pointer as `int64_t` regardless the actual dtype. add a index dtype checking will avoid the nasty index out of bound error. As using `int64_t` is convention in ATen code (a.k.a, a limitation), no further fix is needed at the moment.",
    "Number of deleted lines": 0,
    "Deleted lines": "\nTensor index_fill(const Tensor & self, int64_t dim, const Tensor & index, const Tensor & source) {\n  return self.clone(at::MemoryFormat::Preserve).index_fill_(dim, index, source);\n}\n\nTensor & gather_out_cpu(Tensor & result, const Tensor & self, int64_t dim, const Tensor & index, bool sparse_grad) {\n  result.resize_(index.sizes());\n  gather_stub(result.device().type(), result, self, dim, index);\n  return result;\n}\n\nTensor gather_cpu(const Tensor & self, int64_t dim, const Tensor & index, bool sparse_grad) {\n  Tensor result = at::empty({0}, self.options());\n  return gather_out_cpu(result, self, dim, index, sparse_grad);\n}\n\nTensor & scatter_(Tensor & self, int64_t dim, const Tensor & index, const Tensor & src) {\n  scatter_stub(self.device().type(), self, dim, index, src);\n  return self;\n}\n\nTensor & scatter_fill_(Tensor & self, int64_t dim, const Tensor & index, Scalar src) {\n  scatter_fill_stub(self.device().type(), self, dim, index, src);\n  return self;\n}\n\nTensor scatter(const Tensor & self, int64_t dim, const Tensor & index, const Tensor & source) {\n  return self.clone(at::MemoryFormat::Preserve).scatter_(dim, index, source);\n}\n\nTensor scatter(const Tensor & self, int64_t dim, const Tensor & index, Scalar source) {\n  return self.clone(at::MemoryFormat::Preserve).scatter_(dim, index, source);\n}\n\nTensor & scatter_add_cpu_(Tensor & self, int64_t dim, const Tensor & index, const Tensor & src) {\n  scatter_add_stub(self.device().type(), self, dim, index, src);\n  return self;\n}\n\nTensor scatter_add(const Tensor & self, int64_t dim, const Tensor & index, const Tensor & source) {\n  return self.clone(at::MemoryFormat::Preserve).scatter_add_(dim, index, source);\n}\n\nTensor masked_scatter(const Tensor & self, const Tensor & mask, const Tensor & source) {\n  Tensor _mask, _self;\n  std::tie(_mask, _self) = expand_outplace(mask, self);\n  return _self.clone(at::MemoryFormat::Contiguous).masked_scatter_(_mask, source);\n}"
},
{
    "Id": 165,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/5e50993be72bec4ad939993328dd02691ef7777d",
    "Violation": "missing",
    "Bug report": "Better type checking for pack_padded_sequence symbolic",
    "Number of deleted lines": 0,
    "Deleted lines": "    # optimization pass to remove this later. It is an error if all\n    # PackPadded operators cannot be optimized out.\n\n    def _onnx_symbolic_pack_padded_sequence(g, input, lengths):\n        if batch_first:\n            input = g.op('Transpose', input, perm_i=[1, 0, 2])\n        return g.op(\"prim::PackPadded\", input, lengths, outputs=2)\n\n    def pack_padded_sequence_trace_wrapper(input, lengths):\n        return pack_padded_sequence(input, lengths, batch_first=batch_first)\n\n    outputs = g.wrapPyFuncWithSymbolic(\n        pack_padded_sequence_trace_wrapper, [input, lengths], 2,\n        _onnx_symbolic_pack_padded_sequence)"
},
{
    "Id": 166,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/df475aa1dc4310abc273cf26b14b6ac1cdb7dfa4",
    "Violation": "missing",
    "Bug report": "Update Vulkan runner in benchmark binary to handle non-tensor inputs. Some models may take in a list of tensors as inputs, thus the bundled inputs will contain `IValues` that are of the type `c10::List`. For Vulkan models, every tensor in the `IValue` list has to be converted to a vulkan tensor first, and this case is not currently handled by the Vulkan model wrapper in the benchmark binary. This diff introduces `IValue` type checking to the input processor of the Vulkan model wrapper, and adds support for Tensor and List types.",
    "Number of deleted lines": 1,
    "Deleted lines": "      T& module,\n      const std::vector<c10::IValue>& inputs) override {\n    // Upload the input tensor(s) to GPU memory.\n    inputs_.clear();\n    inputs_.reserve(inputs.size());\n    for (const auto& input : inputs) {\n      inputs_.emplace_back(input.toTensor().vulkan());\n    }\n\n    // Run, and download the output tensor to system memory.\n    return module.forward(inputs_).toTensor().cpu();\n  }\n\n private:\n  std::vector<c10::IValue> inputs_;"
},
{
    "Id": 167,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/e31038d574712d383fdc4c2f1bb63fc82f256ed0",
    "Violation": "missing",
    "Bug report": "Check results dtype in index_out. This logic exists for index_put and index_add, but for some reason not for `index.out` Skip testing, as this function is not technically exposed on the Python level.",
    "Number of deleted lines": 0,
    "Deleted lines": "  // See: https://github.com/pytorch/pytorch/pull/69607\n  check_indices_on_cpu_or_selfdevice(self, materialized);\n\n  const auto& result = maybe_get_output();\n\n  if (result.defined()) {\n    at::assert_no_internal_overlap(result);\n    at::assert_no_overlap(result, self);\n    for (const at::OptionalTensorRef& index : materialized) {\n      if (index.has_value()) {\n        at::assert_no_overlap(result, *index);\n      }\n    }\n  }"
},
{
    "Id": 168,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/a69f427f957a37eee9c1dd5df681f30ab38ed3e4",
    "Violation": "improper",
    "Bug report": "aten: Ensure dim is size_t",
    "Number of deleted lines": 1,
    "Deleted lines": "    const IntArrayRef output_size,\n    bool implicit = false) {\n  TORCH_CHECK(\n      self.dim() > 0 && self.dim() <= 4,\n      \"Vulkan expand supports up to 4d tensors\");\n  TORCH_CHECK(\n      self.dim() <= output_size.size(),\n      \"Vulkan expand: the number of sizes provided (\",\n      output_size.size(),\n      \") must be greater or equal to the number of dimensions in the tensor (\",\n      self.dim(),\n      \").\");\n\n  std::vector<int64_t> repeat_size = std::vector<int64_t>(output_size.size());\n  std::vector<int64_t> input_size = self.sizes().vec();"
},
{
    "Id": 169,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/8340762211e3b55caa178bac748bd902249f6fc0",
    "Violation": "missing",
    "Bug report": "Update lr_scheduler.py to check the type of eta_min. Add float assertion to `eta_min` parameter in `CosineAnnealingWarmRestarts`.",
    "Number of deleted lines": 0,
    "Deleted lines": "\n    def __init__(self, optimizer, T_0, T_mult=1, eta_min=0, last_epoch=-1, verbose=False):\n        if T_0 <= 0 or not isinstance(T_0, int):\n            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n        if T_mult < 1 or not isinstance(T_mult, int):\n            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n        self.T_0 = T_0\n        self.T_i = T_0\n        self.T_mult = T_mult\n        self.eta_min = eta_min\n        self.T_cur = last_epoch\n        super().__init__(optimizer, last_epoch, verbose)\n\n    def get_lr(self):"
},
{
    "Id": 170,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/ae55619a2bb73ebcdc80b02a6ccd72275a9ce23e",
    "Violation": "missing",
    "Bug report": "Add check for same dtype in tensordot implementation",
    "Number of deleted lines": 0,
    "Deleted lines": "}\n\n// implements tensordot, a matrix-multiplication-like contraction, but the dimensions given\n// in the two dimension lists\nTensor tensordot(const Tensor& input1, const Tensor& input2, IntArrayRef dims1, IntArrayRef dims2) {\n  TORCH_CHECK(dims1.size() == dims2.size(), \"both dimension lists should have same length\");\n  int64_t csize = 1;  // total size of the contracted dimensions\n  Tensor t1 = input1;\n  Tensor t2 = input2;\n  for (const auto i : c10::irange(dims1.size())) {\n    int s1 = input1.size(dims1[i]);\n    int s2 = input2.size(dims2[i]);\n    if (s2 == 1) { // broadcasted dimensions can be summed right away\n      t1 = t1.sum(dims1[i], true);"
},
{
    "Id": 171,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/b6920405da340bbd3397b80bf16d9c360b0c48d2",
    "Violation": "improper",
    "Bug report": "reorder checks to shave 1 us off no-op dispatch time ",
    "Number of deleted lines": 5,
    "Deleted lines": "static const char* VOLATILE_WARNING =\n    \"volatile was removed and now has no effect. Use \"\n    \"`with torch.no_grad():` instead.\";\n\nstatic bool check_has_torch_dispatch(PyObject *obj) {\n  PyTypeObject *tp = Py_TYPE(obj);\n  py::object attr = PyObject_FastGetAttrString(obj, \"__torch_dispatch__\");\n  return (\n    !THPVariable_CheckTypeExact(tp) &&\n    // TODO: test if Python key is disabled\n    attr.ptr() != nullptr &&\n    attr.ptr() != torch::disabled_torch_dispatch_impl()\n  );\n}\n\n// NOLINTNEXTLINE\nstatic PyObject* device_to_py_class_ [static_cast<size_t>(c10::DeviceType::COMPILE_TIME_MAX_DEVICE_TYPES)];\n\nvoid registerPythonTensorClass(const std::string& device, PyObject* python_tensor_class) {\n  c10::Device dev(device);"
},
{
    "Id": 172,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/18eeccc7e8cba16d71efdd2eca831983c4abde15",
    "Violation": "missing",
    "Bug report": "Fix Optional type check",
    "Number of deleted lines": 0,
    "Deleted lines": "\n        if self.network.has_implicit_batch_dimension:\n            if has_batch_dim:\n                shape = shape[1:]\n        else:\n            for i, shape_range in enumerate(shape_ranges):\n                self.optimization_profiles[i].set_shape(target, *shape_range)\n\n        return self.network.add_input(name=target, shape=tuple(shape), dtype=torch_dtype_to_trt(dtype))\n\n    def call_module(self, target, args, kwargs):\n        assert isinstance(target, str)\n        submod = self.fetch_attr(target)\n        converter = CONVERTERS.get(type(submod))"
},
{
    "Id": 173,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/4dad00b64b396ef81f16bdb896175688fc629f4d",
    "Violation": "missing",
    "Bug report": "special case tensor type check when getting RRef ",
    "Number of deleted lines": 1,
    "Deleted lines": "    const RRefForkData& rrefForkData,\n    const TypePtr& type) {\n  auto& ownerId = rrefForkData.ownerId_;\n  auto& rrefId = rrefForkData.rrefId_;\n  auto& forkId = rrefForkData.forkId_;\n  if (ownerId == getWorkerId()) {\n    auto ownerRRef = getOwnerRRef(rrefId);\n    TORCH_INTERNAL_ASSERT(ownerRRef->type() == type);\n    return ownerRRef;\n  } else {\n    return createUserRRef(ownerId, rrefId, forkId, type);\n  }\n}\n\nc10::intrusive_ptr<OwnerRRef> RRefContext::getOrCreateOwnerRRef(\n    const RRefId& rrefId,"
},
{
    "Id": 174,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/4cc6e6bbbe1fb114e7d7fb207ef2deb567950102",
    "Violation": "missing",
    "Bug report": "Adding scalar to the c10 registration type check",
    "Number of deleted lines": 0,
    "Deleted lines": "            AT_ASSERT(iter->isBool());\n            tracer::addInputs(node, args[i].name().c_str(), iter->toBool());\n          } else if (type->kind() == TypeKind::StringType) {\n            AT_ASSERT(iter->isString());\n            tracer::addInputs(\n                node, args[i].name().c_str(), iter->toStringRef());\n          } else if (type->kind() == TypeKind::ListType) {\n            const auto& elem_type = type->expect<ListType>()->getElementType();\n            if (elem_type->isSubtypeOf(TensorType::get())) {\n              AT_ASSERT(iter->isTensorList());\n              auto list = iter->toTensorVector();\n              tracer::addInputs(node, args[i].name().c_str(), list);\n            } else if (elem_type->kind() == TypeKind::FloatType) {\n              AT_ASSERT(iter->isDoubleList());"
},
{
    "Id": 175,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/4b1ebd2f65e49d251ac2cfdb635794c7c6eb362f",
    "Violation": "missing",
    "Bug report": "Fast path for serializing large floating-point tensors to protobuf. Summary: Our existing serialization routines take a significant amount of time for large numpy arrays in order to verify the type of each element in the array as well as converting each element to a canonical type.  For large floating-point tensors, such as model parameters, this checking and converting takes a significant amount of time.  Adding a fast track path for just float32 arrays as this is the most common use case to worry about.",
    "Number of deleted lines": 0,
    "Deleted lines": "def MakeArgument(key, value):\n    \"\"\"Makes an argument based on the value type.\"\"\"\n    argument = caffe2_pb2.Argument()\n    argument.name = key\n    iterable = isinstance(value, collections.Iterable)\n\n    if isinstance(value, np.ndarray):\n        value = value.flatten().tolist()\n    elif isinstance(value, np.generic):\n        # convert numpy scalar to native python type\n        value = np.asscalar(value)\n\n    if type(value) is float:\n        argument.f = value"
},
{
    "Id": 176,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/65dfe1203ffab064d4e32fa8f76833042369d2f5",
    "Violation": "missing",
    "Bug report": "add an assertion to check the param num. Introduce this check to see whether it will break any existing workflow",
    "Number of deleted lines": 0,
    "Deleted lines": "        output_tensors, _ = torch._C._jit_flatten(torch_out)\n        for output, tensor in zip(graph.outputs(), output_tensors):\n            output.inferTypeFrom(tensor)\n\n    _set_input_and_output_names(graph, input_names, output_names)\n\n    input_and_param_names = [val.uniqueName() for val in graph.inputs()]\n    param_names = input_and_param_names[len(input_and_param_names) - len(params):]\n    params_dict = dict(zip(param_names, params))\n\n    if verbose:\n        print(graph)\n\n    return graph, params_dict, torch_out"
},
{
    "Id": 177,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/4fd98dfe69287914fd29b38fbccaf7ac4d7261ee",
    "Violation": "unnecessary",
    "Bug report": "Don't only apply DDP optimizer on forward frames. Previously a check would only apply DDP optimizer on frames named \"forward\".",
    "Number of deleted lines": 1,
    "Deleted lines": "                and frame.f_code.co_name == \"__new__\"\n            ):\n                # nametuple constructor\n                return None\n            if config.optimize_ddp:\n                ddp_module = DistributedDataParallel._get_active_ddp_module()\n                if ddp_module and frame.f_code.co_name == \"forward\":\n                    with compile_lock:\n                        ddp_optimizer = DDPOptimizer(\n                            bucket_bytes_cap=ddp_module.bucket_bytes_cap,\n                            parameters_to_ignore=ddp_module.parameters_to_ignore,\n                            backend_compile_fn=callback._torchdynamo_orig_callable,\n                        )\n                        hijacked_callback = convert_frame.convert_frame(\n                            ddp_optimizer.compile_fn, guard_export_fn=None"
},
{
    "Id": 178,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/8a644f0c136cb12cf200050c2ae6875ec487d174",
    "Violation": "improper",
    "Bug report": "Summary: Sometimes first dim of X in FC is BATCH_OF_FEATURE_MAX instead of BATCH. This caused an issue in f207899183 (when first dim of X is 64 but is set to 1 in inferFC). Change the check from `!= BATCH` to `== UNKNOWN`",
    "Number of deleted lines": 1,
    "Deleted lines": "    }\n    // Note: for FbFCPacked, weight is fp16 but activations are in fp32\n    CheckAndSetTensorBoundShape(\n        op.input(0), dimTypes, dims, w_data_type, int8_fc ? true : false);\n  } else {\n    ShapeInfo& x_shape_info = x_it->second;\n    if (x_shape_info.getDimType(0) != TensorBoundShape_DimType_BATCH) {\n      CAFFE_ENFORCE_GE(x_shape_info.shape.dims_size(), 1);\n      x_shape_info.shape.set_dims(0, spec_.max_batch_size);\n      x_shape_info.setDimType(0, TensorBoundShape_DimType_BATCH);\n    }\n  }\n\n  // Standard shape inference for outputs\n  std::vector<TensorShape> input_shapes{"
},
{
    "Id": 179,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/5023995292f5119c447de15c20a375b7e3aa2d0b",
    "Violation": "improper",
    "Bug report": " fix output size adjustment for onnxifi_op. Summary: this breaks if we cut the net at certain int8 ops boundary.",
    "Number of deleted lines": 1,
    "Deleted lines": "          \" (\",\n          max_shape[j],\n          \" vs \",\n          real_shape.dims(j),\n          \")\");\n      begin_ptr[j] = 0;\n      if (max_shape[j] > real_shape.dims(j)) {\n        end_ptr[j] = real_shape.dims(j);\n        mismatch += j;\n      } else {\n        end_ptr[j] = -1;\n      }\n    }\n    output_reshape_info.fast_path[i] = !mismatch;\n  }"
},
{
    "Id": 180,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/a1edf5f63c62d88230d1f7feb26edb059551ae71",
    "Violation": "improper",
    "Bug report": "Do hook sizes check with SymInt. I don't think this matters for any uses right now, but I found it during an audit; might as well fix it.",
    "Number of deleted lines": 1,
    "Deleted lines": "    } else {\n      ss << \" (was CPU tensor got CUDA tensor)\";\n    }\n    throw std::runtime_error(ss.str());\n  }\n\n  if (original.sizes().vec() != result.sizes().vec()) {\n    std::stringstream ss;\n    ss << \"hook '\" << hook_name << \"' has changed the size of value\";\n    throw std::runtime_error(ss.str());\n  }\n}\n\nvoid AutogradContext::save_for_backward(variable_list to_save) {\n  to_save_ = std::move(to_save);"
},
{
    "Id": 181,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/f6e137598ddf0b990c423b1d6412502b62e095b2",
    "Violation": "unnecessary",
    "Bug report": "ns for fx: fix nit in default qlinear weight extraction function. Removes the assert for node type in default qlinear weight extraction function. Without the assert, user defined functions can now use this util function without failing this check.",
    "Number of deleted lines": 1,
    "Deleted lines": "    else:\n        assert linear_second_arg.op == 'get_attr'\n        weight = getattr_from_fqn(gm, linear_second_arg.target)  # type: ignore[arg-type]\n        return weight.detach()\n\ndef get_qlinear_fun_weight(node: Node, gm: GraphModule) -> torch.Tensor:\n    assert node.target in (toq.linear, toq.linear_relu)\n    # packed weight is arg 1\n    packed_weight_node = node.args[1]\n    assert isinstance(packed_weight_node, Node)\n    assert packed_weight_node.op == 'get_attr'\n    packed_weight = getattr_from_fqn(gm, packed_weight_node.target)  # type: ignore[arg-type]\n    # TODO(future PR): why does packed_weight.unpack() not work?\n    (weight, _bias), _name = packed_weight.__getstate__()\n    return weight"
},
{
    "Id": 182,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/5a20c56ebce3426397210e91693fbbeade8b46ba",
    "Violation": "unnecessary",
    "Bug report": "emove hasOperation() check. by removing the hasOperation() check, the Operation gets successfully materialized, and static runtime enables successfully and runs ok. Will check that the outputs match with jit interpreter",
    "Number of deleted lines": 1,
    "Deleted lines": "  if (!fn_ && (native_fn_ = getNativeOperation(node))) {\n    VLOG(1) << \"Switch to native impl for node: \" << PrintNode(node);\n    return;\n  }\n  {\n    const Operator& op = node->getOperator();\n    TORCH_CHECK(op.hasOperation());\n    op_ = op.getOperation(node);\n    VLOG(1) << \"Fallback interpreter for node: \" << PrintNode(node);\n  }\n}\n\nvoid ProcessedNode::run() {\n  if (fn_) {\n    fn_(this);"
},
{
    "Id": 183,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/012829eb3657aff2d58cead0bd166089c6e90c7f",
    "Violation": "unnecessary",
    "Bug report": "Do not crash when target device is unsupported by fuser. The `canFuseOnDevice` function now crashes when the device is not covered (i.e., CPU, GPU, XPU). However, now we have some devices, such as XLA and Lazy, that could perform fusion by themselves. This checker then prevents these devices from working on the models partially implemented in `jit.script`. This PR proposes to remove this checker and simply return false for all uncovered cases.",
    "Number of deleted lines": 2,
    "Deleted lines": "    if (device->is_cpu()) {\n      return canFuseOnCPU();\n    } else if (device->is_cuda()) {\n      return canFuseOnGPU();\n    } else if (device->is_xpu()) {\n      return false;\n    } else {\n      TORCH_CHECK_NOT_IMPLEMENTED(false, \"Unknown device for tensorexpr fuser\")\n    }\n  }\n\n  bool isFusableOnDevice(Node* node) {\n    for (const auto& input : node->inputs()) {\n      if (input->node()->kind() == prim::ListConstruct) {\n        if (!isFusableOnDevice(input->node())) {\n          return false;\n        }"
},
{
    "Id": 184,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/f386312ec936a94bfb1abe44acdd61d498f4272b",
    "Violation": "improper",
    "Bug report": "Don't do extra numel() check in TensorImpl::data(). `is_empty()` checks `numel() == 0`, but we don't need to access `numel_` at all (or the policy that `numel()` checks) in our happy path -- we just need the data pointer from `storage_`. Let's do the check we need to do using only the data we strictly need, rather than adding instructions loading other pieces of data.",
    "Number of deleted lines": 4,
    "Deleted lines": "        dtype_initialized(),\n        \"Cannot access data pointer of Tensor that doesn't have initialized dtype \"\n        \"(e.g., caffe2::Tensor x(CPU), prior to calling mutable_data<T>() on x)\");\n    // Computing an offset into an empty tensor would be UB, since an empty\n    // tensor's storage will be nullptr, and adding a nonzero offset to nullptr\n    // is UB.  So we skip the offset computation in this case.\n    if (is_empty()) {\n      return nullptr;\n    }\n    return static_cast<void*>(\n        static_cast<char*>(storage_.data()) +\n        data_type_.itemsize() * storage_offset_);\n  }\n\n  /**\n   * Like data<T>(), but performs no checks.  You are responsible for ensuring\n   * that all invariants required by data() are upheld here.\n   */\n  template <typename T>\n  inline T* unsafe_data() const {"
},
{
    "Id": 185,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/fc304bec9f550075d4c899aa0fc5b1a0a573c1e5",
    "Violation": "unnecessary",
    "Bug report": "Remove redundant checks from canHandle in TE fuser",
    "Number of deleted lines": 3,
    "Deleted lines": "    if (node->output()->type()->cast<TensorType>()) {\n      // TODO: add support for tensor constants.\n      return false;\n    }\n    return true;\n  }\n  if (node->kind() == prim::Loop) {\n    return false; // TODO\n  }\n  if (!allShapesAreKnown(node)) {\n    return false;\n  }\n\n  // Don't include nodes whose inputs are tensor constants - we cannot handle\n  // them at the moment.\n  // TODO: actually support tensor constants and remove this.\n  for (torch::jit::Value* input : node->inputs()) {"
},
{
    "Id": 186,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/5b7c72101ca8e9d4edba1d16b6121ad900ca3936",
    "Violation": "unnecessary",
    "Bug report": "Removed check for is_quantized in dequantize_cpu_or_cuda. This particular PR isn't dispatcher related but does remove the extraneous torch check for a quant tensor since the dispatcher already handles a quantized backend for this particular function",
    "Number of deleted lines": 1,
    "Deleted lines": "    ScalarType dtype) {\n  auto quantizer = make_per_channel_affine_quantizer(scales, zero_points, axis, dtype);\n  return quantizer->quantize(self);\n}\n\nTensor dequantize_cpu_or_cuda(const Tensor& self) {\n  TORCH_CHECK(!self.is_quantized());\n  return self.to(at::kFloat);\n}\n\nTensor dequantize_quantized(const Tensor& self) {\n  return get_qtensorimpl(self)->quantizer()->dequantize(self);\n}\n\nstd::vector<Tensor> dequantize_tensors_quantized_cpu(TensorList tensors) {"
},
{
    "Id": 187,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/2597d5d72272d196b4cb5442ffc8cde376d1f785",
    "Violation": "insufficient",
    "Bug report": " TorchDynamo: always convert flexiblelayout to be FixedLayout when given a stride_order. For convolution, we always call **require_stride_order** to convert the input to the target stride order,  if the original input's layout is flexiblelayout, there always have a memory copy because the **is_stride_order_storage_and_layout** only checks the init stride order,  I think for flexiblelayout, means it's layout can be changed, if the user gives a stride order, I think we always need to convert the flexiblelayout to be FixedLayout using given strider order.",
    "Number of deleted lines": 3,
    "Deleted lines": "    def require_stride_order(cls, x, order):\n        if x.get_numel() == 0:  # Layout doesn't matter\n            return x\n\n        # require x to have the layout as strided_ordered as order\n        if is_storage_and_layout(x):\n            if isinstance(\n                x.get_layout(), FlexibleLayout\n            ) and is_stride_order_storage_and_layout(x, order):\n                # fix flexiblelayout to be FixedLayout with stride_order\n                as_storage_and_layout(\n                    x, freeze=True, want_contiguous=False, stride_order=order\n                )\n                return x\n            elif isinstance(\n                x.get_layout(), FixedLayout\n            ) and x.get_layout().is_stride_ordered(order):"
},
{
    "Id": 188,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/201f7d330ac8c33a7bedb8f0a66954415d1d27db",
    "Violation": "unnecessary",
    "Bug report": "Remove duplicate check in distributions arg validation ",
    "Number of deleted lines": 2,
    "Deleted lines": "                        f\"Expected parameter {param} \"\n                        f\"({type(value).__name__} of shape {tuple(value.shape)}) \"\n                        f\"of distribution {repr(self)} \"\n                        f\"to satisfy the constraint {repr(constraint)}, \"\n                        f\"but found invalid values:\\n{value}\"\n                    )\n                if not constraint.check(getattr(self, param)).all():\n                    raise ValueError(\"The parameter {} has invalid values\".format(param))\n        super(Distribution, self).__init__()\n\n    def expand(self, batch_shape, _instance=None):\n        \"\"\"\n        Returns a new distribution instance (or populates an existing instance\n        provided by a derived class) with batch dimensions expanded to\n        `batch_shape`. This method calls :class:`~torch.Tensor.expand` on\n        the distribution's parameters. As such, this does not allocate new"
},
{
    "Id": 189,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/a47cc18254ade6dee1fe4a3c4eb5aca7ba40c77c",
    "Violation": "unnecessary",
    "Bug report": "remove unnecessary tuple check on tensor types",
    "Number of deleted lines": 1,
    "Deleted lines": "            return list(self.__args__) == list(other.__args__)\n        else:\n            return False\n\n    @staticmethod\n    def __class_getitem__(*args):\n        assert isinstance(args[0], tuple)\n        return TensorType(args[0])\n\n\nclass _DynType:\n    \"\"\"\n    _DynType defines a type which stands for the absence of type information.\n    \"\"\"\n    def __init__(self):"
},
{
    "Id": 190,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/2512017814fb2e3d6f3ae9dd3b315692ffc8fc71",
    "Violation": "unnecessary",
    "Bug report": "Fix for out of bounds read in torch mobile flatbuffer loader ",
    "Number of deleted lines": 2,
    "Deleted lines": "mobile::Module parse_and_initialize_mobile_module(\n    void* data,\n    size_t size,\n    c10::optional<at::Device>,\n    ExtraFilesMap* extra_files,\n    bool should_copy_tensor_memory) {\n  TORCH_CHECK(\n      mobile::serialization::ModuleBufferHasIdentifier(data), \"Format error\");\n  // TODO(T128189662): If not copying, enforce that data is aligned to\n  // kFlatbufferDataAlignmentBytes, and add unit tests.\n\n  // Validate Flatbuffer module before parsing.\n  flatbuffers::Verifier verifier(reinterpret_cast<uint8_t*>(data), size);\n  TORCH_CHECK(\n      mobile::serialization::VerifyModuleBuffer(verifier),\n      \"Malformed Flatbuffer module\");"
},
{
    "Id": 191,
    "Library": "pytorch",
    "Commit Link": "https://github.com/pytorch/pytorch/commit/e7fc7c732cbde822f9490840704b1f57fe86c50a",
    "Violation": "insufficient",
    "Bug report": "Bugfix for fusion device check",
    "Number of deleted lines": 1,
    "Deleted lines": "\n  void refreshAliasDb() {\n    aliasDb_ = torch::make_unique<AliasDb>(graph_);\n  }\n\n  bool canFuseWithConcat(Value* producer, Node* before_check) {\n    if (!isFusable(producer->node())) {\n      return false;\n    }\n    // NB: it is important that this check happens after isFusable, which checks\n    // that the blocks match, and it's not a special node like prim::Param\n    if (!aliasDb_->couldMoveBeforeTopologically(\n            producer->node(), before_check)) {\n      return false;\n    }"
},
{
    "Id": 192,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/4a343043dbc6ce229b4dcf2258f7b6352db32b64",
    "Violation": "improper",
    "Bug report": "Fix hasattr check in saved_model_cli ",
    "Number of deleted lines": 2,
    "Deleted lines": "  return parser\n\n\ndef main():\n  parser = create_parser()\n  args = parser.parse_args()\n  if not hasattr(args.func):\n    parser.error(\"too few arguments\")\n  args.func(args)\n\n\nif __name__ == '__main__':\n  sys.exit(main())\n"
},
{
    "Id": 193,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/73f25fc34c69878c83ee2eeb8f030cb79a76472f",
    "Violation": "insufficient",
    "Bug report": "This fix tries to address the issue by adding an `hasattr()` check so that AttributeError is not thrown.",
    "Number of deleted lines": 1,
    "Deleted lines": "  visited_symbols = set()\n\n  # Traverse over everything imported above. Specifically,\n  # we want to traverse over TensorFlow Python modules.\n  for module in sys.modules.values():\n    # Only look at tensorflow modules.\n    if not module or 'tensorflow.' not in module.__name__:\n      continue\n    # Do not generate __init__.py files for contrib modules for now.\n    if '.contrib.' in module.__name__ or module.__name__.endswith('.contrib'):\n      continue\n\n    for module_contents_name in dir(module):\n      attr = getattr(module, module_contents_name)\n      if id(attr) in visited_symbols:"
},
{
    "Id": 194,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/cdc36a3b1f7d227984bb5e415b555ed334737f82",
    "Violation": "missing",
    "Bug report": "cosmetic fix to MonitoredSession.__del__ AttributeError. This CL prevents this message by checking that the underlying _sess object has the __del__ method defined before calling it.",
    "Number of deleted lines": 1,
    "Deleted lines": "\n  def __exit__(self, exec_type, exec_value, exec_tb):\n    self._default_session_context_manager.__exit__(\n        exec_type, exec_value, exec_tb)\n\n  def __del__(self):\n    self._sess.__del__()\n\n  def close(self):\n    self._sess.close()\n\n  # TODO(cais): Add _node_name_regex_whitelist and\n  #   _node_op_type_regex_whitelist.\n\n  @abc.abstractmethod"
},
{
    "Id": 195,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/67b6c880e39ba02ba53c7d499e45fd136090ee32",
    "Violation": "missing",
    "Bug report": " In tf.map_fn: skip sanity check for shape of first value in elems if it doesn't have a shape attribute. (E.g., this can happen if it's a CompsiteTensor.)",
    "Number of deleted lines": 4,
    "Deleted lines": "    elems_flat = [\n        ops.convert_to_tensor_or_composite(t, name=\"elem\") for t in elems_flat\n    ]\n\n    # Check that inputs are not scalars.\n    first_elem = elems_flat[0]\n    elems_static_shape = first_elem.shape\n    if elems_static_shape.ndims is not None and elems_static_shape.ndims < 1:\n      raise ValueError(\n          \"Elements in elems must be 1+ dimensional Tensors, not scalars\")\n\n    # Box any composite tensors into tensor lists.\n    elems_batchable = _elems_flat_to_batchable(elems_flat)\n\n    # Find the number of iterations, n.  (may be known statically.)\n    n_static = tensor_shape.Dimension(\n        tensor_shape.dimension_value(\n            elems_batchable[0].get_shape().with_rank_at_least(1)[0]))"
},
{
    "Id": 196,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/dcdca11bcbab4b2474e7bf4d21d1806e6c2790a3",
    "Violation": "insufficient",
    "Bug report": " Check both output name and output slot in duplicate scope id sanity check. Before this change, we would throw an error if different outputs of a node were committed to different scope ids.  Since that is legal, this change fixes the bug by making the check based on both output name and output index.",
    "Number of deleted lines": 1,
    "Deleted lines": "  Status CheckExistingScopedAllocator(const std::vector<InputDesc>& inputs) {\n    for (const InputDesc& nd : inputs) {\n      VLOG(2) << \"get attrs for \" << nd.from_node_def->name();\n      AttrSlice n_attrs = AttrSlice(*nd.from_node_def);\n      std::vector<int32> scope_ids;\n      Status ss = GetNodeAttr(n_attrs, kScopedAllocatorAttrName, &scope_ids);\n      if (ss.ok()) {\n        LOG(INFO) << \"Abandoning ScopedAllocatorOptimizer because input \"\n                  << nd.from_node_def->name() << \" output \" << scope_ids[0]\n                  << \" is already assigned to scope_id \" << scope_ids[1];\n        return errors::Internal(\n            \"Abandoning ScopedAllocatorOptimizer because input \",\n            nd.from_node_def->name(), \" output \", scope_ids[0], \" is already \",\n            \"assigned to scope_id \", scope_ids[1]);\n      }"
},
{
    "Id": 197,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a607eb012b1bc4f6dbe263ad99caa76d84ae3ab2",
    "Violation": "insufficient",
    "Bug report": "fix output shape check for strided slice always failing when stride != 1 ",
    "Number of deleted lines": 3,
    "Deleted lines": "      RETURN_IF_ERROR(\n          ReadAttribsWithBatch(reader, tf_options, input->tensor.shape, &attr));\n    }\n    if (attr.strides.h < 0 || attr.strides.w < 0 || attr.strides.c < 0) {\n      return UnimplementedError(\"Reverse slices are not supported.\");\n    }\n    if (attr.ends.h - attr.starts.h != out_shape.h) {\n      return UnimplementedError(\"Output height doesn't match\");\n    }\n    if (attr.ends.w - attr.starts.w != out_shape.w) {\n      return UnimplementedError(\"Output width doesn't match\");\n    }\n    if (attr.ends.c - attr.starts.c != out_shape.c) {\n      return UnimplementedError(\"Output channels don't match\");\n    }\n    node->operation.attributes = attr;\n    return OkStatus();\n  }\n\n private:\n  Status UpdateWithMask(const TfLiteStridedSliceParams* tf_options,"
},
{
    "Id": 198,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/2bf2799ee80791107d4fe587ff9b6c7cf6c8b418",
    "Violation": "missing",
    "Bug report": "Fail gracefully if the serialized graph would be too large. Without this explicit check, a large graph would trigger an assertion failure in the protobuf codebase",
    "Number of deleted lines": 1,
    "Deleted lines": "  void* buf = tensorflow::port::Malloc(proto_size);\n  if (buf == nullptr) {\n    return tensorflow::errors::ResourceExhausted(\n        \"Failed to allocate memory to serialize message of type '\",\n        in.GetTypeName(), \"' and size \", proto_size);\n  }\n  in.SerializeToArray(buf, proto_size);\n  out->data = buf;\n  out->length = proto_size;\n  out->data_deallocator = [](void* data, size_t length) {\n    tensorflow::port::Free(data);\n  };\n  return Status::OK();\n}\n"
},
{
    "Id": 199,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/0197a2d8a3070af763cb67227835ee63df095e6d",
    "Violation": "missing",
    "Bug report": " Add a check to catch out-of-bound access on invalid Graphs. The existing Check trying to catch malformed graph is not robust when an op is registered with an expected number of inputs but has data edges beyond this.",
    "Number of deleted lines": 0,
    "Deleted lines": "    inputs.clear();\n    inputs.resize(node->num_inputs(), nullptr);\n    for (const Edge* edge : node->in_edges()) {\n      if (edge->IsControlEdge()) {\n        inputs.push_back(edge);\n      } else {\n        CHECK(inputs[edge->dst_input()] == nullptr)\n            << \"Edge \" << edge->src()->DebugString() << \":\"\n            << edge->dst()->DebugString() << \" with dst_input \"\n            << edge->dst_input() << \" and had pre-existing input edge \"\n            << inputs[edge->dst_input()]->src()->DebugString() << \":\"\n            << inputs[edge->dst_input()]->dst()->DebugString();\n\n        inputs[edge->dst_input()] = edge;"
},
{
    "Id": 200,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/314d9cd9b607460f8bfea80fc828b1521ca18443",
    "Violation": "missing",
    "Bug report": "Fix segfault in MacOS when GPU is not available ",
    "Number of deleted lines": 1,
    "Deleted lines": "  CFRelease(kext_id_query);\n\n  CFDictionaryRef cuda_driver_info = nullptr;\n  if (CFDictionaryGetValueIfPresent(kext_infos, kDriverKextIdentifier, (const void**)&cuda_driver_info)) {\n    // NOTE: OSX CUDA driver does not currently store the same driver version\n    // in kCFBundleVersionKey as is returned by cuDriverGetVersion\n    const char * version = CFStringGetCStringPtr((CFStringRef)CFDictionaryGetValue(cuda_driver_info, kCFBundleVersionKey), kCFStringEncodingUTF8);\n    CFRelease(kext_infos);\n    return StringToDriverVersion(version);\n  }\n  CFRelease(kext_infos);\n  auto status =\n    port::Status{port::error::INTERNAL,\n                 port::StrCat(\"failed to read driver bundle version: \",\n                              CFStringGetCStringPtr(kDriverKextIdentifier, kCFStringEncodingUTF8))\n    };"
},
{
    "Id": 201,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/abd645085b1dd1496df847b05a1934d471a2f2c0",
    "Violation": "missing",
    "Bug report": " Use the correct device ordinal to check whether the device the executable was built for is equivalent to the device the it will run on. Before this patch, if the device to run on was provided via a stream without setting the device ordinal in the ExecutableRunOptions, we would check the default device against the device the executable was built for.",
    "Number of deleted lines": 5,
    "Deleted lines": "      return InvalidArgument(\n          \"cannot set both device ordinal and stream options in \"\n          \"ExecutableRunOptions; the stream determines the device ordinal\");\n    }\n  }\n\n  // Verify that the device the executable was built for is equivalent to the\n  // device it will run on.\n  int run_device_ordinal = run_options.device_ordinal() == -1\n                               ? backend_->default_device_ordinal()\n                               : run_options.device_ordinal();\n  TF_ASSIGN_OR_RETURN(bool devices_equivalent,\n                      backend_->devices_equivalent(\n                          run_device_ordinal, build_options_.device_ordinal()));\n  if (!devices_equivalent) {\n    TF_ASSIGN_OR_RETURN(se::StreamExecutor * run_executor,\n                        backend_->stream_executor(run_device_ordinal));\n    TF_ASSIGN_OR_RETURN(se::StreamExecutor * build_executor,\n                        backend_->stream_executor(build_device_ordinal()));"
},
{
    "Id": 202,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/083fd8c4b23104f6b27a871c6469629ace4ee9c3",
    "Violation": "insufficient",
    "Bug report": " Don't check soname on Windows. This allow users to specify a certain CUDA version on Windows again.",
    "Number of deleted lines": 1,
    "Deleted lines": "    \"\"\"\n    objdump = repository_ctx.which(\"objdump\")\n    mismatches = []\n    for path in [repository_ctx.path(path) for path in paths]:\n        if not path.exists:\n            continue\n        if check_soname and objdump != None:\n            output = repository_ctx.execute([objdump, \"-p\", str(path)]).stdout\n            output = [line for line in output.splitlines() if \"SONAME\" in line]\n            sonames = [line.strip().split(\" \")[-1] for line in output]\n            if not any([soname == path.basename for soname in sonames]):\n                mismatches.append(str(path))\n                continue\n        return path\n    if mismatches:"
},
{
    "Id": 203,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/867a918bd3d40afeca6b96430671a098134e7905",
    "Violation": "missing",
    "Bug report": " CUDA Driver: do better error reporting if checking the pointer properties failed. There are many reasons why an operation can fail, propagate the error instead of assuming the cause.",
    "Number of deleted lines": 0,
    "Deleted lines": "template <typename PtrT>\nvoid CheckPointerIsValid(const PtrT ptr, absl::string_view name) {\n  bool is_host_ptr = !std::is_same<PtrT, CUdeviceptr>::value;\n  cudaPointerAttributes attributes;\n  cudaError_t err =\n      cudaPointerGetAttributes(&attributes, reinterpret_cast<const void*>(ptr));\n  // If we failed, reset cuda error status to avoid poisoning cuda streams.\n  if (err != cudaSuccess) cudaGetLastError();\n  bool points_to_host_memory = (err == cudaErrorInvalidValue ||\n                                attributes.memoryType != cudaMemoryTypeDevice);\n  CHECK_EQ(is_host_ptr, points_to_host_memory) << absl::StreamFormat(\n      \"%s pointer is not actually on %s: %p\", name, is_host_ptr ? \"CPU\" : \"GPU\",\n      reinterpret_cast<const void*>(ptr));\n}"
},
{
    "Id": 204,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1a73fdfa83bd50695a7d374d14a5cb3835d94d9e",
    "Violation": "missing",
    "Bug report": " Add extra check incase segmenter does not exclude CPU in order to prevent segfault",
    "Number of deleted lines": 4,
    "Deleted lines": "  std::unordered_map<string, int> input_to_engine_port, output_to_engine_port;\n  for (auto it = reverse_topo_order.rbegin(); it != reverse_topo_order.rend();\n       ++it) {\n    const auto& node_name = (*it)->name();\n    if (segment_nodes.count(node_name) == 0) continue;\n    auto node = *it;\n    // TODO: check for CPU device here\n    // If device is CPU, we should've caught that in the segmenter. Fall back here.\n\n    auto node_device = node->requested_device();\n    if (!node_device.empty()) {\n      segment_devices.insert(node_device);\n    } else {\n      if (node->has_assigned_device_name()) {\n        segment_devices.insert(node->assigned_device_name());\n      } else {\n        VLOG(2) << \"Node \" << node->name()\n                << \" neither have requested device nor assigned device\";\n      }\n    }"
},
{
    "Id": 205,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/b234ff0ee4ce87d21a3e5306b678e1fb4b1fedfc",
    "Violation": "missing",
    "Bug report": " Fixed division by zero, by checking the number of GPUs in GenericLayoutOptimizer.",
    "Number of deleted lines": 0,
    "Deleted lines": "    }\n    if (t_attr->type() == data_type) {\n      num_conv2d_gpu_fp16++;\n    }\n  }\n\n  return (static_cast<float>(num_conv2d_gpu_fp16) /\n          static_cast<float>(num_conv2d_gpu)) >= kConv2DGPUFP16Threshold;\n}\n\ninline std::pair<string, string> GetSrcAndDstDataFormats(\n    const TransposeContext& context, int num_gpus, int num_voltas) {\n  string src_format = kNHWC;\n  string dst_format = kNCHW;"
},
{
    "Id": 206,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9f8ad5ff118166537d42f87f1ee254f83ba553f0",
    "Violation": "improper",
    "Bug report": "Fix CUDA version check (format is 1000 * major + 10 * minor). ",
    "Number of deleted lines": 1,
    "Deleted lines": "    }                                                                         \\\n  } while (false)\n\nport::StatusOr<std::vector<uint8>> LinkGpuAsm(\n    gpu::GpuContext* context, std::vector<CubinOrPTXImage> images) {\n  const bool linking_supported = [] {\n    if (CUDA_VERSION < 11300) {\n      return true;\n    }\n    auto version_or_status = gpu::Diagnostician::FindKernelDriverVersion();\n    if (!version_or_status.ok()) {\n      LOG(WARNING) << \"Couldn't read CUDA driver version.\";\n      return false;\n    }\n    return std::get<0>(*version_or_status) >= 465;"
},
{
    "Id": 207,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/89334fb15c688e7dbd81878745755db01579ea70",
    "Violation": "missing",
    "Bug report": " [NVIDIA] Update VersionCheck APIs for CuDNN. This PR updates the cudnnXXXVersionCheck to the latest for the next CUDNN release.",
    "Number of deleted lines": 2,
    "Deleted lines": "\nenum class PreloadCudnnType { ConvFwd, ConvBwdFilter, ConvBwdData, Rnn };\n\n// Preload sub libs for cudnn 8.0.4+ to make sure that the loading time isn't\n// measured in the autotuning.\nvoid PreloadCudnnSubLibs(PreloadCudnnType type) {\n#if CUDNN_VERSION >= 8004\n  switch (type) {\n    case PreloadCudnnType::ConvBwdFilter:\n    case PreloadCudnnType::ConvBwdData: {\n      cudnnOpsTrainVersionCheck();\n      cudnnCnnTrainVersionCheck();\n      [[clang::fallthrough]];\n    }\n    case PreloadCudnnType::ConvFwd: {\n      cudnnOpsInferVersionCheck();\n      cudnnCnnInferVersionCheck();\n      break;\n    }\n    case PreloadCudnnType::Rnn: {\n      cudnnOpsInferVersionCheck();\n      cudnnAdvInferVersionCheck();\n      cudnnOpsTrainVersionCheck();\n      cudnnAdvTrainVersionCheck();\n      break;\n    }\n  }\n#endif  // CUDNN_VERSION >= 8004\n}\n\nvoid PreloadCudnnSubLibsHelper(dnn::ConvolutionKind kind) {\n  switch (kind) {\n    case dnn::ConvolutionKind::FORWARD:\n    case dnn::ConvolutionKind::FORWARD_GRAPH: {\n      PreloadCudnnSubLibs(PreloadCudnnType::ConvFwd);\n      break;"
},
{
    "Id": 208,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/e5cfbd0eceb4dca98b388b13acff499a5420f863",
    "Violation": "improper",
    "Bug report": "Fix more for cuda version check. ",
    "Number of deleted lines": 1,
    "Deleted lines": "  // for certain input parameters so as to avoid a bug in cuDNNv5 and cuDNNv6.\n  template <typename T>\n  bool ShouldIncludeWinogradNonfusedAlgo(\n      perftools::gputools::StreamExecutor* stream_exec) const {\n    // Skip this check for cuDNN 7 and newer.\n    auto version = stream_exec->AsDnn()->GetVersion();\n    if (version.ok() && std::get<0>(version.ValueOrDie()) >= 7) {\n      return true;\n    }\n    return ShouldIncludeWinogradNonfusedAlgoPreCudnn7<T>();\n  }\n\n protected:\n  using ParameterDataType =\n      std::tuple<int64, int64, SpatialArray, int64, SpatialArray, SpatialArray,"
},
{
    "Id": 209,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/e009644f034fa0ca4df910a812432cab3458d440",
    "Violation": "missing",
    "Bug report": "Add one error check in cuda_dnn for int8 to float convolution. ",
    "Number of deleted lines": 0,
    "Deleted lines": "                                           output_descriptor)) {\n      return port::Status(\n          port::error::FAILED_PRECONDITION,\n          \"This configuration has potential integer overflow in \"\n          \"cuDNNv5 and cuDNNv6. See b/68264959.\");\n    }\n    return port::Status::OK();\n  };\n\n  auto get_bwd_data_bugs = [&]() -> port::Status {\n    if (algorithm_desc.algo_id() ==\n            CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED &&\n        !ShouldIncludeWinogradNonfusedAlgo(input_descriptor,\n                                           output_descriptor)) {"
},
{
    "Id": 210,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/70ade1b64f65d0a2275672d27129627ff116a997",
    "Violation": "missing",
    "Bug report": " Fix defect: shuffle_batch gives ZeroDivisionError when computing capacity stat. * Fix defect: shuffle_batch gives ZeroDivisionError when computing capacity stat. * Cover < case in error checking",
    "Number of deleted lines": 0,
    "Deleted lines": "                   shapes=None, allow_smaller_final_batch=False,\n                   shared_name=None, name=None):\n  \"\"\"Helper function for `shuffle_batch` and `maybe_shuffle_batch`.\"\"\"\n  tensor_list = _as_tensor_list(tensors)\n  with ops.name_scope(name, \"shuffle_batch\",\n                      list(tensor_list) + [keep_input]) as name:\n    tensor_list = _validate(tensor_list)\n    keep_input = _validate_keep_input(keep_input, enqueue_many)\n    tensor_list, sparse_info = _store_sparse_tensors(\n        tensor_list, enqueue_many, keep_input)\n    types = _dtypes([tensor_list])\n    shapes = _shapes([tensor_list], shapes, enqueue_many)\n    queue = data_flow_ops.RandomShuffleQueue(\n        capacity=capacity, min_after_dequeue=min_after_dequeue, seed=seed,"
},
{
    "Id": 211,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a21ec782601aca6c7e0461093d72596f26229e44",
    "Violation": "improper",
    "Bug report": " Use getattr instead of isinstance in tensor_conversion_registry. Using `isinstance` to check if an object is an instance of a Python `typing.Protocol` instead of using `getattr`/`hasattr` has negative performance implications. This change reverts `tensor_conversion_registry.convert()` to use `getattr` for this reason.",
    "Number of deleted lines": 2,
    "Deleted lines": "\n  if dtype is not None:\n    dtype = dtypes.as_dtype(dtype)\n  if preferred_dtype is not None:\n    preferred_dtype = dtypes.as_dtype(preferred_dtype)\n\n  if isinstance(value, core.TensorProtocol):\n    return value.__tf_tensor__(dtype, name)\n\n  for base_type, conversion_func in get(type(value)):\n    # If dtype is None but preferred_dtype is not None, we try to\n    # cast to preferred_dtype first.\n    ret = None\n    if dtype is None and preferred_dtype is not None:\n      try:\n        ret = conversion_func("
},
{
    "Id": 212,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/e1ad3b74ad44b883c7b3fdc3a19adcea1d28bfbc",
    "Violation": "improper",
    "Bug report": " [XLA:GPU] Handle edge case in Triton Softmax rewriter where bitcast is an effective scalar. This short-circuit avoids crashing within last_dimension when attempting to match and either the operand or the result of the bitcast has a shape with rank 0.",
    "Number of deleted lines": 1,
    "Deleted lines": "                 HloOpcode opcode, const GpuVersion& gpu_version);\n\nbool BitcastIsTilingNoop(HloInstruction* bitcast,\n                         const GpuVersion& gpu_version) {\n  CHECK_EQ(bitcast->opcode(), HloOpcode::kBitcast);\n\n  if (bitcast->shape().rank() == 0) {\n    return true;\n  }\n\n  // In the Softmax rewriter for now, tiling is derived from a hero reduction\n  // operation, which should be reducing its input on the last axis. Therefore,\n  // a bitcast is always a no-op with regards to a tile if\n  //   (1) it does not change the size of the reduction dimension of its input\n  //       (the last one); if its input is already reduced, then (1) is true"
},
{
    "Id": 213,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/2f3b69e4976d3b14eaa6ae070eb68f37d1556d98",
    "Violation": "improper",
    "Bug report": "Changed empty check ",
    "Number of deleted lines": 3,
    "Deleted lines": "          and checkpointable._update_uid < self._checkpoint.restore_uid):  # pylint: disable=protected-access\n        raise AssertionError(\n            \"Object not assigned a value from checkpoint: %s\" % (node,))\n    for checkpointable_object in list_objects(self._root_checkpointable):\n      # Remove data structures that do not contain any variables from\n      # restoration checks.\n      if (isinstance(checkpointable_object,\n                     data_structures.CheckpointableDataStructure) and\n              len(checkpointable_object.variables) == 0):\n        continue\n      self._checkpoint.all_python_objects.add(checkpointable_object)\n    unused_python_objects = (\n        _ObjectIdentitySet(self._checkpoint.all_python_objects)\n        - _ObjectIdentitySet(self._checkpoint.object_by_proto_id.values()))\n    if unused_python_objects:\n      raise AssertionError(\n          (\"Some Python objects were not bound to checkpointed values, likely \""
},
{
    "Id": 214,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/5ed3c7881f1f039b1bb502eb68c65250de3bbac8",
    "Violation": "missing",
    "Bug report": "Fix ThreadPoolHandle 0 nthreads argument. It was reported that a value of 0 leads to a check failure.  Using 0 to indicate `port::MaxParallelism`, for consistency with `Dataset`.",
    "Number of deleted lines": 0,
    "Deleted lines": "  explicit ThreadPoolHandleOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"display_name\", &display_name_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_threads\", &num_threads_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"max_intra_op_parallelism\",\n                                     &max_intra_op_parallelism_));\n    OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads_));\n  }\n\n  // The resource is deleted from the resource manager only when it is private\n  // to kernel. Ideally the resource should be deleted when it is no longer held\n  // by anyone, but it would break backward compatibility.\n  ~ThreadPoolHandleOp() override {\n    if (cinfo_.resource_is_private_to_kernel()) {\n      if (!cinfo_.resource_manager()"
},
{
    "Id": 215,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/6381a7b127bd276a3817a93e5423b15a06c33419",
    "Violation": "missing",
    "Bug report": " [tf.data] Add a check for ram_budget == 0 to avoid division by 0 exception when ram_budget is not set.",
    "Number of deleted lines": 0,
    "Deleted lines": "  }\n  return true;\n}\n\n// Records the ram usage of hill climbing algorithm.\nvoid RecordAutotuneRamUsage(int64 ram_budget, double max_buffered_bytes) {\n  const auto memory_info = port::GetMemoryInfo();\n  // Records ratio of memory used since RootDataset was created over the ram\n  // budget.\n  const auto original_free_memory = ram_budget / kRamBudgetShare;\n  const auto current_free_memory = memory_info.free;\n  metrics::RecordTFDataAutotuneUsedRamBudgetRatio(\n      (original_free_memory - current_free_memory) / ram_budget);\n  // Records ratio of maximum buffer bytes tf.data could use over the ram"
},
{
    "Id": 216,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a0fe44410e875e8e7775c6c256496bafb1a41b25",
    "Violation": "improper",
    "Bug report": " Remove the check of NodeItem exists in unfinished_nodes_ in node callback. This fixes the failure of RemoteAsyncTest.test_out_of_range_with_while_loop in DEBUG mode.",
    "Number of deleted lines": 1,
    "Deleted lines": "      node_queue_.pop();\n    } else if (async) {\n      // If it is an Async node then we will find the node in the unfinished\n      // nodes list. However we only notify if we are at the front of the list\n      // since we don't want to notify any waiters of earlier nodes.\n      need_notification = item->id == unfinished_nodes_.begin()->first;\n      auto result = unfinished_nodes_.erase(item->id);\n      DCHECK_GT(result, 0);\n    }\n\n    if (!status.ok() && item->node->Fatal()) {\n      // Since we received an error, broadcast to any waiters.\n      need_notification = true;\n      status_ = status;\n      ok_ = false;\n      if (Async()) {"
},
{
    "Id": 217,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/bd1f1ac1fec05d38f1b8fc98f650c1c55ac06790",
    "Violation": "improper",
    "Bug report": "Fix operator check ",
    "Number of deleted lines": 1,
    "Deleted lines": "    m = operator_a.range_dimension\n    l = operator_b.domain_dimension\n    if m is not None and l is not None:\n      return m == l\n\n  if (operator_a.is_square != operator_b.is_square) and (\n      operator_a.is_square is not None and operator_a.is_square is not None):\n    return False\n\n  return None\n\n\n# Note: Positive definiteness is only guaranteed to be preserved\n# when the operators commute and are symmetric. Only use this method in\n# commuting cases."
},
{
    "Id": 218,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/5e0c9fff657498f9a74da38b2ce1b4721698a388",
    "Violation": "missing",
    "Bug report": " Add bounds checks to jpeg parsing code. ",
    "Number of deleted lines": 2,
    "Deleted lines": "// -----------------------------------------------------------------------------\nvoid MemTermSource(j_decompress_ptr cinfo) {}\n\n// -----------------------------------------------------------------------------\nvoid MemSkipInputData(j_decompress_ptr cinfo, long jump) {\n  MemSourceMgr *src = reinterpret_cast<MemSourceMgr *>(cinfo->src);\n  src->pub.bytes_in_buffer -= jump;\n  src->pub.next_input_byte += jump;\n}\n\n// -----------------------------------------------------------------------------\nvoid SetSrc(j_decompress_ptr cinfo, const void *data,\n            unsigned long int datasize, bool try_recover_truncated_jpeg) {\n  MemSourceMgr *src;\n\n  cinfo->src = reinterpret_cast<struct jpeg_source_mgr *>("
},
{
    "Id": 219,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/28dacabab5aac2963e37e622f4b157cf00d82662",
    "Violation": "insufficient",
    "Bug report": " [tf] Explicitly check that runner index is in bounds and runner is available",
    "Number of deleted lines": 2,
    "Deleted lines": "\n  // Return the OpKernelRunner at the corresponding `index` in the table. The\n  // result can never be nullptr. It is a fatal error to use an index that is\n  // not in the table. Note that the returned pointer will be invalidated if\n  // Insert() is called.\n  const OpKernelRunner* Get(int64_t index) const {\n    DCHECK_GT(runners_.size(), index);\n    auto& result = runners_.at(index);\n    DCHECK(result.has_value());\n    return &(*result);\n  }\n\n private:\n  std::vector<absl::optional<OpKernelRunner>> runners_;\n};\n\n// OpKernelRunnerCache is similar to OpKernelRunnerTable but thread-safe."
},
{
    "Id": 220,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/bb6a0383ed553c286f87ca88c207f6774d5c4a8f",
    "Violation": "missing",
    "Bug report": " Prevent heap OOB read in TFLite's gather_nd.cc. Passing negative indices is illegal but there was a missing check so that resulted in OOB accesses.",
    "Number of deleted lines": 0,
    "Deleted lines": "  return kTfLiteOk;\n}\n\ntemplate <typename IndicesT>\nTfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                          const TfLiteTensor* indices, TfLiteTensor* output) {\n  switch (params->type) {\n    case kTfLiteFloat32:\n      return GatherNd<float, IndicesT>(params, indices, output);\n    case kTfLiteUInt8:\n      return GatherNd<uint8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt8:\n      return GatherNd<int8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt16:"
},
{
    "Id": 221,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/22783fdf812b700f7de9980038ab41ee0a4a2284",
    "Violation": "missing",
    "Bug report": "Add checks recently removed ",
    "Number of deleted lines": 0,
    "Deleted lines": "  absl::Status GetTensorId(uint32_t input_id, int* tensor_id) const;\n\n  absl::Status GetTensorDims(uint32_t idx, TfLiteIntArray* dimensions) const;\n\n  template <typename TensorT>\n  absl::Status ReadTensor(uint32_t index, TensorT* tensor) const {\n    const int32_t tensor_id = node_->inputs->data[index];\n    const TfLiteTensor* tflite_tensor = context_->tensors + tensor_id;\n    tensor->data.resize(NumElements(tflite_tensor));\n    if (tflite_tensor->sparsity) {\n      std::vector<int> dims;\n      dims.reserve(tflite_tensor->dims->size);\n      for (int i = 0; i < tflite_tensor->dims->size; ++i) {\n        dims.push_back(tflite_tensor->dims->data[i]);\n      }"
},
{
    "Id": 222,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/459b4bfe1f73737fae23aa1499b06a69605d0f65",
    "Violation": "missing",
    "Bug report": "Added a check in EagerExecutor to avoid getting invalid range. ",
    "Number of deleted lines": 0,
    "Deleted lines": "      upperbound_id = unfinished_nodes_.begin()->first - 1;\n    } else if (!node_queue_.empty()) {\n      upperbound_id = node_queue_.front()->id - 1;\n    } else {\n      upperbound_id = next_node_id_ - 1;\n    }\n    DVLOG(3) << \"Notify node done: [id \" << id << \" to \" << upperbound_id\n             << \"] \";\n    // Note that we notify all waiting threads in case an error has\n    // occurred. These calling threads are responsible for checking status_\n    // before proceeding.\n    const auto range =\n        status_.ok()\n            ? make_pair(node_done_notifications_.lower_bound(id),"
},
{
    "Id": 223,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/cddca76312f5ae4fb92a101e79eeff6d5ac16932",
    "Violation": "missing",
    "Bug report": "Add check for reading input tensors at an index that is out of range. ",
    "Number of deleted lines": 0,
    "Deleted lines": "  int GetNumberOfRuntimeInputs() const;\n\n  absl::Status GetTensorDims(uint32_t idx, TfLiteIntArray* dimensions) const;\n\n  template <typename TensorT>\n  absl::Status ReadTensor(uint32_t idx, TensorT* t) const {\n    const int32_t tensor_idx = node_->inputs->data[idx];\n    if (tensor_idx < 0) {\n      return absl::InvalidArgumentError(\n          \"Invalid data index found. Possibly an unset optional tensor is \"\n          \"being read.\");\n    }\n\n    const TfLiteTensor* tflite_tensor = context_->tensors + tensor_idx;"
},
{
    "Id": 224,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/823b694639a3f49b6adbf9e73a08c529d583878e",
    "Violation": "missing",
    "Bug report": "Add bounds checking when looking at the stack in TF Registry. ",
    "Number of deleted lines": 2,
    "Deleted lines": "                     (self._name, name, function_name, filename, line_number))\n\n    logging.vlog(1, \"Registering %s (%s) in %s.\", name, candidate, self._name)\n    # stack trace is [this_function, Register(), user_function,...]\n    # so the user function is #2.\n    stack = tf_stack.extract_stack()\n    user_function = stack[2]\n    location_tag = tf_stack.convert_stack([user_function])[0]\n    self._registry[name] = {_TYPE_TAG: candidate, _LOCATION_TAG: location_tag}\n\n  def list(self):\n    \"\"\"Lists registered items.\n\n    Returns:\n      A list of names of registered objects.\n    \"\"\""
},
{
    "Id": 225,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/b1c9e600e02b93885dbebfa5dae92436c63d6c03",
    "Violation": "missing",
    "Bug report": "[XLA] Add range check for xla::Array<> indexing. ",
    "Number of deleted lines": 0,
    "Deleted lines": "    CHECK_EQ(sizes_.size(), indexes.size());\n    int64 index = 0;\n    for (int64 i = 0; i < sizes_.size(); ++i) {\n      index *= sizes_[i];\n      index += indexes[i];\n    }\n    return index;\n  }\n\n  // Advances the specified set of indexes and returns true if we haven't\n  // wrapped around (i.e. result isn't {0, 0, ...}).\n  bool next_index(std::vector<int64>* index) const {\n    CHECK_EQ(index->size(), sizes_.size());\n    for (int64 i = sizes_.size() - 1; i >= 0; --i) {"
},
{
    "Id": 226,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1908d7ef706f0f3f8c7a300068355bf795fb3d17",
    "Violation": "improper",
    "Bug report": "Fix out-of-bounds StringPiece access in ForwardNUTF8CharPositions().  Even a simple invocation like 'int p = 0; ForwardNUTF8CharPositions(\"a\", 1, &p);' will cause an invalid access to in[1]. Checking for *pos < size before that access fixes this issue.",
    "Number of deleted lines": 1,
    "Deleted lines": "  const size_t size = in.size();\n  T utf8_chars_counted = 0;\n  while (utf8_chars_counted < num_utf8_chars_to_shift && *pos < size) {\n    // move forward one utf-8 character\n    do {\n      ++*pos;\n    } while (IsTrailByte(in[*pos]) && *pos < size);\n    ++utf8_chars_counted;\n  }\n  return utf8_chars_counted == num_utf8_chars_to_shift;\n}\n\n// Get the previous UTF8 character position starting at the given position and\n// skipping the given number of characters. Position is a byte offset with a\n// positive value, relative to the beginning of the string, and should never be"
},
{
    "Id": 227,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/aa54f547f04c3007b26df2379c6cf5f081948d0b",
    "Violation": "missing",
    "Bug report": " Updated the check_numerics function to also validate the gradient corresponding to the tensor it's validating",
    "Number of deleted lines": 1,
    "Deleted lines": "  raise NotImplementedError(\"Gradient for gather_nd is not implemented.\")\n\n\n@ops.RegisterGradient(\"CheckNumerics\")\ndef _CheckNumericsGrad(_, grad):\n  \"\"\"Gradient for check_numerics op.\"\"\"\n  return grad\n\n\n@ops.RegisterGradient(\"Identity\")\ndef _IdGrad(_, grad):\n  return grad\n\n\n@ops.RegisterGradient(\"RefIdentity\")"
},
{
    "Id": 228,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/236660d0fccff6f59f29a1936dc731d783722e28",
    "Violation": "missing",
    "Bug report": " [XLA:GPU] Fix host conv checker canonicalization for f16 and nans. The GPU-side checker is correct, but the host-side checker was canonicalizing nan to F16_MAX.  The effect of this is that you'd get a \"conv mismatch!\" error but no description of exactly what mismatched.",
    "Number of deleted lines": 0,
    "Deleted lines": "  stream->ThenMemcpy(host_rhs.data(), rhs, rhs.size());\n  TF_RETURN_IF_ERROR(stream->BlockHostUntilDone());\n\n  const auto canonicalize = [](ComparisonType a) -> ComparisonType {\n    if (std::is_same<ElementType, Eigen::half>::value && a) {\n      constexpr float kMaxFp16Value = 65504.;\n      if (a < 0) {\n        return -(kMaxFp16Value + 1);\n      }\n      return kMaxFp16Value + 1;\n    }\n    return a;\n  };\n  int differences_seen = 0;"
},
{
    "Id": 229,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/8c6f391a2282684a25cbfec7687bd5d35261a209",
    "Violation": "missing",
    "Bug report": " [lite] Add check for bias_size is zero to avoid division by zero. This shouldn't happen for properly converted models. Just safety check",
    "Number of deleted lines": 0,
    "Deleted lines": "                                      output_activation_max);\n}\n\ninline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\n                         const float* bias_data, int array_size,\n                         float* array_data) {\n  // Note: see b/132215220: in May 2019 we thought it would be OK to replace\n  // this with the Eigen one-liner:\n  //   return (array.colwise() + bias).cwiseMin(clamp_max).cwiseMin(clamp_max).\n  // This turned out to severely regress performance: +4ms (i.e. 8%) on\n  // MobileNet v2 / 1.0 / 224. So we keep custom NEON code for now.\n  TFLITE_DCHECK_EQ((array_size % bias_size), 0);\n#ifdef USE_NEON\n  float* array_ptr = array_data;"
},
{
    "Id": 230,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/7008e41f183ae9de3f4656067932b36afa822ef2",
    "Violation": "missing",
    "Bug report": " Fix the check for empty reduction indices. In the general case indices can be any rank.",
    "Number of deleted lines": 2,
    "Deleted lines": "  if (!IsReallyConstant(*reductions_indices) ||\n      !reductions_indices->attr().count(\"value\")) {\n    return false;\n  }\n  const TensorProto& reduction_indices_tensor =\n      reductions_indices->attr().at(\"value\").tensor();\n  *indices_is_empty =\n      reduction_indices_tensor.tensor_shape().dim(0).size() == 0;\n  return true;\n}\n\nbool ConstantFolding::IsReductionCandidateForSimplification(\n    const NodeDef& node, const GraphProperties& properties,\n    TensorShapeProto* input_tensor_shape, TensorShapeProto* output_tensor_shape,\n    bool* is_single_element_op) const {\n  // Get the properties of the input & output tensors and check if they both"
},
{
    "Id": 231,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/551a90f2e3d20420d68a2796d19f1c42b6636e0d",
    "Violation": "missing",
    "Bug report": " Add checks in ReduceWindowOpOnTensorsConversion. The pattern does not support ops with non-zero padding config. Add a check to prevent unexpected lowering. It is not easy to add tests because other patterns will convert body ops, and it causes issues like invalid IRs.",
    "Number of deleted lines": 0,
    "Deleted lines": "    auto loc = op.getLoc();\n    int rank = op.getResultTypes()[0].cast<ShapedType>().getRank();\n    if (rank != 4) {\n      return rewriter.notifyMatchFailure(op, \"expected NHWC pooling-based op\");\n    }\n\n    SmallVector<int64_t, 2> shapes;\n    shapes.push_back(op.window_dimensions().getValue<int64_t>(1));\n    shapes.push_back(op.window_dimensions().getValue<int64_t>(2));\n\n    if (op.window_strides() &&\n        (op.window_strides().getValue().getValue<int64_t>(0) != 1 ||\n         op.window_strides().getValue().getValue<int64_t>(3) != 1)) {\n      return rewriter.notifyMatchFailure("
},
{
    "Id": 232,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/f6f62119587baf8ccb7378ceac86bacd2db2863d",
    "Violation": "missing",
    "Bug report": "Add missing validation in maxpooling_op.cc ",
    "Number of deleted lines": 0,
    "Deleted lines": "    }\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, output_shape, &output));\n\n    SpatialMaxPoolWithArgMaxHelper<CPUDevice, T, int64>(\n        context, &tensor_out_dup, &tensor_out_arg_max, output, tensor_in,\n        out_backprop, params, true);\n  }\n\n private:\n  std::vector<int32> ksize_;\n  std::vector<int32> stride_;"
},
{
    "Id": 233,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/b86513673b98ac6c4458033fcda718365539afae",
    "Violation": "missing",
    "Bug report": "added check for zero stride values to strided slice ",
    "Number of deleted lines": 0,
    "Deleted lines": "                                              input->tensor.shape, &attr));\n    }\n    if (read_with_batch) {\n      RETURN_IF_ERROR(\n          ReadAttribsWithBatch(reader, tf_options, input->tensor.shape, &attr));\n    }\n    if (attr.strides.h < 0 || attr.strides.w < 0 || attr.strides.c < 0) {\n      return UnimplementedError(\"Reverse slices are not supported.\");\n    }\n    if ((attr.ends.h - attr.starts.h + attr.strides.h - 1) / attr.strides.h !=\n        out_shape.h) {\n      return UnimplementedError(\"Output height doesn't match\");\n    }\n    if ((attr.ends.w - attr.starts.w + attr.strides.w - 1) / attr.strides.w !="
},
{
    "Id": 234,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/4377a561b7757ed83757f07532e6564c42c286ba",
    "Violation": "missing",
    "Bug report": " Add a check for group size when sorting grouped AllReduces within a block.",
    "Number of deleted lines": 0,
    "Deleted lines": "                << all_reduce_groups.size() << \" groups\";\n\n        all_reduce_groups = createSubgroupsByElemType(all_reduce_groups);\n        all_reduce_groups = createSubgroupsByReductionAttr(all_reduce_groups);\n        all_reduce_groups = createSubgroupsByGroupAssignment(all_reduce_groups);\n\n        std::sort(all_reduce_groups.begin(), all_reduce_groups.end(),\n                  [](std::vector<mlir::TF::DTensorAllReduceOp> lhs,\n                     std::vector<mlir::TF::DTensorAllReduceOp> rhs) {\n                    if (lhs[0]->getBlock() == rhs[0]->getBlock())\n                      return lhs[0]->isBeforeInBlock(rhs[0]);\n                    return true;\n                  });\n        for (const auto& reduce_group : all_reduce_groups) {\n          if (reduce_group.size() > 1) {\n            VLOG(4) << \"Combining following reduce ops into one: ------------\";\n            for (auto reduce_op : reduce_group) {"
},
{
    "Id": 235,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/31bd5026304677faa8a0b77602c6154171b9aec1",
    "Violation": "missing",
    "Bug report": " Prevent check fail in FFT ",
    "Number of deleted lines": 0,
    "Deleted lines": "    input_slice_sizes[0] = input_dims[0];\n    TensorShape temp_shape{input_dims[0]};\n    for (int i = 1; i <= FFTRank; ++i) {\n      input_slice_sizes[i] = fft_shape[i - 1];\n      temp_shape.AddDim(fft_shape[i - 1]);\n    }\n\n    auto output = out->flat_inner_dims<ComplexT, FFTRank + 1>();\n    const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> zero_start_indices;\n\n    // Compute the full FFT using a temporary tensor.\n    Tensor temp;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),\n                                           temp_shape, &temp));"
},
{
    "Id": 236,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/25bae42b3022b00788a29ae6c400922c31f88231",
    "Violation": "insufficient",
    "Bug report": " Add additional length check for inputs ",
    "Number of deleted lines": 1,
    "Deleted lines": "    ]\n\n  output_ind, output_val, output_shape = (\n      gen_sparse_ops.sparse_concat(inds, vals, shapes, axis, name=name))\n\n  shapes_value = [tensor_util.constant_value(shape) for shape in shapes]\n  if all(shape is not None for shape in shapes_value):\n    dim = sum(shape[axis] for shape in shapes_value)\n    output_shape = shapes_value[0]\n    output_shape[axis] = dim\n    output_shape = tensor_shape.as_shape(output_shape)\n  return sparse_tensor.SparseTensor(output_ind, output_val, output_shape)\n\n\n@tf_export(v1=[\"sparse.add\", \"sparse_add\"])"
},
{
    "Id": 237,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/e07e48b2e0908333a36f1c5726a9406a83b3ec90",
    "Violation": "missing",
    "Bug report": "Added a check on literal_.has_value() to avoid segfault. ",
    "Number of deleted lines": 0,
    "Deleted lines": "}\n\nstring HloConstantInstruction::OperandsToStringWithCanonicalNameMap(\n    const HloPrintOptions& options,\n    CanonicalNameMap* canonical_name_map) const {\n  if (options.print_only_essential_constants()) {\n    if (literal().IsAll(0)) {\n      return \"0\";\n    }\n    if (literal().IsAll(1)) {\n      return \"1\";\n    }\n    if (shape().IsInteger()) {\n      return literal_->ToStringWithoutShapeOneline();"
},
{
    "Id": 238,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/cc560f64b6e3e6724517757e9789c52cde224ee9",
    "Violation": "missing",
    "Bug report": " Profiler: restore correct behavior of StartTracing with empty workers list. absl::StrSplit behaves differently from str_util::Split when the passed string is empty. Restore previous behavior by explicitly checking for an empty string.",
    "Number of deleted lines": 1,
    "Deleted lines": "                    int num_tracing_attempts) {\n  // Use the current timestamp as the run name.\n  tensorflow::string session_id = GetCurrentTimeStampAsString();\n  constexpr char kProfilePluginDirectory[] = \"plugins/profile/\";\n  tensorflow::string repository_root =\n      io::JoinPath(logdir, kProfilePluginDirectory);\n  std::vector<tensorflow::string> hostnames = absl::StrSplit(workers_list, ',');\n\n  TF_RETURN_IF_ERROR(MaybeCreateEmptyEventFile(logdir));\n\n  Status status = Status::OK();\n  int remaining_attempts = num_tracing_attempts;\n  tensorflow::ProfileOptions opts;\n  opts.set_include_dataset_ops(include_dataset_ops);\n  while (true) {"
},
{
    "Id": 239,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/fe4f74018ec6a7dff2718ea59d0f317460c0b3ad",
    "Violation": "missing",
    "Bug report": " Temporarily check for empty proto fields to avoid a crash for old cached traces. We can remove this code once we land all the necessary changes and invalidate all the caches.",
    "Number of deleted lines": 0,
    "Deleted lines": "void PopulateOpMetricsNode(\n    const OpMetrics& op_metrics, double peak_gigaflops_per_second_per_core,\n    std::vector<double> peak_mem_gibibytes_per_second_per_core,\n    uint64_t total_time_ps, Node* node) {\n  DCHECK_EQ(ChildrenTimePs(op_metrics), 0);\n\n  Metrics* metrics = node->mutable_metrics();\n  // The UI computes flops_rate = raw_flops / raw_time\n  // and memory_bandwidth = raw_bytes_accessed / raw_time. See:\n  // https://github.com/tensorflow/profiler/blob/master/frontend/app/common/utils/utils.ts\n  metrics->set_raw_time(op_metrics.time_ps());\n  metrics->set_raw_flops(op_metrics.flops());\n  metrics->set_raw_bytes_accessed(op_metrics.bytes_accessed());\n"
},
{
    "Id": 240,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c56d0cd8ce8239ee369fac1ae6b9cae67fd4c447",
    "Violation": "missing",
    "Bug report": " Avoid signed integer overflow when loading tensors with both 0 and large dims. `TensorShapeBase` ensures `num_elements` doesn't overflow when adding a new dimension. However, this check is insufficient to prevent other functions that use a different multiplication order from hitting an overflow _if any of the dimensions are 0_. For example, Eigen currently multiplies dimensions in reverse order, so dimensions of (0, 4294967296,4294967296) will trigger an overflow in Eigen code. To prevent overflow for all multiplication orders, we can that `num_elements` doesn't overflow if zero dimensions are skipped.",
    "Number of deleted lines": 0,
    "Deleted lines": "  if (kIsPartial && proto.unknown_rank()) {\n    out->set_ndims_byte(kUnknownRank);\n    out->set_num_elements(-1);\n  } else {\n    out->set_ndims_byte(0);\n    out->set_num_elements(1);\n    Status s = OkStatus();\n    for (const auto& d : proto.dim()) {\n      s = out->AddDimWithStatus(d.size());\n      if (!s.ok()) {\n        return s;\n      }\n    }\n  }\n  return OkStatus();\n}\n\ntemplate <class Shape>\nTensorShapeBase<Shape>::TensorShapeBase(gtl::ArraySlice<int64_t> dim_sizes) {\n  set_tag(REP16);"
},
{
    "Id": 241,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/80bb2f5511e7d2d386c79da52ff517691e19ac54",
    "Violation": "missing",
    "Bug report": " Add check condition for large values of range_max, which is causing session abort.",
    "Number of deleted lines": 0,
    "Deleted lines": "    sampled_expected_count: A tensor of type `float`. Same shape as\n      `sampled_candidates`. The expected counts under the sampling distribution\n      of each of `sampled_candidates`.\n\n  \"\"\"\n  seed1, seed2 = random_seed.get_seed(seed)\n  return gen_candidate_sampling_ops.learned_unigram_candidate_sampler(\n      true_classes, num_true, num_sampled, unique, range_max, seed=seed1,\n      seed2=seed2, name=name)\n\n\n@tf_export('random.fixed_unigram_candidate_sampler',\n           'nn.fixed_unigram_candidate_sampler')\n@dispatch.add_dispatch_support"
},
{
    "Id": 242,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/4ea68093eeaf4c4157368668afd7f809b806a504",
    "Violation": "missing",
    "Bug report": "Add negative parameter validation to convolution layers. ",
    "Number of deleted lines": 0,
    "Deleted lines": "        activity_regularizer=regularizers.get(activity_regularizer),\n        **kwargs)\n    self.rank = rank\n\n    if isinstance(filters, float):\n      filters = int(filters)\n    self.filters = filters\n    self.groups = groups or 1\n    self.kernel_size = conv_utils.normalize_tuple(\n        kernel_size, rank, 'kernel_size')\n    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n    self.padding = conv_utils.normalize_padding(padding)\n    self.data_format = conv_utils.normalize_data_format(data_format)\n    self.dilation_rate = conv_utils.normalize_tuple("
},
{
    "Id": 243,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/199f1ff12a28d571100b323ec54a5eee47078d8b",
    "Violation": "missing",
    "Bug report": " Add necessary check in fft ops to fix crash. This PR tries to address the issue raised in 55263 where tf.single.rfft2d will crash when length contains negative value.",
    "Number of deleted lines": 0,
    "Deleted lines": "                      fft_length.shape().dim_size(0) == fft_rank,\n                  errors::InvalidArgument(\"fft_length must have shape [\",\n                                          fft_rank, \"]\"));\n\n      auto fft_length_as_vec = fft_length.vec<int32>();\n      for (int i = 0; i < fft_rank; ++i) {\n        fft_shape[i] = fft_length_as_vec(i);\n        // Each input dimension must have length of at least fft_shape[i]. For\n        // IRFFTs, the inner-most input dimension must have length of at least\n        // fft_shape[i] / 2 + 1.\n        bool inner_most = (i == fft_rank - 1);\n        uint64 min_input_dim_length =\n            !IsForward() && inner_most ? fft_shape[i] / 2 + 1 : fft_shape[i];\n        auto input_index = input_shape.dims() - fft_rank + i;"
},
{
    "Id": 244,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/076f909b70b251daea6c443c9b1929b9745aed20",
    "Violation": "improper",
    "Bug report": "fix boolean expression in length check ",
    "Number of deleted lines": 1,
    "Deleted lines": "                errors::Unimplemented(\"Length has to be non-empty\"));\n    int64_t length = lengths[0];\n    for (int64_t len : lengths) {\n      OP_REQUIRES(ctx, len == length,\n                  errors::Unimplemented(\"All lengths have to be the same\"));\n    }\n    OP_REQUIRES(ctx, length,\n                errors::Unimplemented(\"All lengths must be positive\"));\n    OP_REQUIRES(\n        ctx, element_dims[0] % length == 0,\n        errors::Unimplemented(\"Buffer size has to be a multiple of length\"));\n    std::vector<int64_t> new_dims = {element_dims[0] / length, length};\n    for (int i = 1; i < element_dims.size(); i++) {\n      new_dims.push_back(element_dims[i]);\n    }"
},
{
    "Id": 245,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/3acc8eaf602b3e9a009f54e1e0164644dd793831",
    "Violation": "missing",
    "Bug report": "Add sanity check for resize-bilinear input shape. ",
    "Number of deleted lines": 1,
    "Deleted lines": "constexpr int kOutputTensor = 0;\n\nTfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                const TfLiteTensor* input,\n                                const TfLiteTensor* size,\n                                TfLiteTensor* output) {\n  TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);\n  output_size->data[0] = input->dims->data[0];\n  const int32* size_data = GetTensorData<int32>(size);\n  output_size->data[1] = size_data[0];\n  output_size->data[2] = size_data[1];\n  output_size->data[3] = input->dims->data[3];\n  return context->ResizeTensor(context, output, output_size);\n}\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);"
},
{
    "Id": 246,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/fffbe5a26da2d6fab5a3eb648cefef49db4d38de",
    "Violation": "missing",
    "Bug report": " Check if the session has been deleted before releasing a callable. In some versions of Python, the Session._session field may be cleared (in `Session.__del__()`) before a callable that has a reference to that Session is deleted. Add a defensive check in the `Session._Callable.__del__()` method.",
    "Number of deleted lines": 1,
    "Deleted lines": "              self._session._session, self._handle, args, status, None)\n        else:\n          return tf_session.TF_DeprecatedSessionRunCallable(\n              self._session._session, self._handle, args, status, None)\n\n    def __del__(self):\n      if self._handle is not None:\n        with errors.raise_exception_on_not_ok_status() as status:\n          if self._session._created_with_new_api:\n            tf_session.TF_SessionReleaseCallable(\n                self._session._session, self._handle, status)\n          else:\n            tf_session.TF_DeprecatedSessionReleaseCallable(\n                self._session._session, self._handle, status)\n  # pylint: enable=protected-access"
},
{
    "Id": 247,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/ebeb598c2d1f341d6d641bf58c370cf7b43f6e37",
    "Violation": "missing",
    "Bug report": " Correctly check shape not None in Keras add_weight. When calling Keras add_weight with a np list, as written the `shape or ()` \"trick\" results in the following exception: \"\"\"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\"\"\" This change fixes the problem by using an explicit `if`.",
    "Number of deleted lines": 1,
    "Deleted lines": "    Raises:\n      RuntimeError: If called with partioned variable regularization and\n        eager execution is enabled.\n      ValueError: When giving unsupported dtype and no initializer or when\n        trainable has been set to True with synchronization set as `ON_READ`.\n    \"\"\"\n    shape = shape or ()\n    # Validate optional keyword arguments.\n    for kwarg in kwargs:\n      if kwarg not in ['getter', 'collections', 'experimental_autocast']:\n        raise TypeError('Unknown keyword argument:', kwarg)\n    getter = kwargs.pop('getter', None)\n    collections = kwargs.pop('collections', None)\n    # 'experimental_autocast' can be set to False by the caller to indicate an\n    # AutoCastVariable should never be created."
},
{
    "Id": 248,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c7c4a42c4372ca560ea415fe3a798e18286cedec",
    "Violation": "improper",
    "Bug report": "Fix an error in keras input_layer.Input() dtype type checking. ",
    "Number of deleted lines": 2,
    "Deleted lines": "\n    if not dtype:\n      if input_tensor is None:\n        dtype = backend.floatx()\n      else:\n        dtype = backend.dtype(input_tensor)\n    elif input_tensor and input_tensor.dtype != dtype:\n      raise ValueError('`input_tensor.dtype` differs from `dtype`.')\n    super(InputLayer, self).__init__(dtype=dtype, name=name)\n    self.built = True\n    self.sparse = sparse\n    self.batch_size = batch_size\n    self.supports_masking = True\n\n    if isinstance(input_shape, tensor_shape.TensorShape):\n      input_shape = tuple(input_shape.as_list())"
},
{
    "Id": 249,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a5b8d6c4694e4cd3e3cc4a162053ab0dfa6e174f",
    "Violation": "insufficient",
    "Bug report": "Relax the check for whether the relevant aggregation dimensions are known ahead of time.",
    "Number of deleted lines": 1,
    "Deleted lines": "    * the shift by which the mean must be corrected or None if `shift` is None.\n  \"\"\"\n  axes = list(set(axes))\n  with ops.name_scope(name, \"sufficient_statistics\", [x, shift]):\n    x = ops.convert_to_tensor(x, name=\"x\")\n    x_shape = x.get_shape()\n    if x_shape.is_fully_defined():\n      counts = 1\n      for d in axes:\n        counts *= x_shape[d].value\n      counts = constant_op.constant(counts, dtype=x.dtype)\n    else:  # shape needs to be inferred at runtime.\n      x_dims = array_ops.gather(\n          math_ops.cast(array_ops.shape(x), x.dtype), axes)\n      counts = math_ops.reduce_prod(x_dims, name=\"count\")"
},
{
    "Id": 250,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/0d65cfaab050295c311d9f2fb28388435359db27",
    "Violation": "insufficient",
    "Bug report": " Add an additional NoneType check when converting a traced tensor to a `KerasTensor`.",
    "Number of deleted lines": 1,
    "Deleted lines": "  def from_tensor(cls, tensor):\n    \"\"\"Convert a traced (composite)tensor to a representative KerasTensor.\"\"\"\n    if isinstance(tensor, ops.Tensor):\n      name = getattr(tensor, 'name', None)\n      type_spec = type_spec_module.type_spec_from_value(tensor)\n      inferred_value = None\n      if (type_spec.dtype == dtypes.int32 and type_spec.shape.rank < 2):\n        # If this tensor might be representing shape information,\n        # (dtype=int32, rank of 0 or 1, not too large to represent a shape)\n        # we attempt to capture any value information tensorflow's\n        # shape handling can extract from the current scratch graph.\n        #\n        # Even though keras layers each trace in their own scratch\n        # graph, this shape value info extraction allows us to capture\n        # a sizable and useful subset of the C++ shape value inference TF can do"
},
{
    "Id": 251,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/31849c61e0432009baabdfafc2ec1a1aed1a40e8",
    "Violation": "insufficient",
    "Bug report": " Small change in tf.nn.sufficient_statistics to guard against unknown shapes. Use is_fully_defined instead of checking shape.dims[d] as the dims variable may be None, if the rank is unknown.",
    "Number of deleted lines": 1,
    "Deleted lines": "      \"keepdims\", keepdims, \"keep_dims\", keep_dims)\n  if keep_dims is None:\n    keep_dims = False\n  with ops.name_scope(name, \"sufficient_statistics\", [x, shift]):\n    x = ops.convert_to_tensor(x, name=\"x\")\n    x_shape = x.get_shape()\n    if all(x_shape.dims[d].value is not None for d in axes):\n      counts = 1\n      for d in axes:\n        counts *= x_shape.dims[d].value\n      counts = constant_op.constant(counts, dtype=x.dtype)\n    else:  # shape needs to be inferred at runtime.\n      x_dims = array_ops.gather(\n          math_ops.cast(array_ops.shape(x), x.dtype), axes)\n      counts = math_ops.reduce_prod(x_dims, name=\"count\")"
},
{
    "Id": 252,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/30bd9d5bcc64097d21872486a5726d756ed7067b",
    "Violation": "insufficient",
    "Bug report": " Explicitly handle Tensors in start & stop. The current check was doing a identity check in order to handle both tensors and integers. This becomes problematic when enabling tensor equality. Instead we explicitly check for Tensor type and only compare with sys.maxsize for non-Tensors.",
    "Number of deleted lines": 2,
    "Deleted lines": "  ellipsis_mask = 0\n  for s in slice_spec:\n    if isinstance(s, _BaseSlice):\n      # python doesn't always use None when constructing ranges\n      # for example a[:] gives slice(None,sys.maxsize,None)\n      # whereas a[::1] gives slice(None,None,None)\n      if s.start is not None and s.start is not sys.maxsize:\n        _check_index(s.start)\n        begin.append(s.start)\n      else:\n        begin.append(0)\n        begin_mask |= (1 << index)\n      if s.stop is not None and s.stop != sys.maxsize:\n        _check_index(s.stop)\n        end.append(s.stop)\n      else:\n        end.append(0)\n        end_mask |= (1 << index)\n      if s.step is not None:\n        _check_index(s.step)\n        strides.append(s.step)"
},
{
    "Id": 253,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/fb1c4cd8283f262bca95ccd04df6f9eb4ae1da0c",
    "Violation": "missing",
    "Bug report": "Add None check for seq_len_mask before reshape.",
    "Number of deleted lines": 4,
    "Deleted lines": "        maxlen=array_ops.shape(nest.flatten(memory)[0])[1],\n        dtype=nest.flatten(memory)[0].dtype)\n  def _maybe_mask(m, seq_len_mask):\n    rank = m.get_shape().ndims\n    rank = rank if rank is not None else array_ops.rank(m)\n    extra_ones = array_ops.ones(rank - 2, dtype=dtypes.int32)\n    seq_len_mask = array_ops.reshape(\n        seq_len_mask,\n        array_ops.concat((array_ops.shape(seq_len_mask), extra_ones), 0))\n    return m * seq_len_mask if memory_sequence_length is not None else m\n  return nest.map_structure(lambda m: _maybe_mask(m, seq_len_mask), memory)\n\n\nclass _BaseAttentionMechanism(AttentionMechanism):\n  \"\"\"A base AttentionMechanism class providing common functionality.\n\n  Common functionality includes:\n    1. Storing the query and memory layers."
},
{
    "Id": 254,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a0ca4bcb81dfd07fdb1c7872b5852f84cfc1a081",
    "Violation": "improper",
    "Bug report": "Fix separable convolution bias check",
    "Number of deleted lines": 1,
    "Deleted lines": "        rate=self.dilation_rate)\n\n    if self.data_format == 'channels_first':\n      # Reshape to channels first\n      outputs = array_ops.transpose(outputs, (0, 3, 1, 2))\n\n    if self.bias:\n      outputs = nn.bias_add(\n          outputs,\n          self.bias,\n          data_format=utils.convert_data_format(self.data_format, ndim=4))\n\n    if self.activation is not None:\n      return self.activation(outputs)\n    return outputs"
},
{
    "Id": 255,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1ff493ed1a2059f82f7607a7f0a0aa2ce8d5a542",
    "Violation": "improper",
    "Bug report": "Replace a defensive check with TF_RET_CHECK",
    "Number of deleted lines": 4,
    "Deleted lines": "\n  TF_RET_CHECK(!device_names.empty()) << \"No devices to choose from\";\n  DCHECK_NE(out_can_pick_device == nullptr, out_device_picked == nullptr);\n\n  absl::flat_hash_set<absl::string_view> device_names_set;\n  for (absl::string_view device_name : device_names) {\n    if (!device_name.empty()) {\n      // TODO(sanjoy): Figure out if this is necessary.\n      device_names_set.insert(device_name);\n    }\n  }\n\n  absl::optional<absl::string_view> maybe_gpu_device;\n  absl::optional<absl::string_view> maybe_cpu_device;\n  absl::optional<absl::string_view> maybe_unknown_device;\n\n  for (absl::string_view device_name : device_names_set) {\n    DeviceNameUtils::ParsedName parsed_name;"
},
{
    "Id": 256,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/201982013046116767545cda18137b38abb39468",
    "Violation": "missing",
    "Bug report": "toco: Fix missing check for buffer in ResizeBilinear.",
    "Number of deleted lines": 0,
    "Deleted lines": "  const auto& output_size_array = *model->arrays[output_size_name];\n  CHECK(output_size_array.data_type == ArrayDataType::kInt32);\n  CHECK(output_size_array.has_shape());\n  const auto& output_size_shape = output_size_array.shape();\n  CHECK_EQ(output_size_shape.dimensions_count(), 1);\n  CHECK_EQ(output_size_shape.dims(0), 2);\n  std::vector<int32> output_shape =\n      output_size_array.GetBuffer<ArrayDataType::kInt32>().data;\n  model->arrays[op->outputs[0]]->copy_shape(\n      Shape({input_data_shape.dims(0), output_shape[0], output_shape[1],\n             input_data_shape.dims(3)}));\n}\n\nvoid ProcessLstmCellOperator(Model* model, LstmCellOperator* op) {"
},
{
    "Id": 257,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c676a2d7ce8884aad59ca9cd5f45e9b851574cac",
    "Violation": "missing",
    "Bug report": " [tensorflow] Add a check that strided slice op strides argument has reasonable size",
    "Number of deleted lines": 1,
    "Deleted lines": "}  // namespace\n\ntemplate <class T>\nstatic Status TF_MUST_USE_RESULT BuildDenseSpec(\n    const StridedSliceSparseSpec& sparse, StridedSliceDenseSpec* dense) {\n  if (dense->dims < 0) {\n    return errors::InvalidArgument(\"Unexpected negative dense.dims\");\n  }\n\n  // Build expanded begin, end, strides, begin_mask, end_mask\n  // to remove any ellipsis\n  dense->begin.resize(dense->dims);\n  dense->end.resize(dense->dims);\n  dense->strides.resize(dense->dims);\n  dense->input_shape_gather_indices_sparse.resize(dense->dims);"
},
{
    "Id": 258,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/f61175812426009a4c96e51befb2951612990903",
    "Violation": "missing",
    "Bug report": "To add a check of input_dims greater than zero in embedding layers. ",
    "Number of deleted lines": 0,
    "Deleted lines": "    # before casting to int32 might cause the int32 values to be different due\n    # to a loss of precision.\n    kwargs['autocast'] = False\n    super(Embedding, self).__init__(dtype=dtype, **kwargs)\n\n    self.input_dim = input_dim\n    self.output_dim = output_dim\n    self.embeddings_initializer = initializers.get(embeddings_initializer)\n    self.embeddings_regularizer = regularizers.get(embeddings_regularizer)\n    self.activity_regularizer = regularizers.get(activity_regularizer)\n    self.embeddings_constraint = constraints.get(embeddings_constraint)\n    self.mask_zero = mask_zero\n    self.supports_masking = mask_zero\n    self.input_length = input_length"
},
{
    "Id": 259,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a0dc73569fc193c1ce26a7bd2d4a8776e7b813ac",
    "Violation": "missing",
    "Bug report": "add check for empty cs_prev_tensor",
    "Number of deleted lines": 0,
    "Deleted lines": "                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n                                        x_tensor->dims(), \".\"));\n    OP_REQUIRES(\n        ctx, cs_prev_tensor->dims() == 2,\n        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n                                cs_prev_tensor->dims(), \".\"));\n    OP_REQUIRES(\n        ctx, h_prev_tensor->dims() == 2,\n        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n                                h_prev_tensor->dims(), \".\"));\n    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n                                        w_tensor->dims(), \".\"));\n    OP_REQUIRES("
},
{
    "Id": 260,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/258233804f2bc92b4bdb9714b396aed34b53ff0d",
    "Violation": "missing",
    "Bug report": " sanity check of empty tensor on avgpool3d_grad",
    "Number of deleted lines": 0,
    "Deleted lines": "    try {\n      const Tensor& orig_input_tensor =\n          MklGetInput(context, kInputTensorIndexInputShape);\n      const Tensor& grad_tensor =\n          MklGetInput(context, kInputTensorIndexInputGradient);\n\n      MklDnnShape orig_input_mkl_shape, grad_mkl_shape;\n      GetMklShape(context, kInputTensorIndexInputShape, &orig_input_mkl_shape,\n                  this->native_format_);\n      GetMklShape(context, kInputTensorIndexInputGradient, &grad_mkl_shape,\n                  this->native_format_);\n      if (!context->status().ok()) return;\n\n      // Used to allocate output_diff_src/diff_src."
},
{
    "Id": 261,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a3d9f9be9ac2296615644061b40cefcee341dcc4",
    "Violation": "missing",
    "Bug report": " Add missing validation to pooling_ops_3d ",
    "Number of deleted lines": 0,
    "Deleted lines": "                            padding_, data_format_, tensor_in.shape()};\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {2}, 0, tensor_out.shape(), &output));\n\n    LaunchMaxPooling3dGradGradOp<Device, T>::launch(\n        context, params, tensor_in, tensor_out, out_grad_backprop, output);\n  }\n\n private:\n  std::vector<int32> ksize_;\n  std::vector<int32> stride_;\n  Padding padding_;"
},
{
    "Id": 262,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/27bd8aaa7b58d2591fed43a6c245f3037664cfb1",
    "Violation": "missing",
    "Bug report": "Fix another Eigen missing validation ",
    "Number of deleted lines": 0,
    "Deleted lines": "        ctx, in0.dims() >= 2,\n        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\n\n    OP_REQUIRES(\n        ctx, in1.dims() >= 2,\n        errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1.dims()));\n  }\n  bool lower_;\n  bool adjoint_;\n};\n\n#define REGISTER_BANDED_TRIANGULAR_SOLVE_CPU(TYPE)        \\\n  REGISTER_KERNEL_BUILDER(Name(\"BandedTriangularSolve\")   \\\n                              .Device(DEVICE_CPU)         \\"
},
{
    "Id": 263,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/dedac5053f1ca2d6a7820e330714e50d2d724cee",
    "Violation": "missing",
    "Bug report": " Fix edge case bug in handling FP16 weights in XNNPACK delegate. Quasi-static tensors may become subgraph outputs after partitioning; we need to explicitly exclude them from outputs and treat as static tensors.",
    "Number of deleted lines": 3,
    "Deleted lines": "                          const TfLiteDelegateParams* params,\n                          const Delegate* delegate) {\n    // Convert subgraph inputs and outputs to hash sets for faster lookup.\n    const std::unordered_set<int> inputs(\n        &params->input_tensors->data[0],\n        &params->input_tensors->data[params->input_tensors->size]);\n    const std::unordered_set<int> outputs(\n        &params->output_tensors->data[0],\n        &params->output_tensors->data[params->output_tensors->size]);\n    std::unordered_set<int> externals(outputs);\n\n    TfLiteIntArray* execution_plan;\n    if (context->GetExecutionPlan(context, &execution_plan) != kTfLiteOk) {\n      return nullptr;\n    }\n\n    xnn_subgraph_t subgraph_ptr = nullptr;"
},
{
    "Id": 264,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/ce589223a5fa78cb12efaf1efd1d8d0e5507bd08",
    "Violation": "missing",
    "Bug report": " Update nn_ops.py. Added check for pooling_ratio",
    "Number of deleted lines": 0,
    "Deleted lines": "\n  References:\n    Fractional Max-Pooling:\n      [Graham, 2015](https://arxiv.org/abs/1412.6071)\n      ([pdf](https://arxiv.org/pdf/1412.6071.pdf))\n  \"\"\"\n  pooling_ratio = _get_sequence(pooling_ratio, 2, 3, \"pooling_ratio\")\n\n  if seed == 0:\n    return gen_nn_ops.fractional_max_pool(value, pooling_ratio, pseudo_random,\n                                          overlapping, deterministic=False,\n                                          seed=0, seed2=0, name=name)\n  else:\n    seed1, seed2 = random_seed.get_seed(seed)"
},
{
    "Id": 265,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/63feaf321165e1e2795f43e3834c007364921df6",
    "Violation": "missing",
    "Bug report": "Add check for raster bits.",
    "Number of deleted lines": 0,
    "Deleted lines": "    return nullptr;\n  }\n\n  if (DGifSlurp(gif_file) != GIF_OK) {\n    *error_string = absl::StrCat(\"failed to slurp gif file: \",\n                                 GifErrorStringNonNull(gif_file->Error));\n    LOG(ERROR) << *error_string;\n    return nullptr;\n  }\n\n  if (gif_file->ImageCount <= 0) {\n    *error_string = \"gif file does not contain any image\";\n    return nullptr;\n  }"
},
{
    "Id": 266,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/e5b0eec199c2d03de54fd6a7fd9275692218e2bc",
    "Violation": "missing",
    "Bug report": " [lite] Add validation check for dilation height/width to be positive integers.",
    "Number of deleted lines": 0,
    "Deleted lines": "  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n  TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 4);\n\n  const TfLiteType data_type = input->type;\n\n  const TfLiteType filter_type = filter->type;\n  const bool is_hybrid =\n      data_type == kTfLiteFloat32 && filter_type == kTfLiteInt8;\n  TF_LITE_ENSURE(context,\n                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||"
},
{
    "Id": 267,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/5cedb0427bd4db4117182da8bc0680dd555b4f49",
    "Violation": "missing",
    "Bug report": "Add checks for dilation_rate. ",
    "Number of deleted lines": 0,
    "Deleted lines": "  const int32 filter_offset = params.weights_offset;\n  const int32 output_offset = params.output_offset;\n  const int32 output_multiplier = params.output_multiplier;\n  const int output_shift = params.output_shift;\n  const int dilation_width_factor = params.dilation_width_factor;\n  const int dilation_height_factor = params.dilation_height_factor;\n  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);\n  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);\n  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);\n  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);\n  const int batches = MatchingDim(input_shape, 0, output_shape, 0);\n  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);\n  const int input_height = input_shape.Dims(1);\n  const int input_width = input_shape.Dims(2);"
},
{
    "Id": 268,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/55aec0a33011773240f6696393952c984ca8de16",
    "Violation": "insufficient",
    "Bug report": " Add explicit not-None checks for the height and width in `resize_images()`. This was previously raising a `FutureWarning` when the height and/or width were dynamic.",
    "Number of deleted lines": 1,
    "Deleted lines": "  except (TypeError, ValueError):\n    raise ValueError('new_height must be a scalar integer')\n\n  new_width_const = tensor_util.constant_value(new_width)\n  new_height_const = tensor_util.constant_value(new_height)\n\n  if width == new_width_const and height == new_height_const:\n    if not is_batch:\n      images = array_ops.squeeze(images, squeeze_dims=[0])\n    return images\n\n  new_size = array_ops.pack([new_height, new_width])\n\n  if method == ResizeMethod.BILINEAR:\n    images = gen_image_ops.resize_bilinear(images,"
},
{
    "Id": 269,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c6899c721f3a4b4f2e71ae4e6d1767341112ff93",
    "Violation": "missing",
    "Bug report": "bug fix when iterators stops at multiple of batch_size ",
    "Number of deleted lines": 0,
    "Deleted lines": "      for i in xrange(self._batch_size):\n        # Add handling when queue ends.\n        try:\n          inp[i, :] = six.next(self._x)\n        except StopIteration:\n          self.stopped = True\n          inp = inp[:i, :]\n          if self._y is not None:\n            out = out[:i]\n          break\n\n        if self._y is not None:\n          y = six.next(self._y)\n          if self.n_classes is not None and self.n_classes > 1:"
},
{
    "Id": 270,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/66e0cb1d9afd251931f4f920c5d7bd638bc882b4",
    "Violation": "missing",
    "Bug report": " validate clip_norm argument in clip_by_norm API. The API clip_by_norm have argument clip_norm which accepts  0-D (scalar) `Tensor` > 0 . But if we pass -ve value for this argument then its not raising intended error and converting the input tensor into Negative which IMO is wrong. Hence I am adding validation code for -ve values to raise value error.",
    "Number of deleted lines": 0,
    "Deleted lines": "      complex type.\n  \"\"\"\n  with ops.name_scope(name, \"clip_by_norm\", [t, clip_norm]) as name:\n    values = ops.convert_to_tensor(\n        t.values if isinstance(t, indexed_slices.IndexedSlices) else t,\n        name=\"t\")\n\n    # Calculate L2-norm, clip elements by ratio of clip_norm to L2-norm\n    l2sum = math_ops.reduce_sum(values * values, axes, keepdims=True)\n    pred = l2sum > 0\n    # Two-tap tf.where trick to bypass NaN gradients\n    l2sum_safe = array_ops.where(pred, l2sum, array_ops.ones_like(l2sum))\n    l2norm = array_ops.where(pred, math_ops.sqrt(l2sum_safe), l2sum)\n    intermediate = values * clip_norm"
},
{
    "Id": 271,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/81ff894c113a5912ba52078ac27e36d06831112e",
    "Violation": "missing",
    "Bug report": "[XLA] Add bounds checks to xla::Array::Slice. To guard against specifying limits that are out of bounds, which ends up touching OOB data.",
    "Number of deleted lines": 0,
    "Deleted lines": "                 absl::Span<const int64_t> limits) const {\n    CHECK_EQ(starts.size(), num_dimensions());\n    CHECK_EQ(limits.size(), num_dimensions());\n\n    OwnedBuffer<int64_t> sizes(starts.size());\n    for (int64_t i = 0; i < starts.size(); ++i) {\n      sizes[i] = limits[i] - starts[i];\n    }\n    Array<T> result(sizes.span());\n\n    OwnedBuffer<int64_t> index(sizes_.size, default_init_t{});\n    int64_t slice_i = 0;\n    for (int64_t i = 0; i < num_elements(); ++i, next_index(&index)) {\n      if (array_impl::all_inside_range(index.span(), starts, limits)) {"
},
{
    "Id": 272,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/b7e107eaa6dffb649d055d893a1fce734ee50d55",
    "Violation": "missing",
    "Bug report": " [XLA:GPU] Error out for ptxas version - Update ptxas version check. ",
    "Number of deleted lines": 5,
    "Deleted lines": "}\n\ntsl::StatusOr<std::vector<uint8_t>> CompileGpuAsm(int cc_major, int cc_minor,\n                                                  const char* ptx_contents,\n                                                  GpuAsmOpts options,\n                                                  bool cancel_if_reg_spill) {\n  auto ptxas_version_tuple = GetAsmCompilerVersion(options.preferred_cuda_dir);\n  if (ptxas_version_tuple.value() == std::array<int64_t, 3>{12, 3, 1}) {\n    return tsl::errors::Internal(\n        absl::StrFormat(\"ptxas 12.3.1 has a bug that we think can affect XLA. \"\n                        \"Please use a different version.\"));\n  }\n  std::string ptxas_path =\n      FindCudaExecutable(\"ptxas\", options.preferred_cuda_dir);\n\n  WarnIfBadPtxasVersion(ptxas_path);\n\n  // Write ptx into a temporary file.\n  std::string ptx_path;"
},
{
    "Id": 273,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/cb164786dc891ea11d3a900e90367c339305dc7b",
    "Violation": "improper",
    "Bug report": " Properly handle the case where SpecializeType() returns an error `Status`. If the error case in `SpecializeType()` is reached, then we would get a crash when trying to access the value of an errorenous `StatusOr` object",
    "Number of deleted lines": 1,
    "Deleted lines": "\nvoid InferenceContext::PreInputInit(\n    const OpDef& op_def, const std::vector<const Tensor*>& input_tensors,\n    const std::vector<ShapeHandle>& input_tensors_as_shapes) {\n  // TODO(mdan): This is also done at graph construction. Run only here instead?\n  const auto ret = full_type::SpecializeType(attrs_, op_def);\n  DCHECK(ret.status().ok()) << \"while instantiating types: \" << ret.status();\n  ret_types_ = ret.ValueOrDie();\n\n  input_tensors_ = input_tensors;\n  input_tensors_as_shapes_ = input_tensors_as_shapes;\n\n  construction_status_ =\n      NameRangesForNode(attrs_, op_def, &input_name_map_, &output_name_map_);\n  if (!construction_status_.ok()) return;"
},
{
    "Id": 274,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/84d7bf6f64fd9c8677f7f26511ce3031fe8d35a6",
    "Violation": "missing",
    "Bug report": "Add is_numeric to dtypes.cc to check whether a data type is numeric ",
    "Number of deleted lines": 0,
    "Deleted lines": "      .def_property_readonly(\n          \"is_bool\",\n          [](tensorflow::DataType self) {\n            return tensorflow::BaseType(self) == tensorflow::DT_BOOL;\n          },\n          \"Returns whether this is a boolean data type.\")\n      .def_property_readonly(\n          \"is_complex\",\n          [](tensorflow::DataType self) {\n            return tensorflow::DataTypeIsComplex(tensorflow::BaseType(self));\n          },\n          \"Returns whether this is a complex floating point type.\")\n      .def_property_readonly(\n          \"is_floating\","
},
{
    "Id": 275,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/cd34289b744040974ebe81e1b1e88f1c752d68e0",
    "Violation": "missing",
    "Bug report": "Update types.h to check if a data type is numeric ",
    "Number of deleted lines": 0,
    "Deleted lines": "    ToSet(DT_HALF) | ToSet(DT_BFLOAT16) | ToSet(DT_FLOAT) | ToSet(DT_DOUBLE) |\n    ToSet(DT_FLOAT8_E4M3FN) | ToSet(DT_FLOAT8_E5M2);\ninline bool DataTypeIsFloating(DataType dt) {\n  return kDataTypeIsFloating.Contains(dt);\n}\n\n// Returns true iff 'dt' is a complex type.\nconstexpr DataTypeSet kDataTypeIsComplex =\n    ToSet(DT_COMPLEX64) | ToSet(DT_COMPLEX128);\ninline bool DataTypeIsComplex(DataType dt) {\n  return kDataTypeIsComplex.Contains(dt);\n}\n\ninline bool DataTypeIsQuantized(DataType dt) {"
},
{
    "Id": 276,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/43fd10302bcc8447e7a7205bae848a3a88624775",
    "Violation": "missing",
    "Bug report": "Return error on invalid input in tfl.atan2_custom",
    "Number of deleted lines": 1,
    "Deleted lines": "    case kTfLiteFloat32:\n      TF_LITE_ENSURE_OK(context, Atan2<float>(input_y, input_x, output));\n      break;\n    case kTfLiteFloat64:\n      TF_LITE_ENSURE_OK(context, Atan2<double>(input_y, input_x, output));\n      break;\n    default:\n      TF_LITE_KERNEL_LOG(context, \"Unsupported datatype for atan2 output: %s\",\n                         TfLiteTypeGetName(output->type));\n  }\n\n  return TfLiteStatus::kTfLiteOk;\n}\n\n}  // namespace atan2\n\nTfLiteRegistration* Register_ATAN2() {"
},
{
    "Id": 277,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/40c7fe94824100338ef0c495143b26501b1c367e",
    "Violation": "missing",
    "Bug report": "Return error on invalid input in tfl.topkv2 ",
    "Number of deleted lines": 0,
    "Deleted lines": "      return TopKImpl(context, node, k, GetTensorData<int16_t>(output_indexes));\n    } break;\n    default:\n      TF_LITE_KERNEL_LOG(\n          context, \"Output index type %s is currently not supported by TopK.\",\n          TfLiteTypeGetName(output_values->type));\n  }\n\n  return kTfLiteOk;\n}\n\n}  // namespace topk_v2\nTfLiteRegistration* Register_TOPK_V2() {\n  static TfLiteRegistration r = {nullptr, nullptr, topk_v2::Prepare,"
},
{
    "Id": 278,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/ef049bdfc4f307c8b3a9dc480a90a5ff287f3d55",
    "Violation": "missing",
    "Bug report": "Add check for ResizeOutput return value in range.cc",
    "Number of deleted lines": 1,
    "Deleted lines": "  output->type = dtype;\n\n  if (IsConstantOrPersistentTensor(start) &&\n      IsConstantOrPersistentTensor(limit) &&\n      IsConstantOrPersistentTensor(delta)) {\n    SetTensorToPersistentRo(output);\n    ResizeOutput(context, start, limit, delta, output);\n\n    op_data->noop = true;\n    return EvalImpl(context, start, delta, output);\n  }\n\n  SetTensorToDynamic(output);\n  return kTfLiteOk;\n}"
},
{
    "Id": 279,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1707ed9b9b0cc5cb02df22a06718c9c738825d39",
    "Violation": "missing",
    "Bug report": " Add a check to make sure that the allocation before an Evict() is not a prefetch.",
    "Number of deleted lines": 3,
    "Deleted lines": "\nAlternateMemoryBestFitHeap::Result AlternateMemoryBestFitHeap::Evict(\n    const AllocationRequest& request) {\n  CHECK_GT(request.allocation_value->allocation_sequence()->size(), 0);\n  MemorySpaceAssignment::Allocation* prev_allocation =\n      request.allocation_value->allocation_sequence()->back().get();\n  // TODO(b/306478911): prev_allocation can never be a prefetch, or we would be\n  // using an incorrect start time (we would need to wait until the copies\n  // finish)\n\n  // The previous allocation's inclusive start time is the eviction's exclusive\n  // start time to ensure that the value is created before we start copying\n  // back to default memory.\n  int64_t eviction_exclusive_start_time = prev_allocation->start_time();\n  int64_t eviction_end_time = prev_allocation->end_time();\n  CHECK(eviction_exclusive_start_time <= eviction_end_time);\n"
},
{
    "Id": 280,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/f636be3bb1f556c15dba3028e61a8969d90dadd9",
    "Violation": "misleading",
    "Bug report": "Return error on invalid input in tfl.sign_custom",
    "Number of deleted lines": 5,
    "Deleted lines": "      break;\n    case kTfLiteFloat64:\n      TF_LITE_ENSURE_OK(\n          context,\n          (PointwiseUnaryOpDoEval<Op, double>(context, input, output)));\n      break;\n    default:\n      TF_LITE_KERNEL_LOG(\n          context,\n          \"Unsupported datatype for atan2 output: %s\",\n          TfLiteTypeGetName(output->type));\n  }\n\n  return TfLiteStatus::kTfLiteOk;\n}\n\n// Operator that computes the sign function.\nstruct Sign {\n  template <typename T>"
},
{
    "Id": 281,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/e99e31597c1b5cc9f0cbc8a3dea71674d81c20b1",
    "Violation": "misleading",
    "Bug report": " Fix GRUCellBlockOp message for invalid rank of x. The validation checks that x is a matrix, so rank must be 2.",
    "Number of deleted lines": 2,
    "Deleted lines": "    OP_REQUIRES_OK(ctx, ctx->input(\"b_c\", &b_c_tensor));\n\n    // Sanity checks for input shapes.\n\n    // Shape of 'x' must be [batch_size, input_size]\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(x_tensor->shape()),\n                errors::InvalidArgument(\"Rank of x must be 2\", x_tensor->dims(),\n                                        \" vs. 2\"));\n    const int64_t batch_size = x_tensor->dim_size(0);\n    const int64_t input_size = x_tensor->dim_size(1);\n\n    // Shape of 'h' must be [batch_size, cell_size]\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(h_prev_tensor->shape()),\n                errors::InvalidArgument(\"Rank of h_prev must be 2, got \",\n                                        h_prev_tensor->dims()));\n    OP_REQUIRES(ctx, h_prev_tensor->dim_size(0) == batch_size,"
},
{
    "Id": 282,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/18dd91ccd4b1817cd5c34e40f76823a162bea029",
    "Violation": "misleading",
    "Bug report": " [XLA] Report that real -> complex bitcast_convert is not allowed. The check as exists is bidirectional: it prevents conversions from complex to real and real to complex alike, but the reported error message was unidirectional.",
    "Number of deleted lines": 1,
    "Deleted lines": "\n/* static */ StatusOr<Shape> ShapeInference::InferBitcastConvertShape(\n    const Shape& operand_shape, PrimitiveType new_element_type) {\n  auto old_element_type = operand_shape.element_type();\n  if (primitive_util::IsComplexType(old_element_type) !=\n      primitive_util::IsComplexType(new_element_type)) {\n    return InvalidArgument(\"Conversion from complex to real type %s => %s.\",\n                           ShapeUtil::HumanString(operand_shape),\n                           PrimitiveType_Name(new_element_type));\n  }\n  if (!operand_shape.IsArray() ||\n      !primitive_util::IsArrayType(new_element_type)) {\n    // Note: we may want to support tuple conversions via this operation in the\n    // future, by recursing into the tuple elements to check all sub-conversions\n    // are valid. For now we just reject them, though."
},
{
    "Id": 283,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1e5c11676dce37bb7c8eb58b35fd298a655c6fd3",
    "Violation": "misleading",
    "Bug report": " [tf.data service] Include dispatcher address in version check error message. This is the error message that happens when the address was specified incorrectly, so it is useful to include the potentially-incorrect address in the error message.",
    "Number of deleted lines": 1,
    "Deleted lines": "  GetVersionResponse resp;\n  TF_RETURN_IF_ERROR(grpc_util::Retry(\n      [&] {\n        grpc::ClientContext ctx;\n        grpc::Status s = stub_->GetVersion(&ctx, req, &resp);\n        if (!s.ok()) {\n          return grpc_util::WrapError(\"Failed to get dispatcher version\", s);\n        }\n        return Status::OK();\n      },\n      \"check service version\",\n      /*deadline_micros=*/kint64max));\n  if (resp.version() != kDataServiceVersion) {\n    return errors::FailedPrecondition(\n        \"Version mismatch with tf.data service server. The server is running \""
},
{
    "Id": 284,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/07898e752cf02518508f193a0be2e451450044bd",
    "Violation": "misleading",
    "Bug report": " Provide a more informative error message when the bazel version check fails. ",
    "Number of deleted lines": 2,
    "Deleted lines": "  _TF_BAZELRC = os.path.join(_TF_WORKSPACE_ROOT, _TF_BAZELRC_FILENAME)\n\n  # Make a copy of os.environ to be clear when functions and getting and setting\n  # environment variables.\n  environ_cp = dict(os.environ)\n\n  current_bazel_version = check_bazel_version(_TF_MIN_BAZEL_VERSION,\n                                              _TF_MAX_BAZEL_VERSION)\n  _TF_CURRENT_BAZEL_VERSION = convert_version_to_int(current_bazel_version)\n\n  reset_tf_configure_bazelrc()\n\n  cleanup_makefile()\n  setup_python(environ_cp)\n\n  if is_windows():"
},
{
    "Id": 285,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/01e84d7cc214dbf5a7a21bc418ad43afb5694fbc",
    "Violation": "misleading",
    "Bug report": " Update error message for data_adapter with validation split. Remove the user provided value in the error string in case it contains large amount of data. Dump large input data to log might crash on user side.",
    "Number of deleted lines": 2,
    "Deleted lines": "    tensor_types = (ops.Tensor, np.ndarray)\n    if pd:\n      tensor_types = (ops.Tensor, np.ndarray, pd.Series, pd.DataFrame)\n    return isinstance(t, tensor_types) or t is None\n\n  flat_arrays = nest.flatten(arrays)\n  if not all(_can_split(t) for t in flat_arrays):\n    raise ValueError(\n        \"`validation_split` is only supported for Tensors or NumPy \"\n        \"arrays, found: {}\".format(arrays))\n\n  if all(t is None for t in flat_arrays):\n    return arrays, arrays\n\n  first_non_none = None\n  for t in flat_arrays:\n    if t is not None:\n      first_non_none = t"
},
{
    "Id": 286,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/4c75fb1cb917320acb386cf26adeb8e5151ca4f6",
    "Violation": "misleading",
    "Bug report": " Improve error message reporting for check_numerics gradient. At present the op message is only printed if the numeric check fails during the op's 'forward' computation. If the check fails during the gradient, there is no identifier on *which* op's gradient failed.",
    "Number of deleted lines": 2,
    "Deleted lines": "  else:\n    ref_grad = array_ops.scatter_nd(indices, grad, ref_shape)\n  return [ref_grad, None]\n\n\n@ops.RegisterGradient(\"CheckNumerics\")\ndef _CheckNumericsGrad(_, grad):\n  \"\"\"Gradient for check_numerics op.\"\"\"\n  return array_ops.check_numerics(\n      grad, \"Not a number (NaN) or infinity (Inf) values detected in gradient.\")\n\n\n@ops.RegisterGradient(\"PlaceholderWithDefault\")\n@ops.RegisterGradient(\"Identity\")\ndef _IdGrad(_, grad):\n  return grad\n\n"
},
{
    "Id": 287,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/40918f36823973e816bd50766b1f447225b1bb9b",
    "Violation": "misleading",
    "Bug report": " Make the type check error message more informative for contrib.layers fully_connected.",
    "Number of deleted lines": 2,
    "Deleted lines": "     The tensor variable representing the result of the series of operations.\n\n  Raises:\n    ValueError: If x has rank less than 2 or if its last dimension is not set.\n  \"\"\"\n  if not isinstance(num_outputs, six.integer_types):\n    raise ValueError('num_outputs should be int or long, got %s.' %\n                     (num_outputs,))\n\n  layer_variable_getter = _build_variable_getter({\n      'bias': 'biases',\n      'kernel': 'weights'\n  })\n\n  with variable_scope.variable_scope(\n      scope,"
},
{
    "Id": 288,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9c1f14322484e44a93b77619ffd2e24b9b7a9b1d",
    "Violation": "misleading",
    "Bug report": " Fix error message in TF-keras dataset shape check. (Dimension and tensor # were transposed in the error message)",
    "Number of deleted lines": 1,
    "Deleted lines": "            hint = ''\n          raise ValueError(\n              'The Keras-TPU integration for `tf.data` '\n              'currently requires static shapes. The provided '\n              'dataset only has a partially defined shape. '\n              '(Dimension %d of output tensor %d is not statically known '\n              'for output shapes: %s.%s)' % (i, j, dataset.output_shapes, hint))\n\n  @property\n  def dummy_x(self):\n    return self._dummy_x\n\n  @property\n  def dummy_y(self):\n    return self._dummy_y"
},
{
    "Id": 289,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/f0bf6c5191d224f229808f4b321158d890a481e0",
    "Violation": "misleading",
    "Bug report": "Minor change for better error msg in eager input type checking ",
    "Number of deleted lines": 1,
    "Deleted lines": "        memtypes[i] == HOST_MEMORY ? host_device : op_device;\n    TF_RETURN_IF_ERROR(MaybeCopyInputToExpectedDevice(\n        op, i, expected_device, run_metadata, &((*op->MutableInputs())[i])));\n    tensorflow::TensorHandle* handle = op->Inputs()[i];\n    if (handle->dtype != kernel->input_type(i)) {\n      return errors::InvalidArgument(\n          \"cannot compute \", op->Name(), \" as input #\", i,\n          \" was expected to be a \", DataTypeString(kernel->input_type(i)),\n          \" tensor but is a \", DataTypeString(handle->dtype), \" tensor\");\n    }\n  }\n  return Status::OK();\n}\n\nStatus SelectDevice(const NodeDef& ndef, EagerContext* ctx, Device** device) {"
},
{
    "Id": 290,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/178d62a63ea043a4b9969b4cd6f8983eb8eae523",
    "Violation": "misleading",
    "Bug report": " Update check failure to logging a warning for repeated computation placer registration. This is to bypass a duplicated registration issue seen in open-source build during TF/PJRT integration.",
    "Number of deleted lines": 1,
    "Deleted lines": "\n/* static */ void ComputationPlacer::RegisterComputationPlacer(\n    se::Platform::Id platform_id,\n    ComputationPlacerCreationFunction creation_function) {\n  absl::MutexLock lock(&ComputationPlacer::platform_computation_placer_mutex_);\n  auto* computation_placers = GetPlatformComputationPlacers();\n  CHECK(computation_placers->find(platform_id) == computation_placers->end());\n  (*computation_placers)[platform_id].creation_function = creation_function;\n}\n\n/* static */ StatusOr<ComputationPlacer*> ComputationPlacer::GetForPlatform(\n    const se::Platform* platform) {\n  absl::MutexLock lock(&ComputationPlacer::platform_computation_placer_mutex_);\n  auto* computation_placers = GetPlatformComputationPlacers();\n"
},
{
    "Id": 291,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/6aece71ebf756d32ea730576a7ff12d2cfc7b242",
    "Violation": "insufficient",
    "Bug report": "Places relatively cheap type checks for list, tuple, and dict before other more expensive checks. Specifically, this avoids calling expensive checks like isinstance(structure, collections.abc.Mapping) and nest._is_named_tuple in the most common cases (since these abc isinstance checks take ~10x as long as normal isinstance checks).",
    "Number of deleted lines": 1,
    "Deleted lines": "  Args:\n    iterable: an iterable.\n\n  Yields:\n    The iterable's (key, value) pairs, in order of sorted keys.\n  \"\"\"\n  if isinstance(iterable, _collections_abc.Mapping):\n    # Iterate through dictionaries in a deterministic order by sorting the\n    # keys. Notice this means that we ignore the original order of `OrderedDict`\n    # instances. This is intentional, to avoid potential bugs caused by mixing\n    # ordered and plain dicts (e.g., flattening a dict but using a\n    # corresponding `OrderedDict` to pack it back).\n    for key in _sorted(iterable):\n      yield key, iterable[key]\n  elif _is_attrs(iterable):"
},
{
    "Id": 292,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a7c02f1a9bbc35473969618a09ee5f9f5d3e52d9",
    "Violation": "missing",
    "Bug report": " Validate real and expected type of arguments to cwise ops. Without this validation, it is possible to trigger a `CHECK`-fail denial of service.",
    "Number of deleted lines": 0,
    "Deleted lines": "  explicit BinaryOp(OpKernelConstruction* ctx)\n      : BinaryOpShared(ctx, DataTypeToEnum<Tout>::v(),\n                       DataTypeToEnum<Tin>::v()) {}\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input_0 = ctx->input(0);\n    const Tensor& input_1 = ctx->input(1);\n    const Device& eigen_device = ctx->eigen_device<Device>();\n    bool error = false;\n    bool* const error_ptr = Functor::has_errors ? &error : nullptr;\n\n    // NOTE: Handle three simple cases before building the BinaryOpState, which\n    // is relatively expensive for small operations.\n    if (input_0.shape() == input_1.shape()) {\n      // tensor op tensor with no broadcasting."
},
{
    "Id": 293,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/798b2ebda0cc6f12f1ca6460611f760149771a11",
    "Violation": "missing",
    "Bug report": " Ensure the allocation type is kTfLiteCustom when doing shallow copies in DeepOrShallowCopyTensorsShapeTypeData.  This code is correct only under the assumption that the caller has correctly prepared the tensors that get passed in for shallow copying, by setting their allocation types to kTfLiteCustom. This ensures that those tensors won't be double `free`'d later on. This check simply ensures that that assumption always holds, to ensure we fail early if ever a bug is introduced that breaks that assumption.",
    "Number of deleted lines": 0,
    "Deleted lines": "        src_subgraph->tensor(src_tensor_indices[i]);\n    TfLiteTensor* dst_tensor = dst_subgraph->tensor(dst_tensor_indices[i]);\n    if (IsResourceOrVariant(src_tensor)) {\n      TfLiteTensorRealloc(src_tensor->bytes, dst_tensor);\n      TF_LITE_ENSURE_OK(context, TfLiteTensorCopy(src_tensor, dst_tensor));\n    } else {\n      dst_tensor->bytes = src_tensor->bytes;\n      dst_tensor->data.raw = src_tensor->data.raw;\n    }\n  }\n  return kTfLiteOk;\n}\n}  // namespace builtin\n}  // namespace ops"
},
{
    "Id": 294,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/b65d9ec2b78c7c23e368ed4eec7b4deb89dcd712",
    "Violation": "insufficient",
    "Bug report": "Fix value error generated on is_scalar check. Fix value error generated on is_scalar check. `is_scalar = shape is not None and not shape` raises a value error when shape is a scalar, \"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\"",
    "Number of deleted lines": 1,
    "Deleted lines": "    # Note: the parameters of _true_getter, and their documentation, match\n    # *exactly* item-for-item with the docstring of this method.\n    def _true_getter(name, shape=None, dtype=dtypes.float32,  # pylint: disable=missing-docstring\n                     initializer=None, regularizer=None, reuse=None,\n                     trainable=True, collections=None, caching_device=None,\n                     partitioner=None, validate_shape=True, use_resource=None):\n      is_scalar = shape is not None and not shape\n      # Partitioned variable case\n      if partitioner is not None and not is_scalar:\n        if not callable(partitioner):\n          raise ValueError(\n              \"Partitioner must be callable, but received: %s\" % partitioner)\n        with ops.name_scope(None):\n          return self._get_partitioned_variable(name=name,\n                                                shape=shape,"
},
{
    "Id": 295,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9baa064387b0a114c3fcec88abaa0568834e8e34",
    "Violation": "insufficient",
    "Bug report": " Only apply check for non-tensor case ",
    "Number of deleted lines": 3,
    "Deleted lines": "  # Convert lower/mixed case to upper for NumPy compatibility\n  # NumPy uses all lower-case modes.\n  mode = mode.upper()\n  if mode == \"CONSTANT\":\n    # TODO(rjryan): Once the forward compatibility period (3 weeks) have passed\n    # remove the \"Pad\" fallback here.\n    if constant_values != 0:\n      result = gen_array_ops.pad_v2(\n          tensor, paddings, constant_values, name=name)\n    else:\n      result = gen_array_ops.pad(tensor, paddings, name=name)\n  elif mode == \"REFLECT\":\n    result = gen_array_ops.mirror_pad(\n        tensor, paddings, mode=\"REFLECT\", name=name)\n  elif mode == \"SYMMETRIC\":\n    result = gen_array_ops.mirror_pad(\n        tensor, paddings, mode=\"SYMMETRIC\", name=name)\n  else:\n    raise ValueError(\"Unknown padding mode: %s\" % mode)"
},
{
    "Id": 296,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/cb2828a844ccaf0394e602d15fd95e45073729a2",
    "Violation": "missing",
    "Bug report": " Check that the type of an implicitly dereferenced tensor matches the expected input type. The dtype of a tensor reference can change between the point when it is \"produced\" by an operation and consumed by the next operation. This evades checks in the executor that the type of tensor on each edge matches the type signatures of the producing and consuming operation, which could lead to undefined behavior. Although there is no existing operation that changes the type of a tensor reference, it is possible to use the OpKernelContext API to do so, so we add a further check in the runtime to defend against operations that might be added in the future.",
    "Number of deleted lines": 0,
    "Deleted lines": "          entry->val_field_is_set = true;\n        }\n        entry->ref = nullptr;\n        entry->ref_mu = nullptr;\n\n        inp->tensor = entry->val.get();\n      }\n    }\n  }\n  return Status::OK();\n}\n\nStatus ExecutorState::ProcessOutputs(const NodeItem& item, OpKernelContext* ctx,\n                                     EntryVector* outputs,"
},
{
    "Id": 297,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/924f80a4fdb34230965a7a8a4476901847463645",
    "Violation": "missing",
    "Bug report": "Add stricter type checking for tf.math.real. Fix for tf.math.real so that it only accepts tensors with numeric entries as input.",
    "Number of deleted lines": 1,
    "Deleted lines": "  \"\"\"\n  with ops.name_scope(name, \"Real\", [input]) as name:\n    input = ops.convert_to_tensor(input, name=\"input\")\n    if input.dtype.is_complex:\n      real_dtype = input.dtype.real_dtype\n      return gen_math_ops.real(input, Tout=real_dtype, name=name)\n    else:\n      return input\n\n\n@tf_export(\"math.imag\", v1=[\"math.imag\", \"imag\"])\n@dispatch.register_unary_elementwise_api\n@dispatch.add_dispatch_support\n@deprecation.deprecated_endpoints(\"imag\")\ndef imag(input, name=None):\n  r\"\"\"Returns the imaginary part of a complex (or real) tensor."
},
{
    "Id": 298,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/e6df768b81e973f2123bc83a18a60773fc4da99e",
    "Violation": "insufficient",
    "Bug report": "[TFG] Fix IsAdd string type check in tf_op_names ",
    "Number of deleted lines": 1,
    "Deleted lines": "namespace tfg {\n\nbool TFGraphDialect::IsAdd(TFOp op) const {\n  StringAttr op_name = op->getName().getIdentifier();\n\n  if (op_name == add_v2_) return true;\n  if (op_name == add_) return !op->getAttrOfType<StringAttr>(\"T\");\n  return false;\n}\n\nbool TFGraphDialect::IsAddN(TFOp op) const {\n  StringAttr op_name = op->getName().getIdentifier();\n  return op_name == add_n_;\n}\n"
},
{
    "Id": 299,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/4f4a0276a2cf9186c0541072964676159368286e",
    "Violation": "missing",
    "Bug report": " Add appropriate PyObject type check for bool. This PR fixes an issue where PyObject type in tf's C bindings does not check if an input is a boolean and will always cast to bool.",
    "Number of deleted lines": 2,
    "Deleted lines": "          .c_str());\n  return false;\n}\n\nbool ParseBoolValue(const string& key, PyObject* py_value, TF_Status* status,\n                    unsigned char* value) {\n  *value = PyObject_IsTrue(py_value);\n  return true;\n}\n\n// The passed in py_value is expected to be an object of the python type\n// dtypes.DType or an int.\nbool ParseTypeValue(const string& key, PyObject* py_value, TF_Status* status,\n                    int* value) {\n  if (IsInteger(py_value)) {\n    return ParseIntValue(key, py_value, status, value);"
},
{
    "Id": 300,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/88609e2e22fa5c296de2e27e04d1cc4743b2dfcd",
    "Violation": "missing",
    "Bug report": " Add appropriate dtype check for tf.boolean_mask's mask. This PR tries to address the issue raised in 54412 where mask's dtype was checked in tf.boolean_mask and an invalid result has been returned instead.",
    "Number of deleted lines": 0,
    "Deleted lines": "    indices = squeeze(where_v2(mask), axis=[1])\n    return gather(reshaped_tensor, indices, axis=axis)\n\n  with ops.name_scope(name, values=[tensor, mask]):\n    tensor = ops.convert_to_tensor(tensor, name=\"tensor\")\n    mask = ops.convert_to_tensor(mask, name=\"mask\")\n\n    shape_mask = mask.get_shape()\n    ndims_mask = shape_mask.ndims\n    shape_tensor = tensor.get_shape()\n    if ndims_mask == 0:\n      raise ValueError(\"mask cannot be scalar.\")\n    if ndims_mask is None:\n      raise ValueError("
},
{
    "Id": 301,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a76646d4b4ad5d56b5e63c139985bbd1eb98dd90",
    "Violation": "misleading",
    "Bug report": " Add type checking at the beginning of tpu.shard(). Otherwise a message like \"TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.\" will be thrown, which is confusing.",
    "Number of deleted lines": 1,
    "Deleted lines": "    ValueError: If len(output_shard_axes) != len(outputs from `computation`)\n  \"\"\"\n\n  if num_shards <= 0:\n    raise ValueError(\"num_shards must be a positive integer.\")\n\n  # Converts inputs to Tensors.\n  inputs = [] if inputs is None else [ops.convert_to_tensor(x) for x in inputs]\n\n  if input_shard_axes is None:\n    input_shard_axes = [0] * len(inputs)\n  if len(inputs) != len(input_shard_axes):\n    raise ValueError(\"Length of input_shard_axes must be equal to the number \"\n                     \"of inputs.\")\n\n  if inputs:"
},
{
    "Id": 302,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1c49c13ba59961cf7581e3e29b951db8faca94f5",
    "Violation": "missing",
    "Bug report": "Add type check for reduction axis in reducer operation. ",
    "Number of deleted lines": 0,
    "Deleted lines": "\nTfLiteStatus PrepareSimple(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  OpContext op_context(context, node);\n  TF_LITE_ENSURE_OK(context, InitializeTemporaries(context, node, &op_context));\n\n  TfLiteTensor* resolved_axis = GetTemporary(context, node, /*index=*/1);\n  // Leaves work to Eval if axis is not constant; else resizes output.\n  if (!IsConstantTensor(op_context.axis)) {\n    SetTensorToDynamic(op_context.output);\n    SetTensorToDynamic(resolved_axis);\n    return kTfLiteOk;"
},
{
    "Id": 303,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/b6f3366a716ca9b5a1e6114a3bea050c80d8a475",
    "Violation": "missing",
    "Bug report": " Don't check for if null after already dereferenced. I'm not sure how it could be null at this point (and obviously it is nowhere else we'd have seen failures), but keeping the check as is and just moving it to where it would catch it before dereferencing.",
    "Number of deleted lines": 3,
    "Deleted lines": "  opts.expect_device_spec = false;\n  TF_RETURN_IF_ERROR(ConvertNodeDefsToGraph(opts, result.nodes, graph.get()));\n\n  const StackTracesMap& stack_traces =\n      lib_def->GetStackTraces(fdef.signature().name());\n  for (Node* n : graph->nodes()) {\n    auto it = stack_traces.find(n->name());\n    if (n && it != stack_traces.end()) {\n      n->SetStackTrace(it->second);\n    }\n  }\n\n  // Call BuildControlFlowInfo to validate that this function body has\n  // well-formed control flow.\n  std::vector<ControlFlowInfo> dummy;\n  TF_RETURN_IF_ERROR(BuildControlFlowInfo(graph.get(), &dummy));\n"
},
{
    "Id": 304,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/89fa1ae2cb34eab0e6137e72e6fab01f6c5bc164",
    "Violation": "improper",
    "Bug report": "Fix check for cloning FunctionLibraryRuntime",
    "Number of deleted lines": 1,
    "Deleted lines": "    std::unique_ptr<ProcessFunctionLibraryRuntime>* out_pflr,\n    FunctionLibraryRuntime** out_flr, bool skip_flib_def) {\n  TF_RETURN_IF_ERROR(parent_->Clone(\n      env_, graph_def_version_, optimizer_.options(), custom_kernel_creator_,\n      out_lib_def, out_pflr, skip_flib_def));\n  *out_flr = (*out_pflr)->GetFLR(device_->name());\n  if (out_flr != nullptr) {\n    return Status::OK();\n  } else {\n    return errors::Internal(\"Cloning FunctionLibraryRuntime failed.\");\n  }\n}\n\nnamespace {\n"
},
{
    "Id": 305,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/3a7b36bca7f43ce4f0d0791ce0e0d84ece8683d9",
    "Violation": "improper",
    "Bug report": " [Grappler] Remove DCHECK from a MutableGraphView CanDedupControlWithRegularInput check.",
    "Number of deleted lines": 2,
    "Deleted lines": "// control dependency. Specifically, if a node is an Identity that leads to a\n// Switch node, when used as a control dependency, that control dependency\n// should not be deduped even though the same node is used as a regular input.\nbool CanDedupControlWithRegularInput(const MutableGraphView& graph,\n                                     absl::string_view control_node_name) {\n  NodeDef* control_node = graph.GetNode(control_node_name);\n  DCHECK(control_node != nullptr)\n      << \"Didn't find a node for control dependency: \" << control_node_name;\n  return CanDedupControlWithRegularInput(graph, *control_node);\n}\n\nbool HasRegularFaninNode(const MutableGraphView& graph, const NodeDef& node,\n                         absl::string_view fanin_node_name) {\n  const int num_regular_fanins =\n      graph.NumFanins(node, /*include_controlling_nodes=*/false);\n  for (int i = 0; i < num_regular_fanins; ++i) {"
},
{
    "Id": 306,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c5019e2156c749d35ec786ff7946a55006d9ba91",
    "Violation": "missing",
    "Bug report": "missing checking on null pointer dereference",
    "Number of deleted lines": 1,
    "Deleted lines": "  stats_->largest_alloc_size = 0;\n  return true;\n}\n\nvoid GpuCudaMallocAsyncAllocator::SetStream(void* stream) {\n#if TF_CUDA_MALLOC_ASYNC_SUPPORTED\n  uint64_t pool_size_64 = 0;\n  if (auto status = cuMemPoolGetAttribute(\n          pool_, CU_MEMPOOL_ATTR_RELEASE_THRESHOLD, &pool_size_64)) {\n    LOG(FATAL) <<  // Crash OK.\n        \"Failed to get CUDA pool attribute: \" << GetCudaErrorMessage(status);\n\n  }\n  cuda_stream_ = *(reinterpret_cast<CUstream*>(stream));\n  int64 prealloc_size = 0;\n  // TF_CUDA_MALLOC_ASYNC_SUPPORTED_PREALLOC=-1 is a special value that\n  // preallocates the total pool size.\n  TF_CHECK_OK(ReadInt64FromEnvVar(\"TF_CUDA_MALLOC_ASYNC_SUPPORTED_PREALLOC\", 0,\n                                  &prealloc_size));\n  if (prealloc_size == -1) {"
},
{
    "Id": 307,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a7908e924af3105c3007988e219855174b26774f",
    "Violation": "missing",
    "Bug report": "Added check for output buffer ",
    "Number of deleted lines": 0,
    "Deleted lines": "// -----------------------------------------------------------------------------\n// Compression\n\nnamespace {\nbool CompressInternal(const uint8* srcdata, int width, int height,\n                      const CompressFlags& flags, tstring* output) {\n  output->clear();\n  const int components = (static_cast<int>(flags.format) & 0xff);\n\n  int64 total_size = static_cast<int64>(width) * static_cast<int64>(height);\n  // Some of the internal routines do not gracefully handle ridiculously\n  // large images, so fail fast.\n  if (width <= 0 || height <= 0) {\n    LOG(ERROR) << \"Invalid image size: \" << width << \" x \" << height;"
},
{
    "Id": 308,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/04b97cde86550995da57d16d81084006456ccce5",
    "Violation": "missing",
    "Bug report": "Fix segmentation fault with tf.stack an keras's Input in TF2.0. This fix adds the `PySequence_Fast` and checks the return value to make sure it is not nullptr.",
    "Number of deleted lines": 2,
    "Deleted lines": "        VLOG(1) << \"Falling back to slow path for Op \\\"\" << op_def.name()\n                << \"\\\", Input \\\"\" << op_def.input_arg(i).name()\n                << \"\\\" since we expected a sequence, but got \"\n                << item->ob_type->tp_name;\n        return false;\n      }\n      for (Py_ssize_t j = 0; j < PySequence_Fast_GET_SIZE(item); j++) {\n        PyObject* inner_item = PySequence_Fast_GET_ITEM(item, j);\n        if (!CheckOneInput(inner_item)) {\n          VLOG(1) << \"Falling back to slow path for Op \\\"\" << op_def.name()\n                  << \"\\\", Input \\\"\" << op_def.input_arg(i).name()\n                  << \"\\\", Index \" << j\n                  << \" since we expected an EagerTensor/ResourceVariable, \"\n                     \"but got \"\n                  << inner_item->ob_type->tp_name;\n          return false;"
},
{
    "Id": 309,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/cd8d0bf58ad554588012898161c91fa453bbf7f0",
    "Violation": "missing",
    "Bug report": "Address edge case where runStats is null and the interface is closed.",
    "Number of deleted lines": 1,
    "Deleted lines": "   */\n  public void close() {\n    closeFeeds();\n    closeFetches();\n    sess.close();\n    g.close();\n    runStats.close();\n    runStats = null;\n    enableStats = false;\n  }\n\n  // Methods for taking a native Tensor and filling it with values from Java arrays.\n\n  /**\n   * Given a source array with shape {@link dims} and content {@link src}, copy the contents into"
},
{
    "Id": 310,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1a1a381b5be7701843c3f1e34aa1846ae2a1d0ce",
    "Violation": "improper",
    "Bug report": "Fix a SIGSEGV bug in InferShapeForXlaGatherOp. Since `ComputeOutputComponent` may return nullptr, we need to check for null attributes explicitly to be safe.",
    "Number of deleted lines": 1,
    "Deleted lines": "  DenseIntElementsAttr slice_sizes_attr;\n  if (DenseIntElementsAttr attr;\n      matchPattern(op.getSliceSizes(), m_Constant(&attr))) {\n    slice_sizes_attr = attr;\n  } else if (const auto it = results_.find(ValuePort(op.getSliceSizes()));\n             it != results_.end() &&\n             llvm::isa<DenseIntElementsAttr>(it->second)) {\n    slice_sizes_attr = llvm::cast<DenseIntElementsAttr>(it->second);\n  } else {\n    return false;\n  }\n\n  llvm::SmallVector<int64_t> slice_sizes;\n  for (const auto& attr : slice_sizes_attr.getValues<APInt>()) {\n    slice_sizes.push_back(attr.getSExtValue());"
},
{
    "Id": 311,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9720b405905dee209a3f7d003de21d388e1aaef4",
    "Violation": "improper",
    "Bug report": " Avoid nullptr as row offsets to cusparseCreateCsr. As of CUDA 12.2 additional input validation allows NULL for the row offsets only when rows=0.",
    "Number of deleted lines": 1,
    "Deleted lines": "                         b_input_matrix->col_indices_vec(b_batch).data(),\n                         b_input_matrix->values_vec<T>(b_batch).data()));\n      OP_REQUIRES_OK(ctx,\n                     matC.InitializeCsr<int, T>(\n                         a_input_dense_shape(a_input_dense_shape.size() - 2),\n                         b_input_dense_shape(b_input_dense_shape.size() - 1), 0,\n                         nullptr, nullptr, nullptr));\n\n      // Check required size for buffer1 and possibly re-allocate\n      size_t bufferSize1;\n      OP_REQUIRES_OK(\n          ctx, cudaSparse.SpGEMM_workEstimation<T>(matA, matB, matC, gemmDesc,\n                                                   &bufferSize1, nullptr));\n      if (bufferSize1 > buffer1_t.NumElements()) {\n        OP_REQUIRES_OK("
},
{
    "Id": 312,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/47eaa828a1dd4bf50ec4203ef4bbb348b3ef0dd0",
    "Violation": "missing",
    "Bug report": "Add nullptr check",
    "Number of deleted lines": 0,
    "Deleted lines": "  auto* cc_ctx = reinterpret_cast<::tensorflow::OpKernelContext*>(ctx);\n  if (i < 0 || i >= cc_ctx->num_inputs()) {\n    TF_SetStatus(status, TF_OUT_OF_RANGE, \"input index out of range\");\n    return;\n  }\n  const ::tensorflow::Tensor& cc_tensor(cc_ctx->input(i));\n  TF_Tensor* result =\n      ::tensorflow::TF_TensorFromTensor(cc_tensor, &status->status);\n  if (TF_GetCode(status) == TF_OK) {\n    *tensor = result;\n  }\n}\n\nvoid TF_InputRange(TF_OpKernelContext* ctx, const char* name,"
},
{
    "Id": 313,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c2fc1f2b5a8b8152c43b81cf31394f3e0a2cb837",
    "Violation": "missing",
    "Bug report": "Add null pointer check",
    "Number of deleted lines": 0,
    "Deleted lines": "      \"doing cuBLAS SGEMM: at=%d bt=%d m=%u n=%u \"\n      \"k=%u alpha=%p a=%p lda=%d b=%p ldb=%d beta=%p \"\n      \"c=%p ldc=%d\",\n      static_cast<int>(transa), static_cast<int>(transb), m, n, k, alpha,\n      a.opaque(), lda, b.opaque(), ldb, beta, c->opaque(), ldc);\n\n  switch (dtype) {\n    case blas::DataType::kHalf: {\n#if CUDA_VERSION < 7050\n      return tsl::errors::Internal(\n          \"fp16 sgemm is not implemented in this cuBLAS version \"\n          \"(need at least CUDA 7.5)\");\n#endif\n"
},
{
    "Id": 314,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/b677392e4af8095dbde8068b0ceb60bca815e94b",
    "Violation": "missing",
    "Bug report": " Reject non-PjRt devices in PjRtArray::Reshard(). PjRt buffers traditionally support some degree of interoperability between PjRt clients (e.g., CPU and TPU). However, this is not universally true between arbitrary IFRT clients that may use a non-PjRt-compatible runtime. This change adds extra checks to make sure that non-PjRt devices are not accidentally used in PjRtArray's destination devices.",
    "Number of deleted lines": 0,
    "Deleted lines": "          // TODO(hyeontaek): We may try std::move(pjrt_buffers_[i]), but this\n          // would be unsafe if there is a subsequent access to the buffer.\n          buffers.push_back(pjrt_buffers_[i]);\n          break;\n      }\n    } else {\n      TF_ASSIGN_OR_RETURN(\n          std::unique_ptr<xla::PjRtBuffer> copied_buffer,\n          pjrt_buffers_[i]->CopyToDevice(new_sharding->devices()[i]));\n      if (semantics == ArrayCopySemantics::kDonateInput) {\n        pjrt_buffers_[i] = nullptr;\n      }\n      buffers.push_back(std::shared_ptr<PjRtBuffer>(copied_buffer.release()));\n    }"
},
{
    "Id": 315,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/aaa3fb49374d59c89115730c8e2f672e70b9e3fa",
    "Violation": "missing",
    "Bug report": " [TFLite] Bucketize op: Fix processing of bucket boundary array. The param value may be a nullptr, which is an error; we should catch this and avoid dereferencing it.",
    "Number of deleted lines": 0,
    "Deleted lines": "      auto params = safe_allocator.Allocate<TfLiteBucketizeParams>();\n      TF_LITE_ENSURE(error_reporter, params != nullptr);\n      if (const auto* bucketize_params =\n              op->builtin_options_as_BucketizeOptions()) {\n        const flatbuffers::Vector<float>* boundaries =\n            bucketize_params->boundaries();\n        params->num_boundaries = boundaries->size();\n        params->boundaries = boundaries->data();\n      }\n      *builtin_data = params.release();\n      return kTfLiteOk;\n    }\n    case BuiltinOperator_RANDOM_UNIFORM: {\n      auto params = safe_allocator.Allocate<TfLiteRandomParams>();\n      TF_LITE_ENSURE(error_reporter, params != nullptr);"
},
{
    "Id": 316,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1835465ac5a9c823f7187cb0dd5786da9c360838",
    "Violation": "missing",
    "Bug report": " Add error_reporter DCHECK back into SimpleMemoryAllocator. This check was removed due to an internal build problem.",
    "Number of deleted lines": 0,
    "Deleted lines": "                                             size_t buffer_size)\n    : SimpleMemoryAllocator(error_reporter, buffer, buffer + buffer_size) {}\n\n/* static */\nSimpleMemoryAllocator* SimpleMemoryAllocator::Create(\n    ErrorReporter* error_reporter, uint8_t* buffer_head, size_t buffer_size) {\n  TFLITE_DCHECK(buffer_head != nullptr);\n  SimpleMemoryAllocator tmp =\n      SimpleMemoryAllocator(error_reporter, buffer_head, buffer_size);\n\n  // Allocate enough bytes from the buffer to create a SimpleMemoryAllocator.\n  // The new instance will use the current adjusted tail buffer from the tmp\n  // allocator instance.\n  uint8_t* allocator_buffer = tmp.AllocateFromTail("
},
{
    "Id": 317,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/7578e120de2a3a5282ced8d41881f19363f83466",
    "Violation": "missing",
    "Bug report": " Fix crash on closing the app when classifier failed to initialize. When testing on an API 21 emulator, the classifier fails to initialize. The fix is to check for null before calling `.close()`.",
    "Number of deleted lines": 1,
    "Deleted lines": "    stopBackgroundThread();\n    super.onPause();\n  }\n\n  @Override\n  public void onDestroy() {\n    classifier.close();\n    super.onDestroy();\n  }\n\n  /**\n   * Sets up member variables related to camera.\n   *\n   * @param width The width of available size for camera preview\n   * @param height The height of available size for camera preview"
},
{
    "Id": 318,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c1b9ac9f215a3a83f7f0b6233bf4cef0b3e74598",
    "Violation": "missing",
    "Bug report": "Error checking in c/python code.",
    "Number of deleted lines": 0,
    "Deleted lines": "}\n\nbool GetNextValuesForIterable(PyObject* nested,\n                              std::vector<Safe_PyObjectPtr>* next_values) {\n  PyObject* item;\n  PyObject* iterator = PyObject_GetIter(nested);\n  while ((item = PyIter_Next(iterator)) != nullptr) {\n    next_values->emplace_back(item);\n  }\n  Py_DECREF(iterator);\n  return true;\n}\n\n// GetNextValues returns the values that the FlattenHelper function will recurse"
},
{
    "Id": 319,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/ed043aec4962dfdc3c58e2ad90dacb557dafcf4e",
    "Violation": "missing",
    "Bug report": " Lite: ResizeTensor Dim size check added to avoid reallocation if no change",
    "Number of deleted lines": 0,
    "Deleted lines": "  return status;\n}\n\nTfLiteStatus Subgraph::ResizeTensor(TfLiteContext* context,\n                                    TfLiteTensor* tensor,\n                                    TfLiteIntArray* new_size) {\n  // Note here that context->impl_ is recovering the this pointer for an\n  // instance of Interpreter to call into the member function ResizeTensorImpl\n  // (this function is static).\n  return static_cast<Subgraph*>(context->impl_)\n      ->ResizeTensorImpl(tensor, new_size);\n}\n\nvoid Subgraph::ReportErrorImpl(const char* format, va_list args) {"
},
{
    "Id": 320,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/20d54796563631c23c27548b321487e8b0c982a9",
    "Violation": "insufficient",
    "Bug report": " Add a nil check before init the device_name string, and also assign an empty string as a placeholder.",
    "Number of deleted lines": 1,
    "Deleted lines": "      outputs_.push_back(output->id);\n      output_tensor_ids_.push_back(tensor_index);\n      tensor->buffer_handle = output->id;\n      tensor->delegate = &delegate_;\n    }\n\n    std::string device_name = std::string([[metal_device_ name] UTF8String]);\n    GpuInfo gpu_info;\n    GetGpuInfoFromDeviceDescription(device_name, GpuApi::kMetal, &gpu_info);\n    size_t storage_type_size;\n    CalculationsPrecision precision;\n    if (options_.allow_precision_loss) {\n      storage_type_size = sizeof(HalfBits);\n      if (gpu_info.IsRoundToNearestSupported()) {\n        precision = CalculationsPrecision::F16;"
},
{
    "Id": 321,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/db10718b38b2884cb5ed46d33c135c079f649d16",
    "Violation": "missing",
    "Bug report": "With some memory allocators, attempting to allocate 0 bytes will return a null pointer. This specifically happens when building tensorflow with mkl support. If TF_TensorData returns null, the go code to create a slice from the data leads to a null pointer exception. This fixes the issue by checking for the nil return and returning a slice zero value to (nil) to the caller. ",
    "Number of deleted lines": 0,
    "Deleted lines": "\treturn io.Copy(w, bytes.NewReader(tensorData(t.c)))\n}\n\nfunc tensorData(c *C.TF_Tensor) []byte {\n\t// See: https://github.com/golang/go/wiki/cgo#turning-c-arrays-into-go-slices\n\tcbytes := C.TF_TensorData(c)\n\tlength := int(C.TF_TensorByteSize(c))\n\tslice := (*[1 << 30]byte)(unsafe.Pointer(cbytes))[:length:length]\n\treturn slice\n}\n\nvar types = []struct {\n\ttyp      reflect.Type\n\tdataType C.TF_DataType"
},
{
    "Id": 322,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/2465d4e77654f0d4f7799bc46d5fd5812590acc6",
    "Violation": "missing",
    "Bug report": " Add a check in auto-sharding setup and die if the input mesh shape contains more than two shardable dimensions, which is currently not supported.",
    "Number of deleted lines": 0,
    "Deleted lines": "                       [](const int64_t i) { return i <= 0; })) {\n      return tsl::errors::OutOfRange(\n          absl::StrCat(\"device_mesh_shape values need to be larger than 0: \"\n                       \"device_mesh_shape=\",\n                       absl::StrJoin(device_mesh_shape, \",\")));\n    }\n    if (device_mesh_alpha.empty()) {\n      // Generates simple device_mesh_alpha based on the size of\n      // device_mesh_shape.\n      device_mesh_alpha =\n          std::vector(device_mesh_shape.size(), kDeviceMeshAlpha);\n      VLOG(0) << \"Using default values for device_mesh_alpha: \"\n              << absl::StrJoin(device_mesh_alpha, \",\");\n    }"
},
{
    "Id": 323,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/3e0152a8b4aad03dd06274e0dd3b94bd5f8bf5d3",
    "Violation": "missing",
    "Bug report": "Fix invalid syntax error when import carla is present. The issue is that, when `import carla` is invoked, I/O operation for `std::ostringstream s` might fail, which caused the conversion of AttrValue to string as empty. This PR check `s.good()` to make sure the I/O operation is OK, and, fallback to normal conversion if locale-neutral I/O operation fails.",
    "Number of deleted lines": 1,
    "Deleted lines": "    } else {\n      // Use locale-independent conversion.\n      static_assert(FLT_DIG < 10, \"FLT_DIG is too big\");\n      std::ostringstream s;\n      s.imbue(std::locale::classic());\n      s << std::setprecision(FLT_DIG) << value.f();\n      return s.str();\n    }\n  } else if (type == \"bool\") {\n    return value.b() ? \"True\" : \"False\";\n  } else if (type == \"type\") {\n    return DataTypeToPython(value.type(), dtype_module);\n  } else if (type == \"shape\") {\n    return ShapeToPython(value.shape());\n  } else if (type == \"tensor\") {"
},
{
    "Id": 324,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/0317f64491ba42376d96b157983a02d8b31b679e",
    "Violation": "improper",
    "Bug report": " Update RNNCell._rnn_get_variable to use Variable._trainable in TF2 mode. When using a legacy RNNCell in TF2 mode within a tf.function the \"var in trainable_variables()\" check led to treating a tf.bool tensor as a Python bool. This change makes use within a tf.function use the same logic that is used in Eager mode.",
    "Number of deleted lines": 2,
    "Deleted lines": "        setattr(self, scope_attrname, scope)\n      with scope:\n        return super(RNNCell, self).__call__(inputs, state)\n\n  def _rnn_get_variable(self, getter, *args, **kwargs):\n    variable = getter(*args, **kwargs)\n    if context.executing_eagerly():\n      trainable = variable._trainable  # pylint: disable=protected-access\n    else:\n      trainable = (\n          variable in tf_variables.trainable_variables() or\n          (isinstance(variable, tf_variables.PartitionedVariable) and\n           list(variable)[0] in tf_variables.trainable_variables()))\n    if trainable and all(variable is not v for v in self._trainable_weights):\n      self._trainable_weights.append(variable)\n    elif not trainable and all("
},
{
    "Id": 325,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/b8c517ab4ef0bd851ef2f8187935fd3a90261af5",
    "Violation": "missing",
    "Bug report": "Reinstate eager check inside _GradientsHelper",
    "Number of deleted lines": 0,
    "Deleted lines": "                     gate_gradients=False,\n                     aggregation_method=None,\n                     stop_gradients=None,\n                     unconnected_gradients=UnconnectedGradients.NONE,\n                     src_graph=None):\n  \"\"\"Implementation of gradients().\"\"\"\n  if src_graph is None:\n    src_graph = ops.get_default_graph()\n  try:\n    unconnected_gradients = UnconnectedGradients(unconnected_gradients)\n  except ValueError:\n    raise ValueError(\n        \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n"
},
{
    "Id": 326,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c9b4689bc4d4024aa16b7d6cfc1c65fa1ed8486e",
    "Violation": "improper",
    "Bug report": "Removed no longer supported call to in_eager_execution. Swapped context.in_eager_execution() to the currently supported context.executing_eagerly(). Added negation to eager check. In all likelihood, the negation was always supposed to be there since getting default graph in eager mode does not make sense",
    "Number of deleted lines": 1,
    "Deleted lines": "    run_meta: optional tensorflow.RunMetadata proto. It is necessary to\n        to support run time information profiling, such as time and memory.\n    options: see ALL_ADVICE example above. Default checks everything.\n  Returns:\n    Returns AdviceProto proto\n  \"\"\"\n  if not graph and context.in_eager_execution():\n    graph = ops.get_default_graph()\n\n  if options == _DEFAULT_ADVISE_OPTIONS:\n    options = ALL_ADVICE.copy()\n\n  # pylint: disable=protected-access\n  op_log = tfprof_logger.merge_default_with_oplog(\n      graph, None, run_meta, add_trace=True)"
},
{
    "Id": 327,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/e5496b556734bb1d8de85311092804e0150b3009",
    "Violation": "unnecessary",
    "Bug report": " Remove extraneous check for Eager mode.The check is already made once at the start of the method",
    "Number of deleted lines": 2,
    "Deleted lines": "\n      def true_assert():\n        return gen_logging_ops._assert(\n            condition, data, summarize, name=\"Assert\")\n\n      guarded_assert = cond(condition, no_op, true_assert, name=\"AssertGuard\")\n      if context.in_eager_mode():\n        return\n      return guarded_assert.op\n\n\ndef _Identity(data, name=None):\n  \"\"\"Return a tensor with the same shape and contents as the input tensor.\n\n  Args:\n    data: A Tensor."
},
{
    "Id": 328,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/be5116dd131a92da298dbb68d26e0d47f66f2fe5",
    "Violation": "improper",
    "Bug report": " Correct graph check in broadcast_to gradient. ",
    "Number of deleted lines": 1,
    "Deleted lines": "\n@ops.RegisterGradient(\"BroadcastTo\")\ndef _BroadcastToGrad(op, grad):\n  input_value = op.inputs[0]\n  broadcast_shape = op.inputs[1]\n  input_value_shape = array_ops.shape(input_value)\n  if not context.executing_eagerly():\n    broadcast_shape_static = tensor_shape.TensorShape(\n        pywrap_tf_session.TF_TryEvaluateConstant_wrapper(\n            broadcast_shape.graph._c_graph, broadcast_shape._as_tf_output()))  # pylint: disable=protected-access\n    if broadcast_shape_static.is_fully_defined():\n      broadcast_shape = constant_op.constant(\n          broadcast_shape_static.as_list(), dtype=dtypes.int32)\n  _, reduction_axes = gen_array_ops.broadcast_gradient_args(\n      broadcast_shape, input_value_shape)"
},
{
    "Id": 329,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1d6dae88efef68dd7fbeeb5c39ea0f69c1c721c1",
    "Violation": "missing",
    "Bug report": "Add check to tf.device when called with a function in eager mode. ",
    "Number of deleted lines": 0,
    "Deleted lines": "    device_name_or_function: The device name or function to use in\n      the context.\n\n  Returns:\n    A context manager that specifies the default device to use for newly\n    created ops.\n  \"\"\"\n  if context.in_graph_mode():\n    return get_default_graph().device(device_name_or_function)\n  else:\n    # TODO(agarwal): support device functions in EAGER mode.\n    return context.device(device_name_or_function)\n\n\ndef container(container_name):\n  \"\"\"Wrapper for `Graph.container()` using the default graph.\n\n  Args:\n    container_name: The container string to use in the context."
},
{
    "Id": 330,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/8c3822edbb31cf71cedaf49f2167e45c1e2d0b83",
    "Violation": "missing",
    "Bug report": "Update the is_dtensor check to only run in eager mode.",
    "Number of deleted lines": 0,
    "Deleted lines": "\n    Args:\n      tensor: an object to be checked.\n\n    Returns:\n      bool, True if the given tensor is a DTensor.\n    \"\"\"\n    if not tensor_util.is_tensor(tensor):\n      return False\n    if isinstance(tensor, variables.Variable):\n      # Get the resource handle for tf.Variable\n      tensor = tensor._handle   # pylint: disable=protected-access\n    return _pywrap_dtensor_device.IsDTensor(\n        context.context()._handle,  # pylint: disable=protected-access\n        tensor,"
},
{
    "Id": 331,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a63f3006f703428ff980748cdbe24d6a13f761e2",
    "Violation": "missing",
    "Bug report": "Skip checking for graph_key in V1 optimizer when running in eager mode.",
    "Number of deleted lines": 1,
    "Deleted lines": "    \"\"\"From Trackable. Gather graph-specific non-slot variables to save.\"\"\"\n    current_graph_non_slot_variables = {}\n    current_graph_key = ops.get_default_graph()._graph_key  # pylint: disable=protected-access\n    for (name, _), variable_object in sorted(self._non_slot_dict.items(),\n                                             # Avoid comparing graphs\n                                             key=lambda item: item[0][0]):\n      if variable_object._graph_key == current_graph_key:  # pylint: disable=protected-access\n        current_graph_non_slot_variables[name] = variable_object\n    current_graph_non_slot_variables.update(\n        super(Optimizer, self)._trackable_children(save_type, **kwargs))\n    return current_graph_non_slot_variables\n\n  def _lookup_dependency(self, name):\n    \"\"\"From Trackable. Find a non-slot variable in the current graph.\"\"\"\n    unconditional = super(Optimizer, self)._lookup_dependency(name)"
},
{
    "Id": 332,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/dd7d791e02396346d98b7b2c58137d7e51756c0c",
    "Violation": "missing",
    "Bug report": "Add isinstance check for eager execution.",
    "Number of deleted lines": 2,
    "Deleted lines": "    device_only_candidate.device = v.device\n    device_only_candidate.name = v.name\n    if graph.building_function:\n      return graph.capture(v.handle).op, device_only_candidate\n    else:\n      return v.handle.op, device_only_candidate\n\n  if isinstance(v, internal.NativeObject):\n    return v.op, None\n  else:\n    return convert_to_tensor(v, as_ref=True).op, None\n\n\ndef _is_keras_symbolic_tensor(x):\n  return hasattr(x, \"graph\") and getattr(x.graph, \"name\", None) == \"keras_graph\"\n"
},
{
    "Id": 333,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/0a9b39caefd437fec742ae48b25061abd6e2699b",
    "Violation": "missing",
    "Bug report": " When allocating GPU constants, check to see if the destination. tensor is intialized early (because we ran out of memory) and report it as such.",
    "Number of deleted lines": 0,
    "Deleted lines": "  } else {\n    if (!DMAHelper::CanUseDMA(&parsed)) {\n      return errors::Internal(\"GPU copy from non-DMA \",\n                              DataTypeString(parsed.dtype()), \" tensor\");\n    }\n    Tensor copy(GetAllocator(alloc_attrs), parsed.dtype(), parsed.shape());\n    port::Tracing::ScopedAnnotation annotation(\"MakeTensorFromProto\");\n    Notification n;\n    device_contexts_[0]->CopyCPUTensorToDevice(&parsed, this, &copy,\n                                               [&n, &status](const Status& s) {\n                                                 status = s;\n                                                 n.Notify();\n                                               });\n    n.WaitForNotification();"
},
{
    "Id": 334,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/d8df06a9403b1434aea8b82a193fc30a4ab29bbb",
    "Violation": "missing",
    "Bug report": " Add assert in Operation->printAssembly to check improperly created Op's. We allow the name of an operation to be different from the name of the 'ConcreteType' op it was instantiated with. This can happen when you sub-class an existing op and provide a getOperationName for it. Such a situation leads to an assertion too deep and at a place seeminly unrelated, and typically when the module is printed with the trace: printOperation, printAssembly, Op::print, getOperand, dyn_cast<OperationStmt>, isa. 'isa' will complain about being called on a null pointer, and the null pointer actually comes from the getAs<> in printAssembly. This should have been caught in printAssembly.",
    "Number of deleted lines": 1,
    "Deleted lines": "    return ConcreteType::parse(parser, result);\n  }\n\n  /// This is the hook used by the AsmPrinter to emit this to the .mlir file.\n  /// Op implementations should provide a print method.\n  static void printAssembly(const Operation *op, OpAsmPrinter *p) {\n    op->getAs<ConcreteType>()->print(p);\n  }\n\n  /// This is the hook that checks whether or not this instruction is well\n  /// formed according to the invariants of its opcode.  It delegates to the\n  /// Traits for their policy implementations, and allows the user to specify\n  /// their own verify() method.\n  ///\n  /// On success this returns false; on failure it emits an error to the"
},
{
    "Id": 335,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/4f38b1ac8e42727e18a2f0bde06d3bee8e77b250",
    "Violation": "missing",
    "Bug report": " Prevent null dereference read in GetInitOp. We have a map of maps. We test that the key exists in the first map but then we don't have any validation that this also means the second map has the needed key. In the scenariosc where this is not the case, we'll dereference a nullptr, if we don't have this chec",
    "Number of deleted lines": 3,
    "Deleted lines": "Status GetInitOp(const string& export_dir, const MetaGraphDef& meta_graph_def,\n                 string* init_op_name) {\n  const auto& sig_def_map = meta_graph_def.signature_def();\n  const auto& init_op_sig_it =\n      meta_graph_def.signature_def().find(kSavedModelInitOpSignatureKey);\n  if (init_op_sig_it != sig_def_map.end()) {\n    *init_op_name = init_op_sig_it->second.outputs()\n                        .find(kSavedModelInitOpSignatureKey)\n                        ->second.name();\n    return Status::OK();\n  }\n\n  const auto& collection_def_map = meta_graph_def.collection_def();\n  string init_op_collection_key;\n  if (collection_def_map.find(kSavedModelMainOpKey) !=\n      collection_def_map.end()) {\n    init_op_collection_key = kSavedModelMainOpKey;"
},
{
    "Id": 336,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/e7de472681079932b2547024f31c876da54f61a0",
    "Violation": "insufficient",
    "Bug report": " Fix a bug in flatbuffer importer that use tensor quantization before checking.",
    "Number of deleted lines": 1,
    "Deleted lines": "  if (IsQuantized(tensor)) {\n    auto op = builder.create<tfl::QConstOp>(\n        loc, mlir::TypeAttr::get(shaped_type), value);\n    return op.getOperation();\n  }\n  auto op = builder.create<tfl::ConstOp>(loc, value);\n  if (!tensor.quantization->min.empty()) {\n    if (auto stats_op =\n            ConvertMinMaxToStatsOp(tensor, builder, op.getResult())) {\n      return stats_op;\n    }\n  }\n  return op.getOperation();\n}\n"
},
{
    "Id": 337,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/19b2e1b5868a044df4622ef7e26fa5570ca52e5e",
    "Violation": "insufficient",
    "Bug report": "Only perform scalar check for a tensor shape if it's not empty.",
    "Number of deleted lines": 1,
    "Deleted lines": "    nvinfer1::DataType type, DimsAdapter dims, Tensor tensor) {\n  TRT_ShapedWeights weights(type);\n  weights.shape_ = dims;\n  weights.tensor_ = std::forward<Tensor>(tensor);\n  weights.volume_ = weights.shape_.Volume();\n  if (weights.shape_.NumDims() == 0) {\n    DCHECK(weights.shape_.IsScalar());\n  }\n  return weights;\n}\n\nnvinfer1::Weights TRT_ShapedWeights::GetTrtWeights() const {\n  return nvinfer1::Weights{type_, GetPointer<int8>(), volume_};\n}\n"
},
{
    "Id": 338,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9c92b50fc4b95985a0749101976d04896bf19bfe",
    "Violation": "improper",
    "Bug report": " [conv3d_transpose] Fix dim check for bias. Per discussion with @thaink, the previous way to do the dim check for bias is not correct. So we need this change.",
    "Number of deleted lines": 1,
    "Deleted lines": "  TF_LITE_ENSURE_TYPES_EQ(context, output_shape->type, kTfLiteInt32);\n\n  // Check bias.\n  const TfLiteTensor* bias = GetInput(context, node, 3);\n  if (bias) {\n    TF_LITE_ENSURE_TYPES_EQ(context, bias->type, input->type);\n    TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 4));\n  }\n\n  // GenericOptimized kernel currently doesn't support dilation.\n  if (params->dilation_depth_factor > 1 || params->dilation_height_factor > 1 ||\n      params->dilation_width_factor > 1) {\n    kernel_type = kReference;\n  }\n"
},
{
    "Id": 339,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/5bc536f1afbaff5d3d5a14a9185cd1e3cc31b302",
    "Violation": "improper",
    "Bug report": "[Fix] bug fix during check static shape.",
    "Number of deleted lines": 1,
    "Deleted lines": "bool HasSameStaticShapes(Operation* op) {\n  auto values = op->getOperands();\n  int index = 0;\n  ArrayRef<int64_t> shape;\n  for (Value value : values) {\n    auto shaped_type = value.getType().dyn_cast<ShapedType>();\n    if (!shaped_type && !shaped_type.hasStaticShape()) {\n      return false;\n    }\n    if (index == 0) {\n      shape = shaped_type.getShape();\n    } else {\n      if (shape != shaped_type.getShape()) {\n        return false;\n      }"
},
{
    "Id": 340,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/264eb6ed1dbfb5e078c7dd977da8d7e633106fc5",
    "Violation": "missing",
    "Bug report": " Fixed add bias transformation. Added check for convolution with dynamic weights.",
    "Number of deleted lines": 0,
    "Deleted lines": "}\n\nclass AddBias : public NodeTransformation {\n public:\n  TransformResult ApplyToNode(Node* node, GraphFloat32* graph) final {\n    if (node->operation.type == ToString(OperationType::CONVOLUTION_2D)) {\n      auto& attr =\n          absl::any_cast<Convolution2DAttributes&>(node->operation.attributes);\n      return FillBias(attr.weights.shape.o, &attr.bias);\n    }\n    if (node->operation.type ==\n        ToString(OperationType::CONVOLUTION_TRANSPOSED)) {\n      auto& attr = absl::any_cast<ConvolutionTransposedAttributes&>(\n          node->operation.attributes);"
},
{
    "Id": 341,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/8cef4cda26e08256b6698e942820d9a3ac1bcc94",
    "Violation": "missing",
    "Bug report": "Add minor checks for data_format and padding value ",
    "Number of deleted lines": 2,
    "Deleted lines": "\n  ArrayRef<Attribute> strides = op.strides().getValue();\n  StringRef data_format = op.data_format().getValue();\n  ArrayRef<Attribute> dilations = op.dilations().getValue();\n\n  tensorflow::TensorFormat format;\n  FormatFromString(data_format.str(), &format);\n  tensorflow::Padding padding;\n  GetPaddingFromString(paddings.str(), &padding);\n  auto get_int = [](Attribute attr) {\n    return attr.template cast<IntegerAttr>().getInt();\n  };\n\n  // Necessary sanity checks.\n  // Verifies that,\n  // * Ranks of operands and result are valid\n  // * Length of explicit_paddings attribute is valid and has non negative"
},
{
    "Id": 342,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/0d5668cbdc6b46d099bd3abd93374c09b2e8121f",
    "Violation": "improper",
    "Bug report": " [XLA:SHAPE_UTIL] Return nullopt instead of a check failure if the input dimensions are not sorted.",
    "Number of deleted lines": 1,
    "Deleted lines": "}\n\n/* static */ absl::optional<std::vector<int64_t>>\nShapeUtil::ReshapeLeavesDimensionsUnmodified(\n    const Shape& from_shape, const Shape& to_shape,\n    absl::Span<const int64_t> input_dim_indices) {\n  CHECK(std::is_sorted(input_dim_indices.begin(), input_dim_indices.end()));\n\n  std::vector<int64_t> output_dim_indices;\n  std::vector<std::pair<int64_t, int64_t>> unmodified_dims =\n      ShapeUtil::DimensionsUnmodifiedByReshape(from_shape, to_shape);\n  size_t i = 0;  // index to unmodified_dims\n  for (int64_t input_dim_index : input_dim_indices) {\n    // Search unmodified_dims for input_dim_index. We can search from the last\n    // matching position because input_dim_indices is guaranteed to be sorted."
},
{
    "Id": 343,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/824af2acfa0cdf897c08d91224aea0958c1afc02",
    "Violation": "missing",
    "Bug report": " Add ndmin check. Added ndmin check to allow maximum 32 ndmin to make same behavior as numpy. Currently it is crashing when very large ndmin is passed.",
    "Number of deleted lines": 0,
    "Deleted lines": "  elif dtype:\n    result_t = math_ops.cast(result_t, dtype)\n\n  if copy:\n    result_t = array_ops.identity(result_t)\n\n  if ndmin == 0:\n    return result_t\n\n  ndims = array_ops.rank(result_t)\n\n  def true_fn():\n    old_shape = array_ops.shape(result_t)\n    new_shape = array_ops.concat("
},
{
    "Id": 344,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/b73a3c21a224f479af8d3b8af320c220a091906c",
    "Violation": "missing",
    "Bug report": "[XLA] Add check for potential out-of-bound access.",
    "Number of deleted lines": 0,
    "Deleted lines": "    result_literals.emplace_back(sort->operand(i)->shape());\n  }\n  std::vector<int64_t> zero_base(rank, 0);\n  std::vector<int64_t> increment(rank, 1);\n  int64_t sort_dim = sort->dimensions(0);\n  int64_t sort_dim_elements = key_shape.dimensions(sort_dim);\n  increment[sort_dim] = sort_dim_elements;\n  HloEvaluator embedded_evaluator(max_loop_iterations_);\n  // Iterate through each dimension except 'sort_dim'.\n  TF_RETURN_IF_ERROR(ShapeUtil::ForEachIndexWithStatus(\n      key_shape, zero_base, AsInt64Slice(key_shape.dimensions()), increment,\n      [&](absl::Span<const int64_t> indices) -> StatusOr<bool> {\n        // Extract a slice from each operand literal that corresponds to\n        // exactly the row in dimension 'sort_dim'."
},
{
    "Id": 345,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/63753d5f1531b17cf8cbbf1d8b77c16edcfb9711",
    "Violation": "improper",
    "Bug report": " Change DCHECK_LE to DCHECK_LT when checking invariant on original indices for sorted items Indices of items should be strictly smaller than the size of the vector.",
    "Number of deleted lines": 1,
    "Deleted lines": "  std::sort(original_indices.begin(), original_indices.end(),\n            [&](int x, int y) { return names[x] < names[y]; });\n\n  // Use sorted indices to generate sorted names.\n  sorted_names.reserve(names.size());\n  for (int original_index : original_indices) {\n    DCHECK_LE(original_index, names.size());\n    sorted_names.push_back(names[original_index]);\n  }\n}\n\n}  // namespace\n\nstruct SavedModelImpl::JoinedSignature {\n  // A unique name for the joined signature."
},
{
    "Id": 346,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/7f9929732ced22fe8ef42a695dae39c1caf44608",
    "Violation": "missing",
    "Bug report": " For gather op, if params.shape[:batch_dims] is not the same as indice s.shape[:batch_dims], return an error instead of check fail ",
    "Number of deleted lines": 0,
    "Deleted lines": "                                          params.dims(), \").\"));\n\n      OP_REQUIRES(c, axis >= batch_dims_,\n                  errors::InvalidArgument(\"batch_dims (\", batch_dims_,\n                                          \") must be less than or equal to \",\n                                          \"axis (\", axis, \").\"));\n    }\n\n    // Check that we have enough index space\n    int64 gather_dim_size = params.dim_size(axis);\n    const int64 N = indices.NumElements();\n    OP_REQUIRES(\n        c, gather_dim_size <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[\", axis, \"] too large for \","
},
{
    "Id": 347,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9e62869465573cb2d9b5053f1fa02a81fce21d69",
    "Violation": "missing",
    "Bug report": "Add more validation to RequantizationRangePerChannel. ",
    "Number of deleted lines": 0,
    "Deleted lines": "        errors::InvalidArgument(\"input_min has incorrect size, expected \",\n                                depth, \" was \", input_min.dim_size(0)));\n    OP_REQUIRES(\n        ctx, input_max.dim_size(0) == depth,\n        errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                depth, \" was \", input_max.dim_size(0)));\n\n    const float* input_min_data = input_min.flat<float>().data();\n    const float* input_max_data = input_max.flat<float>().data();\n    std::vector<float> ranges(depth);\n    bool is_non_negative = true;\n    Eigen::array<int, 2> shuffling({1, 0});\n    auto input_matrix = input.flat_inner_dims<qint32>();\n"
},
{
    "Id": 348,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/ba91c04e001f417641e757a6417e5325c1c4e15e",
    "Violation": "insufficient",
    "Bug report": "Add more check to sparsity parameter verifier.",
    "Number of deleted lines": 1,
    "Deleted lines": "      sparsity->dim_metadata() == nullptr) {\n    return absl::nullopt;\n  }\n\n  const int total_dims = sparsity->traversal_order()->size();\n\n  if (sparsity->dim_metadata()->size() != total_dims) {\n    return absl::nullopt;\n  }\n\n  const int block_rank = total_dims - tensor.shape()->size();\n  if (block_rank > 0 && (sparsity->block_map() == nullptr ||\n                         sparsity->block_map()->size() != block_rank)) {\n    return absl::nullopt;\n  }"
},
{
    "Id": 349,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1610f391833738972b538e4ee97f90dbd30fc745",
    "Violation": "improper",
    "Bug report": " Replace DCHECK with actual validation in AddRangeStats",
    "Number of deleted lines": 2,
    "Deleted lines": "                          StatsPartitionMap* stats_map,\n                          const TTypes<float>::ConstMatrix& gradients,\n                          const TTypes<float>::ConstMatrix& hessians,\n                          const TTypes<int32>::ConstVec& node_ids,\n                          const int32_t feature_dims, const int32_t bucket_id,\n                          const int32_t logits_dims, const int32_t stats_dims) {\n  DCHECK_LE(start_instance, end_instance);\n  if (start_instance == end_instance) {\n    DCHECK_LT(start_feature_dim, end_feature_dim);\n  }\n  for (int32_t instance = start_instance; instance <= end_instance;\n       ++instance) {\n    const int32_t start_f_dim =\n        (instance == start_instance) ? start_feature_dim + 1 : 0;\n    const int32_t end_f_dim =\n        (instance == end_instance) ? end_feature_dim : feature_dims;\n    for (int32_t f_dim = start_f_dim; f_dim < end_f_dim; ++f_dim) {"
},
{
    "Id": 350,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/150a6c06b281246cb5a075a704fceeb257bb63af",
    "Violation": "missing",
    "Bug report": "Add a check on the 0th dimension of filter for DepthwiseConv.",
    "Number of deleted lines": 0,
    "Deleted lines": "  const TfLiteType data_type = input->type;\n  TF_LITE_ENSURE(context, data_type == kTfLiteFloat32 ||\n                              data_type == kTfLiteUInt8 ||\n                              data_type == kTfLiteInt8);\n  TF_LITE_ENSURE_EQ(context, output->type, data_type);\n  TF_LITE_ENSURE_EQ(context, filter->type, data_type);\n\n  if (hasBias) {\n    bias = GetInput(context, node, kBiasTensor);\n    if (data_type == kTfLiteUInt8 || data_type == kTfLiteInt8) {\n      TF_LITE_ENSURE_EQ(context, bias->type, kTfLiteInt32);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else {\n      TF_LITE_ENSURE_EQ(context, bias->type, data_type);"
},
{
    "Id": 351,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/bf686faeddcca97be6ad7b6421cb26ab1c3cea2c",
    "Violation": "missing",
    "Bug report": "TFLite: Enhance input check for ResizeNearestNeghbor",
    "Number of deleted lines": 2,
    "Deleted lines": "  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n  const TfLiteTensor* size = GetInput(context, node, kSizeTensor);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n\n  // TODO(ahentz): Our current implementations rely on the inputs being 4D.\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n  TF_LITE_ENSURE_EQ(context, NumDimensions(size), 1);\n\n  TF_LITE_ENSURE_EQ(context, size->type, kTfLiteInt32);\n  output->type = input->type;\n\n  if (!IsConstantTensor(size)) {\n    SetTensorToDynamic(output);\n    return kTfLiteOk;\n  }\n  return ResizeOutputTensor(context, input, size, output);\n}"
},
{
    "Id": 352,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c040db5e9003cc20016586df9f2964db83b98c4f",
    "Violation": "missing",
    "Bug report": " [XLA] Add a defensive check in dynamic dimension inference to prevent scalar reshape with dynamic dimension. In theory we can just ignore a [1] -> [] reshape, but adding a check here for now.",
    "Number of deleted lines": 3,
    "Deleted lines": "    HloInstruction* hlo) {\n  return PassThroughDynamicDimension(hlo);\n}\n\nStatus DynamicDimensionInferenceVisitor::HandleReshape(HloInstruction* hlo) {\n  return ForEachOperandDynamicDimension(\n      hlo, [&](HloInstruction* operand, ShapeIndex index, int64 dimension,\n               int64 operand_index, HloInstruction* dynamic_size,\n               DimensionConstraint constraint) {\n        HloInstruction* reshape = hlo;\n        // Reshape is supported as long as it is the most\n        // major one and it is combining with other non-dynamic dimensions.\n        const int64 output_most_major = reshape->shape().dimensions(0);\n        const int64 input_most_major = operand->shape().dimensions(0);\n        if (dimension == 0) {\n          if (output_most_major > input_most_major) {\n            const int64 multiplier =\n                reshape->shape().dimensions(0) / operand->shape().dimensions(0);"
},
{
    "Id": 353,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/48393637f8154be16088d84742485a0e153ecbb2",
    "Violation": "improper",
    "Bug report": "Change check to allow tensors with up to 6 dims.",
    "Number of deleted lines": 2,
    "Deleted lines": "  }\n  if (!dims_array.buffer) {\n    // Yield until the dims are constant\n    return;\n  }\n  CHECK(dims_array.data_type == ArrayDataType::kInt32) << \"dims must be int32\";\n  CHECK_LE(RequiredBufferSizeForShape(dims_array.shape()), 4)\n      << \"dims vector can be no larger than 4 values\";\n\n  std::vector<int32> const& dims =\n      dims_array.GetBuffer<ArrayDataType::kInt32>().data;\n  *(output_array.mutable_shape()->mutable_dims()) = dims;\n}\n\nvoid ProcessFullyConnectedOperator(Model* model, FullyConnectedOperator* op) {\n  const auto& input_array = model->GetArray(op->inputs[0]);"
},
{
    "Id": 354,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/662128e8ca3411286b234553a7efc1356353d0f5",
    "Violation": "missing",
    "Bug report": " add rank checking for MEAN op. The MEAN op of NNAPI only supports a tensor with rank <= 4. Check the rank of the input tensor before delegating the op.",
    "Number of deleted lines": 0,
    "Deleted lines": "               \"Expected Float32 input\", &val_ctx);\n      }\n      Expect(context->tensors[node->outputs->data[0]].dims->size > 0,\n             NNAPIValidationFailureType::kUnsupportedOutputType,\n             \"NNAPI does not support generating a scalar as output for MEAN.\",\n             &val_ctx);\n    } break;\n    case kTfLiteBuiltinEmbeddingLookup: {\n      ExpectOpVersion(version, 1, &val_ctx);\n      Expect(context->tensors[node->inputs->data[1]].type == kTfLiteFloat32,\n             NNAPIValidationFailureType::kUnsupportedInputType,\n             \"NNAPI only support float32 values.\", &val_ctx);\n    } break;\n    case kTfLiteBuiltinHashtableLookup: {"
},
{
    "Id": 355,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9b947dd6377c022091c8aa005cdcff52c53ff5f0",
    "Violation": "insufficient",
    "Bug report": "Also check dst_format",
    "Number of deleted lines": 1,
    "Deleted lines": "      regular_fanin.node_view()->GetAttr(kAttrOutputShape);\n  const auto& shape = output_shape_attr->list().shape(0);\n  const int rank = shape.dim_size();\n  std::string src_format = context->src_format;\n  std::string dst_format = context->dst_format;\n  // Update the format from 4D to 5D layout if necessary.\n  bool allow_5d = rank == 5 && (src_format == \"NHWC\" || src_format == \"NCHW\");\n  if (allow_5d) {\n    std::string src_format_3d = src_format == \"NHWC\" ? \"NDHWC\" : \"NCDHW\";\n    std::string dst_format_3d = dst_format == \"NHWC\" ? \"NDHWC\" : \"NCDHW\";\n    context->AssignDeviceAndDataFormats(context->target_device, src_format_3d,\n                                        dst_format_3d);\n  }\n  if (!ShouldProcess(*context, *node) || !IsFaninPortRankN(*node, 0, rank) ||\n      !IsReduceAxisSupported(*context, *node) ||"
},
{
    "Id": 356,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/450dec35448a73b3fcb5d4f82108d5fdcb3f59b4",
    "Violation": "missing",
    "Bug report": "Internal change, add some checks on the sparseTensor format checking.",
    "Number of deleted lines": 1,
    "Deleted lines": "    // TODO(pineapplejuice233): should we support arbitrary rank of sparse tensor and\n    // convert it to 2D?\n    // For 2D sparse tensor, as we always combine on the last dimension.\n    // The row ids are just the sample ids which is the first dim of the\n    // indices.\n    auto indices_matrix = indices_or_row_splits.matrix<int32>();\n    for (int32 i = 0; i < total_id_count; ++i) {\n      *(row_ids_before_padding + i) = indices_matrix(i, 0);\n    }\n  } else if (indices_or_row_splits.dims() == 1 &&\n             indices_or_row_splits.NumElements() > 0) {\n    // Ragged tensor to COO format.\n    const int32* indices_or_row_splits_ptr =\n        indices_or_row_splits.flat<int32>().data();\n    int32 current_row_id = -1;\n    for (int32 i = 0; i < total_id_count; ++i) {"
},
{
    "Id": 357,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/356f360e8772a2697ec0d30036237342549803f5",
    "Violation": "missing",
    "Bug report": " Add additional shape validation to compute_accidental_hits. In `compute_accidental_hits`, the `sampled_candidates` must be a vector, as is shown in the kernel implementation in `tensorflow/core/kernels candidate_sampler_ops.cc`. This fix adds shape validation of `sampled_candidates` in the shape function whenever possible.",
    "Number of deleted lines": 1,
    "Deleted lines": "    .Attr(\"seed: int = 0\")\n    .Attr(\"seed2: int = 0\")\n    .SetShapeFn([](InferenceContext* c) {\n      int64 num_true;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"num_true\", &num_true));\n\n      // Validate true_classes.\n      ShapeHandle true_classes;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &true_classes));\n      DimensionHandle unused;\n      TF_RETURN_IF_ERROR(\n          c->WithValue(c->Dim(true_classes, 1), num_true, &unused));\n\n      // All three outputs are the same shape.\n      ShapeHandle v = c->Vector(InferenceContext::kUnknownDim);\n      c->set_output(0, v);\n      c->set_output(1, v);\n      c->set_output(2, v);\n      return Status::OK();\n    });"
},
{
    "Id": 358,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/7c88788e63f3a747d2794175076db551d768734e",
    "Violation": "missing",
    "Bug report": " Shape validation of max_features in QuantizedReluX. In shape function of QuantizedReluX, `max_value` and `min_features` have shape validation but not `max_features`. This fix add restriction to `max_features` as well.",
    "Number of deleted lines": 0,
    "Deleted lines": "    .Attr(\"out_type: quantizedtype = DT_QUINT8\")\n    .SetShapeFn([](InferenceContext* c) {\n      TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused));\n      c->set_output(1, c->Scalar());\n      c->set_output(2, c->Scalar());\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizedBatchNormWithGlobalNormalization\")\n    .Input(\"t: Tinput\")\n    .Input(\"t_min: float\")"
},
{
    "Id": 359,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/ff6be80a1ec3c353ebd0d17e2f0b46d9097310db",
    "Violation": "missing",
    "Bug report": " Improve the shape function for ParameterizedTruncatedNormal.  The parameters of ParameterizedTruncatedNormal should be 0-D or 1-D, which is checked in ther kernel functions. There is no check in the shape function of the ops. This fix improves the shape function and checks the parameters of ParameterizedTruncatedNormal whever possible.",
    "Number of deleted lines": 1,
    "Deleted lines": "    .SetIsStateful()\n    .Output(\"output: dtype\")\n    .Attr(\"seed: int = 0\")\n    .Attr(\"seed2: int = 0\")\n    .Attr(\"dtype: {half,bfloat16,float,double}\")\n    .Attr(\"T: {int32, int64}\")\n    .SetShapeFn(shape_inference::RandomShape);\n\nREGISTER_OP(\"TruncatedNormal\")\n    .Input(\"shape: T\")\n    .SetIsStateful()\n    .Output(\"output: dtype\")\n    .Attr(\"seed: int = 0\")\n    .Attr(\"seed2: int = 0\")\n    .Attr(\"dtype: {half,bfloat16,float,double}\")"
},
{
    "Id": 360,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c59c37e7b2d563967da813fa50fe20b21f4da683",
    "Violation": "missing",
    "Bug report": " Prevent array write out-of-bounds. If user passes an invalid axis, then we copy one too many dimensions to the output in the loop below these checks. Even if we didn't do that, there will be further issues with an invalid axis, so we check for that right now.",
    "Number of deleted lines": 0,
    "Deleted lines": "    axis_value = *GetTensorData<int>(axis);\n  }\n  if (axis_value < 0) {\n    axis_value += NumDimensions(input);\n  }\n\n  // Copy the input dimensions to output except the axis dimension.\n  TfLiteIntArray* output_dims = TfLiteIntArrayCreate(NumDimensions(input) - 1);\n  int j = 0;\n  for (int i = 0; i < NumDimensions(input); ++i) {\n    if (i != axis_value) {\n      output_dims->data[j] = SizeOfDimension(input, i);\n      ++j;\n    }"
},
{
    "Id": 361,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/e82a377de614fed51da8a7c5242a90a7967169f2",
    "Violation": "missing",
    "Bug report": "Correct axis check",
    "Number of deleted lines": 3,
    "Deleted lines": "  Value operand0 = op.getOperand(0);\n  auto input_type = operand0.getType().cast<ShapedType>();\n\n  // Check axis bounds.\n  if (input_type.hasRank()) {\n    int64_t axis_value = op.axis().getSExtValue();\n    if (abs(axis_value) > input_type.getRank())\n      return op.emitOpError(\"op attribute 'axis' is out of bounds, got \")\n             << axis_value;\n  }\n\n  // Make sure all inputs have the same shape and element type.\n  // TODO(b/135032063): Simplify once fixed.\n  for (Type operand_type : op.getOperandTypes()) {\n    if (failed(mlir::verifyCompatibleShape(input_type, operand_type)))\n      return op.emitOpError(\"operands should be of the same type. got \")\n             << input_type << \", \" << operand_type;"
},
{
    "Id": 362,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/27de8e717c1bec91398f5a6be6c7287b657fc960",
    "Violation": "missing",
    "Bug report": " Improve shape function for CudnnRNNParamsSize. In cudnn_rnn_ops.cc, the CudnnRNNParamsSize does not have restrictions on num_layers, num_units, and input_size, though they all should be scalars. This fix adds the shape check of num_layers, num_units, and input_size for CudnnRNNParamsSize.",
    "Number of deleted lines": 0,
    "Deleted lines": "    .Attr(kRNNDirectionAttrs)\n    .Attr(\"dropout: float = 0.0\")\n    .Attr(\"seed: int = 0\")\n    .Attr(\"seed2: int = 0\")\n    .Output(\"params_size: S\")\n    .SetShapeFn([](InferenceContext* c) {\n      c->set_output(0, c->Vector(1));\n      return Status::OK();\n    });\n\n\nREGISTER_OP(\"CudnnRNN\")\n    .Input(\"input: T\")\n    .Input(\"input_h: T\")"
},
{
    "Id": 363,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/4a1d1c8413a3752af7dc91a7128e202660b0f05c",
    "Violation": "improper",
    "Bug report": " Fix mismatch of shape restriction in DrawBoundingBoxes. In the kernel of DrawBoundingBoxes, the shape of the input images should be 4-D. Though in the shape function, at the end `UnchangedShapeWithRankAtLeast(c, 3)` was used instead (at the beginning of the shape function the validation is `WithRank(c->input(0), 4, &images)` which is correct). This fix address the discrepancy by changing to `UnchangedShape`.",
    "Number of deleted lines": 1,
    "Deleted lines": "      ShapeHandle boxes;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 3, &boxes));\n      // The last value of boxes shape is 4.\n      DimensionHandle unused;\n      TF_RETURN_IF_ERROR(c->WithValue(c->Dim(boxes, 2), 4, &unused));\n\n      return shape_inference::UnchangedShapeWithRankAtLeast(c, 3);\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"SampleDistortedBoundingBox\")\n    .Input(\"image_size: T\")\n    .Input(\"bounding_boxes: float\")\n    .Output(\"begin: T\")\n    .Output(\"size: T\")"
},
{
    "Id": 364,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/181ca305a7954ce86a453a39db0b4f6d10b82720",
    "Violation": "missing",
    "Bug report": " Add shape validation in shape function of MapAndBatchDataset. In MapAndBatchDataset, batch_size, num_parallel_batches, and drop_remainder are 0-D scalars. This fix adds the shape check to those Inputs. Note since the Input of `other_arguments` is a list and is before `batch_size`, the shape of the `batch_size` and others could not be obtained through index like `c->input(2)` etc directly. It is still possible to obtain the ShapeHandle with names `c >input(\"batch_size\", &batch_size)`, though.",
    "Number of deleted lines": 1,
    "Deleted lines": "    .Input(\"drop_remainder: bool\")\n    .Output(\"handle: variant\")\n    .Attr(\"f: func\")\n    .Attr(\"Targuments: list(type) >= 0\")\n    .Attr(\"output_types: list(type) >= 1\")\n    .Attr(\"output_shapes: list(shape) >= 1\")\n    .SetShapeFn(shape_inference::ScalarShape);\n\nREGISTER_OP(\"MapAndBatchDatasetV2\")\n    .Input(\"input_dataset: variant\")\n    .Input(\"other_arguments: Targuments\")\n    .Input(\"batch_size: int64\")\n    .Input(\"num_parallel_calls: int64\")\n    .Input(\"drop_remainder: bool\")\n    .Output(\"handle: variant\")"
},
{
    "Id": 365,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/6e153325b66330dafea4e4e8b67b5d56b1a37852",
    "Violation": "missing",
    "Bug report": " [XLA:GPU] Handle edge case in Triton Softmax rewriter where bitcast produces a scalar. This avoids crashing within last_dimension when attempting to match.",
    "Number of deleted lines": 0,
    "Deleted lines": "bool TrivialEdge(HloInstruction** producer, HloInstruction* consumer,\n                 HloOpcode opcode);\n\nbool BitcastIsTilingNoop(HloInstruction* bitcast) {\n  CHECK_EQ(bitcast->opcode(), HloOpcode::kBitcast);\n\n  // In the Softmax rewriter for now, tiling is derived from a hero reduction\n  // operation, which should be reducing its input on the last axis. Therefore,\n  // a bitcast is always a no-op with regards to a tile if\n  //   (1) it does not change the size of the reduction dimension of its input\n  //       (the last one); if its input is already reduced, then (1) is true\n  //       by default\n  //   (2) the layout of its output is ordered in the same way as the layout of\n  //       its input. This is a fuzzy definition, but since we assume fusible"
},
{
    "Id": 366,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/d94ffe08a65400f898241c0374e9edc6fa8ed257",
    "Violation": "missing",
    "Bug report": " Prevent an OOB read in expand_dims.cc. The for loop that follows this check assumes that `axis` is between `0` and `input_dims.size`. If user supplied `axis` is negative, the if code before this check is supposed to bring it back to positive (similar to how in Python one can do `l[-3]` to mean `l[-3 + len(l)]`).",
    "Number of deleted lines": 0,
    "Deleted lines": "                             int axis, TfLiteTensor* output) {\n  const TfLiteIntArray& input_dims = *input.dims;\n  if (axis < 0) {\n    axis = input_dims.size + 1 + axis;\n  }\n  TF_LITE_ENSURE(context, axis <= input_dims.size);\n\n  TfLiteIntArray* output_dims = TfLiteIntArrayCreate(input_dims.size + 1);\n  for (int i = 0; i < output_dims->size; ++i) {\n    if (i < axis) {\n      output_dims->data[i] = input_dims.data[i];\n    } else if (i == axis) {\n      output_dims->data[i] = 1;\n    } else {"
},
{
    "Id": 367,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a680ed0bf03d5ca3b2c4a70c0d95eeebc20da6d6",
    "Violation": "missing",
    "Bug report": " For Substr check pos and len rank equality only when their rank is known. This fixes a bug where len has unknown rank, while pos has known shape. The WithRank(...) check returned error in such a case. Here we compare their ranks only when both pos and len have known rank.",
    "Number of deleted lines": 2,
    "Deleted lines": "    .Attr(\"T: {int32, int64}\")\n    .Attr(\"unit: {'BYTE', 'UTF8_CHAR'} = 'BYTE'\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle pos_shape = c->input(1);\n      ShapeHandle len_shape = c->input(2);\n      ShapeHandle unused;\n      // Check that pos/len have same rank\n      TF_RETURN_IF_ERROR(c->WithRank(pos_shape, c->Rank(len_shape), &unused));\n      // Check that dimensions are equal\n      for (int32 i = 0; i < c->Rank(pos_shape); ++i) {\n        DimensionHandle pos_dim = c->Dim(pos_shape, i);\n        DimensionHandle len_dim = c->Dim(len_shape, i);\n        if (c->Value(pos_dim) != c->Value(len_dim)) {\n          return errors::InvalidArgument(\n              \"pos and len shapes must match: \", c->DebugString(pos_shape),\n              \" vs. \", c->DebugString(len_shape));"
},
{
    "Id": 368,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9187be7adff07be82856add498aa3ff4b5f95998",
    "Violation": "missing",
    "Bug report": "add checks for compression_type and buffer_size also",
    "Number of deleted lines": 0,
    "Deleted lines": "                      // stateful to inhibit constant folding.\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      shape_inference::ShapeHandle unused;\n      // `filenames` must be a scalar or a vector.\n      TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(0), 1, &unused));\n      return shape_inference::ScalarShape(c);\n    });\n\nREGISTER_OP(\"SqlDataset\")\n    .Input(\"driver_name: string\")\n    .Input(\"data_source_name: string\")\n    .Input(\"query: string\")\n    .Output(\"handle: variant\")\n    .Attr(\"output_types: list(type) >= 1\")"
},
{
    "Id": 369,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/779664494d43b18a812361197dcbea2f25912c02",
    "Violation": "missing",
    "Bug report": "Add shape check to TextLineDataset op",
    "Number of deleted lines": 4,
    "Deleted lines": "    .Input(\"filenames: string\")\n    .Input(\"compression_type: string\")\n    .Input(\"buffer_size: int64\")\n    .Output(\"handle: variant\")\n    .SetIsStateful()  // TODO(b/65524810): Source dataset ops must be marked\n                      // stateful to inhibit constant folding.\n    .SetShapeFn(shape_inference::ScalarShape);  // TODO(mrry): validate\n                                                // that `filenames` is\n                                                // a scalar or a\n                                                // vector.\n\nREGISTER_OP(\"SqlDataset\")\n    .Input(\"driver_name: string\")\n    .Input(\"data_source_name: string\")\n    .Input(\"query: string\")\n    .Output(\"handle: variant\")\n    .Attr(\"output_types: list(type) >= 1\")\n    .Attr(\"output_shapes: list(shape) >= 1\")"
},
{
    "Id": 370,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c4dea2255c71037c9cade9cbd1d7820b3429b3fa",
    "Violation": "missing",
    "Bug report": "Add shape check for buffer_size with TFRecordDataset",
    "Number of deleted lines": 0,
    "Deleted lines": "    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      shape_inference::ShapeHandle unused;\n      // `filenames` must be a scalar or a vector.\n      TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(0), 1, &unused));\n      // `compression_type` could only be a scalar.\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused) );\n      return shape_inference::ScalarShape(c);\n    });\n\nREGISTER_OP(\"Iterator\")\n    .Output(\"handle: resource\")\n    .Attr(\"shared_name: string\")\n    .Attr(\"container: string\")\n    .Attr(\"output_types: list(type) >= 1\")"
},
{
    "Id": 371,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/d97ffbdf362fa7d06ef8d946c8620ff7a3a50a08",
    "Violation": "missing",
    "Bug report": "Add shape check for compression_type in TFrecordDataset",
    "Number of deleted lines": 0,
    "Deleted lines": "    .SetIsStateful()  // TODO(b/65524810): Source dataset ops must be marked\n                      // stateful to inhibit constant folding.\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      shape_inference::ShapeHandle unused;\n      // `filenames` must be a scalar or a vector.\n      TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(0), 1, &unused));\n      return shape_inference::ScalarShape(c);\n    });\n\nREGISTER_OP(\"Iterator\")\n    .Output(\"handle: resource\")\n    .Attr(\"shared_name: string\")\n    .Attr(\"container: string\")\n    .Attr(\"output_types: list(type) >= 1\")"
},
{
    "Id": 372,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/7586dee9aa8b4b63143ab658ca59658aaed0df97",
    "Violation": "missing",
    "Bug report": " Add shape check to TFRecordDataset. The inputs of TFRecordDataset have the requirements for shapes. However, the check was not done in the shape function. This fix adds shape checks whenever possible.",
    "Number of deleted lines": 1,
    "Deleted lines": "    .Input(\"filenames: string\")\n    .Input(\"compression_type: string\")\n    .Input(\"buffer_size: int64\")\n    .Output(\"handle: variant\")\n    .SetIsStateful()  // TODO(b/65524810): Source dataset ops must be marked\n                      // stateful to inhibit constant folding.\n    .SetShapeFn(shape_inference::ScalarShape);\n\nREGISTER_OP(\"Iterator\")\n    .Output(\"handle: resource\")\n    .Attr(\"shared_name: string\")\n    .Attr(\"container: string\")\n    .Attr(\"output_types: list(type) >= 1\")\n    .Attr(\"output_shapes: list(shape) >= 1\")\n    .SetShapeFn(shape_inference::ScalarShape);"
},
{
    "Id": 373,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/851177fee860211e2fabcb019d644e75b7f701b0",
    "Violation": "missing",
    "Bug report": "Add shape check for shift of tf.roll",
    "Number of deleted lines": 0,
    "Deleted lines": "    .Attr(\"Tshift: {int32,int64}\")\n    .Attr(\"Taxis: {int32,int64}\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      shape_inference::ShapeHandle unused;\n      // The `input` must be 1-D or higher\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &unused));\n      // The `axis` must be scalar or 1-D.\n      TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(2), 1, &unused));\n\n      return shape_inference::UnchangedShape(c);\n    });\n\n}  // namespace tensorflow\n"
},
{
    "Id": 374,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/3f796ff8c9e6d7ff88f99c056b78e88fb0b31114",
    "Violation": "missing",
    "Bug report": "Add axis shape check for tf.roll",
    "Number of deleted lines": 0,
    "Deleted lines": "    .Attr(\"Tshift: {int32,int64}\")\n    .Attr(\"Taxis: {int32,int64}\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      shape_inference::ShapeHandle unused;\n      // The `input` must be 1-D or higher\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &unused));\n\n      return shape_inference::UnchangedShape(c);\n    });\n\n}  // namespace tensorflow\n"
},
{
    "Id": 375,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/10467d29e05d9957a6e3cb2335f8eeba1fd8896e",
    "Violation": "missing",
    "Bug report": " Improve shape function check for tf.roll. The `tf.roll` op has requirements for the shape of inputs. However, the shape of the inputs are only done at the runtime inside the kernel. This fix improve the shape function so that the check could be done early if shape is already known in the shape function.",
    "Number of deleted lines": 1,
    "Deleted lines": "    .Input(\"shift: Tshift\")\n    .Input(\"axis: Taxis\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tshift: {int32,int64}\")\n    .Attr(\"Taxis: {int32,int64}\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n}  // namespace tensorflow\n"
},
{
    "Id": 376,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/41deb95a7bde735d3c8b9adedd8b1fe8c1ef2732",
    "Violation": "missing",
    "Bug report": "support unknown rank, check rank>=0",
    "Number of deleted lines": 0,
    "Deleted lines": "ShapeHandle InferenceContext::UnknownShape() {\n  return shape_manager_.UnknownShape();\n}\n\nShapeHandle InferenceContext::UnknownShapeOfRank(int64 rank) {\n  CHECK_LE(rank, kint32max) << \"rank must be less than kint32max\";\n  std::vector<DimensionHandle> dims(rank);\n  for (int32 i = 0; i < rank; ++i) {\n    dims[i] = UnknownDim();\n  }\n  return MakeShape(dims);\n}\n\nShapeHandle InferenceContext::Scalar() { return MakeShape({}); }"
},
{
    "Id": 377,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/8b742f8559e88474735d0a2c03e00da65e40b412",
    "Violation": "missing",
    "Bug report": "Fix check error on shape overflow.",
    "Number of deleted lines": 2,
    "Deleted lines": "    }\n\n    const int row_dimension = input_rank - 2;\n    const int col_dimension = input_rank - 1;\n    const int64_t num_rows = in.dim_size(row_dimension);\n    const int64_t num_cols = in.dim_size(col_dimension);\n    input_matrix_shapes->emplace_back(\n        std::initializer_list<int64_t>({num_rows, num_cols}));\n    inputs->emplace_back(&in);\n    OP_REQUIRES(\n        context, in.dtype() == DataTypeToEnum<InputScalar>::v(),\n        errors::InvalidArgument(\"Invalid input dtype \", in.dtype(), \" vs \",\n                                DataTypeToEnum<InputScalar>::v()));\n  }\n  // Have the derived class validate that the inputs are as expected.\n  ValidateInputMatrixShapes(context, *input_matrix_shapes);"
},
{
    "Id": 378,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1595906c2192b7f402f746652042a592ad290378",
    "Violation": "missing",
    "Bug report": " Prevent CHECK-fail DOS in BoostedTreesSparseAggregateStatsOp. Calling `tensor->matrix` should only happen after checking that the tensor shape implies a matrix.",
    "Number of deleted lines": 0,
    "Deleted lines": "    const auto hessians = hessians_t->matrix<float>();\n\n    // feature indices.\n    const Tensor* feature_indices_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"feature_indices\", &feature_indices_t));\n    const auto feature_indices = feature_indices_t->matrix<int32>();\n\n    // feature values.\n    const Tensor* feature_values_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"feature_values\", &feature_values_t));\n    const auto feature_values = feature_values_t->vec<int32>();\n"
},
{
    "Id": 379,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/54c94431e5dd17fc46d99da1a3f132c76414c161",
    "Violation": "missing",
    "Bug report": " Prevent CHECK-fail DOS in BoostedTreesSparseAggregateStatsOp. Calling `tensor->matrix` should only happen after checking that the tensor shape implies a matrix.",
    "Number of deleted lines": 0,
    "Deleted lines": "                                gradients_t->shape().DebugString()));\n    const auto gradients = gradients_t->matrix<float>();\n\n    // hessians.\n    const Tensor* hessians_t;\n    OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));\n    const auto hessians = hessians_t->matrix<float>();\n\n    // feature indices.\n    const Tensor* feature_indices_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"feature_indices\", &feature_indices_t));\n    const auto feature_indices = feature_indices_t->matrix<int32>();\n"
},
{
    "Id": 380,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/5d96267d907ac2119cbccf1416b749195e8fd8de",
    "Violation": "missing",
    "Bug report": " Prevent CHECK-fail DOS in BoostedTreesSparseAggregateStatsOp. Calling `tensor->matrix` should only happen after checking that the tensor shape implies a matrix.",
    "Number of deleted lines": 0,
    "Deleted lines": "    OP_REQUIRES_OK(context, context->input(\"node_ids\", &node_ids_t));\n    const auto node_ids = node_ids_t->vec<int32>();\n\n    // gradients.\n    const Tensor* gradients_t;\n    OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));\n    const auto gradients = gradients_t->matrix<float>();\n\n    // hessians.\n    const Tensor* hessians_t;\n    OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));\n    const auto hessians = hessians_t->matrix<float>();\n\n    // feature indices."
},
{
    "Id": 381,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/41ab69692ede0db3422fa70bc5889d470741e69c",
    "Violation": "missing",
    "Bug report": " Check for tensors to be vectors in BoostedTreesSparseAggregateStatsOp. Calling `tensor->vec` should only happen after checking that the tensor shape implies a vector. Otherwise, we can get denial of service via `CHECK`-fails",
    "Number of deleted lines": 0,
    "Deleted lines": "    const auto feature_indices = feature_indices_t->matrix<int32>();\n\n    // feature values.\n    const Tensor* feature_values_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"feature_values\", &feature_values_t));\n    const auto feature_values = feature_values_t->vec<int32>();\n\n    // feature shape.\n    const Tensor* feature_shape_t;\n    OP_REQUIRES_OK(context, context->input(\"feature_shape\", &feature_shape_t));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(feature_shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Input shapes should be a vector but received shapes \","
},
{
    "Id": 382,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/8d733ecdb270dd90b2b5f53fd220d5ce17a5e20f",
    "Violation": "missing",
    "Bug report": " Check for tensors to be vectors in BoostedTreesSparseAggregateStatsOp. Calling `tensor->vec` should only happen after checking that the tensor shape implies a vector. Otherwise, we can get denial of service via `CHECK`-fails",
    "Number of deleted lines": 0,
    "Deleted lines": "  }\n\n  void Compute(OpKernelContext* const context) override {\n    // node_ids.\n    const Tensor* node_ids_t;\n    OP_REQUIRES_OK(context, context->input(\"node_ids\", &node_ids_t));\n    const auto node_ids = node_ids_t->vec<int32>();\n\n    // gradients.\n    const Tensor* gradients_t;\n    OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsMatrix(gradients_t->shape()),\n        errors::InvalidArgument(\"gradients must be a matrix, received shape \","
},
{
    "Id": 383,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/f482488b481a799ca07e7e2d153cf47b8e91a60c",
    "Violation": "missing",
    "Bug report": " TFLite OpenGL ES delegate: out of boundary writes fixed for bhwc->phwc4 conversion.",
    "Number of deleted lines": 1,
    "Deleted lines": "    return InvalidArgumentError(\n        \"BhwcToPhwc4: output data size does not match expected size.\");\n  }\n  if (shape.b != 1) {\n    return UnimplementedError(\"BhwcToPhwc4: Batch size is not equal to 1.\");\n  }\n  uint3 workload = uint3(shape.w, shape.h, shape.c);\n  uint3 num_workgroups = IntegralDivideRoundUp(workload, workgroup_size_);\n\n  RETURN_IF_ERROR(program_.SetParameter(\n      {\"sizes_\",\n       int4(static_cast<int32_t>(workload.x), static_cast<int32_t>(workload.y),\n            static_cast<int32_t>(workload.z), static_cast<int32_t>(shape.c))}));\n  RETURN_IF_ERROR(source.BindToIndex(0));\n  RETURN_IF_ERROR(destination->BindToIndex(1));"
},
{
    "Id": 384,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/58759659ee547a957c5d36e72f2274ab34fdb6cb",
    "Violation": "improper",
    "Bug report": "Fix OOB check for result_index in header generation",
    "Number of deleted lines": 1,
    "Deleted lines": "                      const CompileResult& compile_result,\n                      const MetadataResult& metadata_result, string* header) {\n  TF_RETURN_IF_ERROR(ValidateConfig(config));\n  TF_RETURN_IF_ERROR(ValidateFeedFetchCppNames(config));\n  const int64 result_index = compile_result.aot->result_buffer_index();\n  const xla::BufferSizes& temp_sizes = compile_result.aot->buffer_sizes();\n  if (result_index < 0 || result_index > temp_sizes.size()) {\n    return errors::InvalidArgument(\"result index: \", result_index,\n                                   \" is outside the range of temp sizes: [0,\",\n                                   temp_sizes.size(), \")\");\n  }\n\n  // Compute sizes and generate methods.\n  std::vector<int64> arg_sizes;\n  TF_RETURN_IF_ERROR(ComputeArgSizes(compile_result, &arg_sizes));"
},
{
    "Id": 385,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/80b65ab79bf8dd6ec03c570b59a1208bb27fec24",
    "Violation": "improper",
    "Bug report": " Small fix to axis check for tfl.pack to tosa. There was an off-by-one error when checking the axis value based on the input rank.",
    "Number of deleted lines": 1,
    "Deleted lines": "\n  // Sanity check 2: axis can be from [0, rank(input)+1]\n  // Where rank(input)+1 means create a new dimension\n  // Negative values are also allowed up to -(rank(input)+1)\n  // where the axis \"wraps around\".\n  if (axis < 0) axis += input_tensor_rank;\n  if ((axis < 0) || (axis > (input_tensor_rank + 1))) {\n    (void)rewriter.notifyMatchFailure(op, \"axis out of valid range\");\n    return std::nullopt;\n  }\n\n  // Sanity check 2: if input shape is [A, B, C], output shape should be [N,\n  // A, B, C]\n  // 2.a check output is rank(input) + 1\n  SmallVector<int64_t> output_shape_vals(result_type.getShape().begin(),"
},
{
    "Id": 386,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c2ff14318050e26302785a49a1719d29ddcc91b4",
    "Violation": "improper",
    "Bug report": " [XNNPACK] Fix incorrect check in slice node. begin+size == input dimension is valid, e.g. input size is 3, begin is 2, size is 1.",
    "Number of deleted lines": 2,
    "Deleted lines": "                                 \"size %\" PRId64\n                                 \" does not match output shape %d at \"\n                                 \"dimension %d in SLICE node #%d\",\n                                 size[i], output_shape->data[i], i, node_index);\n        return kTfLiteError;\n      }\n      if (begin[i] + size[i] >= input_shape->data[i]) {\n        TF_LITE_MAYBE_KERNEL_LOG(logging_context,\n                                 \"begin + size (%\" PRId64 \" + %\" PRId64\n                                 \") must be less input \"\n                                 \"dimension %d in SLICE node #%d\",\n                                 begin[i], size[i], input_shape->data[i],\n                                 node_index);\n        return kTfLiteError;\n      }\n    }\n\n    if (subgraph != nullptr) {"
},
{
    "Id": 387,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/d23458fdd2655c83ff9d54725062ded31b644ba4",
    "Violation": "improper",
    "Bug report": " [XLA:CPU] Do not check that the size of the XLA parameter buffer is exactly equal to the size of the underlying given buffer Instead, check that the underlying allocation is \"large enough\". This is also more consistent with XLA:GPU behavior. The mismatch can happen when the input comes from tf.where, which is backed by an allocation larger than is actually required.",
    "Number of deleted lines": 1,
    "Deleted lines": "    se::DeviceMemoryAllocator* memory_allocator, int device_ordinal) {\n  VLOG(3) << allocation.ToString();\n  if (allocation.is_entry_computation_parameter()) {\n    se::DeviceMemoryBase out = arguments[allocation.parameter_number()]\n                                   .Buffer(allocation.param_shape_index())\n                                   .AsDeviceMemoryBase();\n    CHECK_EQ(allocation.size(), out.size())\n        << \"Size mismatch on param \" << allocation.parameter_number()\n        << \" at shape index \" << allocation.param_shape_index().ToString();\n    VLOG(3) << \"allocation is a parameter\";\n    return MaybeOwningDeviceMemory{out};\n  } else if (allocation.is_constant()) {\n    VLOG(3) << \"allocation is a constant\";\n    return MaybeOwningDeviceMemory{se::DeviceMemoryBase{}};\n  } else if (allocation.is_thread_local()) {"
},
{
    "Id": 388,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/4863013a3ec5b97c042a38ab567bcc4a62ccde5c",
    "Violation": "insufficient",
    "Bug report": " Add checking for number of inputs in GetOptionalInputTensor to avoid indexing out of array bounds.",
    "Number of deleted lines": 1,
    "Deleted lines": "  return NumElements(t->dims);\n}\n\ninline const TfLiteTensor* GetOptionalInputTensor(TfLiteContext* context,\n                                                  const TfLiteNode* node,\n                                                  int index) {\n  const bool use_tensor = node->inputs->data[index] != kTfLiteOptionalTensor;\n  if (use_tensor) {\n    return &context\n                ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];\n  }\n  return nullptr;\n}\n\n// Determines whether tensor is constant."
},
{
    "Id": 389,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1e38a0025c9a983bf3229299109b5b1781215c7e",
    "Violation": "missing",
    "Bug report": " [XLA] CHECK that sparse indices are in range in MutableLiteralBase::AppendSparseElement. Previously there was no range-checking on sparse elements' indices.",
    "Number of deleted lines": 1,
    "Deleted lines": "}\n\ntemplate <typename NativeT>\nvoid MutableLiteralBase::AppendSparseElement(\n    absl::Span<const int64> multi_index, NativeT value,\n    const ShapeIndex& shape_index) {\n  // TODO(jlebar): CHECK that multi_index is in range?\n  Piece& p = piece(shape_index);\n  const Shape& subshape = p.subshape();\n  CHECK(LayoutUtil::IsSparseArray(subshape));\n  int64 rank = subshape.rank();\n  CHECK_EQ(multi_index.size(), rank);\n  int64 last_element = p.sparse_indices()->index_count();\n  CHECK_LT(last_element, LayoutUtil::MaxSparseElements(subshape.layout()));\n  p.sparse_indices()->Append(multi_index);\n  CHECK_LT(last_element, p.data<NativeT>().size());\n  p.data<NativeT>()[last_element] = value;\n}\n\ntemplate <typename NativeT>"
},
{
    "Id": 390,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1610da3f992487bd9a8181d1e83cae99fe1e34d9",
    "Violation": "missing",
    "Bug report": "add more sanity check on AvgPoolGrad op",
    "Number of deleted lines": 0,
    "Deleted lines": "          grad_mkl_shape.IsMklTensor()\n              ? grad_mkl_shape.GetSizesAsMklDnnDims()\n              : is_pool2d ? TFShapeToMklDnnDimsInNCHW(grad_tensor.shape(),\n                                                      this->data_format_tf_)\n                          : TFShapeToMklDnnDimsInNCDHW(grad_tensor.shape(),\n                                                       this->data_format_tf_);\n      memory::dims output_dims_mkl_order;\n      this->GetOutputDims(pool_params, &output_dims_mkl_order);\n\n      // get src memory::desc\n      memory::desc src_md =\n          orig_input_mkl_shape.IsMklTensor()\n              ? orig_input_mkl_shape.GetMklLayout()\n              : memory::desc(orig_input_dims_mkl_order, MklDnnType<T>(),"
},
{
    "Id": 391,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a68f57a24203fd49c4a5c4a8f51098d4415a93f8",
    "Violation": "missing",
    "Bug report": " [XNNPACK] Add missing return when output channels do not match in TransposeConvolution Add a check that input channels in the filter and tensor match.",
    "Number of deleted lines": 0,
    "Deleted lines": "      TF_LITE_MAYBE_KERNEL_LOG(\n          logging_context,\n          \"transpose convolution kernel output channel dimension (%d) \"\n          \"doesn't match output shape channel dimension (%d) in node #%d: \"\n          \"4 dimensions expected\",\n          output_channels, output_tensor_channels, node_index);\n    }\n\n    int padding_top = 0;\n    int padding_bottom = 0;\n    int padding_left = 0;\n    int padding_right = 0;\n    int adjustment_height = 0;\n    int adjustment_width = 0;"
},
{
    "Id": 392,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1b54cadd19391b60b6fcccd8d076426f7221d5e8",
    "Violation": "missing",
    "Bug report": "Add missing validation to sparse dense cwise ops.",
    "Number of deleted lines": 0,
    "Deleted lines": "                    TensorShapeUtils::IsVector(shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs sp_values and sp_shape should be vectors \"\n                    \"but received shapes: \",\n                    values_t->shape().DebugString(), \" and \",\n                    shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of values and indices should match. (\",\n            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n\n    const auto indices_mat = indices_t->matrix<int64_t>();\n    const auto shape_vec = shape_t->vec<int64_t>();\n    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n    const auto rhs_dims = BCast::FromShape(dense_t->shape());\n    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n\n    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal"
},
{
    "Id": 393,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/b51b82fe65ebace4475e3c54eb089c18a4403f1c",
    "Violation": "missing",
    "Bug report": " Add missing validation to AddManySparseToTensorsMap. Sparse tensors have a set of requirements for the 3 components and not all of them were checked.",
    "Number of deleted lines": 2,
    "Deleted lines": "    OP_REQUIRES_OK(context, GetMap(context, true /* is_writing */, &map));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices->shape().DebugString()));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_values->shape().DebugString()));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape->shape().DebugString()));\n\n    int rank = input_shape->NumElements();\n\n    OP_REQUIRES(\n        context, rank > 1,\n        errors::InvalidArgument(\n            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n"
},
{
    "Id": 394,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/23968a8bf65b009120c43b5ebcceaf52dbc9e943",
    "Violation": "missing",
    "Bug report": " Fix out of bound access in DequantizeOp by adding check for axis < input dimension",
    "Number of deleted lines": 0,
    "Deleted lines": "\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const Tensor& input_min_tensor = ctx->input(1);\n    const Tensor& input_max_tensor = ctx->input(2);\n\n    int num_slices = 1;\n    if (axis_ > -1) {\n      num_slices = input.dim_size(axis_);\n    }\n    OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,\n                errors::InvalidArgument(\n                    \"input_min_tensor must have as many elements as input on \"\n                    \"the dequantization axis (\","
},
{
    "Id": 395,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/4923de56ec94fff7770df259ab7f2288a74feb41",
    "Violation": "missing",
    "Bug report": " Don't do any work when reshaping 0 elements sparse tensor. If reshaping to 0 elements tensor, check that input has no elements. If reshaping no elements input, check that output has no elements.",
    "Number of deleted lines": 0,
    "Deleted lines": "  Tensor *result_indices = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(output_indices_idx,\n                                          TensorShape({nnz, output_rank}),\n                                          &result_indices));\n  if (nnz > 0) {\n    OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                context, input_shape, output_shape,\n                                input_indices_in.matrix<int64>(),\n                                result_indices->matrix<int64>()));\n  }\n}\n\n#define EXPLICITLY_INSTANTIATE_FUNCTION(Device)                    \\"
},
{
    "Id": 396,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/467730fe90282a75f15f67d701b278e86cfad65e",
    "Violation": "missing",
    "Bug report": "Fix dimension check for tf.keras.losses.BinaryCrossentropy. The reason was that broadcasting was applied directly. This fix adds dimension check to throw an error if there is a mismatch.",
    "Number of deleted lines": 0,
    "Deleted lines": "  Returns:\n      A tensor.\n  \"\"\"\n  if not from_logits:\n    if (isinstance(output, (ops.EagerTensor, variables_module.Variable)) or\n        output.op.type != 'Sigmoid'):\n      epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n      output = clip_ops.clip_by_value(output, epsilon_, 1. - epsilon_)\n\n      # Compute cross entropy from probabilities.\n      bce = target * math_ops.log(output + epsilon())\n      bce += (1 - target) * math_ops.log(1 - output + epsilon())\n      return -bce\n    else:"
},
{
    "Id": 397,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/7e2d53c1c371f38c7f0ef13c1c06336b22a195c0",
    "Violation": "missing",
    "Bug report": "[tf.data] Adds the expected check for better debugging.",
    "Number of deleted lines": 0,
    "Deleted lines": "        std::vector<Tensor> state_and_output;\n        state_and_output.reserve(dataset()->state_types_.size() +\n                                 output_dtypes().size());\n\n        Status s = instantiated_captured_func_->Run(ctx, std::move(args),\n                                                    &state_and_output);\n        if (s.ok()) {\n          state_.clear();\n          size_t i = 0;\n          for (; i < dataset()->state_types_.size(); ++i) {\n            if (state_and_output[i].dtype() != dataset()->state_types_[i]) {\n              return errors::InvalidArgument(\n                  \"Got wrong type for scan_func return value \", i,\n                  \" (expected \", DataTypeString(dataset()->state_types_[i]),"
},
{
    "Id": 398,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/a12b8c4afdca3ac2945d62b3b83ca2599ab360f9",
    "Violation": "insufficient",
    "Bug report": " [xla] Improve validation of Broadcast shape. If one misreads the semantics of this instruction, it's easy to cause an out of bounds access into the dimensions here. Add an extra check to return a proper error to the user rather than crashing in that case.",
    "Number of deleted lines": 2,
    "Deleted lines": "  TF_RET_CHECK(ShapeUtil::Rank(operand_shape) ==\n               broadcast->dimensions().size());\n  for (int64 operand_dimension = 0;\n       operand_dimension < ShapeUtil::Rank(operand_shape);\n       ++operand_dimension) {\n    int64 output_dimension = broadcast->dimensions()[operand_dimension];\n    TF_RET_CHECK(broadcast->shape().dimensions(output_dimension) ==\n                 operand_shape.dimensions(operand_dimension))\n        << broadcast->ToString() << \" operand shape \" << operand_shape;\n  }\n  return Status::OK();\n}\n\nStatus ShapeVerifier::HandleReshape(HloInstruction* reshape) {\n  // Check for mixed precision.\n  TF_RETURN_IF_ERROR(CheckShape(reshape, reshape->shape()));"
},
{
    "Id": 399,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/32dc203f55a7462ddf780c68d619af574daedd46",
    "Violation": "insufficient",
    "Bug report": "Improve gradient shape validation errors.",
    "Number of deleted lines": 2,
    "Deleted lines": "                in_grads = control_flow_ops.tuple(in_grads)\n          _LogOpGradients(op, out_grads, in_grads)\n        else:\n          # If no grad_fn is defined or none of out_grads is available,\n          # just propagate a list of None backwards.\n          in_grads = [None] * len(op.inputs)\n        for t_in, in_grad in zip(op.inputs, in_grads):\n          if in_grad is not None:\n            if (isinstance(in_grad, ops.Tensor) and\n                t_in.dtype != dtypes.resource):\n              in_grad.set_shape(t_in.get_shape())\n            _SetGrad(grads, t_in, in_grad)\n        if loop_state:\n          loop_state.ExitGradWhileContext(op, before=False)\n\n      # Update pending count for the inputs of op and enqueue ready ops.\n      _UpdatePendingAndEnqueueReady(grads, op, queue, pending_count, loop_state)\n\n  if loop_state:"
},
{
    "Id": 400,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/25821f0d91623d654bb1bdd62423e644bae9f7f8",
    "Violation": "improper",
    "Bug report": "TensorFlow: Fix OP_REQUIRES check for depthwise pooling.",
    "Number of deleted lines": 2,
    "Deleted lines": "    OP_REQUIRES_OK(context, context->allocate_output(\n                                0, params.forward_output_shape(), &output));\n\n    if (params.depth_window > 1) {\n      // Validate spec against the current implementation.  A\n      // relaxation of these requirements would be ideal.\n      OP_REQUIRES(context, params.out_depth % params.depth_window > 0,\n                  errors::Unimplemented(\n                      \"Depthwise max pooling requires \"\n                      \"the depth window to evenly divide the input depth.\"));\n      OP_REQUIRES(\n          context, params.out_depth == params.depth_stride,\n          errors::Unimplemented(\"Depthwise max pooling requires \"\n                                \"the depth window to equal the depth stride.\"));\n\n      DepthwiseMaxPool(context, output, tensor_in, params);\n    } else {\n      SpatialMaxPool(context, output, tensor_in, params, padding_);\n    }\n  }"
},
{
    "Id": 401,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/05ec322172958f6e67e4bcaef4681e6aa54fabeb",
    "Violation": "missing",
    "Bug report": " Return error message with illegal input rather than check-failing in op_kernel.",
    "Number of deleted lines": 0,
    "Deleted lines": "    } else {\n      const TensorShape& shape = kernel->outputs[i].shape;\n      const DataType& type = kernel->outputs[i].type;\n      VLOG(2) << \"Retval \" << i << \" shape \" << shape.DebugString() << \" type \"\n              << DataTypeString(type);\n      if (type == DT_RESOURCE) {\n        ctx->set_output(i, ctx->input(kernel->outputs[i].input_index));\n      } else {\n        se::DeviceMemoryBase buffer = output.buffer({output_num});\n        if (allocate_xla_tensors_) {\n          Tensor* output_tensor;\n          TF_RETURN_IF_ERROR(ctx->allocate_output(i, shape, &output_tensor));\n          XlaTensor* xla_tensor = XlaTensor::FromTensor(output_tensor);\n          if (xla_tensor) {"
},
{
    "Id": 402,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/62cb54f2caf48480dc6b3c1ce9629eaac4688f83",
    "Violation": "missing",
    "Bug report": " Set 2nd output shape for SparseSegmentReduceGradV2 Fixes a debug check failure.",
    "Number of deleted lines": 0,
    "Deleted lines": "    dim0_shape = c->Vector(dim0_value);\n  }\n\n  ShapeHandle out;\n  TF_RETURN_IF_ERROR(c->Concatenate(dim0_shape, subshape, &out));\n  c->set_output(0, out);\n  return OkStatus();\n}\n\nStatus SparseSegmentReductionGradShapeFn(InferenceContext* c) {\n  return SparseSegmentReductionGradShapeFnImpl(\n      c,\n      /*outputs_unique_indices=*/false);\n}"
},
{
    "Id": 403,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9b0f99ddd27e7738732a154be5469391ee8fc977",
    "Violation": "missing",
    "Bug report": "Add check to ensure element sizes are the same",
    "Number of deleted lines": 1,
    "Deleted lines": "template <typename T>\ninline void SubWithActivation(\n    const ArithmeticParams& params, const RuntimeShape& input1_shape,\n    const T* input1_data, const RuntimeShape& input2_shape,\n    const T* input2_data, const RuntimeShape& output_shape, T* output_data) {\n  ruy::profiler::ScopeLabel label(\"SubWithActivation_optimized\");\n\n  auto input1_map = MapAsVector(input1_data, input1_shape);\n  auto input2_map = MapAsVector(input2_data, input2_shape);\n  auto output_map = MapAsVector(output_data, output_shape);\n  T activation_min, activation_max;\n  GetActivationParams(params, &activation_min, &activation_max);\n  output_map.array() = (input1_map.array() - input2_map.array())\n                           .cwiseMin(activation_max)\n                           .cwiseMax(activation_min);"
},
{
    "Id": 404,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/f8ec0f101bac066faa2e917ac714ca9eea310eac",
    "Violation": "missing",
    "Bug report": "adding checks that pad fusion works only Conv2D",
    "Number of deleted lines": 1,
    "Deleted lines": "                                  filter_tf_shape, filter_mkl_shape);\n        return;\n      }\n\n      bool isConv2D = (strides_.size() == 4);\n      // TODO(Intel-tf) Add check to make sure padEnabled is true only for 2D\n\n      // Create memory for user data.\n      // Describe how the inputs and outputs of Convolution look like. Also\n      // specify buffers containing actual input and output data.\n      auto tf_fmt = isConv2D ? TFDataFormatToMklDnnDataFormat(data_format_)\n                             : TFDataFormatToMklDnn3DDataFormat(data_format_);\n\n      // If input is in MKL layout, then simply grab input layout; otherwise,\n      // construct input Tf layout. For TF layout, although input shape"
},
{
    "Id": 405,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9718fed7b9aba244359b3d38c2a1dc20e50428bd",
    "Violation": "missing",
    "Bug report": " Added size check to avoid memory corruption in GraphDefImporter::ConvertNodeDef.",
    "Number of deleted lines": 0,
    "Deleted lines": "    }\n  }\n\n  // Get the result types. Ops can have multiple named results. Track the\n  // segment sizes.\n  SmallVector<std::pair<unsigned, unsigned>> result_segments;\n  result_segments.reserve(op_def->output_arg_size());\n  state.types.reserve(op_def->output_arg_size() + 1);\n  for (const OpDef::ArgDef &def : op_def->output_arg()) {\n    unsigned index = state.types.size();\n    TF_ASSIGN_OR_RETURN(unsigned size,\n                        ArgNumType(state.attributes, def, state.types));\n    result_segments.emplace_back(index, size);\n  }"
},
{
    "Id": 406,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/edd9fb416e04b8ca4398c4eea65f14dc6704a44a",
    "Violation": "unnecessary",
    "Bug report": " TfLiteTensorCopy returns an error status when src and dest bytes are not equal. So we don't need to check them specifically if we ensure the status of the call to copy (which we should do anyways).",
    "Number of deleted lines": 2,
    "Deleted lines": "    const TfLiteTensor* src_tensor =\n        src_subgraph->tensor(src_tensor_indices[i]);\n    TfLiteTensor* dst_tensor = dst_subgraph->tensor(dst_tensor_indices[i]);\n    if (IsDynamicTensor(dst_tensor)) {\n      TfLiteTensorRealloc(src_tensor->bytes, dst_tensor);\n    }\n    TF_LITE_ENSURE_EQ(context, src_tensor->bytes, dst_tensor->bytes);\n    TfLiteTensorCopy(src_tensor, dst_tensor);\n  }\n  return kTfLiteOk;\n}\n\n// Propagate tensor shapes and types from `src_tensor_indices` in `src_subgraph`\n// to `dst_tensor_indices` in `dst_subgraph` and copy data deeply.\ntemplate <typename SrcVector, typename DstVector>\nTfLiteStatus DeepCopyTensorsShapeTypeData(TfLiteContext* context,"
},
{
    "Id": 407,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/8a2e7deb21f02e4072d6b62cf7f447b9264afe01",
    "Violation": "improper",
    "Bug report": " Adjust checks for type(Tensor) to isinstance or is_eager/is_symbolic_tensor.",
    "Number of deleted lines": 1,
    "Deleted lines": "  Returns:\n    Returns the modified tensors with the same structure.\n  Raises:\n    `TypeError` if undefined type in the tensors structure.\n  \"\"\"\n  tensors_type = type(tensors)\n  if tensors_type is ops.Tensor:\n    return apply_fn(tensors)\n  elif isinstance(tensors, variables.Variable):\n    return apply_fn(tensors.value())\n  elif isinstance(tensors, (list, tuple)):\n    tensors = [_recursive_apply(t, apply_fn) for t in tensors]\n    if tensors_type is list:\n      return list(tensors)\n    elif tensors_type is tuple:"
},
{
    "Id": 408,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/b68b869e75916e6de37c2ca23a93643faf333011",
    "Violation": "improper",
    "Bug report": "Fix invalid keras tensor isinstance check",
    "Number of deleted lines": 1,
    "Deleted lines": "\n      self.is_placeholder = True\n      self._batch_input_shape = batch_input_shape\n    else:\n      raise_eager_tensor_error = False\n      if keras_tensor.keras_tensors_enabled():\n        if not isinstance(input_tensor, keras_tensor.keras_tensors_enabled()):\n          raise_eager_tensor_error = True\n      else:\n        if not tf_utils.is_symbolic_tensor(input_tensor):\n          raise_eager_tensor_error = True\n      if raise_eager_tensor_error:\n        raise ValueError('You should not pass an EagerTensor to `Input`. '\n                         'For example, instead of creating an '\n                         'InputLayer, you should instantiate your model and '"
},
{
    "Id": 409,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/040aaf39aebda57921991d05d29be5123e908d7c",
    "Violation": "missing",
    "Bug report": "Don't check that bool arrays are quantized.",
    "Number of deleted lines": 4,
    "Deleted lines": "  return in_shape == out_shape;\n}\n\nvoid CheckFinalDataTypesSatisfied(const Model& model) {\n  for (const auto& array_entry : model.GetArrayMap()) {\n    const auto& array = *array_entry.second;\n    // If the final data type is int16, the data type may be float, for example\n    // after dequantization.\n    if (array.final_data_type != ArrayDataType::kNone &&\n        array.final_data_type != ArrayDataType::kInt16) {\n      CHECK(array.final_data_type == array.data_type)\n          << \"Array \\\"\" << array_entry.first\n          << \"\\\" has mis-matching actual and final data types (\"\n          << ArrayDataTypeName(array.data_type) << \",\"\n          << ArrayDataTypeName(array.final_data_type) << \").\";\n    }\n  }\n}\n\nArrayDataType ConvertIODataTypeToArrayDataType(IODataType type) {\n  switch (type) {\n    case FLOAT:\n      return ArrayDataType::kFloat;"
},
{
    "Id": 410,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9a0de0ca6a39f3037e1be6ec740829863bcda3e8",
    "Violation": "improper",
    "Bug report": "[XLA:GPU] Fix type check in IsMatrixMultiplication",
    "Number of deleted lines": 1,
    "Deleted lines": "  bool type_is_allowed =\n      (output_primitive_type == F8E4M3FN || output_primitive_type == F8E5M2 ||\n       output_primitive_type == F16 || output_primitive_type == BF16 ||\n       output_primitive_type == F32 || output_primitive_type == F64 ||\n       output_primitive_type == C64 || output_primitive_type == C128) ||\n      (output_primitive_type == S32 && lhs_shape.element_type() == S8 &&\n       lhs_shape.element_type() == S8);\n  bool shapes_are_valid =\n      type_is_allowed &&\n      IsRank2(lhs_shape, dim_numbers.lhs_batch_dimensions_size()) &&\n      IsRank2(rhs_shape, dim_numbers.lhs_batch_dimensions_size()) &&\n      IsRank2(dot.shape(), dim_numbers.lhs_batch_dimensions_size()) &&\n      !ShapeUtil::IsZeroElementArray(lhs_shape) &&\n      !ShapeUtil::IsZeroElementArray(rhs_shape);\n"
},
{
    "Id": 411,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/db9b247cd1f3ff046359f7b64ca60c2d697fe2e1",
    "Violation": "insufficient",
    "Bug report": " Fix the functional model loading with nested sequential model. The nested sequential model is created with _is_graph_network = False, the current instance check is not strong enough.",
    "Number of deleted lines": 1,
    "Deleted lines": "  return nest.flatten([nodes for nodes in nodes_by_depth.values()]), layers\n\n\ndef _should_skip_first_node(layer):\n  \"\"\"Returns True if the first layer node should not be saved or loaded.\"\"\"\n  # Networks start with a pre-existing node linking their input to output.\n  return isinstance(layer, Functional)\n\n\ndef _deserialize_keras_tensors(kwargs, layer_map):\n  \"\"\"Deserializes Keras Tensors passed to `call`..\"\"\"\n\n  def _deserialize_keras_tensor(t):\n    \"\"\"Deserializes a single Keras Tensor passed to `call`.\"\"\"\n    if isinstance(t, tf_utils.ListWrapper):"
},
{
    "Id": 412,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/9a4b6b6bcc7a813162bf0378727950e321aca19c",
    "Violation": "improper",
    "Bug report": "Add stricter type checking for tf.math.real (using is_numeric)",
    "Number of deleted lines": 1,
    "Deleted lines": "  \"\"\"\n  with ops.name_scope(name, \"Real\", [input]) as name:\n    input = ops.convert_to_tensor(input, name=\"input\")\n    if input.dtype.is_complex:\n      real_dtype = input.dtype.real_dtype\n      return gen_math_ops.real(input, Tout=real_dtype, name=name)\n    elif tf.debugging.is_numeric_tensor(input):\n      return input\n    else:\n      raise TypeError(\"input must be a numeric tensor, but got tensor with dtype {}\".format(input.dtype))\n\n\n@tf_export(\"math.imag\", v1=[\"math.imag\", \"imag\"])\n@dispatch.register_unary_elementwise_api\n@dispatch.add_dispatch_support"
},
{
    "Id": 413,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/8a0fee00855a0e806bd5c9cc1ad6c0175a985922",
    "Violation": "unnecessary",
    "Bug report": " [XLA] Don't use isnan on values which can't have NaN. While we are here, don't upcast to double just to check if something is NaN.",
    "Number of deleted lines": 5,
    "Deleted lines": "        return true;\n      });\n}\n\ntemplate <typename NativeT>\nstatic bool EqualIncludingNan(NativeT a, NativeT b) {\n  // msvc can't compile std::isnan(a) where `a` is uint8_t.  This is a bug\n  // according to https://en.cppreference.com/w/cpp/numeric/math/isnan, but it's\n  // easy to work around.\n  return a == b || (std::isnan(static_cast<double>(a)) &&\n                    std::isnan(static_cast<double>(b)));\n}\n\ntemplate <typename T>\nstatic bool EqualIncludingNan(std::complex<T> a, std::complex<T> b) {\n  return EqualIncludingNan(a.real(), b.real()) &&\n         EqualIncludingNan(a.imag(), b.imag());\n}\n"
},
{
    "Id": 414,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/580140611a47413dcf6373deb1250c0ed605e873",
    "Violation": "missing",
    "Bug report": " [XLA] Do not check fail in proto copy from if the backend config proto and desired proto type do not match.",
    "Number of deleted lines": 2,
    "Deleted lines": "\nStatus HloInstruction::GetBackendConfigInternal(\n    tensorflow::protobuf::Message* proto) const {\n  proto->Clear();\n\n  if (auto* proto_ptr = backend_config_.GetProtoPtr()) {\n    proto->CopyFrom(*proto_ptr);\n    return Status::OK();\n  }\n\n  auto& raw_string = raw_backend_config_string();\n  // Empty string does not parse as valid JSON, but it's a valid backend config,\n  // corresponding to the empty proto.\n  if (raw_string.empty()) {\n    return Status::OK();\n  }"
},
{
    "Id": 415,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/d3d1cd3ad2becac5c31387f7fc483af65c7c8c84",
    "Violation": "unnecessary",
    "Bug report": " Fixes the crashes caused by the refcount checks for non-copyable types. For async value refs, refcounts don't equal to number of waiters as waiters can make copies of the async value refs.",
    "Number of deleted lines": 1,
    "Deleted lines": "                          callback = std::move(callback)]() mutable {\n      DCHECK(promise.IsConcrete());\n      if constexpr (std::is_copy_constructible_v<T>) {\n        std::move(callback)(*promise);\n        return;\n      }\n      DCHECK_EQ(promise.value()->NumRef(), 1);\n      std::move(callback)(std::move(*promise));\n    });\n  }\n\n  // Indicates that event will not complete until after this becomes ready.\n  //\n  // May safely be called with event==nullptr in which case AssertHappensBefore\n  // has no effect."
},
{
    "Id": 416,
    "Library": "tensorflow",
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/02907e867c74651a9eb74971f56559d5db2efa1c",
    "Violation": "missing",
    "Bug report": " Use Nano seconds in Timestamp check as Pico seconds can lead to overflow.",
    "Number of deleted lines": 0,
    "Deleted lines": "\n  int64_t DurationPs() const { return event_->duration_ps(); }\n\n  int64_t EndOffsetPs() const {\n    return event_->offset_ps() + event_->duration_ps();\n  }\n  int64_t EndTimestampPs() const { return TimestampPs() + DurationPs(); }\n\n  int64_t NumOccurrences() const { return event_->num_occurrences(); }\n\n  bool operator<(const XEventVisitor& other) const {\n    return GetTimespan() < other.GetTimespan();\n  }\n"
}]