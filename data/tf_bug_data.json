[
  {
    "Title": "\n        `CHECK` fail in `QuantizeAndDequantizeV3`\n      ",
    "Bug description": "If  QuantizeAndDequantizeV3  is given a nonscalar  num_bits  input tensor, it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "signed_input = True\nrange_given = False\nnarrow_range = False\naxis = -1\ninput = tf.constant(-3.5, shape=[1], dtype=tf.float32)\ninput_min = tf.constant(-3.5, shape=[1], dtype=tf.float32)\ninput_max = tf.constant(-3.5, shape=[1], dtype=tf.float32)\nnum_bits = tf.constant([], shape=[0], dtype=tf.int32)\n)\ntf.raw_ops.QuantizeAndDequantizeV3(input=input, input_min=input_min, input_max=input_max, num_bits=num_bits, signed_input=signed_input, range_given=range_given, narrow_range=narrow_range, axis=axis)",
    "Code change": [
      "@@ -21,19 +21,23 @@ limitations under the License.\n #define EIGEN_USE_GPU\n #endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n \n-#include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"\n-\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/type_traits.h\"\n #include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n \n namespace tensorflow {\n+namespace {\n \n-typedef Eigen::ThreadPoolDevice CPUDevice;\n-typedef Eigen::GpuDevice GPUDevice;\n+using CpuDevice = ::Eigen::ThreadPoolDevice;\n+using GpuDevice = ::Eigen::GpuDevice;\n+using ::tensorflow::errors::InvalidArgument;\n+\n+}  // namespace\n \n // Simulate quantization precision loss in a float tensor by:\n // 1. Quantize the tensor to fixed point numbers, which should match the target\n@@ -49,8 +53,8 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n-                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n-                                        \" with signed_input_ \", signed_input_));\n+                InvalidArgument(\"num_bits is out of range: \", num_bits_,\n+                                \" with signed_input_ \", signed_input_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n \n     string round_mode_string;\n@@ -58,10 +62,10 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n     OP_REQUIRES(\n         ctx,\n         (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),\n-        errors::InvalidArgument(\"Round mode string must be \"\n-                                \"'HALF_UP' or \"\n-                                \"'HALF_TO_EVEN', is '\" +\n-                                round_mode_string + \"'\"));\n+        InvalidArgument(\"Round mode string must be \"\n+                        \"'HALF_UP' or \"\n+                        \"'HALF_TO_EVEN', is '\" +\n+                        round_mode_string + \"'\"));\n     if (round_mode_string == \"HALF_UP\") {\n       round_mode_ = ROUND_HALF_UP;\n     } else if (round_mode_string == \"HALF_TO_EVEN\") {\n@@ -72,12 +76,10 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n-    OP_REQUIRES(\n-        ctx, axis_ >= -1,\n-        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n-    OP_REQUIRES(\n-        ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n-        errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,\n+    OP_REQUIRES(ctx, axis_ >= -1,\n+                InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n+    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n+                InvalidArgument(\"Shape must be at least rank \", axis_ + 1,\n                                 \" but is rank \", input.shape().dims()));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     Tensor input_min_tensor;\n@@ -91,21 +93,21 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n         auto min_val = input_min_tensor.scalar<T>()();\n         auto max_val = input_max_tensor.scalar<T>()();\n         OP_REQUIRES(ctx, min_val <= max_val,\n-                    errors::InvalidArgument(\"Invalid range: input_min \",\n-                                            min_val, \" > input_max \", max_val));\n+                    InvalidArgument(\"Invalid range: input_min \", min_val,\n+                                    \" > input_max \", max_val));\n       } else {\n-        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_min_tensor has incorrect size, was \",\n-                        input_min_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_min_tensor.shape()));\n-        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_max_tensor has incorrect size, was \",\n-                        input_max_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_max_tensor.shape()));\n+        OP_REQUIRES(\n+            ctx, input_min_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_min_tensor has incorrect size, was \",\n+                            input_min_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_min_tensor.shape()));\n+        OP_REQUIRES(\n+            ctx, input_max_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_max_tensor has incorrect size, was \",\n+                            input_max_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_max_tensor.shape()));\n       }\n     } else {\n       auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n@@ -158,38 +160,34 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n     Tensor* input_backprop = nullptr;\n     OP_REQUIRES_OK(ctx,\n                    ctx->allocate_output(0, input.shape(), &input_backprop));\n-    OP_REQUIRES(\n-        ctx, axis_ >= -1,\n-        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n+    OP_REQUIRES(ctx, axis_ >= -1,\n+                InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n     OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n-                errors::InvalidArgument(\n+                InvalidArgument(\n                     \"Axis should be -1 or 0 or a positive value less than \",\n                     input.shape().dims(), \"but given axis value was \", axis_));\n \n-    OP_REQUIRES(\n-        ctx, input.IsSameSize(gradient),\n-        errors::InvalidArgument(\"gradient and input must be the same size\"));\n+    OP_REQUIRES(ctx, input.IsSameSize(gradient),\n+                InvalidArgument(\"gradient and input must be the same size\"));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     const Tensor& input_min_tensor = ctx->input(2);\n     OP_REQUIRES(ctx,\n                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n-                errors::InvalidArgument(\n+                InvalidArgument(\n                     \"Input min tensor must have dimension 0 or 1. Received \",\n                     input_min_tensor.dims(), \".\"));\n     const Tensor& input_max_tensor = ctx->input(3);\n     OP_REQUIRES(ctx,\n                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n-                errors::InvalidArgument(\n+                InvalidArgument(\n                     \"Input max tensor must have dimension 0 or 1. Received \",\n                     input_max_tensor.dims(), \".\"));\n     if (axis_ != -1) {\n-      OP_REQUIRES(\n-          ctx, input_min_tensor.dim_size(0) == depth,\n-          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n+      OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n+                  InvalidArgument(\"min has incorrect size, expected \", depth,\n                                   \" was \", input_min_tensor.dim_size(0)));\n-      OP_REQUIRES(\n-          ctx, input_max_tensor.dim_size(0) == depth,\n-          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n+      OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n+                  InvalidArgument(\"max has incorrect size, expected \", depth,\n                                   \" was \", input_max_tensor.dim_size(0)));\n     }\n \n@@ -203,12 +201,12 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n \n     if (axis_ == -1) {\n-      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n-                  errors::InvalidArgument(\n-                      \"input_min must be a scalar if axis is unspecified\"));\n-      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n-                  errors::InvalidArgument(\n-                      \"input_max must be a scalar if axis is unspecified\"));\n+      OP_REQUIRES(\n+          ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n+          InvalidArgument(\"input_min must be a scalar if axis is unspecified\"));\n+      OP_REQUIRES(\n+          ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n+          InvalidArgument(\"input_max must be a scalar if axis is unspecified\"));\n       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n         input.template flat<T>(), input_min_tensor.scalar<T>(),\n@@ -252,21 +250,25 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n     OP_REQUIRES(ctx, axis_ < input.dims(),\n-                errors::InvalidArgument(\n+                InvalidArgument(\n                     \"Axis requested is larger than input dimensions. Axis: \",\n                     axis_, \" Input Dimensions: \", input.dims()));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n \n-    Tensor num_bits_tensor;\n-    num_bits_tensor = ctx->input(3);\n-    int num_bits_val = num_bits_tensor.scalar<int32>()();\n+    // Get num_bits and validate.\n+    const Tensor num_bits_tensor = ctx->input(3);\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(num_bits_tensor.shape()),\n+                InvalidArgument(\"Invalid shape. The `num_bits` tensor should \"\n+                                \"be a scalar. Got dimensions: \",\n+                                num_bits_tensor.dims()));\n \n-    OP_REQUIRES(\n-        ctx, num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),\n-        errors::InvalidArgument(\"num_bits is out of range: \", num_bits_val,\n-                                \" with signed_input_ \", signed_input_));\n+    const int num_bits_val = num_bits_tensor.scalar<int32>()();\n+    OP_REQUIRES(ctx,\n+                num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),\n+                InvalidArgument(\"num_bits is out of range: \", num_bits_val,\n+                                \" with `signed_input_` \", signed_input_));\n \n     Tensor input_min_tensor;\n     Tensor input_max_tensor;\n@@ -274,24 +276,24 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\n       input_min_tensor = ctx->input(1);\n       input_max_tensor = ctx->input(2);\n       if (axis_ == -1) {\n-        auto min_val = input_min_tensor.scalar<T>()();\n-        auto max_val = input_max_tensor.scalar<T>()();\n+        const auto min_val = input_min_tensor.scalar<T>()();\n+        const auto max_val = input_max_tensor.scalar<T>()();\n         OP_REQUIRES(ctx, min_val <= max_val,\n-                    errors::InvalidArgument(\"Invalid range: input_min \",\n-                                            min_val, \" > input_max \", max_val));\n+                    InvalidArgument(\"Invalid range: input_min \", min_val,\n+                                    \" > input_max \", max_val));\n       } else {\n-        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_min_tensor has incorrect size, was \",\n-                        input_min_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_min_tensor.shape()));\n-        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_max_tensor has incorrect size, was \",\n-                        input_max_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_max_tensor.shape()));\n+        OP_REQUIRES(\n+            ctx, input_min_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_min_tensor has incorrect size, was \",\n+                            input_min_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_min_tensor.shape()));\n+        OP_REQUIRES(\n+            ctx, input_max_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_max_tensor has incorrect size, was \",\n+                            input_max_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_max_tensor.shape()));\n       }\n     } else {\n       auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n@@ -331,15 +333,14 @@ class QuantizeAndDequantizeOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n-                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n-                                        \" with signed_input_ \", signed_input_));\n+                InvalidArgument(\"num_bits is out of range: \", num_bits_,\n+                                \" with signed_input_ \", signed_input_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));\n     if (range_given_) {\n-      OP_REQUIRES(\n-          ctx, input_min_ <= input_max_,\n-          errors::InvalidArgument(\"Invalid range: input_min \", input_min_,\n+      OP_REQUIRES(ctx, input_min_ <= input_max_,\n+                  InvalidArgument(\"Invalid range: input_min \", input_min_,\n                                   \" > input_max \", input_max_));\n     }\n   }\n@@ -371,53 +372,53 @@ class QuantizeAndDequantizeOp : public OpKernel {\n   float input_max_;\n };\n \n-// Specializations for CPUDevice.\n+// Specializations for CpuDevice.\n \n namespace functor {\n template <typename T>\n-struct QuantizeAndDequantizeOneScaleFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d, typename TTypes<T>::ConstVec input,\n+struct QuantizeAndDequantizeOneScaleFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d, typename TTypes<T>::ConstVec input,\n                   const bool signed_input, const int num_bits,\n                   const bool range_given, Tensor* input_min_tensor,\n                   Tensor* input_max_tensor, QuantizerRoundMode round_mode,\n                   bool narrow_range, typename TTypes<T>::Vec out) {\n-    QuantizeAndDequantizeOneScaleImpl<CPUDevice, T>::Compute(\n+    QuantizeAndDequantizeOneScaleImpl<CpuDevice, T>::Compute(\n         d, input, signed_input, num_bits, range_given, input_min_tensor,\n         input_max_tensor, round_mode, narrow_range, out);\n   }\n };\n \n template <typename T>\n-struct QuantizeAndDequantizePerChannelFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d, typename TTypes<T, 3>::ConstTensor input,\n+struct QuantizeAndDequantizePerChannelFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d, typename TTypes<T, 3>::ConstTensor input,\n                   bool signed_input, int num_bits, bool range_given,\n                   Tensor* input_min_tensor, Tensor* input_max_tensor,\n                   QuantizerRoundMode round_mode, bool narrow_range,\n                   typename TTypes<T, 3>::Tensor out) {\n-    QuantizeAndDequantizePerChannelImpl<CPUDevice, T>::Compute(\n+    QuantizeAndDequantizePerChannelImpl<CpuDevice, T>::Compute(\n         d, input, signed_input, num_bits, range_given, input_min_tensor,\n         input_max_tensor, round_mode, narrow_range, out);\n   }\n };\n \n template <typename T>\n-struct QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d, typename TTypes<T>::ConstFlat gradient,\n+struct QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d, typename TTypes<T>::ConstFlat gradient,\n                   typename TTypes<T>::ConstFlat input,\n                   typename TTypes<T>::ConstScalar input_min_tensor,\n                   typename TTypes<T>::ConstScalar input_max_tensor,\n                   typename TTypes<T>::Flat input_backprop,\n                   typename TTypes<T>::Scalar input_min_backprop,\n                   typename TTypes<T>::Scalar input_max_backprop) {\n-    QuantizeAndDequantizeOneScaleGradientImpl<CPUDevice, T>::Compute(\n+    QuantizeAndDequantizeOneScaleGradientImpl<CpuDevice, T>::Compute(\n         d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,\n         input_min_backprop, input_max_backprop);\n   }\n };\n \n template <typename T>\n-struct QuantizeAndDequantizePerChannelGradientFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d,\n+struct QuantizeAndDequantizePerChannelGradientFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d,\n                   typename TTypes<T, 3>::ConstTensor gradient,\n                   typename TTypes<T, 3>::ConstTensor input,\n                   const Tensor* input_min_tensor,\n@@ -425,16 +426,16 @@ struct QuantizeAndDequantizePerChannelGradientFunctor<CPUDevice, T> {\n                   typename TTypes<T, 3>::Tensor input_backprop,\n                   typename TTypes<T>::Flat input_min_backprop,\n                   typename TTypes<T>::Flat input_max_backprop) {\n-    QuantizeAndDequantizePerChannelGradientImpl<CPUDevice, T>::Compute(\n+    QuantizeAndDequantizePerChannelGradientImpl<CpuDevice, T>::Compute(\n         d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,\n         input_min_backprop, input_max_backprop);\n   }\n };\n \n-template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice,\n+template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice,\n                                                                       float>;\n template struct functor::QuantizeAndDequantizePerChannelGradientFunctor<\n-    CPUDevice, double>;\n+    CpuDevice, double>;\n \n }  // namespace functor\n \n@@ -442,22 +443,22 @@ template struct functor::QuantizeAndDequantizePerChannelGradientFunctor<\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV2\")                      \\\n                               .Device(DEVICE_CPU)                              \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\\n                               .Device(DEVICE_CPU)                              \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV3Op<CPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV3Op<CpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\\n                               .Device(DEVICE_CPU)                              \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\\n                               .Device(DEVICE_CPU)                              \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV4GradientOp<CPUDevice, T>);    \\\n+                          QuantizeAndDequantizeV4GradientOp<CpuDevice, T>);    \\\n   REGISTER_KERNEL_BUILDER(                                                     \\\n       Name(\"QuantizeAndDequantize\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n-      QuantizeAndDequantizeOp<CPUDevice, T>);\n+      QuantizeAndDequantizeOp<CpuDevice, T>);\n TF_CALL_float(REGISTER_CPU_KERNEL);\n TF_CALL_double(REGISTER_CPU_KERNEL);\n #undef REGISTER_CPU_KERNEL\n@@ -470,29 +471,29 @@ TF_CALL_double(REGISTER_CPU_KERNEL);\n                               .HostMemory(\"input_min\")                         \\\n                               .HostMemory(\"input_max\")                         \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\\n                               .Device(DEVICE_GPU)                              \\\n                               .HostMemory(\"input_min\")                         \\\n                               .HostMemory(\"input_max\")                         \\\n                               .HostMemory(\"num_bits\")                          \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV3Op<GPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV3Op<GpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\\n                               .Device(DEVICE_GPU)                              \\\n                               .HostMemory(\"input_min\")                         \\\n                               .HostMemory(\"input_max\")                         \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\\n                               .Device(DEVICE_GPU)                              \\\n                               .HostMemory(\"input_min\")                         \\\n                               .HostMemory(\"input_max\")                         \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV4GradientOp<GPUDevice, T>);    \\\n+                          QuantizeAndDequantizeV4GradientOp<GpuDevice, T>);    \\\n   REGISTER_KERNEL_BUILDER(                                                     \\\n       Name(\"QuantizeAndDequantize\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\\n-      QuantizeAndDequantizeOp<GPUDevice, T>);\n+      QuantizeAndDequantizeOp<GpuDevice, T>);\n TF_CALL_float(REGISTER_GPU_KERNEL);\n TF_CALL_double(REGISTER_GPU_KERNEL);\n #undef REGISTER_GPU_KERNEL\n",
      "@@ -15,9 +15,11 @@\n \"\"\"Tests for tf.quantize ops.\"\"\"\n import numpy as np\n \n+from tensorflow.python.eager import context\n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors\n+from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import math_ops\n@@ -407,5 +409,59 @@ class QuantizeDownAndShrinkRangeOpTest(test_util.TensorFlowTestCase):\n               out_type=dtypes.quint8))\n \n \n+class QuantizeAndDequantizeV3OpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_valid(self):\n+    with ops.Graph().as_default(), context.eager_mode():\n+      input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],\n+                                         shape=(6,),\n+                                         dtype=dtypes.float32),\n+      input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)\n+      input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)\n+      num_bits = constant_op.constant(8, shape=(), dtype=dtypes.int32)\n+\n+      quantized = array_ops.quantize_and_dequantize_v3(\n+          input_value,\n+          input_min,\n+          input_max,\n+          num_bits,\n+          signed_input=True,\n+          range_given=False)\n+      self.assertSequenceAlmostEqual(\n+          input_value[0].numpy(), quantized.numpy()[0], delta=0.05)\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],\n+                                       shape=(6,),\n+                                       dtype=dtypes.float32),\n+    input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)\n+    input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)\n+    # Tensor with invalid shape and invalid number of elements.\n+    num_bits = constant_op.constant([], shape=(0,), dtype=dtypes.int32)\n+\n+    # Test that running the op raises error. It raises different errors\n+    # depending on whether the shape inference is run first or the op's\n+    # Compute() is run first.\n+    try:\n+      array_ops.quantize_and_dequantize_v3(\n+          input_value, input_min, input_max, num_bits, signed_input=True)\n+    except Exception as ex:  # pylint: disable=broad-except\n+      if isinstance(ex, errors.InvalidArgumentError):\n+        self.assertRegex(str(ex), \"The `num_bits` tensor should be a scalar.\")\n+      elif isinstance(ex, ValueError):\n+        self.assertRegex(str(ex), \"Shape must be rank 0\")\n+      else:\n+        self.fail(\n+            \"Raised exception other than expected: %s. \"\n+            \"Expected exceptions are errors.InvalidArgumentError or ValueError\",\n+            ex.__name__)\n+    else:\n+      self.fail(\n+          \"Did not raise an exception where it is expected to raise either \"\n+          \"a ValueError or errors.InvalidArgumentError.\")\n+\n+\n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9cr2-8pwr-fhfq",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV3(\n    input,\n    input_min,\n    input_max,\n    num_bits,\n    signed_input=True,\n    range_given=True,\n    narrow_range=False,\n    axis=-1,\n    name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "num_bits = tf.constant([], shape=[0], dtype=tf.int32)"
  },
  {
    "Title": "\n        `CHECK` fail in `FakeQuantWithMinMaxVarsGradient`\n      ",
    "Bug description": "When  tf.quantization.fake_quant_with_min_max_vars_gradient  receives input  min  or  max  that is nonscalar, it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "import numpy as np \narg_0=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)\narg_1=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)\narg_2=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)\narg_3=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)\narg_4=8\narg_5=False\narg_6=''\ntf.quantization.fake_quant_with_min_max_vars_gradient(gradients=arg_0, inputs=arg_1,\n,\nmin=arg_2, max=arg_3, num_bits=arg_4, narrow_range=arg_5, name=arg_6)",
    "Code change": [
      "@@ -261,6 +261,12 @@ class FakeQuantWithMinMaxVarsGradientOp : public OpKernel {\n                 InvalidArgument(\"gradient and input must be the same size\"));\n     const Tensor& min = context->input(2);\n     const Tensor& max = context->input(3);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n \n     Tensor* grad_wrt_input;\n     OP_REQUIRES_OK(context,\n@@ -414,10 +420,16 @@ class FakeQuantWithMinMaxVarsPerChannelGradientOp : public OpKernel {\n                 InvalidArgument(\"gradient and input must be the same size\"));\n     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n     const Tensor& min = context->input(2);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n     OP_REQUIRES(context, min.dim_size(0) == depth,\n                 InvalidArgument(\"min has incorrect size, expected \", depth,\n                                 \" was \", min.dim_size(0)));\n     const Tensor& max = context->input(3);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n     OP_REQUIRES(context, max.dim_size(0) == depth,\n                 InvalidArgument(\"max has incorrect size, expected \", depth,\n                                 \" was \", max.dim_size(0)));\n",
      "@@ -77,6 +77,71 @@ class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n               inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n \n \n+class FakeQuantWithMinMaxVarsGradientOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    gradients = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be equal rank|must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_gradient(\n+              gradients=gradients,\n+              inputs=inputs,\n+              min=0.0,\n+              max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_gradient(\n+              gradients=gradients,\n+              inputs=inputs,\n+              min=[[1.0], [2.0], [4.0]],\n+              max=[[1.0], [2.0], [4.0]]))\n+\n+\n+class FakeQuantWithMinMaxVarsPerChannelGradientOpTest(\n+    test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    gradients = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Shapes must be equal rank|must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[[0.0]], max=[1.0]))\n+\n+    with self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError),\n+        \"Dimension 0 in both shapes must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Shapes must be equal rank|must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[1.0], max=[[1.0]]))\n+\n+    with self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError),\n+        \"Dimension 0 in both shapes must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n+\n+\n class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n \n   @test_util.run_in_graph_and_eager_modes\n@@ -337,10 +402,9 @@ class QuantizeDownAndShrinkRangeOpTest(test_util.TensorFlowTestCase):\n     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                 \"must be rank 0\"):\n       self.evaluate(\n-          math_ops.quantize_down_and_shrink_range(input=inputs,\n-                                                  input_min=[],\n-                                                  input_max=4.0,\n-                                                  out_type=dtypes.quint8))\n+          math_ops.quantize_down_and_shrink_range(\n+              input=inputs, input_min=[], input_max=4.0,\n+              out_type=dtypes.quint8))\n \n \n if __name__ == \"__main__\":\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-r26c-679w-mrjm",
    "API Signature": "tf.quantization.fake_quant_with_min_max_vars_gradient(\n    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "arg_2=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)\narg_3=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK` fail in `tf.random.gamma`\n      ",
    "Bug description": "When  tf.random.gamma  receives large input shape and rates, it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(4,), dtype=tf.int32, maxval=65536)\narg_1=tf.random.uniform(shape=(4, 4), dtype=tf.float64, maxval=None)\narg_2=tf.random.uniform(shape=(4, 4, 4, 4, 4), dtype=tf.float64, maxval=None)\narg_3=tf.float64\narg_4=48\narg_5='None'\n\ntf.random.gamma(shape=arg_0, alpha=arg_1, beta=arg_2, dtype=arg_3, seed=arg_4, name=arg_5)",
    "Code change": [
      "@@ -166,7 +166,7 @@ class RandomGammaOp : public OpKernel {\n     }\n     const int64_t samples_per_alpha = samples_shape.num_elements();\n \n-    samples_shape.AppendShape(alpha_t.shape());\n+    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(alpha_t.shape()));\n     // Allocate output samples.\n     Tensor* samples_t = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));\n",
      "@@ -296,8 +296,8 @@ class RandomPoissonOp : public OpKernel {\n     TensorShape samples_shape;\n     OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_t, &samples_shape));\n     const int64_t num_samples = samples_shape.num_elements();\n+    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(rate_t.shape()));\n \n-    samples_shape.AppendShape(rate_t.shape());\n     // Allocate output samples.\n     Tensor* samples_t = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));\n",
      "@@ -16,7 +16,10 @@\n \n import numpy as np\n \n+from tensorflow.python.eager import context\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import random_seed\n from tensorflow.python.framework import test_util\n@@ -216,6 +219,16 @@ class RandomGammaTest(test.TestCase):\n         self.assertEqual(0, math_ops.reduce_sum(math_ops.cast(\n             math_ops.less_equal(x, 0.), dtype=dtypes.int64)).eval())\n \n+  def testSizeTooLarge(self):\n+    # Grappler asserts on size overflow, so this error is only caught when\n+    # running eagerly.\n+    if context.executing_eagerly():\n+      with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                  \"overflow\"):\n+        rate = constant_op.constant(1.0, shape=(4, 4, 4, 4, 4))\n+        self.evaluate(\n+            random_ops.random_gamma(\n+                shape=[46902, 51188, 34063, 59195], alpha=rate))\n \n if __name__ == \"__main__\":\n   test.main()\n",
      "@@ -17,6 +17,7 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.kernel_tests.random import util\n@@ -171,6 +172,14 @@ class RandomPoissonTest(test.TestCase):\n     sample = random_ops.random_poisson(shape=[2], lam=np.inf)\n     self.assertAllEqual([np.inf, np.inf], self.evaluate(sample))\n \n+  def testSizeTooLarge(self):\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"overflow\"):\n+      rate = constant_op.constant(1.0, shape=(4, 4, 4, 4, 4))\n+      self.evaluate(\n+          random_ops.random_poisson(\n+              shape=[46902, 51188, 34063, 59195], lam=rate))\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mv8m-8x97-937q",
    "API Signature": "tf.random.gamma(\n    shape,\n    alpha,\n    beta=None,\n    dtype=tf.dtypes.float32,\n    seed=None,\n    name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Very large tensor",
    "Category": "Tensor",
    "Argument": "arg_0=tf.random.uniform(shape=(4,), dtype=tf.int32, maxval=65536)"
  },
  {
    "Title": "\n        `CHECK` fail in `RandomPoissonV2`\n      ",
    "Bug description": "When  RandomPoissonV2  receives large input shape and rates, it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(4,), dtype=tf.int32, maxval=65536)\narg_1=tf.random.uniform(shape=(4, 4, 4, 4, 4), dtype=tf.float32, maxval=None)\narg_2=0\narg_3=0\narg_4=tf.int32\narg_5=None\ntf.raw_ops.RandomPoissonV2(shape=arg_0, rate=arg_1, seed=arg_2,\n                           ,\n                           seed2=arg_3, dtype=arg_4, name=arg_5)",
    "Code change": [
      "@@ -166,7 +166,7 @@ class RandomGammaOp : public OpKernel {\n     }\n     const int64_t samples_per_alpha = samples_shape.num_elements();\n \n-    samples_shape.AppendShape(alpha_t.shape());\n+    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(alpha_t.shape()));\n     // Allocate output samples.\n     Tensor* samples_t = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));\n",
      "@@ -296,8 +296,8 @@ class RandomPoissonOp : public OpKernel {\n     TensorShape samples_shape;\n     OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_t, &samples_shape));\n     const int64_t num_samples = samples_shape.num_elements();\n+    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(rate_t.shape()));\n \n-    samples_shape.AppendShape(rate_t.shape());\n     // Allocate output samples.\n     Tensor* samples_t = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));\n",
      "@@ -16,7 +16,10 @@\n \n import numpy as np\n \n+from tensorflow.python.eager import context\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import random_seed\n from tensorflow.python.framework import test_util\n@@ -216,6 +219,16 @@ class RandomGammaTest(test.TestCase):\n         self.assertEqual(0, math_ops.reduce_sum(math_ops.cast(\n             math_ops.less_equal(x, 0.), dtype=dtypes.int64)).eval())\n \n+  def testSizeTooLarge(self):\n+    # Grappler asserts on size overflow, so this error is only caught when\n+    # running eagerly.\n+    if context.executing_eagerly():\n+      with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                  \"overflow\"):\n+        rate = constant_op.constant(1.0, shape=(4, 4, 4, 4, 4))\n+        self.evaluate(\n+            random_ops.random_gamma(\n+                shape=[46902, 51188, 34063, 59195], alpha=rate))\n \n if __name__ == \"__main__\":\n   test.main()\n",
      "@@ -17,6 +17,7 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.kernel_tests.random import util\n@@ -171,6 +172,14 @@ class RandomPoissonTest(test.TestCase):\n     sample = random_ops.random_poisson(shape=[2], lam=np.inf)\n     self.assertAllEqual([np.inf, np.inf], self.evaluate(sample))\n \n+  def testSizeTooLarge(self):\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"overflow\"):\n+      rate = constant_op.constant(1.0, shape=(4, 4, 4, 4, 4))\n+      self.evaluate(\n+          random_ops.random_poisson(\n+              shape=[46902, 51188, 34063, 59195], lam=rate))\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cv2p-32v3-vhwq",
    "API Signature": "tf.raw_ops.RandomPoissonV2(\n    shape,\n    rate,\n    seed=0,\n    seed2=0,\n    dtype=tf.dtypes.int64,\n    name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Very large tensor",
    "Category": "Tensor",
    "Argument": "arg_0=tf.random.uniform(shape=(4,), dtype=tf.int32, maxval=65536)"
  },
  {
    "Title": "\n        `CHECK` fail in `Unbatch`\n      ",
    "Bug description": "When  Unbatch  receives a nonscalar input  id , it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "import numpy as np\narg_0=tf.constant(value=np.random.random(size=(3, 3, 1)), dtype=tf.float64)\narg_1=tf.constant(value=np.random.randint(0,100,size=(3, 3, 1)), dtype=tf.int64)\narg_2=tf.constant(value=np.random.randint(0,100,size=(3, 3,  1)), dtype=tf.int64)\narg_3=47\narg_4=''\narg_5=''\ntf.raw_ops.Unbatch(batched_tensor=arg_0, batch_index=arg_1, id=arg_2, \n                   , \n                   timeout_micros=arg_3, container=arg_4, shared_name=arg_5)",
    "Code change": [
      "@@ -23,6 +23,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/resource_mgr.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/batching_util/adaptive_shared_batch_scheduler.h\"\n@@ -654,6 +655,12 @@ class UnbatchResource : public ResourceBase {\n           batch_index_t.shape().dim_size(1), \".\");\n     }\n \n+    if (!TensorShapeUtils::IsScalar(context->input(2).shape())) {\n+      return errors::InvalidArgument(\n+          \"Input id should be scalar; \"\n+          \"Got: \",\n+          context->input(2).DebugString(), \".\");\n+    }\n     const int64_t batch_key = context->input(2).scalar<int64_t>()();\n     const bool nonempty_input = batch_index_t.dim_size(0) > 0;\n \n",
      "@@ -236,6 +236,26 @@ class BatchOpsTest(test.TestCase):\n       self.assertEqual(thread_results[0], [2])\n       self.assertEqual(main_results[0], [3])\n \n+  def testUnbatchInvalidIdArg(self):\n+    \"\"\"Tests that unbatch work together.\"\"\"\n+    if context.executing_eagerly():\n+      batched_tensor = constant_op.constant(\n+          value=np.random.random(size=(3, 3, 1)), dtype=dtypes.float64)\n+      batched_index = constant_op.constant(\n+          value=np.random.randint(0, 100, size=(3, 3, 1)), dtype=dtypes.int64)\n+      arg_id = constant_op.constant(\n+          value=np.random.randint(0, 100, size=(3, 3, 1)), dtype=dtypes.int64)\n+\n+      with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                  \"Input id should be scalar;\"):\n+        batch_ops.unbatch(\n+            batched_tensor=batched_tensor,\n+            batch_index=batched_index,\n+            id=arg_id,\n+            timeout_micros=50,\n+            container=\"\",\n+            shared_name=\"\")\n+\n   def testBatchDecoratedWithCapturedInput(self):\n     \"\"\"Tests that the batch_function decorator works.\"\"\"\n     if context.executing_eagerly():\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mh3m-62v7-68xg",
    "API Signature": "tf.raw_ops.Unbatch(\n    batched_tensor,\n    batch_index,\n    id,\n    timeout_micros,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "arg_2=tf.constant(value=np.random.randint(0,100,size=(3, 3,  1)), dtype=tf.int64)"
  },
  {
    "Title": "\n        `CHECK` fail in `DrawBoundingBoxes`\n      ",
    "Bug description": "When  DrawBoundingBoxes  receives an input  boxes  that is not of dtype  float , it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "import numpy as np\narg_0=tf.constant(value=np.random.random(size=(1, 3, 2, 3)), shape=(1, 3, 2, 3), dtype=tf.half)\narg_1=tf.constant(value=np.random.random(size=(1, 2, 4)), shape=(1, 2, 4), dtype=tf.float32)\narg_2=''\n\ntf.raw_ops.DrawBoundingBoxes(images=arg_0, boxes=arg_1, name=arg_2)",
    "Code change": [
      "@@ -119,7 +119,7 @@ class DrawBoundingBoxesOp : public OpKernel {\n \n     for (int64_t b = 0; b < batch_size; ++b) {\n       const int64_t num_boxes = boxes.dim_size(1);\n-      const auto tboxes = boxes.tensor<T, 3>();\n+      const auto tboxes = boxes.tensor<float, 3>();\n       for (int64_t bb = 0; bb < num_boxes; ++bb) {\n         int64_t color_index = bb % color_table.size();\n         const int64_t min_box_row =\n",
      "@@ -50,11 +50,16 @@ class DrawBoundingBoxOpTest(test.TestCase):\n     image[height - 1, 0:width, 0:depth] = color\n     return image\n \n-  def _testDrawBoundingBoxColorCycling(self, img, colors=None):\n+  def _testDrawBoundingBoxColorCycling(self,\n+                                       img,\n+                                       dtype=dtypes.float32,\n+                                       colors=None):\n     \"\"\"Tests if cycling works appropriately.\n \n     Args:\n       img: 3-D numpy image on which to draw.\n+      dtype: image dtype (float, half).\n+      colors: color table.\n     \"\"\"\n     color_table = colors\n     if colors is None:\n@@ -82,7 +87,7 @@ class DrawBoundingBoxOpTest(test.TestCase):\n       bboxes = math_ops.cast(bboxes, dtypes.float32)\n       bboxes = array_ops.expand_dims(bboxes, 0)\n       image = ops.convert_to_tensor(image)\n-      image = image_ops_impl.convert_image_dtype(image, dtypes.float32)\n+      image = image_ops_impl.convert_image_dtype(image, dtype)\n       image = array_ops.expand_dims(image, 0)\n       image = image_ops.draw_bounding_boxes(image, bboxes, colors=colors)\n       with self.cached_session(use_gpu=False) as sess:\n@@ -118,6 +123,14 @@ class DrawBoundingBoxOpTest(test.TestCase):\n                          [0, 0, 0.5, 1]])\n     self._testDrawBoundingBoxColorCycling(image, colors=colors)\n \n+  def testDrawBoundingBoxHalf(self):\n+    \"\"\"Test if RGBA color cycling works correctly with provided colors.\"\"\"\n+    image = np.zeros([10, 10, 4], \"float32\")\n+    colors = np.asarray([[0.5, 0, 0.5, 1], [0.5, 0.5, 0, 1], [0.5, 0, 0, 1],\n+                         [0, 0, 0.5, 1]])\n+    self._testDrawBoundingBoxColorCycling(\n+        image, dtype=dtypes.half, colors=colors)\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jqm7-m5q7-3hm5",
    "API Signature": "tf.raw_ops.DrawBoundingBoxes(\n    images, boxes, name=None\n)\n",
    "Score": 0.0035460992907801418,
    "Anomaly": "Half input tensor",
    "Category": "Tensor",
    "Argument": "arg_1=tf.constant(value=np.random.random(size=(1, 2, 4)), shape=(1, 2, 4), dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK` fail in `Eig`\n      ",
    "Bug description": "Eig  can be fed an incorrect  Tout  input, resulting in a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "import numpy as np \narg_0=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)\narg_1=tf.complex128\narg_2=True\narg_3=''\n\ntf.raw_ops.Eig(input=arg_0, Tout=arg_1, compute_v=arg_2, name=arg_3)",
    "Code change": [
      "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include \"tensorflow/core/kernels/linalg/linalg_ops_common.h\"\n \n+#include <initializer_list>\n #include <utility>\n \n #include \"third_party/eigen3/Eigen/Core\"\n@@ -22,7 +23,9 @@ limitations under the License.\n #include \"tensorflow/core/framework/kernel_def_builder.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/types.h\"\n \n@@ -152,6 +155,10 @@ void LinearAlgebraOp<InputScalar, OutputScalar>::AnalyzeInputs(\n     input_matrix_shapes->emplace_back(\n         std::initializer_list<int64_t>({num_rows, num_cols}));\n     inputs->emplace_back(&in);\n+    OP_REQUIRES(\n+        context, in.dtype() == DataTypeToEnum<InputScalar>::v(),\n+        errors::InvalidArgument(\"Invalid input dtype \", in.dtype(), \" vs \",\n+                                DataTypeToEnum<InputScalar>::v()));\n   }\n   // Have the derived class validate that the inputs are as expected.\n   ValidateInputMatrixShapes(context, *input_matrix_shapes);\n@@ -212,6 +219,11 @@ void LinearAlgebraOp<InputScalar, OutputScalar>::PrepareOutputs(\n       OP_REQUIRES_OK(context, context->allocate_output(\n                                   output_idx, output_tensor_shape, &out));\n     }\n+    OP_REQUIRES(\n+        context, out->dtype() == DataTypeToEnum<OutputScalar>::v(),\n+        errors::InvalidArgument(\"Invalid output dtype \", out->dtype(), \" vs \",\n+                                DataTypeToEnum<OutputScalar>::v()));\n+\n     outputs->emplace_back(out);\n   }\n }\n",
      "@@ -18,8 +18,10 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes as dtypes_lib\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import gen_linalg_ops\n from tensorflow.python.ops import gradient_checker_v2\n from tensorflow.python.ops import linalg_ops\n from tensorflow.python.ops import math_ops\n@@ -88,6 +90,16 @@ class EigTest(test.TestCase):\n       self.assertAllClose(matrix,\n                           np.matmul(np.matmul(v, np.diag(e)), v.transpose()))\n \n+  def testMismatchedDtypes(self):\n+    tensor = constant_op.constant([[0, 1], [2, 3]], dtype=dtypes_lib.float32)\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Invalid output dtype\"):\n+      self.evaluate(\n+          gen_linalg_ops.eig(\n+              input=tensor,\n+              Tout=dtypes_lib.complex128,  # Expected dtype: complex64.\n+              compute_v=True))\n+\n \n def SortEigenValues(e):\n   perm = np.argsort(e.real + e.imag, -1)\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fqxc-pvf8-2w9v",
    "API Signature": "tf.raw_ops.Eig(\n    input, Tout, compute_v=True, name=None\n)\n",
    "Score": 0.0035460992907801418,
    "Anomaly": "Complex input",
    "Category": "TF complex",
    "Argument": "arg_1=tf.complex128"
  },
  {
    "Title": "\n        `CHECK` fail in `Conv2DBackpropInput`\n      ",
    "Bug description": "When  Conv2DBackpropInput  receives empty  out_backprop  inputs (e.g.  [3, 1, 0, 1] ), the current CPU/GPU kernels  CHECK  fail (one with dnnl, the other with cudnn). This can be used to trigger a denial of service attack.",
    "Sample Code": "import numpy as np\ninput_sizes = [3, 1, 1, 2]\nfilter = np.ones([1, 3, 2, 3])\nout_backprop = np.ones([3, 1, 0, 3])\nstrides = [1, 1, 2, 1]\npadding = 'VALID'\n\ntf.raw_ops.Conv2DBackpropInput(\n   input_sizes = input_sizes,\n   filter = filter,\n   out_backprop = out_backprop,\n   strides = strides,\n   padding = padding\n)\n)",
    "Code change": [
      "@@ -37,6 +37,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/conv_2d.h\"\n #include \"tensorflow/core/kernels/conv_grad_ops.h\"\n #include \"tensorflow/core/kernels/conv_grad_shape_utils.h\"\n+#include \"tensorflow/core/kernels/fill_functor.h\"\n #ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS\n #include \"tensorflow/core/kernels/xsmm_conv2d.h\"\n #endif\n@@ -436,6 +437,15 @@ class Conv2DBackpropInputOp : public OpKernel {\n       return;\n     }\n \n+    // If shapes are valid but `out_backprop` is empty, in_backprop should be\n+    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.\n+    if (out_backprop.NumElements() == 0) {\n+      functor::SetZeroFunctor<Device, T> set_zero;\n+      set_zero(context->eigen_device<Device>(),\n+               in_backprop->template flat<T>());\n+      return;\n+    }\n+\n     // For now we take the stride from the second and third dimensions only (we\n     // do not support striding on the batch or depth dimension).\n     const int stride_rows = GetTensorDim(strides_, data_format_, 'H');\n@@ -554,6 +564,15 @@ class Conv2DCustomBackpropInputOp : public OpKernel {\n       return;\n     }\n \n+    // If shapes are valid but `out_backprop` is empty, in_backprop should be\n+    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.\n+    if (out_backprop.NumElements() == 0) {\n+      functor::SetZeroFunctor<Device, T> set_zero;\n+      set_zero(context->eigen_device<Device>(),\n+               in_backprop->template flat<T>());\n+      return;\n+    }\n+\n // TODO(ezhulenev): Remove custom kernel and move XSMM support to\n // LaunchConv2DBackpropInputOp functor.\n #if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\\n",
      "@@ -1103,6 +1103,23 @@ class Conv2DTest(test.TestCase):\n           use_gpu=use_gpu,\n           err=1e-5)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  @test_util.disable_xla(\"b/239598470\")\n+  def testConv2DBackpropInputDegenerateBackpropInput(self):\n+    input_sizes = [3, 1, 1, 2]\n+    expected_output = np.zeros(input_sizes).flatten()\n+    for (data_format, use_gpu) in GetTestConfigs():\n+      self._RunAndVerifyBackpropInput(\n+          input_sizes=input_sizes,\n+          filter_sizes=[1, 3, 2, 3],\n+          output_sizes=[3, 1, 0, 3],\n+          strides=[1, 2],\n+          padding=\"VALID\",\n+          expected=expected_output,\n+          data_format=data_format,\n+          use_gpu=use_gpu,\n+          err=1e-5)\n+\n   # Testing for backprops\n   def _RunAndVerifyBackpropFilter(self,\n                                   input_sizes,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-37jf-mjv6-xfqw",
    "API Signature": "tf.raw_ops.Conv2DBackpropInput(\n    input_sizes,\n    filter,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Zero integer list element",
    "Category": "Numpy array",
    "Argument": "np.ones([3, 1, 0, 3])"
  },
  {
    "Title": "\n        `CHECK` fail in `EmptyTensorList`\n      ",
    "Bug description": "If  EmptyTensorList  receives an input  element_shape  with more than one dimension, it gives a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.EmptyTensorList(element_shape=tf.ones(dtype=tf.int32, shape=[1, 0]), max_num_elements=tf.constant(1),element_dtype=tf.int32)",
    "Code change": [
      "@@ -21,7 +21,11 @@ limitations under the License.\n \n #include \"tensorflow/core/kernels/list_kernels.h\"\n \n+#include <algorithm>\n+#include <iterator>\n #include <limits>\n+#include <memory>\n+#include <utility>\n \n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/allocator.h\"\n@@ -30,10 +34,6 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_types.h\"\n #include \"tensorflow/core/framework/variant.h\"\n #include \"tensorflow/core/framework/variant_op_registry.h\"\n-#include \"tensorflow/core/kernels/concat_lib.h\"\n-#include \"tensorflow/core/lib/core/coding.h\"\n-#include \"tensorflow/core/lib/core/errors.h\"\n-#include \"tensorflow/core/util/util.h\"\n \n namespace tensorflow {\n \n@@ -49,6 +49,9 @@ Status TensorShapeFromTensor(const Tensor& t, PartialTensorShape* out) {\n     return errors::InvalidArgument(\n         \"The only valid scalar shape tensor is the fully unknown shape \"\n         \"specified as -1.\");\n+  } else if (t.shape().dims() != 1) {\n+    return errors::InvalidArgument(\"Shape must be at most rank 1 but is rank \",\n+                                   t.shape().dims());\n   }\n   if (t.dtype() == DT_INT32) {\n     return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),\n",
      "@@ -1458,6 +1458,15 @@ class ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n       t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n       self.evaluate(t)\n \n+  def testEmptyTensorListInvalidShape(self):\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                r\"Shape must be at most rank 1 but is rank 2\"):\n+      t = gen_list_ops.EmptyTensorList(\n+          element_shape=array_ops.ones(dtype=dtypes.int32, shape=[1, 0]),\n+          max_num_elements=constant_op.constant(1),\n+          element_dtype=dtypes.int32)\n+      self.evaluate(t)\n+\n   def testEvenSplit(self):\n \n     def RunTest(input_tensor, lengths, expected_stacked_output):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qhw4-wwr7-gjc5",
    "API Signature": "tf.raw_ops.EmptyTensorList(\n    element_shape, max_num_elements, element_dtype, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "tf.ones(dtype=tf.int32, shape=[1, 0])"
  },
  {
    "Title": "\n        `CHECK` fail in `tf.sparse.cross`\n      ",
    "Bug description": "If  tf.sparse.cross  receives an input  separator  that is not a scalar, it gives a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": " tensorflow as tf\n\ntf.sparse.cross(inputs=[],name='a',separator=tf.constant(['a', 'b'],dtype=tf.string))",
    "Code change": [
      "@@ -24,12 +24,14 @@ limitations under the License.\n #include \"tensorflow/core/framework/kernel_def_builder.h\"\n #include \"tensorflow/core/framework/op_def_builder.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/framework/types.pb.h\"\n #include \"tensorflow/core/lib/core/stringpiece.h\"\n #include \"tensorflow/core/lib/strings/str_util.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/fingerprint.h\"\n #include \"tensorflow/core/platform/strong_hash.h\"\n #include \"tensorflow/core/util/work_sharder.h\"\n@@ -832,6 +834,10 @@ class SparseCrossV2Op : public OpKernel {\n \n     const Tensor* sep_t;\n     OP_REQUIRES_OK(context, context->input(\"sep\", &sep_t));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(sep_t->shape()),\n+                errors::InvalidArgument(\"Input separator should be a scalar. \"\n+                                        \"Received: \",\n+                                        sep_t->DebugString()));\n     const tstring separator = sep_t->scalar<tstring>()();\n \n     std::vector<std::unique_ptr<ColumnInterface<tstring>>> columns =\n",
      "@@ -873,6 +873,14 @@ class SparseCrossV2OpTest(BaseSparseCrossOpTest):\n     with self.cached_session():\n       self._assert_sparse_tensor_empty(self.evaluate(out))\n \n+  def testNonScalarInput(self):\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                'Input separator should be a scalar.'):\n+      self.evaluate(sparse_ops.sparse_cross(\n+          inputs=[],\n+          name='a',\n+          separator=constant_op.constant(['a', 'b'], dtype=dtypes.string)))\n+\n \n class SparseCrossHashedOpTest(BaseSparseCrossOpTest):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-p7hr-f446-x6qf",
    "API Signature": "tf.sparse.cross(\n    inputs, name=None, separator=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "separator=tf.constant(['a', 'b']"
  },
  {
    "Title": "\n        Floating point exception in `Conv2D`\n      ",
    "Bug description": "If  Conv2D  is given empty  input  and the  filter  and  padding  sizes are valid, the output is all-zeros. This causes division-by-zero floating point exceptions that can be used to trigger a denial of service attack.",
    "Sample Code": "import numpy as np\nwith tf.device(\"CPU\"): # also can be triggerred on GPU\n   input = np.ones([1, 0, 2, 1])\n   filter = np.ones([1, 1, 1, 1])\n   strides = ([1, 1, 1, 1])\n   padding = \"EXPLICIT\"\n   explicit_paddings = [0 , 0, 1, 1, 1, 1, 0, 0]\n   data_format = \"NHWC\"\n   res = tf.raw_ops.Conv2D(\n       input=input,\n       filter=filter,\n       strides=strides,\n       padding=padding,\n        explicit_paddings=explicit_paddings,\n       data_format=data_format,\n  ),\n  )",
    "Code change": [
      "@@ -44,6 +44,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/conv_2d.h\"\n #include \"tensorflow/core/kernels/deep_conv2d.h\"\n+#include \"tensorflow/core/kernels/fill_functor.h\"\n #include \"tensorflow/core/kernels/ops_util.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/lib/gtl/array_slice.h\"\n@@ -701,6 +702,15 @@ class Conv2DOp : public BinaryOp<T> {\n       return;\n     }\n \n+    // If the input is empty, result can only be due to padding.\n+    if (input.NumElements() == 0) {\n+      // Zero-out output and return.\n+      functor::SetZeroFunctor<Device, T>()(context->eigen_device<Device>(),\n+                                           output->template flat<T>());\n+\n+      return;\n+    }\n+\n #ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS\n     if (params_.padding != EXPLICIT &&\n         LaunchXsmmConvOp<Device, T>::Run(\n",
      "@@ -759,6 +759,15 @@ class Conv2DTest(test.TestCase):\n         padding=[[2, 1], [1, 2]],\n         dilations=[2, 3])\n \n+  @test_util.run_in_graph_and_eager_modes()\n+  def testConv2dOnlyPaddingReturnsZeros(self):\n+    self._VerifyValues(\n+        tensor_in_sizes=[1, 0, 2, 1],\n+        filter_in_sizes=[1, 1, 1, 1],\n+        strides=[1, 1],\n+        padding=[[1, 1], [1, 1]],\n+        expected=[0, 0, 0, 0, 0, 0, 0, 0])\n+\n   def testConv2DExplicitPaddingWithLayoutOptimizer(self):\n     # Test with Grappler's layout optimizer, to ensure the layout optimizer\n     # handles explicit padding correctly.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-q5jv-m6qw-5g37",
    "API Signature": "tf.raw_ops.Conv2D(\n    input,\n    filter,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Zero integer list element",
    "Category": "Numpy array",
    "Argument": "np.ones([1, 0, 2, 1])"
  },
  {
    "Title": "\n        `CHECK` fail in `AudioSummaryV2`\n      ",
    "Bug description": "When  AudioSummaryV2  receives an input  sample_rate  with more than one element, it gives a  CHECK  fails that can be used to trigger a denial of service attack.",
    "Sample Code": "arg_0=''\narg_1=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)\narg_2=tf.random.uniform(shape=(2,1), dtype=tf.float32, maxval=None)\narg_3=3\narg_4=''\ntf.raw_ops.AudioSummaryV2(tag=arg_0, tensor=arg_1, sample_rate=arg_2,\n                          ,\n                          max_outputs=arg_3, name=arg_4)",
    "Code change": [
      "@@ -49,6 +49,11 @@ class SummaryAudioOp : public OpKernel {\n     float sample_rate = sample_rate_attr_;\n     if (!has_sample_rate_attr_) {\n       const Tensor& sample_rate_tensor = c->input(2);\n+      OP_REQUIRES(c,\n+                  sample_rate_tensor.IsAligned() &&\n+                      sample_rate_tensor.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"sample_rate must be rank-0 or contain a single value\"));\n       sample_rate = sample_rate_tensor.scalar<float>()();\n     }\n     OP_REQUIRES(c, sample_rate > 0.0f,\n",
      "@@ -23,6 +23,7 @@ tensorflow/python/kernel_tests/summary_v1_*.py.\n from tensorflow.core.framework import summary_pb2\n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import meta_graph\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n@@ -183,6 +184,11 @@ class SummaryTest(test.TestCase):\n         'family/outer/family/inner/audio/{}'.format(i) for i in range(3))\n     self.assertEqual(tags, expected)\n \n+  def testAudioSummaryWithInvalidSampleRate(self):\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      invalid_sample_rate = [22000.0, 22000.0]\n+      self.evaluate(summary_lib.audio('', [[1.0]], invalid_sample_rate))\n+\n   @test_util.run_deprecated_v1\n   def testTextSummary(self):\n     with self.cached_session():\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-g9h5-vr8m-x2h4",
    "API Signature": "tf.raw_ops.AudioSummaryV2(\n    tag, tensor, sample_rate, max_outputs=3, name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "arg_2=tf.random.uniform(shape=(2,1), dtype=tf.float32, maxval=None)"
  },
  {
    "Title": "\n        `CHECK` fail in `CollectiveGather`\n      ",
    "Bug description": "When  CollectiveGather  receives an scalar input  input , it gives a  CHECK  fails that can be used to trigger a denial of service attack.",
    "Sample Code": "arg_0=1\narg_1=1\narg_2=1\narg_3=1\narg_4=(3, 3,3)\narg_5='auto'\narg_6=0\narg_7=''\ntf.raw_ops.CollectiveGather(input=arg_0, group_size=arg_1, group_key=arg_2,\n                            instance_key=arg_3, shape=arg_4,\n                            ,\n                            communication_hint=arg_5, timeout_seconds=arg_6, name=arg_7)",
    "Code change": [
      "@@ -176,6 +176,10 @@ class CollectiveGatherOpKernel : public CollectiveOpV1Kernel {\n   void ComputeAsyncImpl(OpKernelContext* c, CollectiveExecutor* col_exec,\n                         DoneCallback done) override {\n     auto output_shape = c->input(0).shape();\n+    OP_REQUIRES_ASYNC(c, output_shape.dims() > 0,\n+                      errors::InvalidArgument(\"input should have rank > 0, \",\n+                                              \"recieved \", output_shape.dims()),\n+                      done);\n     output_shape.set_dim(\n         0, output_shape.dim_size(0) * col_params_->group.group_size);\n     col_params_->instance.shape = output_shape;\n",
      "@@ -451,6 +451,20 @@ class CollectiveOpTest(test.TestCase):\n     ])\n     context.ensure_initialized()\n \n+  @test_util.run_v2_only\n+  def testCollectiveGatherShapeCheckFailure(self):\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                'input should have rank > 0'):\n+      collective_ops.gen_collective_ops.CollectiveGather(\n+          input=1,\n+          group_size=1,\n+          group_key=1,\n+          instance_key=1,\n+          shape=(3, 3, 3),\n+          communication_hint='auto',\n+          timeout_seconds=0,\n+          name='')\n+\n     @def_function.function\n     def run_all_reduce():\n       group_key = 10\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fhfc-2q7x-929f",
    "API Signature": "tf.raw_ops.CollectiveGather(\n    input,\n    group_size,\n    group_key,\n    instance_key,\n    shape,\n    communication_hint='auto',\n    timeout_seconds=0,\n    name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Scalar input",
    "Category": "Tensor",
    "Argument": "arg_0=1"
  },
  {
    "Title": "\n        `CHECK` fail in `SetSize`\n      ",
    "Bug description": "When  SetSize  receives an input  set_shape  that is not a 1D tensor, it gives a  CHECK  fails that can be used to trigger a denial of service attack.",
    "Sample Code": "arg_0=1\narg_1=[1,1]\narg_2=1\narg_3=True\narg_4=''\ntf.raw_ops.SetSize(set_indices=arg_0, set_values=arg_1, set_shape=arg_2,\n                   ,\n                   validate_indices=arg_3, name=arg_4)",
    "Code change": [
      "@@ -70,8 +70,12 @@ Status SparseTensorFromContext(OpKernelContext* ctx, const int32_t base_index,\n                                sparse::SparseTensor* tensor) {\n   // Assume row-major order.\n   TensorShape shape;\n-  TF_RETURN_IF_ERROR(TensorShape::BuildTensorShape(\n-      ctx->input(base_index + 2).vec<int64_t>(), &shape));\n+  const Tensor& shape_tensor = ctx->input(base_index + 2);\n+  if (shape_tensor.dims() != 1) {\n+    return errors::InvalidArgument(\"Shape must be a 1D tensor.\");\n+  }\n+  TF_RETURN_IF_ERROR(\n+      TensorShape::BuildTensorShape(shape_tensor.vec<int64_t>(), &shape));\n   CheckRankAtLeast2(ctx, shape);\n   std::vector<int64_t> order(shape.dims());\n   std::iota(order.begin(), order.end(), 0);\n",
      "@@ -23,6 +23,7 @@ from tensorflow.python.framework import errors_impl\n from tensorflow.python.framework import sparse_tensor as sparse_tensor_lib\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import gen_set_ops\n from tensorflow.python.ops import math_ops\n from tensorflow.python.ops import sets\n from tensorflow.python.ops import sparse_ops\n@@ -1303,6 +1304,18 @@ class SetOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n         result.values,\n         _constant([1, 3, 5, 7, 9, 0, 2, 4, 5, 6, 6, 8, 9], dtype))\n \n+  def test_raw_ops_setsize_invalid_shape(self):\n+    with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n+                                \"Shape must be a 1D tensor\"):\n+      invalid_shape = 1\n+      self.evaluate(\n+          gen_set_ops.set_size(\n+              set_indices=1,\n+              set_values=[1, 1],\n+              set_shape=invalid_shape,\n+              validate_indices=True,\n+              name=\"\"))\n+\n \n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wq6q-6m32-9rv9",
    "API Signature": "tf.raw_ops.SetSize(\n    set_indices, set_values, set_shape, validate_indices=True, name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Scalar input",
    "Category": "Tensor",
    "Argument": "arg_2=1"
  },
  {
    "Title": "\n        `CHECK` fail in `TensorListFromTensor`\n      ",
    "Bug description": "When  TensorListFromTensor  receives an  element_shape  of a rank greater than one, it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(6, 6, 2), dtype=tf.bfloat16, maxval=None)\narg_1=tf.random.uniform(shape=(6, 9, 1, 3), dtype=tf.int64, maxval=65536)\narg_2=''\n\ntf.raw_ops.TensorListFromTensor(tensor=arg_0, element_shape=arg_1, name=arg_2)",
    "Code change": [
      "@@ -769,6 +769,11 @@ class TensorListFromTensor : public OpKernel {\n     attr.set_on_host(true);\n     OP_REQUIRES_OK(c, c->allocate_output(0, {}, &output_tensor, attr));\n     PartialTensorShape element_shape;\n+    OP_REQUIRES(\n+        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(1).shape()),\n+        errors::InvalidArgument(\n+            \"TensorListFromTensor: element_shape must be at most rank 1 but \",\n+            \"has the shape of \", c->input(1).shape().DebugString()));\n     OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(1), &element_shape));\n     TensorList output_list;\n     const Tensor& t = c->input(0);\n",
      "@@ -584,6 +584,17 @@ class ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n     self.assertAllEqual(e, 1.0)\n     self.assertAllEqual(list_ops.tensor_list_length(l), 0)\n \n+  def testTensorListFromTensorFailsWhenElementShapeIsNotVector(self):\n+    t = constant_op.constant([1.0, 2.0])\n+    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n+    # In graph mode, ValueError is generated by the shape function.\n+    with self.assertRaisesRegex(\n+        (errors.InvalidArgumentError, ValueError),\n+        \"must be at most rank 1\"):\n+      # Wrong element_shape. Should be at most rank 1.\n+      l = list_ops.tensor_list_from_tensor(t, element_shape=[[1]])\n+      self.evaluate(l)\n+\n   @test_util.run_gpu_only\n   def testFromTensorGPU(self):\n     with context.device(\"gpu:0\"):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9v8w-xmr4-wgxp",
    "API Signature": "tf.raw_ops.TensorListFromTensor(\n    tensor, element_shape, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "arg_1=tf.random.uniform(shape=(6, 9, 1, 3), dtype=tf.int64, maxval=65536)"
  },
  {
    "Title": "\n        `CHECK` fail in `TensorListScatter` and `TensorListScatterV2`\n      ",
    "Bug description": "When  TensorListScatter  and  TensorListScatterV2  receive an  element_shape  of a rank greater than one, they give a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(2, 2, 2), dtype=tf.float16, maxval=None)\narg_1=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)\narg_2=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)\narg_3=''\ntf.raw_ops.TensorListScatter(tensor=arg_0, indices=arg_1, \n, \nelement_shape=arg_2, name=arg_3)",
    "Code change": [
      "@@ -895,6 +895,11 @@ class TensorListScatter : public OpKernel {\n     OP_REQUIRES_OK(c, c->allocate_output(0, {}, &output_tensor, attr));\n     Tensor indices = c->input(1);\n     PartialTensorShape element_shape;\n+    OP_REQUIRES(\n+        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(2).shape()),\n+        errors::InvalidArgument(\n+            \"TensorListScatter: element_shape must be at most rank 1 but has \",\n+            \"the shape of \", c->input(2).shape().DebugString()));\n     OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(2), &element_shape));\n     // TensorListScatterV2 passes the num_elements input, TensorListScatter does\n     // not.\n",
      "@@ -481,6 +481,30 @@ class ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n     # TensorListScatter should return a list with size num_elements.\n     self.assertAllEqual(list_ops.tensor_list_length(l), 5)\n \n+  def testScatterFailsWhenElementShapeIsNotVector(self):\n+    c0 = constant_op.constant([1.0, 2.0])\n+    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n+    # In graph mode, ValueError is generated by the shape function.\n+    with self.assertRaisesRegex(\n+        (errors.InvalidArgumentError, ValueError),\n+        \"must be at most rank 1\"):\n+      l = gen_list_ops.tensor_list_scatter(\n+          # Wrong element_shape. Should be at most rank 1.\n+          c0, [1, 3], element_shape=[[1]])\n+      self.evaluate(l)\n+\n+  def testScatterV2FailsWhenElementShapeIsNotVector(self):\n+    c0 = constant_op.constant([1.0, 2.0])\n+    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n+    # In graph mode, ValueError is generated by the shape function.\n+    with self.assertRaisesRegex(\n+        (errors.InvalidArgumentError, ValueError),\n+        \"must be at most rank 1\"):\n+      l = gen_list_ops.tensor_list_scatter_v2(\n+          # Wrong element_shape. Should be at most rank 1.\n+          c0, [1, 3], element_shape=[[1]], num_elements=2)\n+      self.evaluate(l)\n+\n   def testScatterFailsWhenIndexLargerThanNumElements(self):\n     c0 = constant_op.constant([1.0, 2.0])\n     with self.assertRaisesRegex(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vm7x-4qhj-rrcq",
    "API Signature": "tf.raw_ops.TensorListScatter(\n    tensor, indices, element_shape, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "arg_2=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)"
  },
  {
    "Title": "\n        `CHECK` fail in `TensorListScatter` and `TensorListScatterV2`\n      ",
    "Bug description": "When  TensorListScatter  and  TensorListScatterV2  receive an  element_shape  of a rank greater than one, they give a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(2, 2, 2), dtype=tf.float16, maxval=None)\narg_1=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)\narg_2=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)\narg_3=''\ntf.raw_ops.TensorListScatter(tensor=arg_0, indices=arg_1, \n, \nelement_shape=arg_2, name=arg_3)",
    "Code change": [
      "@@ -895,6 +895,11 @@ class TensorListScatter : public OpKernel {\n     OP_REQUIRES_OK(c, c->allocate_output(0, {}, &output_tensor, attr));\n     Tensor indices = c->input(1);\n     PartialTensorShape element_shape;\n+    OP_REQUIRES(\n+        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(2).shape()),\n+        errors::InvalidArgument(\n+            \"TensorListScatter: element_shape must be at most rank 1 but has \",\n+            \"the shape of \", c->input(2).shape().DebugString()));\n     OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(2), &element_shape));\n     // TensorListScatterV2 passes the num_elements input, TensorListScatter does\n     // not.\n",
      "@@ -481,6 +481,30 @@ class ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n     # TensorListScatter should return a list with size num_elements.\n     self.assertAllEqual(list_ops.tensor_list_length(l), 5)\n \n+  def testScatterFailsWhenElementShapeIsNotVector(self):\n+    c0 = constant_op.constant([1.0, 2.0])\n+    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n+    # In graph mode, ValueError is generated by the shape function.\n+    with self.assertRaisesRegex(\n+        (errors.InvalidArgumentError, ValueError),\n+        \"must be at most rank 1\"):\n+      l = gen_list_ops.tensor_list_scatter(\n+          # Wrong element_shape. Should be at most rank 1.\n+          c0, [1, 3], element_shape=[[1]])\n+      self.evaluate(l)\n+\n+  def testScatterV2FailsWhenElementShapeIsNotVector(self):\n+    c0 = constant_op.constant([1.0, 2.0])\n+    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n+    # In graph mode, ValueError is generated by the shape function.\n+    with self.assertRaisesRegex(\n+        (errors.InvalidArgumentError, ValueError),\n+        \"must be at most rank 1\"):\n+      l = gen_list_ops.tensor_list_scatter_v2(\n+          # Wrong element_shape. Should be at most rank 1.\n+          c0, [1, 3], element_shape=[[1]], num_elements=2)\n+      self.evaluate(l)\n+\n   def testScatterFailsWhenIndexLargerThanNumElements(self):\n     c0 = constant_op.constant([1.0, 2.0])\n     with self.assertRaisesRegex(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vm7x-4qhj-rrcq",
    "API Signature": "tf.raw_ops.TensorListScatterV2(\n    tensor, indices, element_shape, num_elements, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "arg_2=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)"
  },
  {
    "Title": "\n        `CHECK` fail in `FakeQuantWithMinMaxVarsPerChannelGradient`\n      ",
    "Bug description": "When  tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient  receives input  min  or  max  of rank other than 1, it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)\narg_1=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)\narg_2=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)\narg_3=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)\narg_4=8\narg_5=False\narg_6=None\ntf.quantization.fake_quant_with_min_max_vars_per_channel_gradient(gradients=arg_0, \n            inputs=arg_1, min=arg_2,  max=arg_3, num_bits=arg_4, \n            , \n            narrow_range=arg_5, name=arg_6)",
    "Code change": [
      "@@ -261,6 +261,12 @@ class FakeQuantWithMinMaxVarsGradientOp : public OpKernel {\n                 InvalidArgument(\"gradient and input must be the same size\"));\n     const Tensor& min = context->input(2);\n     const Tensor& max = context->input(3);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n \n     Tensor* grad_wrt_input;\n     OP_REQUIRES_OK(context,\n@@ -414,10 +420,16 @@ class FakeQuantWithMinMaxVarsPerChannelGradientOp : public OpKernel {\n                 InvalidArgument(\"gradient and input must be the same size\"));\n     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n     const Tensor& min = context->input(2);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n     OP_REQUIRES(context, min.dim_size(0) == depth,\n                 InvalidArgument(\"min has incorrect size, expected \", depth,\n                                 \" was \", min.dim_size(0)));\n     const Tensor& max = context->input(3);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n     OP_REQUIRES(context, max.dim_size(0) == depth,\n                 InvalidArgument(\"max has incorrect size, expected \", depth,\n                                 \" was \", max.dim_size(0)));\n",
      "@@ -77,6 +77,71 @@ class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n               inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n \n \n+class FakeQuantWithMinMaxVarsGradientOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    gradients = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be equal rank|must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_gradient(\n+              gradients=gradients,\n+              inputs=inputs,\n+              min=0.0,\n+              max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_gradient(\n+              gradients=gradients,\n+              inputs=inputs,\n+              min=[[1.0], [2.0], [4.0]],\n+              max=[[1.0], [2.0], [4.0]]))\n+\n+\n+class FakeQuantWithMinMaxVarsPerChannelGradientOpTest(\n+    test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    gradients = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Shapes must be equal rank|must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[[0.0]], max=[1.0]))\n+\n+    with self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError),\n+        \"Dimension 0 in both shapes must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Shapes must be equal rank|must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[1.0], max=[[1.0]]))\n+\n+    with self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError),\n+        \"Dimension 0 in both shapes must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n+\n+\n class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n \n   @test_util.run_in_graph_and_eager_modes\n@@ -337,10 +402,9 @@ class QuantizeDownAndShrinkRangeOpTest(test_util.TensorFlowTestCase):\n     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                 \"must be rank 0\"):\n       self.evaluate(\n-          math_ops.quantize_down_and_shrink_range(input=inputs,\n-                                                  input_min=[],\n-                                                  input_max=4.0,\n-                                                  out_type=dtypes.quint8))\n+          math_ops.quantize_down_and_shrink_range(\n+              input=inputs, input_min=[], input_max=4.0,\n+              out_type=dtypes.quint8))\n \n \n if __name__ == \"__main__\":\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h7ff-cfc9-wmmh",
    "API Signature": "tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient(\n    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "arg_1=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)"
  },
  {
    "Title": "\n        `CHECK` fail in `MaxPool`\n      ",
    "Bug description": "When  MaxPool  receives a window size input array  ksize  with dimensions greater than its input tensor  input , the GPU kernel gives a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "import numpy as np\n\ninput = np.ones([1, 1, 1, 1])\nksize = [1, 1, 2, 2]\nstrides = [1, 1, 1, 1]\npadding = 'VALID'\ndata_format = 'NCHW'\n\n\n\ntf.raw_ops.MaxPool(input=input, ksize=ksize, strides=strides, padding=padding, data_format=data_format)",
    "Code change": [
      "@@ -1268,6 +1268,13 @@ class MaxPoolingNoMaskOp<GPUDevice, T> : public OpKernel {\n         ShapeFromFormat(data_format_, params.tensor_in_batch, params.out_height,\n                         params.out_width, params.depth);\n \n+    // Degenerate pooling output should return an empty tensor.\n+    if (out_shape.num_elements() == 0) {\n+      Tensor* output = nullptr;\n+      OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));\n+      return;\n+    }\n+\n     // Assuming qint8 <--> NCHW_VECT_C (int8x4) here.\n     constexpr bool is_int8x4 = std::is_same<T, qint8>::value;\n     OP_REQUIRES(context, (is_int8x4 == (data_format_ == FORMAT_NCHW_VECT_C)),\n",
      "@@ -772,6 +772,18 @@ class PoolingTest(test.TestCase, parameterized.TestCase):\n         expected=[],\n         **kwargs)\n \n+  @parameterized.parameters(\n+      GetTestConfigsDicts(nn_ops.max_pool, gen_nn_ops.max_pool_v2))\n+  @test_util.run_deprecated_v1\n+  def testMaxPoolInvalidFilterSize(self, **kwargs):\n+    with self.cached_session(use_gpu=test.is_gpu_available()):\n+      t = constant_op.constant(1.0, shape=[1, 1, 1, 1])\n+      with self.assertRaisesRegex(\n+          (errors_impl.InvalidArgumentError, ValueError),\n+          \"Negative dimension size\"):\n+        t = self.evaluate(\n+            nn_ops.max_pool(t, ksize=[1, 1, 2, 1], strides=1, padding=\"VALID\"))\n+\n   # Tests for DepthwiseMaxPooling on CPU only.\n   @parameterized.parameters(\n       GetTestConfigsDicts(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-j43h-pgmg-5hjq",
    "API Signature": "tf.raw_ops.MaxPool(\n    input,\n    ksize,\n    strides,\n    padding,\n    explicit_paddings=[],\n    data_format='NHWC',\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "ksize = [1, 1, 2, 2]"
  },
  {
    "Title": "\n        `CHECK` fail in `tf.linalg.matrix_rank`\n      ",
    "Bug description": "When  tf.linalg.matrix_rank  receives an empty input  a , the GPU kernel gives a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "a = tf.constant([], shape=[0, 1, 1], dtype=tf.float32)\n)\ntf.linalg.matrix_rank(a=a)",
    "Code change": [
      "@@ -395,6 +395,12 @@ class SvdOpGpu : public AsyncOpKernel {\n     OP_REQUIRES_OK_ASYNC(context, context->allocate_output(2, shapeV, &outputV),\n                          done);\n \n+    // If there are zero batches, we are done.\n+    if (shapeRaw.num_elements() == 0) {\n+      done();\n+      return;\n+    }\n+\n     if (n == 0 || m == 0) {\n       if (n == m || !compute_uv_ || !full_matrices_) {\n         // S, U, and V are all empty. Nothing to do.\n",
      "@@ -108,6 +108,14 @@ class SvdOpTest(test.TestCase):\n     for i in range(0, len(val), 2):\n       self.assertAllEqual(val[i], val[i + 1])\n \n+  @test_util.run_in_graph_and_eager_modes(use_gpu=True)\n+  def testEmptyBatches(self):\n+    matrices = constant_op.constant(1.0, shape=[0, 2, 2])\n+    s, u, v = self.evaluate(linalg_ops.svd(matrices))\n+    self.assertAllEqual(s, np.zeros([0, 2]))\n+    self.assertAllEqual(u, np.zeros([0, 2, 2]))\n+    self.assertAllEqual(v, np.zeros([0, 2, 2]))\n+\n \n def _GetSvdOpTest(dtype_, shape_, use_static_shape_, compute_uv_,\n                   full_matrices_):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9vqj-64pv-w55c",
    "API Signature": "tf.linalg.matrix_rank(\n    a, tol=None, validate_args=False, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "a = tf.constant([], shape=[0, 1, 1], dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK` fail in `DenseBincount`\n      ",
    "Bug description": "DenseBincount  assumes its input tensor  weights  to either have the same shape as its input tensor  input  or to be length-0. A different  weights  shape will trigger a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "binary_output = True\ninput = tf.random.uniform(shape=[0, 0], minval=-10000, maxval=10000, dtype=tf.int32, seed=-2460)\nsize = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-10000)\nweights = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.float32, seed=-10000)\n)\ntf.raw_ops.DenseBincount(input=input, size=size, weights=weights, binary_output=binary_output)",
    "Code change": [
      "@@ -80,6 +80,17 @@ class DenseBincountOp : public XlaOpKernel {\n     OP_REQUIRES_OK(ctx, weights_shape_or.status());\n \n     auto weights_shape = weights_shape_or.ValueOrDie();\n+    OP_REQUIRES(ctx,\n+                xla::ShapeUtil::CompatibleIgnoringElementType(weights_shape,\n+                                                              input_shape) ||\n+                    (weights_shape.dimensions_size() > 0 &&\n+                     weights_shape.dimensions(0) == 0),\n+                errors::InvalidArgument(\n+                    \"`weights` must be the same shape as `arr` or a length-0 \"\n+                    \"`Tensor`, in which case it acts as all weights equal to \"\n+                    \"1. Received \",\n+                    weights_shape.DebugString()));\n+\n     auto weights_size = weights_shape.dimensions(0);\n     bool has_weights = false;\n     if (weights_size) {\n",
      "@@ -280,6 +280,14 @@ class DenseBincountOp : public OpKernel {\n     OP_REQUIRES(ctx, size_t.dims() == 0,\n                 errors::InvalidArgument(\"Shape must be rank 0 but is rank \",\n                                         size_t.dims()));\n+    OP_REQUIRES(ctx,\n+                weights.shape() == data.shape() || weights.NumElements() == 0,\n+                errors::InvalidArgument(\n+                    \"`weights` must be the same shape as `arr` or a length-0 \"\n+                    \"`Tensor`, in which case it acts as all weights equal to \"\n+                    \"1. Received \",\n+                    weights.shape().DebugString()));\n+\n     Tidx size = size_t.scalar<Tidx>()();\n     OP_REQUIRES(\n         ctx, size >= 0,\n",
      "@@ -24,6 +24,7 @@ from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import bincount_ops\n from tensorflow.python.ops import gen_math_ops\n+from tensorflow.python.ops import random_ops\n from tensorflow.python.ops import sparse_ops\n from tensorflow.python.ops.ragged import ragged_factory_ops\n from tensorflow.python.ops.ragged import ragged_tensor\n@@ -152,6 +153,31 @@ class BincountTest(test_util.TensorFlowTestCase):\n       v2 = gen_math_ops.bincount([1, 2, 3, 1, 6, 8], s, [])\n       self.assertAllEqual(v2.get_shape().as_list(), [None])\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    binary_output = True\n+    inp = random_ops.random_uniform(\n+        shape=[10, 10],\n+        minval=-10000,\n+        maxval=10000,\n+        dtype=dtypes.int32,\n+        seed=-2460)\n+    size = random_ops.random_uniform(\n+        shape=[], minval=-10000, maxval=10000, dtype=dtypes.int32, seed=-10000)\n+    weights = random_ops.random_uniform(\n+        shape=[],\n+        minval=-10000,\n+        maxval=10000,\n+        dtype=dtypes.float32,\n+        seed=-10000)\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      self.evaluate(\n+          gen_math_ops.dense_bincount(\n+              input=inp,\n+              size=size,\n+              weights=weights,\n+              binary_output=binary_output))\n+\n \n class BincountOpTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-w62h-8xjm-fv49",
    "API Signature": "tf.raw_ops.DenseBincount(\n    input, size, weights, binary_output=False, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "input = tf.random.uniform(shape=[0, 0], minval=-10000, maxval=10000, dtype=tf.int32, seed=-2460)\nweights = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.float32, seed=-10000)"
  },
  {
    "Title": "\n        Segfault in `RaggedBincount`\n      ",
    "Bug description": "If  RaggedBincount  is given an empty input tensor  splits , it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "binary_output = True\nsplits = tf.random.uniform(shape=[0], minval=-10000, maxval=10000, dtype=tf.int64, seed=-7430)\nvalues = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-10000)\nsize = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-10000)\nweights = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.float32, seed=-10000)\n)\ntf.raw_ops.RaggedBincount(splits=splits, values=values, size=size, weights=weights, binary_output=binary_output)",
    "Code change": [
      "@@ -493,6 +493,9 @@ class RaggedBincountOp : public OpKernel {\n     int num_values = values.size();\n     int batch_idx = 0;\n \n+    OP_REQUIRES(ctx, splits.size() > 0,\n+                errors::InvalidArgument(\"Splits must be non-empty\"));\n+\n     OP_REQUIRES(ctx, splits(0) == 0,\n                 errors::InvalidArgument(\"Splits must start with 0, not with \",\n                                         splits(0)));\n",
      "@@ -734,6 +734,18 @@ class RaggedBincountOpTest(test_util.TensorFlowTestCase,\n               binary_output=False,\n               name=None))\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def test_splits_empty(self):  # b/238450914\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Splits must be non-empty\"):\n+      self.evaluate(\n+          gen_math_ops.ragged_bincount(\n+              splits=[],  # Invalid splits\n+              values=[1],\n+              size=1,\n+              weights=[1],\n+              binary_output=False,\n+              name=None))\n \n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wr9v-g9vf-c74v",
    "API Signature": "tf.raw_ops.RaggedBincount(\n    splits, values, size, weights, binary_output=False, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "splits = tf.random.uniform(shape=[0], minval=-10000, maxval=10000, dtype=tf.int64, seed=-7430)"
  },
  {
    "Title": "\n        `CHECK` fail in `LRNGrad`\n      ",
    "Bug description": "If  LRNGrad  is given an  output_image  input tensor that is not 4-D, it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "depth_radius = 1\nbias = 1.59018219\nalpha = 0.117728651\nbeta = 0.404427052\ninput_grads = tf.random.uniform(shape=[4, 4, 4, 4], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2033)\ninput_image = tf.random.uniform(shape=[4, 4, 4, 4], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2033)\noutput_image = tf.random.uniform(shape=[4, 4, 4, 4, 4, 4], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2033)\n)\ntf.raw_ops.LRNGrad(input_grads=input_grads, input_image=input_image, output_image=output_image, depth_radius=depth_radius, bias=bias, alpha=alpha, beta=beta)",
    "Code change": [
      "@@ -668,7 +668,8 @@ class LRNGradOp : public OpKernel {\n         in_image.dim_size(0) == batch && in_image.dim_size(1) == rows &&\n             in_image.dim_size(2) == cols && in_image.dim_size(3) == depth &&\n             out_image.dim_size(0) == batch && out_image.dim_size(1) == rows &&\n-            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth,\n+            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth &&\n+            out_image.dims() == 4,\n         errors::InvalidArgument(\n             \"input_grads, input_image, and out_image should have the same \"\n             \"shape\"));\n",
      "@@ -20,11 +20,13 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors_impl\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gradient_checker\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import nn\n+from tensorflow.python.ops import random_ops\n import tensorflow.python.ops.nn_grad  # pylint: disable=unused-import\n from tensorflow.python.platform import test\n \n@@ -111,6 +113,41 @@ class LRNOpTest(test.TestCase):\n     self.assertAllClose(r, expected)\n     self.assertShapeEqual(expected, grad)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testIncompatibleInputAndOutputImageShapes(self):\n+    depth_radius = 1\n+    bias = 1.59018219\n+    alpha = 0.117728651\n+    beta = 0.404427052\n+    input_grads = random_ops.random_uniform(\n+        shape=[4, 4, 4, 4],\n+        minval=-10000,\n+        maxval=10000,\n+        dtype=dtypes.float32,\n+        seed=-2033)\n+    input_image = random_ops.random_uniform(\n+        shape=[4, 4, 4, 4],\n+        minval=-10000,\n+        maxval=10000,\n+        dtype=dtypes.float32,\n+        seed=-2033)\n+    invalid_output_image = random_ops.random_uniform(\n+        shape=[4, 4, 4, 4, 4, 4],\n+        minval=-10000,\n+        maxval=10000,\n+        dtype=dtypes.float32,\n+        seed=-2033)\n+    with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n+      self.evaluate(\n+          nn.lrn_grad(\n+              input_grads=input_grads,\n+              input_image=input_image,\n+              output_image=invalid_output_image,\n+              depth_radius=depth_radius,\n+              bias=bias,\n+              alpha=alpha,\n+              beta=beta))\n+\n   def _RunAndVerifyGradients(self, dtype):\n     with self.cached_session():\n       # random shape\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9942-r22v-78cp",
    "API Signature": "tf.raw_ops.LRNGrad(\n    input_grads,\n    input_image,\n    output_image,\n    depth_radius=5,\n    bias=1,\n    alpha=1,\n    beta=0.5,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "utput_image = tf.random.uniform(shape=[4, 4, 4, 4, 4, 4], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2033)"
  },
  {
    "Title": "\n        `CHECK` fail in `ParameterizedTruncatedNormal`\n      ",
    "Bug description": "ParameterizedTruncatedNormal  assumes  shape  is of type  int32 . A valid  shape  of type  int64  results in a mismatched type  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "seed = 1618\nseed2 = 0\nshape = tf.random.uniform(shape=[3], minval=-10000, maxval=10000, dtype=tf.int64, seed=4894)\nmeans = tf.random.uniform(shape=[3, 3, 3], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2971)\nstdevs = tf.random.uniform(shape=[3, 3, 3], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2971)\nminvals = tf.random.uniform(shape=[3, 3, 3], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2971)\nmaxvals = tf.random.uniform(shape=[3, 3, 3], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2971)\n)\ntf.raw_ops.ParameterizedTruncatedNormal(shape=shape, means=means, stdevs=stdevs, minvals=minvals, maxvals=maxvals, seed=seed, seed2=seed2)",
    "Code change": [
      "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/kernels/stateless_random_ops.h\"\n #include \"tensorflow/core/lib/random/random_distributions.h\"\n #include \"tensorflow/core/platform/logging.h\"\n@@ -630,20 +631,18 @@ class ParameterizedTruncatedNormalOp : public OpKernel {\n     OP_REQUIRES(ctx, shape_tensor.NumElements() > 0,\n                 errors::InvalidArgument(\"Shape tensor must not be empty, got \",\n                                         shape_tensor.DebugString()));\n-    int32_t num_batches = shape_tensor.flat<int32>()(0);\n+    TensorShape tensor_shape;\n+    OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_tensor, &tensor_shape));\n \n+    int32_t num_batches = tensor_shape.dim_size(0);\n     int32_t samples_per_batch = 1;\n-    const int32_t num_dims = shape_tensor.dim_size(0);\n+    const int32_t num_dims = tensor_shape.dims();\n     for (int32_t i = 1; i < num_dims; i++) {\n-      samples_per_batch *= shape_tensor.flat<int32>()(i);\n+      samples_per_batch *= tensor_shape.dim_size(i);\n     }\n     const int32_t num_elements = num_batches * samples_per_batch;\n \n     // Allocate the output before fudging num_batches and samples_per_batch.\n-    auto shape_vec = shape_tensor.flat<int32>();\n-    TensorShape tensor_shape;\n-    OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(\n-                            shape_vec.data(), shape_vec.size(), &tensor_shape));\n     Tensor* samples_tensor;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, tensor_shape, &samples_tensor));\n \n",
      "@@ -303,6 +303,29 @@ class ParameterizedTruncatedNormalTest(test.TestCase):\n       self.assertAllGreater(samples, 0.)\n       self.assertAllGreater(samples_stateless, 0.)\n \n+  def testShapeTypes(self):\n+    for shape_dtype in [np.int32, np.int64]:\n+      shape = np.array([1000], dtype=shape_dtype)\n+      sample_op = random_ops.parameterized_truncated_normal(\n+          shape=shape, means=0.0, stddevs=0.1, minvals=-1., maxvals=1.)\n+      new_seed = random_ops.random_uniform([2],\n+                                           seed=1234,\n+                                           minval=0,\n+                                           maxval=(2**31 - 1),\n+                                           dtype=np.int32)\n+      sample_op_stateless = stateless.stateless_parameterized_truncated_normal(\n+          shape=shape,\n+          seed=new_seed,\n+          means=0.0,\n+          stddevs=0.1,\n+          minvals=-1.,\n+          maxvals=1.)\n+\n+      samples = self.evaluate(sample_op)\n+      stateless_samples = self.evaluate(sample_op_stateless)\n+      self.assertAllEqual(samples.shape, shape)\n+      self.assertAllEqual(stateless_samples.shape, shape)\n+\n   def testStatelessParameterizedTruncatedNormalHasGrads(self):\n     mean = variables.Variable(0.01)\n     stddev = variables.Variable(1.)\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-p2xf-8hgm-hpw5",
    "API Signature": "tf.raw_ops.ParameterizedTruncatedNormal(\n    shape, means, stdevs, minvals, maxvals, seed=0, seed2=0, name=None\n)\n",
    "Score": 0.010638297872340425,
    "Anomaly": "Tensor with specific dtype",
    "Category": "Tensor",
    "Argument": "shape = tf.random.uniform(shape=[3], minval=-10000, maxval=10000, dtype=tf.int64, seed=4894)"
  },
  {
    "Title": "\n        `CHECK` fail in `Save` and `SaveSlices`\n      ",
    "Bug description": "If  Save  or  SaveSlices  is run over tensors of an unsupported  dtype , it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "filename = tf.constant(\"\")\ntensor_names = tf.constant(\"\")\n# Save\ndata = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=-2021), tf.uint64)\ntf.raw_ops.Save(filename=filename, tensor_names=tensor_names, data=data, )\n# SaveSlices\nshapes_and_slices = tf.constant(\"\")\ndata = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=9712), tf.uint32)\n)\ntf.raw_ops.SaveSlices(filename=filename, tensor_names=tensor_names, shapes_and_slices=shapes_and_slices, data=data, )",
    "Code change": [
      "@@ -131,6 +131,16 @@ Status TensorSliceWriter::Finish() {\n \n /* static */\n size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n+  size_t max_bytes_per_element =\n+      TensorSliceWriter::MaxBytesPerElementOrZero(dt);\n+  if (max_bytes_per_element == 0) {\n+    LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n+  }\n+  return max_bytes_per_element;\n+}\n+\n+/* static */\n+size_t TensorSliceWriter::MaxBytesPerElementOrZero(DataType dt) {\n   switch (dt) {\n     case DT_FLOAT:\n       return 4;\n@@ -170,9 +180,8 @@ size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n     case DT_STRING:\n     case DT_BFLOAT16:\n     default:\n-      LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n+      return 0;\n   }\n-  return 0;\n }\n \n template <>\n",
      "@@ -68,6 +68,8 @@ class TensorSliceWriter {\n   static size_t MaxBytesPerElement(DataType dt);\n \n  private:\n+  static size_t MaxBytesPerElementOrZero(DataType dt);\n+\n   static constexpr size_t kMaxMessageBytes = 1LL << 31;\n   // Filling in the TensorProto in a SavedSlice will add the following\n   // header bytes, in addition to the data:\n@@ -162,9 +164,15 @@ Status TensorSliceWriter::Add(const string& name, const TensorShape& shape,\n template <typename T>\n Status TensorSliceWriter::SaveData(const T* data, int64_t num_elements,\n                                    SavedSlice* ss) {\n-  size_t size_bound =\n-      ss->ByteSize() + kTensorProtoHeaderBytes +\n-      (MaxBytesPerElement(DataTypeToEnum<T>::value) * num_elements);\n+  size_t max_bytes_per_element =\n+      MaxBytesPerElementOrZero(DataTypeToEnum<T>::value);\n+  if (max_bytes_per_element == 0) {\n+    return errors::InvalidArgument(\n+        \"Tensor slice serialization not implemented for dtype \",\n+        DataTypeToEnum<T>::value);\n+  }\n+  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +\n+                      (max_bytes_per_element * num_elements);\n   if (size_bound > kMaxMessageBytes) {\n     return errors::InvalidArgument(\n         \"Tensor slice is too large to serialize (conservative estimate: \",\n",
      "@@ -15,17 +15,19 @@ limitations under the License.\n \n #include \"tensorflow/core/util/tensor_slice_writer.h\"\n \n+#include <algorithm>\n #include <array>\n+#include <memory>\n+#include <vector>\n \n #include \"tensorflow/core/framework/tensor_shape.pb.h\"\n #include \"tensorflow/core/framework/versions.pb.h\"\n #include \"tensorflow/core/lib/core/status_test_util.h\"\n-#include \"tensorflow/core/lib/core/stringpiece.h\"\n-#include \"tensorflow/core/lib/io/path.h\"\n-#include \"tensorflow/core/lib/strings/str_util.h\"\n #include \"tensorflow/core/platform/logging.h\"\n+#include \"tensorflow/core/platform/path.h\"\n #include \"tensorflow/core/platform/protobuf.h\"\n #include \"tensorflow/core/platform/test.h\"\n+#include \"tensorflow/core/protobuf/error_codes.pb.h\"\n #include \"tensorflow/core/public/version.h\"\n #include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n #include \"tensorflow/core/util/tensor_slice_reader.h\"\n@@ -362,6 +364,17 @@ TEST(TensorSliceWriteTest, SizeErrors) {\n   }\n }\n \n+TEST(TensorSliceWriterTest, InvalidInput) {\n+  SavedSlice ss;\n+  std::array<uint32_t, 1> data;\n+  std::fill(data.begin(), data.end(), 1234);\n+  Status s = TensorSliceWriter::SaveData(data.data(), data.size(), &ss);\n+  EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n+  EXPECT_TRUE(absl::StrContains(\n+      s.error_message(),\n+      \"Tensor slice serialization not implemented for dtype\"));\n+}\n+\n }  // namespace checkpoint\n \n }  // namespace tensorflow\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m6vp-8q9j-whx4",
    "API Signature": "tf.raw_ops.Save(\n    filename, tensor_names, data, name=None\n)\n",
    "Score": 0.010638297872340425,
    "Anomaly": "Tensor with specific dtype",
    "Category": "Tensor",
    "Argument": "data = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=-2021), tf.uint64)"
  },
  {
    "Title": "\n        `CHECK` fail in `Save` and `SaveSlices`\n      ",
    "Bug description": "If  Save  or  SaveSlices  is run over tensors of an unsupported  dtype , it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "filename = tf.constant(\"\")\ntensor_names = tf.constant(\"\")\n# Save\ndata = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=-2021), tf.uint64)\ntf.raw_ops.Save(filename=filename, tensor_names=tensor_names, data=data, )\n# SaveSlices\nshapes_and_slices = tf.constant(\"\")\ndata = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=9712), tf.uint32)\n)\ntf.raw_ops.SaveSlices(filename=filename, tensor_names=tensor_names, shapes_and_slices=shapes_and_slices, data=data, )",
    "Code change": [
      "@@ -131,6 +131,16 @@ Status TensorSliceWriter::Finish() {\n \n /* static */\n size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n+  size_t max_bytes_per_element =\n+      TensorSliceWriter::MaxBytesPerElementOrZero(dt);\n+  if (max_bytes_per_element == 0) {\n+    LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n+  }\n+  return max_bytes_per_element;\n+}\n+\n+/* static */\n+size_t TensorSliceWriter::MaxBytesPerElementOrZero(DataType dt) {\n   switch (dt) {\n     case DT_FLOAT:\n       return 4;\n@@ -170,9 +180,8 @@ size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n     case DT_STRING:\n     case DT_BFLOAT16:\n     default:\n-      LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n+      return 0;\n   }\n-  return 0;\n }\n \n template <>\n",
      "@@ -68,6 +68,8 @@ class TensorSliceWriter {\n   static size_t MaxBytesPerElement(DataType dt);\n \n  private:\n+  static size_t MaxBytesPerElementOrZero(DataType dt);\n+\n   static constexpr size_t kMaxMessageBytes = 1LL << 31;\n   // Filling in the TensorProto in a SavedSlice will add the following\n   // header bytes, in addition to the data:\n@@ -162,9 +164,15 @@ Status TensorSliceWriter::Add(const string& name, const TensorShape& shape,\n template <typename T>\n Status TensorSliceWriter::SaveData(const T* data, int64_t num_elements,\n                                    SavedSlice* ss) {\n-  size_t size_bound =\n-      ss->ByteSize() + kTensorProtoHeaderBytes +\n-      (MaxBytesPerElement(DataTypeToEnum<T>::value) * num_elements);\n+  size_t max_bytes_per_element =\n+      MaxBytesPerElementOrZero(DataTypeToEnum<T>::value);\n+  if (max_bytes_per_element == 0) {\n+    return errors::InvalidArgument(\n+        \"Tensor slice serialization not implemented for dtype \",\n+        DataTypeToEnum<T>::value);\n+  }\n+  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +\n+                      (max_bytes_per_element * num_elements);\n   if (size_bound > kMaxMessageBytes) {\n     return errors::InvalidArgument(\n         \"Tensor slice is too large to serialize (conservative estimate: \",\n",
      "@@ -15,17 +15,19 @@ limitations under the License.\n \n #include \"tensorflow/core/util/tensor_slice_writer.h\"\n \n+#include <algorithm>\n #include <array>\n+#include <memory>\n+#include <vector>\n \n #include \"tensorflow/core/framework/tensor_shape.pb.h\"\n #include \"tensorflow/core/framework/versions.pb.h\"\n #include \"tensorflow/core/lib/core/status_test_util.h\"\n-#include \"tensorflow/core/lib/core/stringpiece.h\"\n-#include \"tensorflow/core/lib/io/path.h\"\n-#include \"tensorflow/core/lib/strings/str_util.h\"\n #include \"tensorflow/core/platform/logging.h\"\n+#include \"tensorflow/core/platform/path.h\"\n #include \"tensorflow/core/platform/protobuf.h\"\n #include \"tensorflow/core/platform/test.h\"\n+#include \"tensorflow/core/protobuf/error_codes.pb.h\"\n #include \"tensorflow/core/public/version.h\"\n #include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n #include \"tensorflow/core/util/tensor_slice_reader.h\"\n@@ -362,6 +364,17 @@ TEST(TensorSliceWriteTest, SizeErrors) {\n   }\n }\n \n+TEST(TensorSliceWriterTest, InvalidInput) {\n+  SavedSlice ss;\n+  std::array<uint32_t, 1> data;\n+  std::fill(data.begin(), data.end(), 1234);\n+  Status s = TensorSliceWriter::SaveData(data.data(), data.size(), &ss);\n+  EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n+  EXPECT_TRUE(absl::StrContains(\n+      s.error_message(),\n+      \"Tensor slice serialization not implemented for dtype\"));\n+}\n+\n }  // namespace checkpoint\n \n }  // namespace tensorflow\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m6vp-8q9j-whx4",
    "API Signature": null,
    "Score": 0.010638297872340425,
    "Anomaly": "Tensor with specific dtype",
    "Category": "Tensor",
    "Argument": "data = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=9712), tf.uint32)"
  },
  {
    "Title": "\n        Segfault in `SparseBincount`\n      ",
    "Bug description": "If  SparseBincount  is given inputs for  indices ,  values , and  dense_shape  that do not make a valid sparse tensor, it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "binary_output = True\nindices = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int64, seed=-1288)\nvalues = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-9366)\ndense_shape = tf.random.uniform(shape=[0], minval=-10000, maxval=10000, dtype=tf.int64, seed=-9878)\nsize = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-10000)\nweights = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.float32, seed=-10000)\n)\ntf.raw_ops.SparseBincount(indices=indices, values=values, dense_shape=dense_shape, size=size, weights=weights, binary_output=binary_output)",
    "Code change": [
      "@@ -4421,6 +4421,7 @@ tf_kernel_library(\n     deps = [\n         \":fill_functor\",\n         \":gpu_prim_hdrs\",\n+        \":sparse_utils\",\n         \"//tensorflow/core:framework\",\n         \"//tensorflow/core:lib\",\n         \"//tensorflow/core:lib_internal\",\n@@ -5007,6 +5008,7 @@ cc_library(\n SPARSE_DEPS = [\n     \"//tensorflow/core:framework\",\n     \"//tensorflow/core:lib\",\n+    \":sparse_utils\",\n ]\n \n tf_kernel_library(\n@@ -6480,6 +6482,7 @@ filegroup(\n         \"sparse_reorder_op.h\",\n         \"sparse_slice_op.h\",\n         \"sparse_tensor_dense_matmul_op.h\",\n+        \"sparse_utils.h\",\n         \"string_util.h\",\n         \"string_to_hash_bucket_op.h\",\n         \"string_to_hash_bucket_fast_op.h\",\n@@ -6718,6 +6721,7 @@ filegroup(\n         \"random_ops_util.h\",\n         \"random_poisson_op.cc\",\n         \"shuffle_common.h\",\n+        \"sparse_utils.cc\",\n         \"random_shuffle_op.cc\",\n         \"reduce_join_op.cc\",\n         \"reduction_ops_all.cc\",\n",
      "@@ -23,6 +23,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/bincount_op.h\"\n #include \"tensorflow/core/kernels/fill_functor.h\"\n+#include \"tensorflow/core/kernels/sparse_utils.h\"\n #include \"tensorflow/core/lib/core/threadpool.h\"\n #include \"tensorflow/core/platform/types.h\"\n #include \"tensorflow/core/util/determinism.h\"\n@@ -369,7 +370,8 @@ class SparseBincountOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& indices = ctx->input(0);\n-    const auto values = ctx->input(1).flat<Tidx>();\n+    const Tensor& values = ctx->input(1);\n+    const auto values_flat = values.flat<Tidx>();\n     const Tensor& dense_shape = ctx->input(2);\n     const Tensor& size_t = ctx->input(3);\n     const auto weights = ctx->input(4).flat<T>();\n@@ -382,6 +384,9 @@ class SparseBincountOp : public OpKernel {\n     OP_REQUIRES(\n         ctx, size >= 0,\n         errors::InvalidArgument(\"size (\", size, \") must be non-negative\"));\n+    OP_REQUIRES_OK(\n+        ctx, sparse_utils::ValidateSparseTensor<int64_t>(\n+                 indices, values, dense_shape, /*validate_indices=*/true));\n \n     bool is_1d = dense_shape.NumElements() == 1;\n \n@@ -394,11 +399,11 @@ class SparseBincountOp : public OpKernel {\n       if (binary_output_) {\n         OP_REQUIRES_OK(ctx,\n                        functor::BincountFunctor<Device, Tidx, T, true>::Compute(\n-                           ctx, values, weights, out, size));\n+                           ctx, values_flat, weights, out, size));\n       } else {\n         OP_REQUIRES_OK(\n             ctx, functor::BincountFunctor<Device, Tidx, T, false>::Compute(\n-                     ctx, values, weights, out, size));\n+                     ctx, values_flat, weights, out, size));\n       }\n     } else {\n       const auto shape = dense_shape.flat<int64_t>();\n@@ -410,7 +415,7 @@ class SparseBincountOp : public OpKernel {\n       const auto indices_mat = indices.matrix<int64_t>();\n       for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\n         const int64_t batch = indices_mat(i, 0);\n-        const Tidx bin = values(i);\n+        const Tidx bin = values_flat(i);\n         OP_REQUIRES(\n             ctx, batch < out.dimension(0),\n             errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,\n",
      "@@ -366,7 +366,7 @@ class SparseBincountOpTest(test_util.TensorFlowTestCase,\n     num_rows = 128\n     size = 1000\n     n_elems = 4096\n-    inp_indices = np.random.randint(0, num_rows, (n_elems,))\n+    inp_indices = np.random.randint(0, num_rows, (n_elems, 1))\n     inp_vals = np.random.randint(0, size, (n_elems,), dtype=dtype)\n \n     np_out = np.bincount(inp_vals, minlength=size)\n@@ -390,7 +390,7 @@ class SparseBincountOpTest(test_util.TensorFlowTestCase,\n     num_rows = 128\n     size = 1000\n     n_elems = 4096\n-    inp_indices = np.random.randint(0, num_rows, (n_elems,))\n+    inp_indices = np.random.randint(0, num_rows, (n_elems, 1))\n     inp_vals = np.random.randint(0, size, (n_elems,), dtype=dtype)\n     inp_weight = np.random.random((n_elems,))\n \n@@ -415,7 +415,7 @@ class SparseBincountOpTest(test_util.TensorFlowTestCase,\n     num_rows = 128\n     size = 10\n     n_elems = 4096\n-    inp_indices = np.random.randint(0, num_rows, (n_elems,))\n+    inp_indices = np.random.randint(0, num_rows, (n_elems, 1))\n     inp_vals = np.random.randint(0, size, (n_elems,), dtype=dtype)\n \n     np_out = np.ones((size,))\n@@ -440,7 +440,7 @@ class SparseBincountOpTest(test_util.TensorFlowTestCase,\n     num_rows = 128\n     size = 10\n     n_elems = 4096\n-    inp_indices = np.random.randint(0, num_rows, (n_elems,))\n+    inp_indices = np.random.randint(0, num_rows, (n_elems, 1))\n     inp_vals = np.random.randint(0, size, (n_elems,), dtype=dtype)\n     inp_weight = np.random.random((n_elems,))\n \n@@ -532,6 +532,27 @@ class SparseBincountOpTest(test_util.TensorFlowTestCase,\n               weights=[0, 0],\n               binary_output=False))\n \n+  def test_sparse_bincount_input_validation(self):\n+    np.random.seed(42)\n+    num_rows = 128\n+    size = 1000\n+    n_elems = 4096\n+    inp_indices = np.random.randint(0, num_rows, (n_elems, 1))\n+    inp_vals = np.random.randint(0, size, (n_elems,))\n+\n+    # Insert negative index.\n+    inp_indices[10, 0] = -2\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"out of bounds\"):\n+      self.evaluate(\n+          gen_math_ops.sparse_bincount(\n+              indices=inp_indices,\n+              values=inp_vals,\n+              dense_shape=[num_rows],\n+              size=size,\n+              weights=[]))\n+\n \n class RaggedBincountOpTest(test_util.TensorFlowTestCase,\n                            parameterized.TestCase):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-397c-5g2j-qxpv",
    "API Signature": "tf.raw_ops.SparseBincount(\n    indices, values, dense_shape, size, weights, binary_output=False, name=None\n)\n",
    "Score": 0.010638297872340425,
    "Anomaly": "Non sparse input tensor",
    "Category": "Tensor",
    "Argument": "indices = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int64, seed=-1288)\nvalues = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-9366)\ndense_shape = tf.random.uniform(shape=[0], minval=-10000, maxval=10000, dtype=tf.int64, seed=-9878)"
  },
  {
    "Title": "\n        `CHECK` fail in `RaggedTensorToVariant`\n      ",
    "Bug description": "If  RaggedTensorToVariant  is given a  rt_nested_splits  list that contains tensors of ranks other than one, it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "batched_input = True\nrt_nested_splits = tf.constant([0,32,64], shape=[3], dtype=tf.int64)\nrt_dense_values = tf.constant([0,32,64], shape=[3], dtype=tf.int64)\n)\ntf.raw_ops.RaggedTensorToVariant(rt_nested_splits=rt_nested_splits, rt_dense_values=rt_dense_values, batched_input=batched_input)",
    "Code change": [
      "@@ -188,6 +188,10 @@ class RaggedTensorToVariantOp : public OpKernel {\n     batched_ragged_input.mutable_nested_splits()->reserve(\n         ragged_nested_splits_len);\n     for (int i = 0; i < ragged_nested_splits_len; i++) {\n+      OP_REQUIRES(context, ragged_nested_splits_in[i].dims() == 1,\n+                  errors::InvalidArgument(\"Requires nested_row_splits[\", i, \"]\",\n+                                          \" to be rank 1 but is rank \",\n+                                          ragged_nested_splits_in[i].dims()));\n       batched_ragged_input.append_splits(ragged_nested_splits_in[i]);\n     }\n \n",
      "@@ -1468,6 +1468,21 @@ class RaggedTensorTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n         for i in range(3):\n           self.assertAllEqual(sess.run(rt[i]), out)\n \n+  def testToVariantInvalidParams(self):\n+    self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                           r'be rank 1 but is rank 0',\n+                           gen_ragged_conversion_ops.ragged_tensor_to_variant,\n+                           rt_nested_splits=[0, 1, 2],\n+                           rt_dense_values=[0, 1, 2],\n+                           batched_input=True)\n+\n+    self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                           r'be rank 1 but is rank 2',\n+                           gen_ragged_conversion_ops.ragged_tensor_to_variant,\n+                           rt_nested_splits=[[[0]], [[1]], [[2]]],\n+                           rt_dense_values=[0, 1, 2],\n+                           batched_input=True)\n+\n   def testFromVariantInvalidParams(self):\n     rt = ragged_factory_ops.constant([[0], [1], [2], [3]])\n     batched_variant = rt._to_variant(batched_input=True)\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m6cv-4fmf-66xf",
    "API Signature": "tf.raw_ops.RaggedTensorToVariant(\n    rt_nested_splits, rt_dense_values, batched_input, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "rt_nested_splits = tf.constant([0,32,64], shape=[3], dtype=tf.int64)"
  },
  {
    "Title": "\n        `CHECK` fail in `FractionalMaxPoolGrad`\n      ",
    "Bug description": "FractionalMaxPoolGrad  validates its inputs with  CHECK  failures instead of with returning errors. If it gets incorrectly sized inputs, the  CHECK  failure can be used to trigger a denial of service attack:",
    "Sample Code": "overlapping = True\norig_input = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)\norig_output = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)\nout_backprop = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)\nrow_pooling_sequence = tf.constant(0, shape=[5], dtype=tf.int64)\ncol_pooling_sequence = tf.constant(0, shape=[5], dtype=tf.int64)\n)\ntf.raw_ops.FractionalMaxPoolGrad(orig_input=orig_input, orig_output=orig_output, out_backprop=out_backprop, row_pooling_sequence=row_pooling_sequence, col_pooling_sequence=col_pooling_sequence, overlapping=overlapping)",
    "Code change": [
      "@@ -19,12 +19,13 @@ limitations under the License.\n #include <random>\n #include <vector>\n \n-#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n-\n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n+#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n #include \"tensorflow/core/lib/random/random.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n #include \"tensorflow/core/util/guarded_philox_random.h\"\n@@ -352,7 +353,9 @@ class FractionalMaxPoolGradOp : public OpKernel {\n         output_size[2] * output_size[1] * output_size[0];\n     for (int64_t i = 0; i < num_reshaped_cols; ++i) {\n       for (int64_t j = 0; j < output_size[3]; ++j) {\n-        DCHECK_EQ(tensor_out_dup_mat(j, i), tensor_out_mat(j, i));\n+        OP_REQUIRES(context, tensor_out_dup_mat(j, i) == tensor_out_mat(j, i),\n+                    errors::InvalidArgument(\n+                        \"tensor_out_dup is not the same as tensor_out\"));\n       }\n     }\n \n@@ -369,11 +372,12 @@ class FractionalMaxPoolGradOp : public OpKernel {\n \n     for (int index = 0; index < num_total_outputs; ++index) {\n       int input_backprop_index = out_arg_max_flat(index);\n-      // According to maxpooling_op.cc, the performance impact below is small.\n-      CHECK(input_backprop_index >= 0 &&\n-            input_backprop_index < num_total_inputs)\n-          << \"Invalid input backprop index: \" << input_backprop_index << \", \"\n-          << num_total_inputs;\n+      OP_REQUIRES(\n+          context,\n+          input_backprop_index >= 0 && input_backprop_index < num_total_inputs,\n+          errors::InvalidArgument(\n+              \"Invalid input backprop index: \", input_backprop_index, \", \",\n+              num_total_inputs));\n       input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n     }\n   }\n",
      "@@ -124,7 +124,7 @@ class FractionalMaxPoolTest(test.TestCase):\n     Returns:\n       None\n     \"\"\"\n-    with self.cached_session() as sess:\n+    with self.cached_session():\n       p, r, c = nn_ops.fractional_max_pool_v2(\n           input_tensor,\n           pooling_ratio,\n@@ -155,7 +155,7 @@ class FractionalMaxPoolTest(test.TestCase):\n           overlapping))\n       rand_mat = self._PRNG.randint(10, size=tensor_shape)\n       pooling_ratio = [1, math.sqrt(2), math.sqrt(2), 1]\n-      with self.cached_session() as sess:\n+      with self.cached_session():\n         p, r, c = nn_ops.fractional_max_pool_v2(\n             rand_mat,\n             pooling_ratio,\n@@ -630,6 +630,29 @@ class FractionalMaxPoolGradTest(test.TestCase):\n       self.assertAllClose(expected_input_backprop_overlapping,\n                           input_backprop_overlapping)\n \n+  def testInvalidSeqRaiseErrorForFractionalMaxPoolGrad(self):\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      with self.cached_session() as _:\n+        overlapping = True\n+        orig_input = constant_op.constant(\n+            .453409232, shape=[1, 7, 13, 1], dtype=dtypes.float32)\n+        orig_output = constant_op.constant(\n+            .453409232, shape=[1, 7, 13, 1], dtype=dtypes.float32)\n+        out_backprop = constant_op.constant(\n+            .453409232, shape=[1, 7, 13, 1], dtype=dtypes.float32)\n+        row_pooling_sequence = constant_op.constant(\n+            0, shape=[5], dtype=dtypes.int64)\n+        col_pooling_sequence = constant_op.constant(\n+            0, shape=[5], dtype=dtypes.int64)\n+        t = gen_nn_ops.FractionalMaxPoolGrad(\n+            orig_input=orig_input,\n+            orig_output=orig_output,\n+            out_backprop=out_backprop,\n+            row_pooling_sequence=row_pooling_sequence,\n+            col_pooling_sequence=col_pooling_sequence,\n+            overlapping=overlapping)\n+        self.evaluate(t)\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vxv8-r8q2-63xw",
    "API Signature": "tf.raw_ops.FractionalMaxPoolGrad(\n    orig_input,\n    orig_output,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "orig_output = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)\nout_backprop = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `QuantizedRelu` and `QuantizedRelu6`\n      ",
    "Bug description": "If  QuantizedRelu  or  QuantizedRelu6  are given nonscalar inputs for  min_features  or  max_features , it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.quint8\nfeatures = tf.constant(28, shape=[4,2], dtype=tf.quint8)\nmin_features = tf.constant([], shape=[0], dtype=tf.float32)\nmax_features = tf.constant(-128, shape=[1], dtype=tf.float32)\ntf.raw_ops.QuantizedRelu(features=features, min_features=min_features, max_features=max_features, out_type=out_type)\n)\ntf.raw_ops.QuantizedRelu6(features=features, min_features=min_features, max_features=max_features, out_type=out_type)",
    "Code change": [
      "@@ -32,8 +32,21 @@ class QuantizedReluOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -65,8 +78,21 @@ class QuantizedRelu6Op : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n",
      "@@ -55,8 +55,8 @@ TEST_F(QuantizedActivationsTest, TestRelu) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -86,8 +86,8 @@ TEST_F(QuantizedActivationsTest, TestRelu6) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
      "@@ -25,6 +25,7 @@ limitations under the License.\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n@@ -457,10 +458,28 @@ class QuantizedAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& x = context->input(0);\n     const Tensor& y = context->input(1);\n-    const float min_x = context->input(2).flat<float>()(0);\n-    const float max_x = context->input(3).flat<float>()(0);\n-    const float min_y = context->input(4).flat<float>()(0);\n-    const float max_y = context->input(5).flat<float>()(0);\n+    const Tensor& min_x_tensor = context->input(2);\n+    const Tensor& max_x_tensor = context->input(3);\n+    const Tensor& min_y_tensor = context->input(4);\n+    const Tensor& max_y_tensor = context->input(5);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),\n+                errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",\n+                                        min_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),\n+                errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",\n+                                        max_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),\n+                errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",\n+                                        min_y_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),\n+                errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",\n+                                        max_y_tensor.dims()));\n+\n+    const float min_x = min_x_tensor.scalar<float>()();\n+    const float max_x = max_x_tensor.scalar<float>()();\n+    const float min_y = min_y_tensor.scalar<float>()();\n+    const float max_y = max_y_tensor.scalar<float>()();\n \n     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n     if (!bcast.IsValid()) {\n",
      "@@ -206,5 +206,60 @@ class RequantizeOpTest(test_util.TensorFlowTestCase):\n               out_type=dtypes.qint8))\n \n \n+class QuantizedAddOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    x = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.quantized_add(\n+              x=x,\n+              y=y,\n+              min_x=[],\n+              max_x=1.0,\n+              min_y=0.0,\n+              max_y=1.0,\n+              Toutput=dtypes.qint32))\n+\n+\n+class QuantizedReluOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n+class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu6(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v7vw-577f-vp8x",
    "API Signature": "tf.raw_ops.QuantizedRelu(\n    features,\n    min_features,\n    max_features,\n    out_type=tf.dtypes.quint8,\n    name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "min_features = tf.constant([], shape=[0], dtype=tf.float32)\nmax_features = tf.constant(-128, shape=[1], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `QuantizedRelu` and `QuantizedRelu6`\n      ",
    "Bug description": "If  QuantizedRelu  or  QuantizedRelu6  are given nonscalar inputs for  min_features  or  max_features , it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.quint8\nfeatures = tf.constant(28, shape=[4,2], dtype=tf.quint8)\nmin_features = tf.constant([], shape=[0], dtype=tf.float32)\nmax_features = tf.constant(-128, shape=[1], dtype=tf.float32)\ntf.raw_ops.QuantizedRelu(features=features, min_features=min_features, max_features=max_features, out_type=out_type)\n)\ntf.raw_ops.QuantizedRelu6(features=features, min_features=min_features, max_features=max_features, out_type=out_type)",
    "Code change": [
      "@@ -32,8 +32,21 @@ class QuantizedReluOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -65,8 +78,21 @@ class QuantizedRelu6Op : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n",
      "@@ -55,8 +55,8 @@ TEST_F(QuantizedActivationsTest, TestRelu) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -86,8 +86,8 @@ TEST_F(QuantizedActivationsTest, TestRelu6) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
      "@@ -25,6 +25,7 @@ limitations under the License.\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n@@ -457,10 +458,28 @@ class QuantizedAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& x = context->input(0);\n     const Tensor& y = context->input(1);\n-    const float min_x = context->input(2).flat<float>()(0);\n-    const float max_x = context->input(3).flat<float>()(0);\n-    const float min_y = context->input(4).flat<float>()(0);\n-    const float max_y = context->input(5).flat<float>()(0);\n+    const Tensor& min_x_tensor = context->input(2);\n+    const Tensor& max_x_tensor = context->input(3);\n+    const Tensor& min_y_tensor = context->input(4);\n+    const Tensor& max_y_tensor = context->input(5);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),\n+                errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",\n+                                        min_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),\n+                errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",\n+                                        max_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),\n+                errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",\n+                                        min_y_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),\n+                errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",\n+                                        max_y_tensor.dims()));\n+\n+    const float min_x = min_x_tensor.scalar<float>()();\n+    const float max_x = max_x_tensor.scalar<float>()();\n+    const float min_y = min_y_tensor.scalar<float>()();\n+    const float max_y = max_y_tensor.scalar<float>()();\n \n     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n     if (!bcast.IsValid()) {\n",
      "@@ -206,5 +206,60 @@ class RequantizeOpTest(test_util.TensorFlowTestCase):\n               out_type=dtypes.qint8))\n \n \n+class QuantizedAddOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    x = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.quantized_add(\n+              x=x,\n+              y=y,\n+              min_x=[],\n+              max_x=1.0,\n+              min_y=0.0,\n+              max_y=1.0,\n+              Toutput=dtypes.qint32))\n+\n+\n+class QuantizedReluOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n+class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu6(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v7vw-577f-vp8x",
    "API Signature": "tf.raw_ops.QuantizedRelu6(\n    features,\n    min_features,\n    max_features,\n    out_type=tf.dtypes.quint8,\n    name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "min_features = tf.constant([], shape=[0], dtype=tf.float32)\nmax_features = tf.constant(-128, shape=[1], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `QuantizeDownAndShrinkRange`\n      ",
    "Bug description": "If  QuantizeDownAndShrinkRange  is given nonscalar inputs for  input_min  or  input_max , it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.quint8\ninput = tf.constant([1], shape=[3], dtype=tf.qint32)\ninput_min = tf.constant([], shape=[0], dtype=tf.float32)\ninput_max = tf.constant(-256, shape=[1], dtype=tf.float32)\n)\ntf.raw_ops.QuantizeDownAndShrinkRange(input=input, input_min=input_min, input_max=input_max, out_type=out_type)",
    "Code change": [
      "@@ -40,8 +40,20 @@ class QuantizeDownAndShrinkRangeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n-    const float input_min_float = ctx->input(1).flat<float>()(0);\n-    const float input_max_float = ctx->input(2).flat<float>()(0);\n+    const Tensor& input_min = ctx->input(1);\n+    const Tensor& input_max = ctx->input(2);\n+\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n+        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n+                                input_min.dims()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n+        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n+                                input_max.dims()));\n+\n+    const float input_min_float = input_min.scalar<float>()();\n+    const float input_max_float = input_max.scalar<float>()();\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n     Tensor* output_min = nullptr;\n",
      "@@ -53,8 +53,8 @@ TEST_F(QuantizeDownAndShrinkRangeTest, HandCrafted) {\n   const int value_count = 3;\n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));\n   test::FillValues<quint8>(&expected, {0, 128, 255});\n",
      "@@ -261,5 +261,21 @@ class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n               out_type=dtypes.quint8))\n \n \n+class QuantizeDownAndShrinkRangeOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.quantize_down_and_shrink_range(input=inputs,\n+                                                  input_min=[],\n+                                                  input_max=4.0,\n+                                                  out_type=dtypes.quint8))\n+\n+\n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vgvh-2pf4-jr2x",
    "API Signature": "tf.raw_ops.QuantizeDownAndShrinkRange(\n    input, input_min, input_max, out_type, name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "input_min = tf.constant([], shape=[0], dtype=tf.float32)\ninput_max = tf.constant(-256, shape=[1], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `QuantizedMatMul`\n      ",
    "Bug description": "If  QuantizedMatMul  is given nonscalar input for:",
    "Sample Code": "Toutput = tf.qint32\ntranspose_a = False\ntranspose_b = False\nTactivation = tf.quint8\na = tf.constant(7, shape=[3,4], dtype=tf.quint8)\nb = tf.constant(1, shape=[2,3], dtype=tf.quint8)\nmin_a = tf.constant([], shape=[0], dtype=tf.float32)\nmax_a = tf.constant(0, shape=[1], dtype=tf.float32)\nmin_b = tf.constant(0, shape=[1], dtype=tf.float32)\nmax_b = tf.constant(0, shape=[1], dtype=tf.float32)\n)\ntf.raw_ops.QuantizedMatMul(a=a, b=b, min_a=min_a, max_a=max_a, min_b=min_b, max_b=max_b, Toutput=Toutput, transpose_a=transpose_a, transpose_b=transpose_b, Tactivation=Tactivation)",
    "Code change": [
      "@@ -20,11 +20,14 @@ limitations under the License.\n #define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\n #include \"public/gemmlowp.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/kernels/reference_gemm.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -75,9 +78,21 @@ class QuantizedMatMulOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& a = context->input(0);\n     const Tensor& b = context->input(1);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(2).shape()),\n+                errors::InvalidArgument(\"min_a must be a scalar, but got shape\",\n+                                        context->input(2).shape()));\n     const float min_a = context->input(2).flat<float>()(0);\n+    OP_REQUIRES(context, context->input(3).NumElements() == 1,\n+                errors::InvalidArgument(\"max_a must be a scalar, but got shape\",\n+                                        context->input(3).shape()));\n     const float max_a = context->input(3).flat<float>()(0);\n+    OP_REQUIRES(context, context->input(4).NumElements() == 1,\n+                errors::InvalidArgument(\"min_b must be a scalar, but got shape\",\n+                                        context->input(4).shape()));\n     const float min_b = context->input(4).flat<float>()(0);\n+    OP_REQUIRES(context, context->input(5).NumElements() == 1,\n+                errors::InvalidArgument(\"max_b must be a scalar, but got shape\",\n+                                        context->input(5).shape()));\n     const float max_b = context->input(5).flat<float>()(0);\n \n     // Make sure that we have valid quantization ranges for the input buffers.\n",
      "@@ -62,10 +62,10 @@ TEST_F(QuantizedMatMulTest, Small_NoParams) {\n   // | 15 | 16 | 17 | 18 |\n   AddInputFromArray<quint8>(TensorShape({3, 4}),\n                             {7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n \n   TF_ASSERT_OK(RunOpKernel());\n   // Here are the results we expect, from hand calculations:\n@@ -118,10 +118,10 @@ TEST_F(QuantizedMatMulTest, VerySmall_WithParams) {\n   // The B matrix is:\n   // |   1 |\n   AddInputFromArray<quint8>(TensorShape({b_rows, b_cols}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {-12.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {243.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-12.0f});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   // We're requesting C = A.transposed() * B,\n   // so we expect to get these results:\n@@ -162,12 +162,50 @@ TEST_F(QuantizedMatMulTest, VerySmall_BadRange) {\n   // The B matrix is:\n   // |   1 |\n   AddInputFromArray<quint8>(TensorShape({b_rows, b_cols}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {-12.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-12.0f});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n   // Here we set the range so that the min and max are equal, so we expect to\n   // see an error when we run.\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  EXPECT_EQ(::tensorflow::error::INVALID_ARGUMENT, RunOpKernel().code());\n+}\n+\n+// This test multiplies two 1x1 8bit matrices, but sets invalid quantized min\n+// and max values, so we expect to get an error\n+TEST_F(QuantizedMatMulTest, VerySmall_BadMinMax) {\n+  // These parameters reflect a typical production usage of eight-bit matmuls\n+  // in an Inception-style network.\n+  const bool transpose_a = true;\n+  const int a_rows = 1;\n+  const int a_cols = 1;\n+  const int b_rows = 1;\n+  const int b_cols = 1;\n+  const bool transpose_b = false;\n+  TF_ASSERT_OK(NodeDefBuilder(\"quantized_mat_mul_op\", \"QuantizedMatMul\")\n+                   .Input(FakeInput(DT_QUINT8))\n+                   .Input(FakeInput(DT_QUINT8))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Attr(\"Toutput\", DataTypeToEnum<qint32>::v())\n+                   .Attr(\"transpose_a\", transpose_a)\n+                   .Attr(\"transpose_b\", transpose_b)\n+                   .Finalize(node_def()));\n+  TF_ASSERT_OK(InitOp());\n+  // The A matrix is:\n+  // |  -1 |\n+  AddInputFromArray<quint8>(TensorShape({a_rows, a_cols}), {11});\n+  // The B matrix is:\n+  // |   1 |\n+  AddInputFromArray<quint8>(TensorShape({b_rows, b_cols}), {0});\n+  // Here we set the error of a non scalar min_a value, so we expect to see an\n+  // error when we run.\n+  AddInputFromArray<float>(TensorShape({1}), {2});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n   EXPECT_EQ(::tensorflow::error::INVALID_ARGUMENT, RunOpKernel().code());\n }\n \n@@ -233,10 +271,10 @@ TEST_F(QuantizedMatMulTest, Small_WithParams) {\n                                                                3,\n                                                                6,\n                                                            });\n-  AddInputFromArray<float>(TensorShape({1}), {-12.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {243.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-12.0f});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   // We're requesting C = A.transposed() * B,\n   // so we expect to get these results:\n@@ -326,10 +364,10 @@ TEST_F(QuantizedMatMulTest, Medium_WithParams) {\n \n   AddInputFromArray<quint8>(a_quantized.shape(), a_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(b_quantized.shape(), b_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {a_min});\n-  AddInputFromArray<float>(TensorShape({1}), {a_max});\n-  AddInputFromArray<float>(TensorShape({1}), {b_min});\n-  AddInputFromArray<float>(TensorShape({1}), {b_max});\n+  AddInputFromArray<float>(TensorShape({}), {a_min});\n+  AddInputFromArray<float>(TensorShape({}), {a_max});\n+  AddInputFromArray<float>(TensorShape({}), {b_min});\n+  AddInputFromArray<float>(TensorShape({}), {b_max});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected_float(DT_FLOAT, {a_cols, b_cols});\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-689c-r7h2-fv9v",
    "API Signature": "tf.raw_ops.QuantizedMatMul(\n    a,\n    b,\n    min_a,\n    max_a,\n    min_b,\n    max_b,\n    Toutput=tf.dtypes.qint32,\n    transpose_a=False,\n    transpose_b=False,\n    Tactivation=tf.dtypes.quint8,\n    name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "min_a = tf.constant([], shape=[0], dtype=tf.float32)\nmax_a = tf.constant(0, shape=[1], dtype=tf.float32)\nmin_b = tf.constant(0, shape=[1], dtype=tf.float32)\nmax_b = tf.constant(0, shape=[1], dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK` fail in `FakeQuantWithMinMaxVarsPerChannel`\n      ",
    "Bug description": "If  FakeQuantWithMinMaxVarsPerChannel  is given  min  or  max  tensors of a rank other than one, it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "num_bits = 8\nnarrow_range = False\ninputs = tf.constant(0, shape=[4], dtype=tf.float32)\nmin = tf.constant([], shape=[4,0,0], dtype=tf.float32)\nmax = tf.constant(0, shape=[4], dtype=tf.float32)\n)\ntf.raw_ops.FakeQuantWithMinMaxVarsPerChannel(inputs=inputs, min=min, max=max, num_bits=num_bits, narrow_range=narrow_range)",
    "Code change": [
      "@@ -24,6 +24,7 @@ limitations under the License.\n // Above is the related header but clang tidy doesn't recognize it.\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/lib/monitoring/gauge.h\"\n #include \"tensorflow/core/platform/protobuf.h\"\n@@ -205,6 +206,13 @@ class FakeQuantWithMinMaxVarsOp : public OpKernel {\n     const Tensor& min = context->input(1);\n     const Tensor& max = context->input(2);\n \n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n+\n     Tensor* output;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -342,10 +350,17 @@ class FakeQuantWithMinMaxVarsPerChannelOp : public OpKernel {\n     const Tensor& input = context->input(0);\n     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n     const Tensor& min = context->input(1);\n+    const Tensor& max = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n     OP_REQUIRES(context, min.dim_size(0) == depth,\n                 InvalidArgument(\"min has incorrect size, expected \", depth,\n                                 \" was \", min.dim_size(0)));\n-    const Tensor& max = context->input(2);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n     OP_REQUIRES(context, max.dim_size(0) == depth,\n                 InvalidArgument(\"max has incorrect size, expected \", depth,\n                                 \" was \", max.dim_size(0)));\n",
      "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/ops_util.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n@@ -38,10 +39,30 @@ class QuantizedBiasAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n     const Tensor& bias = context->input(1);\n-    const float input_min = context->input(2).flat<float>()(0);\n-    const float input_max = context->input(3).flat<float>()(0);\n-    const float bias_min = context->input(4).flat<float>()(0);\n-    const float bias_max = context->input(5).flat<float>()(0);\n+\n+    const Tensor& min_input = context->input(2);\n+    const Tensor& max_input = context->input(3);\n+    const Tensor& min_bias = context->input(4);\n+    const Tensor& max_bias = context->input(5);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));\n+\n+    const float input_min = min_input.flat<float>()(0);\n+    const float input_max = max_input.flat<float>()(0);\n+    const float bias_min = min_bias.flat<float>()(0);\n+    const float bias_max = max_bias.flat<float>()(0);\n \n     OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),\n                 errors::InvalidArgument(\"Input tensor must be at least 2D: \",\n",
      "@@ -74,10 +74,10 @@ TEST_F(QuantizedBiasAddTest, Small) {\n                             input_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(bias_quantized.shape(),\n                             bias_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_min});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {bias_min});\n+  AddInputFromArray<float>(TensorShape({}), {bias_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -156,10 +156,10 @@ TEST_F(QuantizedBiasAddTest, RealData) {\n                             input_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(bias_quantized.shape(),\n                             bias_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_min});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {bias_min});\n+  AddInputFromArray<float>(TensorShape({}), {bias_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
      "@@ -25,7 +25,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n-\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n \n #ifdef USE_NEON\n@@ -274,8 +274,16 @@ class QuantizedInstanceNorm : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n \n-    float input_min = context->input(1).flat<float>()(0);\n-    float input_max = context->input(2).flat<float>()(0);\n+    const Tensor& x_min = context->input(1);\n+    const Tensor& x_max = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),\n+                errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",\n+                                        x_min.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),\n+                errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",\n+                                        x_max.dims()));\n+    float input_min = x_min.scalar<float>()();\n+    float input_max = x_max.scalar<float>()();\n     float input_scale = (input_max - input_min) / 255.0f;\n \n     OP_REQUIRES(context, input_min < input_max,\n",
      "@@ -18,9 +18,11 @@ limitations under the License.\n #define EIGEN_USE_THREADS\n \n #include <math.h>\n-#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/type_traits.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n@@ -38,10 +40,34 @@ class RequantizeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n-    const float input_min_float = ctx->input(1).flat<float>()(0);\n-    const float input_max_float = ctx->input(2).flat<float>()(0);\n-    const float requested_output_min_float = ctx->input(3).flat<float>()(0);\n-    const float requested_output_max_float = ctx->input(4).flat<float>()(0);\n+\n+    const Tensor& input_min = ctx->input(1);\n+    const Tensor& input_max = ctx->input(2);\n+    const Tensor& requested_output_min = ctx->input(3);\n+    const Tensor& requested_output_max = ctx->input(4);\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n+        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n+                                input_min.dims()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n+        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n+                                input_max.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_min` must be rank 0 but is rank \",\n+                    requested_output_min.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_max` must be rank 0 but is rank \",\n+                    requested_output_max.dims()));\n+\n+    const float input_min_float = input_min.flat<float>()(0);\n+    const float input_max_float = input_max.flat<float>()(0);\n+    const float requested_output_min_float =\n+        requested_output_min.flat<float>()(0);\n+    const float requested_output_max_float =\n+        requested_output_max.flat<float>()(0);\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n",
      "@@ -53,10 +53,10 @@ TEST_F(RequantizeTest, HandCraftedRequantize) {\n   // Requantize to -1 to 1.\n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-1.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));\n   test::FillValues<quint8>(&expected, {0, 128, 255});\n@@ -71,10 +71,10 @@ TEST_F(RequantizeTest, InvalidOutputMin) {\n \n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0.01f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0.01f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n   EXPECT_EQ(\"requested_output_min must be <= 0, but got 0.01\",\n             RunOpKernel().error_message());\n }\n@@ -85,10 +85,10 @@ TEST_F(RequantizeTest, InvalidOutputMax) {\n \n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-10.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-11.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-10.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-11.0f});\n   EXPECT_EQ(\n       \"requested_output_max must be >= requested_output_min, but got -11 and \"\n       \"-10\",\n",
      "@@ -0,0 +1,24 @@\n+# Tests of TensorFlow quantization ops written using the Python API.\n+\n+# buildifier: disable=same-origin-load\n+load(\"//tensorflow:tensorflow.bzl\", \"tf_py_test\")\n+\n+package(\n+    default_visibility = [\"//tensorflow:internal\"],\n+    licenses = [\"notice\"],\n+)\n+\n+tf_py_test(\n+    name = \"quantization_ops_test\",\n+    size = \"small\",\n+    srcs = [\"quantization_ops_test.py\"],\n+    deps = [\n+        \"//tensorflow/python:array_ops\",\n+        \"//tensorflow/python:client\",\n+        \"//tensorflow/python:client_testlib\",\n+        \"//tensorflow/python:framework\",\n+        \"//tensorflow/python:framework_for_generated_wrappers\",\n+        \"//tensorflow/python:math_ops\",\n+        \"//third_party/py/numpy\",\n+    ],\n+)\n",
      "@@ -0,0 +1,210 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for tf.quantize ops.\"\"\"\n+import numpy as np\n+\n+from tensorflow.python.framework import constant_op\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n+from tensorflow.python.framework import test_util\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import nn_ops\n+from tensorflow.python.platform import googletest\n+\n+\n+class FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars(\n+              inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars(\n+              inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))\n+\n+\n+class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[[0.0]], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Dimensions must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[1.0], max=[[1.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Dimensions must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n+\n+\n+class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)\n+    bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=[],\n+              max_input=1.0,\n+              min_bias=0.0,\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=[],\n+              min_bias=0.0,\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=1.0,\n+              min_bias=[],\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=1.0,\n+              min_bias=0.0,\n+              max_bias=[],\n+              out_type=dtypes.qint32))\n+\n+\n+class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.quantized_instance_norm(\n+              x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.quantized_instance_norm(\n+              x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))\n+\n+\n+class RequantizeOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=[],\n+              input_max=1.0,\n+              requested_output_min=0.0,\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=[],\n+              requested_output_min=0.0,\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=1.0,\n+              requested_output_min=[],\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=1.0,\n+              requested_output_min=0.0,\n+              requested_output_max=[],\n+              out_type=dtypes.qint8))\n+\n+\n+if __name__ == \"__main__\":\n+  googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9j4v-pp28-mxv7",
    "API Signature": "tf.raw_ops.FakeQuantWithMinMaxVarsPerChannel(\n    inputs, min, max, num_bits=8, narrow_range=False, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "min = tf.constant([], shape=[4,0,0], dtype=tf.float32)\nmax = tf.constant(0, shape=[4], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `QuantizedBiasAdd`\n      ",
    "Bug description": "If  QuantizedBiasAdd  is given  min_input ,  max_input ,  min_bias ,  max_bias  tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.qint32\ninput = tf.constant([85,170,255], shape=[3], dtype=tf.quint8)\nbias = tf.constant(43, shape=[2,3], dtype=tf.quint8)\nmin_input = tf.constant([], shape=[0], dtype=tf.float32)\nmax_input = tf.constant(0, shape=[1], dtype=tf.float32)\nmin_bias = tf.constant(0, shape=[1], dtype=tf.float32)\nmax_bias = tf.constant(0, shape=[1], dtype=tf.float32)\n)\ntf.raw_ops.QuantizedBiasAdd(input=input, bias=bias, min_input=min_input, max_input=max_input, min_bias=min_bias, max_bias=max_bias, out_type=out_type)",
    "Code change": [
      "@@ -24,6 +24,7 @@ limitations under the License.\n // Above is the related header but clang tidy doesn't recognize it.\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/lib/monitoring/gauge.h\"\n #include \"tensorflow/core/platform/protobuf.h\"\n@@ -205,6 +206,13 @@ class FakeQuantWithMinMaxVarsOp : public OpKernel {\n     const Tensor& min = context->input(1);\n     const Tensor& max = context->input(2);\n \n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n+\n     Tensor* output;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -342,10 +350,17 @@ class FakeQuantWithMinMaxVarsPerChannelOp : public OpKernel {\n     const Tensor& input = context->input(0);\n     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n     const Tensor& min = context->input(1);\n+    const Tensor& max = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n     OP_REQUIRES(context, min.dim_size(0) == depth,\n                 InvalidArgument(\"min has incorrect size, expected \", depth,\n                                 \" was \", min.dim_size(0)));\n-    const Tensor& max = context->input(2);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n     OP_REQUIRES(context, max.dim_size(0) == depth,\n                 InvalidArgument(\"max has incorrect size, expected \", depth,\n                                 \" was \", max.dim_size(0)));\n",
      "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/ops_util.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n@@ -38,10 +39,30 @@ class QuantizedBiasAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n     const Tensor& bias = context->input(1);\n-    const float input_min = context->input(2).flat<float>()(0);\n-    const float input_max = context->input(3).flat<float>()(0);\n-    const float bias_min = context->input(4).flat<float>()(0);\n-    const float bias_max = context->input(5).flat<float>()(0);\n+\n+    const Tensor& min_input = context->input(2);\n+    const Tensor& max_input = context->input(3);\n+    const Tensor& min_bias = context->input(4);\n+    const Tensor& max_bias = context->input(5);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));\n+\n+    const float input_min = min_input.flat<float>()(0);\n+    const float input_max = max_input.flat<float>()(0);\n+    const float bias_min = min_bias.flat<float>()(0);\n+    const float bias_max = max_bias.flat<float>()(0);\n \n     OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),\n                 errors::InvalidArgument(\"Input tensor must be at least 2D: \",\n",
      "@@ -74,10 +74,10 @@ TEST_F(QuantizedBiasAddTest, Small) {\n                             input_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(bias_quantized.shape(),\n                             bias_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_min});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {bias_min});\n+  AddInputFromArray<float>(TensorShape({}), {bias_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -156,10 +156,10 @@ TEST_F(QuantizedBiasAddTest, RealData) {\n                             input_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(bias_quantized.shape(),\n                             bias_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_min});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {bias_min});\n+  AddInputFromArray<float>(TensorShape({}), {bias_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
      "@@ -25,7 +25,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n-\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n \n #ifdef USE_NEON\n@@ -274,8 +274,16 @@ class QuantizedInstanceNorm : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n \n-    float input_min = context->input(1).flat<float>()(0);\n-    float input_max = context->input(2).flat<float>()(0);\n+    const Tensor& x_min = context->input(1);\n+    const Tensor& x_max = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),\n+                errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",\n+                                        x_min.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),\n+                errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",\n+                                        x_max.dims()));\n+    float input_min = x_min.scalar<float>()();\n+    float input_max = x_max.scalar<float>()();\n     float input_scale = (input_max - input_min) / 255.0f;\n \n     OP_REQUIRES(context, input_min < input_max,\n",
      "@@ -18,9 +18,11 @@ limitations under the License.\n #define EIGEN_USE_THREADS\n \n #include <math.h>\n-#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/type_traits.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n@@ -38,10 +40,34 @@ class RequantizeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n-    const float input_min_float = ctx->input(1).flat<float>()(0);\n-    const float input_max_float = ctx->input(2).flat<float>()(0);\n-    const float requested_output_min_float = ctx->input(3).flat<float>()(0);\n-    const float requested_output_max_float = ctx->input(4).flat<float>()(0);\n+\n+    const Tensor& input_min = ctx->input(1);\n+    const Tensor& input_max = ctx->input(2);\n+    const Tensor& requested_output_min = ctx->input(3);\n+    const Tensor& requested_output_max = ctx->input(4);\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n+        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n+                                input_min.dims()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n+        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n+                                input_max.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_min` must be rank 0 but is rank \",\n+                    requested_output_min.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_max` must be rank 0 but is rank \",\n+                    requested_output_max.dims()));\n+\n+    const float input_min_float = input_min.flat<float>()(0);\n+    const float input_max_float = input_max.flat<float>()(0);\n+    const float requested_output_min_float =\n+        requested_output_min.flat<float>()(0);\n+    const float requested_output_max_float =\n+        requested_output_max.flat<float>()(0);\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n",
      "@@ -53,10 +53,10 @@ TEST_F(RequantizeTest, HandCraftedRequantize) {\n   // Requantize to -1 to 1.\n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-1.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));\n   test::FillValues<quint8>(&expected, {0, 128, 255});\n@@ -71,10 +71,10 @@ TEST_F(RequantizeTest, InvalidOutputMin) {\n \n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0.01f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0.01f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n   EXPECT_EQ(\"requested_output_min must be <= 0, but got 0.01\",\n             RunOpKernel().error_message());\n }\n@@ -85,10 +85,10 @@ TEST_F(RequantizeTest, InvalidOutputMax) {\n \n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-10.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-11.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-10.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-11.0f});\n   EXPECT_EQ(\n       \"requested_output_max must be >= requested_output_min, but got -11 and \"\n       \"-10\",\n",
      "@@ -0,0 +1,24 @@\n+# Tests of TensorFlow quantization ops written using the Python API.\n+\n+# buildifier: disable=same-origin-load\n+load(\"//tensorflow:tensorflow.bzl\", \"tf_py_test\")\n+\n+package(\n+    default_visibility = [\"//tensorflow:internal\"],\n+    licenses = [\"notice\"],\n+)\n+\n+tf_py_test(\n+    name = \"quantization_ops_test\",\n+    size = \"small\",\n+    srcs = [\"quantization_ops_test.py\"],\n+    deps = [\n+        \"//tensorflow/python:array_ops\",\n+        \"//tensorflow/python:client\",\n+        \"//tensorflow/python:client_testlib\",\n+        \"//tensorflow/python:framework\",\n+        \"//tensorflow/python:framework_for_generated_wrappers\",\n+        \"//tensorflow/python:math_ops\",\n+        \"//third_party/py/numpy\",\n+    ],\n+)\n",
      "@@ -0,0 +1,210 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for tf.quantize ops.\"\"\"\n+import numpy as np\n+\n+from tensorflow.python.framework import constant_op\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n+from tensorflow.python.framework import test_util\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import nn_ops\n+from tensorflow.python.platform import googletest\n+\n+\n+class FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars(\n+              inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars(\n+              inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))\n+\n+\n+class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[[0.0]], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Dimensions must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[1.0], max=[[1.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Dimensions must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n+\n+\n+class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)\n+    bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=[],\n+              max_input=1.0,\n+              min_bias=0.0,\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=[],\n+              min_bias=0.0,\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=1.0,\n+              min_bias=[],\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=1.0,\n+              min_bias=0.0,\n+              max_bias=[],\n+              out_type=dtypes.qint32))\n+\n+\n+class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.quantized_instance_norm(\n+              x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.quantized_instance_norm(\n+              x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))\n+\n+\n+class RequantizeOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=[],\n+              input_max=1.0,\n+              requested_output_min=0.0,\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=[],\n+              requested_output_min=0.0,\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=1.0,\n+              requested_output_min=[],\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=1.0,\n+              requested_output_min=0.0,\n+              requested_output_max=[],\n+              out_type=dtypes.qint8))\n+\n+\n+if __name__ == \"__main__\":\n+  googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4pc4-m9mj-v2r9",
    "API Signature": "tf.raw_ops.QuantizedBiasAdd(\n    input, bias, min_input, max_input, min_bias, max_bias, out_type, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "min_input = tf.constant([], shape=[0], dtype=tf.float32)\nmax_input = tf.constant(0, shape=[1], dtype=tf.float32)\nmin_bias = tf.constant(0, shape=[1], dtype=tf.float32)\nmax_bias = tf.constant(0, shape=[1], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `Requantize`\n      ",
    "Bug description": "If  Requantize  is given  input_min ,  input_max ,  requested_output_min ,  requested_output_max  tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.quint8\ninput = tf.constant([1], shape=[3], dtype=tf.qint32)\ninput_min = tf.constant([], shape=[0], dtype=tf.float32)\ninput_max = tf.constant(-256, shape=[1], dtype=tf.float32)\nrequested_output_min = tf.constant(-256, shape=[1], dtype=tf.float32)\nrequested_output_max = tf.constant(-256, shape=[1], dtype=tf.float32)\n)\ntf.raw_ops.Requantize(input=input, input_min=input_min, input_max=input_max, requested_output_min=requested_output_min, requested_output_max=requested_output_max, out_type=out_type)",
    "Code change": [
      "@@ -24,6 +24,7 @@ limitations under the License.\n // Above is the related header but clang tidy doesn't recognize it.\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/lib/monitoring/gauge.h\"\n #include \"tensorflow/core/platform/protobuf.h\"\n@@ -205,6 +206,13 @@ class FakeQuantWithMinMaxVarsOp : public OpKernel {\n     const Tensor& min = context->input(1);\n     const Tensor& max = context->input(2);\n \n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n+\n     Tensor* output;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -342,10 +350,17 @@ class FakeQuantWithMinMaxVarsPerChannelOp : public OpKernel {\n     const Tensor& input = context->input(0);\n     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n     const Tensor& min = context->input(1);\n+    const Tensor& max = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n     OP_REQUIRES(context, min.dim_size(0) == depth,\n                 InvalidArgument(\"min has incorrect size, expected \", depth,\n                                 \" was \", min.dim_size(0)));\n-    const Tensor& max = context->input(2);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n     OP_REQUIRES(context, max.dim_size(0) == depth,\n                 InvalidArgument(\"max has incorrect size, expected \", depth,\n                                 \" was \", max.dim_size(0)));\n",
      "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/ops_util.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n@@ -38,10 +39,30 @@ class QuantizedBiasAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n     const Tensor& bias = context->input(1);\n-    const float input_min = context->input(2).flat<float>()(0);\n-    const float input_max = context->input(3).flat<float>()(0);\n-    const float bias_min = context->input(4).flat<float>()(0);\n-    const float bias_max = context->input(5).flat<float>()(0);\n+\n+    const Tensor& min_input = context->input(2);\n+    const Tensor& max_input = context->input(3);\n+    const Tensor& min_bias = context->input(4);\n+    const Tensor& max_bias = context->input(5);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));\n+\n+    const float input_min = min_input.flat<float>()(0);\n+    const float input_max = max_input.flat<float>()(0);\n+    const float bias_min = min_bias.flat<float>()(0);\n+    const float bias_max = max_bias.flat<float>()(0);\n \n     OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),\n                 errors::InvalidArgument(\"Input tensor must be at least 2D: \",\n",
      "@@ -74,10 +74,10 @@ TEST_F(QuantizedBiasAddTest, Small) {\n                             input_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(bias_quantized.shape(),\n                             bias_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_min});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {bias_min});\n+  AddInputFromArray<float>(TensorShape({}), {bias_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -156,10 +156,10 @@ TEST_F(QuantizedBiasAddTest, RealData) {\n                             input_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(bias_quantized.shape(),\n                             bias_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_min});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {bias_min});\n+  AddInputFromArray<float>(TensorShape({}), {bias_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
      "@@ -25,7 +25,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n-\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n \n #ifdef USE_NEON\n@@ -274,8 +274,16 @@ class QuantizedInstanceNorm : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n \n-    float input_min = context->input(1).flat<float>()(0);\n-    float input_max = context->input(2).flat<float>()(0);\n+    const Tensor& x_min = context->input(1);\n+    const Tensor& x_max = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),\n+                errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",\n+                                        x_min.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),\n+                errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",\n+                                        x_max.dims()));\n+    float input_min = x_min.scalar<float>()();\n+    float input_max = x_max.scalar<float>()();\n     float input_scale = (input_max - input_min) / 255.0f;\n \n     OP_REQUIRES(context, input_min < input_max,\n",
      "@@ -18,9 +18,11 @@ limitations under the License.\n #define EIGEN_USE_THREADS\n \n #include <math.h>\n-#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/type_traits.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n@@ -38,10 +40,34 @@ class RequantizeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n-    const float input_min_float = ctx->input(1).flat<float>()(0);\n-    const float input_max_float = ctx->input(2).flat<float>()(0);\n-    const float requested_output_min_float = ctx->input(3).flat<float>()(0);\n-    const float requested_output_max_float = ctx->input(4).flat<float>()(0);\n+\n+    const Tensor& input_min = ctx->input(1);\n+    const Tensor& input_max = ctx->input(2);\n+    const Tensor& requested_output_min = ctx->input(3);\n+    const Tensor& requested_output_max = ctx->input(4);\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n+        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n+                                input_min.dims()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n+        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n+                                input_max.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_min` must be rank 0 but is rank \",\n+                    requested_output_min.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_max` must be rank 0 but is rank \",\n+                    requested_output_max.dims()));\n+\n+    const float input_min_float = input_min.flat<float>()(0);\n+    const float input_max_float = input_max.flat<float>()(0);\n+    const float requested_output_min_float =\n+        requested_output_min.flat<float>()(0);\n+    const float requested_output_max_float =\n+        requested_output_max.flat<float>()(0);\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n",
      "@@ -53,10 +53,10 @@ TEST_F(RequantizeTest, HandCraftedRequantize) {\n   // Requantize to -1 to 1.\n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-1.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));\n   test::FillValues<quint8>(&expected, {0, 128, 255});\n@@ -71,10 +71,10 @@ TEST_F(RequantizeTest, InvalidOutputMin) {\n \n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0.01f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0.01f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n   EXPECT_EQ(\"requested_output_min must be <= 0, but got 0.01\",\n             RunOpKernel().error_message());\n }\n@@ -85,10 +85,10 @@ TEST_F(RequantizeTest, InvalidOutputMax) {\n \n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-10.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-11.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-10.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-11.0f});\n   EXPECT_EQ(\n       \"requested_output_max must be >= requested_output_min, but got -11 and \"\n       \"-10\",\n",
      "@@ -0,0 +1,24 @@\n+# Tests of TensorFlow quantization ops written using the Python API.\n+\n+# buildifier: disable=same-origin-load\n+load(\"//tensorflow:tensorflow.bzl\", \"tf_py_test\")\n+\n+package(\n+    default_visibility = [\"//tensorflow:internal\"],\n+    licenses = [\"notice\"],\n+)\n+\n+tf_py_test(\n+    name = \"quantization_ops_test\",\n+    size = \"small\",\n+    srcs = [\"quantization_ops_test.py\"],\n+    deps = [\n+        \"//tensorflow/python:array_ops\",\n+        \"//tensorflow/python:client\",\n+        \"//tensorflow/python:client_testlib\",\n+        \"//tensorflow/python:framework\",\n+        \"//tensorflow/python:framework_for_generated_wrappers\",\n+        \"//tensorflow/python:math_ops\",\n+        \"//third_party/py/numpy\",\n+    ],\n+)\n",
      "@@ -0,0 +1,210 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for tf.quantize ops.\"\"\"\n+import numpy as np\n+\n+from tensorflow.python.framework import constant_op\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n+from tensorflow.python.framework import test_util\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import nn_ops\n+from tensorflow.python.platform import googletest\n+\n+\n+class FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars(\n+              inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars(\n+              inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))\n+\n+\n+class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[[0.0]], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Dimensions must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[1.0], max=[[1.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Dimensions must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n+\n+\n+class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)\n+    bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=[],\n+              max_input=1.0,\n+              min_bias=0.0,\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=[],\n+              min_bias=0.0,\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=1.0,\n+              min_bias=[],\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=1.0,\n+              min_bias=0.0,\n+              max_bias=[],\n+              out_type=dtypes.qint32))\n+\n+\n+class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.quantized_instance_norm(\n+              x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.quantized_instance_norm(\n+              x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))\n+\n+\n+class RequantizeOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=[],\n+              input_max=1.0,\n+              requested_output_min=0.0,\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=[],\n+              requested_output_min=0.0,\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=1.0,\n+              requested_output_min=[],\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=1.0,\n+              requested_output_min=0.0,\n+              requested_output_max=[],\n+              out_type=dtypes.qint8))\n+\n+\n+if __name__ == \"__main__\":\n+  googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wqmc-pm8c-2jhc",
    "API Signature": "tf.raw_ops.Requantize(\n    input,\n    input_min,\n    input_max,\n    requested_output_min,\n    requested_output_max,\n    out_type,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "input_min = tf.constant([], shape=[0], dtype=tf.float32)\ninput_max = tf.constant(-256, shape=[1], dtype=tf.float32)\nrequested_output_min = tf.constant(-256, shape=[1], dtype=tf.float32)\nrequested_output_max = tf.constant(-256, shape=[1], dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK` fail in `FakeQuantWithMinMaxVars`\n      ",
    "Bug description": "If  FakeQuantWithMinMaxVars  is given  min  or  max  tensors of a nonzero rank, it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "num_bits = 8\nnarrow_range = False\ninputs = tf.constant(0, shape=[2,3], dtype=tf.float32)\nmin = tf.constant(0, shape=[2,3], dtype=tf.float32)\nmax = tf.constant(0, shape=[2,3], dtype=tf.float32)\n)\ntf.raw_ops.FakeQuantWithMinMaxVars(inputs=inputs, min=min, max=max, num_bits=num_bits, narrow_range=narrow_range)",
    "Code change": [
      "@@ -24,6 +24,7 @@ limitations under the License.\n // Above is the related header but clang tidy doesn't recognize it.\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/lib/monitoring/gauge.h\"\n #include \"tensorflow/core/platform/protobuf.h\"\n@@ -205,6 +206,13 @@ class FakeQuantWithMinMaxVarsOp : public OpKernel {\n     const Tensor& min = context->input(1);\n     const Tensor& max = context->input(2);\n \n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n+\n     Tensor* output;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -342,10 +350,17 @@ class FakeQuantWithMinMaxVarsPerChannelOp : public OpKernel {\n     const Tensor& input = context->input(0);\n     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n     const Tensor& min = context->input(1);\n+    const Tensor& max = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n     OP_REQUIRES(context, min.dim_size(0) == depth,\n                 InvalidArgument(\"min has incorrect size, expected \", depth,\n                                 \" was \", min.dim_size(0)));\n-    const Tensor& max = context->input(2);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n     OP_REQUIRES(context, max.dim_size(0) == depth,\n                 InvalidArgument(\"max has incorrect size, expected \", depth,\n                                 \" was \", max.dim_size(0)));\n",
      "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/ops_util.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n@@ -38,10 +39,30 @@ class QuantizedBiasAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n     const Tensor& bias = context->input(1);\n-    const float input_min = context->input(2).flat<float>()(0);\n-    const float input_max = context->input(3).flat<float>()(0);\n-    const float bias_min = context->input(4).flat<float>()(0);\n-    const float bias_max = context->input(5).flat<float>()(0);\n+\n+    const Tensor& min_input = context->input(2);\n+    const Tensor& max_input = context->input(3);\n+    const Tensor& min_bias = context->input(4);\n+    const Tensor& max_bias = context->input(5);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));\n+\n+    const float input_min = min_input.flat<float>()(0);\n+    const float input_max = max_input.flat<float>()(0);\n+    const float bias_min = min_bias.flat<float>()(0);\n+    const float bias_max = max_bias.flat<float>()(0);\n \n     OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),\n                 errors::InvalidArgument(\"Input tensor must be at least 2D: \",\n",
      "@@ -74,10 +74,10 @@ TEST_F(QuantizedBiasAddTest, Small) {\n                             input_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(bias_quantized.shape(),\n                             bias_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_min});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {bias_min});\n+  AddInputFromArray<float>(TensorShape({}), {bias_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -156,10 +156,10 @@ TEST_F(QuantizedBiasAddTest, RealData) {\n                             input_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(bias_quantized.shape(),\n                             bias_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_min});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {bias_min});\n+  AddInputFromArray<float>(TensorShape({}), {bias_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
      "@@ -25,7 +25,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n-\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n \n #ifdef USE_NEON\n@@ -274,8 +274,16 @@ class QuantizedInstanceNorm : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n \n-    float input_min = context->input(1).flat<float>()(0);\n-    float input_max = context->input(2).flat<float>()(0);\n+    const Tensor& x_min = context->input(1);\n+    const Tensor& x_max = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),\n+                errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",\n+                                        x_min.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),\n+                errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",\n+                                        x_max.dims()));\n+    float input_min = x_min.scalar<float>()();\n+    float input_max = x_max.scalar<float>()();\n     float input_scale = (input_max - input_min) / 255.0f;\n \n     OP_REQUIRES(context, input_min < input_max,\n",
      "@@ -18,9 +18,11 @@ limitations under the License.\n #define EIGEN_USE_THREADS\n \n #include <math.h>\n-#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/type_traits.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n@@ -38,10 +40,34 @@ class RequantizeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n-    const float input_min_float = ctx->input(1).flat<float>()(0);\n-    const float input_max_float = ctx->input(2).flat<float>()(0);\n-    const float requested_output_min_float = ctx->input(3).flat<float>()(0);\n-    const float requested_output_max_float = ctx->input(4).flat<float>()(0);\n+\n+    const Tensor& input_min = ctx->input(1);\n+    const Tensor& input_max = ctx->input(2);\n+    const Tensor& requested_output_min = ctx->input(3);\n+    const Tensor& requested_output_max = ctx->input(4);\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n+        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n+                                input_min.dims()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n+        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n+                                input_max.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_min` must be rank 0 but is rank \",\n+                    requested_output_min.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_max` must be rank 0 but is rank \",\n+                    requested_output_max.dims()));\n+\n+    const float input_min_float = input_min.flat<float>()(0);\n+    const float input_max_float = input_max.flat<float>()(0);\n+    const float requested_output_min_float =\n+        requested_output_min.flat<float>()(0);\n+    const float requested_output_max_float =\n+        requested_output_max.flat<float>()(0);\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n",
      "@@ -53,10 +53,10 @@ TEST_F(RequantizeTest, HandCraftedRequantize) {\n   // Requantize to -1 to 1.\n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-1.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));\n   test::FillValues<quint8>(&expected, {0, 128, 255});\n@@ -71,10 +71,10 @@ TEST_F(RequantizeTest, InvalidOutputMin) {\n \n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0.01f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0.01f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n   EXPECT_EQ(\"requested_output_min must be <= 0, but got 0.01\",\n             RunOpKernel().error_message());\n }\n@@ -85,10 +85,10 @@ TEST_F(RequantizeTest, InvalidOutputMax) {\n \n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-10.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-11.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-10.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-11.0f});\n   EXPECT_EQ(\n       \"requested_output_max must be >= requested_output_min, but got -11 and \"\n       \"-10\",\n",
      "@@ -0,0 +1,24 @@\n+# Tests of TensorFlow quantization ops written using the Python API.\n+\n+# buildifier: disable=same-origin-load\n+load(\"//tensorflow:tensorflow.bzl\", \"tf_py_test\")\n+\n+package(\n+    default_visibility = [\"//tensorflow:internal\"],\n+    licenses = [\"notice\"],\n+)\n+\n+tf_py_test(\n+    name = \"quantization_ops_test\",\n+    size = \"small\",\n+    srcs = [\"quantization_ops_test.py\"],\n+    deps = [\n+        \"//tensorflow/python:array_ops\",\n+        \"//tensorflow/python:client\",\n+        \"//tensorflow/python:client_testlib\",\n+        \"//tensorflow/python:framework\",\n+        \"//tensorflow/python:framework_for_generated_wrappers\",\n+        \"//tensorflow/python:math_ops\",\n+        \"//third_party/py/numpy\",\n+    ],\n+)\n",
      "@@ -0,0 +1,210 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for tf.quantize ops.\"\"\"\n+import numpy as np\n+\n+from tensorflow.python.framework import constant_op\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n+from tensorflow.python.framework import test_util\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import nn_ops\n+from tensorflow.python.platform import googletest\n+\n+\n+class FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars(\n+              inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars(\n+              inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))\n+\n+\n+class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[[0.0]], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Dimensions must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[1.0], max=[[1.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Dimensions must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n+\n+\n+class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)\n+    bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=[],\n+              max_input=1.0,\n+              min_bias=0.0,\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=[],\n+              min_bias=0.0,\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=1.0,\n+              min_bias=[],\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=1.0,\n+              min_bias=0.0,\n+              max_bias=[],\n+              out_type=dtypes.qint32))\n+\n+\n+class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.quantized_instance_norm(\n+              x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.quantized_instance_norm(\n+              x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))\n+\n+\n+class RequantizeOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=[],\n+              input_max=1.0,\n+              requested_output_min=0.0,\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=[],\n+              requested_output_min=0.0,\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=1.0,\n+              requested_output_min=[],\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=1.0,\n+              requested_output_min=0.0,\n+              requested_output_max=[],\n+              out_type=dtypes.qint8))\n+\n+\n+if __name__ == \"__main__\":\n+  googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9fpg-838v-wpv7",
    "API Signature": "tf.raw_ops.FakeQuantWithMinMaxVars(\n    inputs, min, max, num_bits=8, narrow_range=False, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "min = tf.constant(0, shape=[2,3], dtype=tf.float32)\nmax = tf.constant(0, shape=[2,3], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `QuantizedInstanceNorm`\n      ",
    "Bug description": "If  QuantizedInstanceNorm  is given  x_min  or  x_max  tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "output_range_given = False\ngiven_y_min = 0\ngiven_y_max = 0\nvariance_epsilon = 1e-05\nmin_separation = 0.001\nx = tf.constant(88, shape=[1,4,4,32], dtype=tf.quint8)\nx_min = tf.constant([], shape=[0], dtype=tf.float32)\nx_max = tf.constant(0, shape=[], dtype=tf.float32)\n)\ntf.raw_ops.QuantizedInstanceNorm(x=x, x_min=x_min, x_max=x_max, output_range_given=output_range_given, given_y_min=given_y_min, given_y_max=given_y_max, variance_epsilon=variance_epsilon, min_separation=min_separation)",
    "Code change": [
      "@@ -24,6 +24,7 @@ limitations under the License.\n // Above is the related header but clang tidy doesn't recognize it.\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/lib/monitoring/gauge.h\"\n #include \"tensorflow/core/platform/protobuf.h\"\n@@ -205,6 +206,13 @@ class FakeQuantWithMinMaxVarsOp : public OpKernel {\n     const Tensor& min = context->input(1);\n     const Tensor& max = context->input(2);\n \n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n+\n     Tensor* output;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -342,10 +350,17 @@ class FakeQuantWithMinMaxVarsPerChannelOp : public OpKernel {\n     const Tensor& input = context->input(0);\n     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n     const Tensor& min = context->input(1);\n+    const Tensor& max = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n     OP_REQUIRES(context, min.dim_size(0) == depth,\n                 InvalidArgument(\"min has incorrect size, expected \", depth,\n                                 \" was \", min.dim_size(0)));\n-    const Tensor& max = context->input(2);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n     OP_REQUIRES(context, max.dim_size(0) == depth,\n                 InvalidArgument(\"max has incorrect size, expected \", depth,\n                                 \" was \", max.dim_size(0)));\n",
      "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/ops_util.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n@@ -38,10 +39,30 @@ class QuantizedBiasAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n     const Tensor& bias = context->input(1);\n-    const float input_min = context->input(2).flat<float>()(0);\n-    const float input_max = context->input(3).flat<float>()(0);\n-    const float bias_min = context->input(4).flat<float>()(0);\n-    const float bias_max = context->input(5).flat<float>()(0);\n+\n+    const Tensor& min_input = context->input(2);\n+    const Tensor& max_input = context->input(3);\n+    const Tensor& min_bias = context->input(4);\n+    const Tensor& max_bias = context->input(5);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));\n+\n+    const float input_min = min_input.flat<float>()(0);\n+    const float input_max = max_input.flat<float>()(0);\n+    const float bias_min = min_bias.flat<float>()(0);\n+    const float bias_max = max_bias.flat<float>()(0);\n \n     OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),\n                 errors::InvalidArgument(\"Input tensor must be at least 2D: \",\n",
      "@@ -74,10 +74,10 @@ TEST_F(QuantizedBiasAddTest, Small) {\n                             input_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(bias_quantized.shape(),\n                             bias_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_min});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {bias_min});\n+  AddInputFromArray<float>(TensorShape({}), {bias_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -156,10 +156,10 @@ TEST_F(QuantizedBiasAddTest, RealData) {\n                             input_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(bias_quantized.shape(),\n                             bias_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_min});\n-  AddInputFromArray<float>(TensorShape({1}), {bias_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {bias_min});\n+  AddInputFromArray<float>(TensorShape({}), {bias_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
      "@@ -25,7 +25,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n-\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n \n #ifdef USE_NEON\n@@ -274,8 +274,16 @@ class QuantizedInstanceNorm : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n \n-    float input_min = context->input(1).flat<float>()(0);\n-    float input_max = context->input(2).flat<float>()(0);\n+    const Tensor& x_min = context->input(1);\n+    const Tensor& x_max = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),\n+                errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",\n+                                        x_min.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),\n+                errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",\n+                                        x_max.dims()));\n+    float input_min = x_min.scalar<float>()();\n+    float input_max = x_max.scalar<float>()();\n     float input_scale = (input_max - input_min) / 255.0f;\n \n     OP_REQUIRES(context, input_min < input_max,\n",
      "@@ -18,9 +18,11 @@ limitations under the License.\n #define EIGEN_USE_THREADS\n \n #include <math.h>\n-#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/type_traits.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n@@ -38,10 +40,34 @@ class RequantizeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n-    const float input_min_float = ctx->input(1).flat<float>()(0);\n-    const float input_max_float = ctx->input(2).flat<float>()(0);\n-    const float requested_output_min_float = ctx->input(3).flat<float>()(0);\n-    const float requested_output_max_float = ctx->input(4).flat<float>()(0);\n+\n+    const Tensor& input_min = ctx->input(1);\n+    const Tensor& input_max = ctx->input(2);\n+    const Tensor& requested_output_min = ctx->input(3);\n+    const Tensor& requested_output_max = ctx->input(4);\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n+        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n+                                input_min.dims()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n+        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n+                                input_max.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_min` must be rank 0 but is rank \",\n+                    requested_output_min.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_max` must be rank 0 but is rank \",\n+                    requested_output_max.dims()));\n+\n+    const float input_min_float = input_min.flat<float>()(0);\n+    const float input_max_float = input_max.flat<float>()(0);\n+    const float requested_output_min_float =\n+        requested_output_min.flat<float>()(0);\n+    const float requested_output_max_float =\n+        requested_output_max.flat<float>()(0);\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n",
      "@@ -53,10 +53,10 @@ TEST_F(RequantizeTest, HandCraftedRequantize) {\n   // Requantize to -1 to 1.\n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-1.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));\n   test::FillValues<quint8>(&expected, {0, 128, 255});\n@@ -71,10 +71,10 @@ TEST_F(RequantizeTest, InvalidOutputMin) {\n \n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0.01f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0.01f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n   EXPECT_EQ(\"requested_output_min must be <= 0, but got 0.01\",\n             RunOpKernel().error_message());\n }\n@@ -85,10 +85,10 @@ TEST_F(RequantizeTest, InvalidOutputMax) {\n \n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-10.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {-11.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-10.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-11.0f});\n   EXPECT_EQ(\n       \"requested_output_max must be >= requested_output_min, but got -11 and \"\n       \"-10\",\n",
      "@@ -0,0 +1,24 @@\n+# Tests of TensorFlow quantization ops written using the Python API.\n+\n+# buildifier: disable=same-origin-load\n+load(\"//tensorflow:tensorflow.bzl\", \"tf_py_test\")\n+\n+package(\n+    default_visibility = [\"//tensorflow:internal\"],\n+    licenses = [\"notice\"],\n+)\n+\n+tf_py_test(\n+    name = \"quantization_ops_test\",\n+    size = \"small\",\n+    srcs = [\"quantization_ops_test.py\"],\n+    deps = [\n+        \"//tensorflow/python:array_ops\",\n+        \"//tensorflow/python:client\",\n+        \"//tensorflow/python:client_testlib\",\n+        \"//tensorflow/python:framework\",\n+        \"//tensorflow/python:framework_for_generated_wrappers\",\n+        \"//tensorflow/python:math_ops\",\n+        \"//third_party/py/numpy\",\n+    ],\n+)\n",
      "@@ -0,0 +1,210 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for tf.quantize ops.\"\"\"\n+import numpy as np\n+\n+from tensorflow.python.framework import constant_op\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n+from tensorflow.python.framework import test_util\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import nn_ops\n+from tensorflow.python.platform import googletest\n+\n+\n+class FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars(\n+              inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars(\n+              inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))\n+\n+\n+class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[[0.0]], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Dimensions must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[1.0], max=[[1.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Dimensions must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel(\n+              inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n+\n+\n+class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)\n+    bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=[],\n+              max_input=1.0,\n+              min_bias=0.0,\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=[],\n+              min_bias=0.0,\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=1.0,\n+              min_bias=[],\n+              max_bias=1.0,\n+              out_type=dtypes.qint32))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_bias_add(\n+              input=inputs,\n+              bias=bias,\n+              min_input=0.0,\n+              max_input=1.0,\n+              min_bias=0.0,\n+              max_bias=[],\n+              out_type=dtypes.qint32))\n+\n+\n+class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.quantized_instance_norm(\n+              x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.quantized_instance_norm(\n+              x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))\n+\n+\n+class RequantizeOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=[],\n+              input_max=1.0,\n+              requested_output_min=0.0,\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=[],\n+              requested_output_min=0.0,\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=1.0,\n+              requested_output_min=[],\n+              requested_output_max=1.0,\n+              out_type=dtypes.qint8))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.requantize(\n+              input=inputs,\n+              input_min=0.0,\n+              input_max=1.0,\n+              requested_output_min=0.0,\n+              requested_output_max=[],\n+              out_type=dtypes.qint8))\n+\n+\n+if __name__ == \"__main__\":\n+  googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-g35r-369w-3fqp",
    "API Signature": "tf.raw_ops.QuantizedInstanceNorm(\n    x,\n    x_min,\n    x_max,\n    output_range_given=False,\n    given_y_min=0,\n    given_y_max=0,\n    variance_epsilon=1e-05,\n    min_separation=0.001,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "x_min = tf.constant([], shape=[0], dtype=tf.float32)\nx_max = tf.constant(0, shape=[], dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK` fail in `Conv2DBackpropInput`\n      ",
    "Bug description": "The implementation of  Conv2DBackpropInput  requires  input_sizes  to be 4-dimensional. Otherwise, it gives a  CHECK  failure which can be used to trigger a denial of service attack:",
    "Sample Code": "strides = [1, 1, 1, 1]\npadding = \"SAME\"\nuse_cudnn_on_gpu = True\nexplicit_paddings = []\ndata_format = \"NHWC\"\ndilations = [1, 1, 1, 1]\ninput_sizes = tf.constant([65534,65534], shape=[2], dtype=tf.int32)\nfilter = tf.constant(0.159749106, shape=[3,3,2,2], dtype=tf.float32)\nout_backprop = tf.constant(0, shape=[], dtype=tf.float32)\n)\ntf.raw_ops.Conv2DBackpropInput(input_sizes=input_sizes, filter=filter, out_backprop=out_backprop, strides=strides, padding=padding, use_cudnn_on_gpu=use_cudnn_on_gpu, explicit_paddings=explicit_paddings, data_format=data_format, dilations=dilations)",
    "Code change": [
      "@@ -422,6 +422,11 @@ class Conv2DBackpropInputOp : public OpKernel {\n     const Tensor& filter = context->input(1);\n     const Tensor& out_backprop = context->input(2);\n \n+    OP_REQUIRES(\n+        context, out_backprop.dims() == 4,\n+        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",\n+                                out_backprop.dims()));\n+\n     TensorShape input_shape;\n     OP_REQUIRES_OK(context,\n                    Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),\n@@ -527,6 +532,10 @@ class Conv2DCustomBackpropInputOp : public OpKernel {\n     const Tensor& input_sizes = context->input(0);\n     const Tensor& filter = context->input(1);\n     const Tensor& out_backprop = context->input(2);\n+    OP_REQUIRES(\n+        context, out_backprop.dims() == 4,\n+        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",\n+                                out_backprop.dims()));\n \n     TensorShape input_shape;\n     OP_REQUIRES_OK(context,\n",
      "@@ -32,6 +32,7 @@ from tensorflow.python.framework import test_util\n from tensorflow.python.layers import convolutional\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_nn_ops\n from tensorflow.python.ops import gradient_checker\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import math_ops\n@@ -1319,7 +1320,7 @@ class Conv2DTest(test.TestCase):\n     x2 = self._CreateNumpyTensor(filter_sizes)\n     default_dilations = (dilations[0] == 1 and dilations[1] == 1)\n     if default_dilations or use_gpu:\n-      with self.cached_session(use_gpu=use_gpu) as sess:\n+      with self.cached_session(use_gpu=use_gpu):\n         if data_format == \"NCHW\":\n           input_sizes = test_util.NHWCToNCHW(input_sizes)\n         t1 = constant_op.constant(x1, shape=input_sizes)\n@@ -1365,7 +1366,7 @@ class Conv2DTest(test.TestCase):\n     x2 = self._CreateNumpyTensor(filter_sizes)\n     default_dilations = (dilations[0] == 1 and dilations[1] == 1)\n     if default_dilations or use_gpu:\n-      with self.cached_session(use_gpu=use_gpu) as sess:\n+      with self.cached_session(use_gpu=use_gpu):\n         if data_format == \"NCHW\":\n           input_sizes = test_util.NHWCToNCHW(input_sizes)\n         t1 = constant_op.constant(x1, shape=input_sizes)\n@@ -2628,6 +2629,27 @@ class Conv2DTest(test.TestCase):\n               strides=[1, 1, 1, 1],\n               padding=[[0, 0], [-1, 0], [0, 0], [0, 0]]))\n \n+  def testConv2DBackpropInputInvalidOutBackpropRaiseError(self):\n+    with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n+      with self.cached_session():\n+        input_sizes = constant_op.constant([65534, 65534],\n+                                           shape=[2],\n+                                           dtype=dtypes.int32)\n+        filters = constant_op.constant(\n+            0.159749106, shape=[3, 3, 2, 2], dtype=dtypes.float32)\n+        out_backprop = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+        t = gen_nn_ops.conv2d_backprop_input(\n+            input_sizes=input_sizes,\n+            filter=filters,\n+            out_backprop=out_backprop,\n+            strides=[1, 1, 1, 1],\n+            padding=\"SAME\",\n+            use_cudnn_on_gpu=True,\n+            explicit_paddings=[],\n+            data_format=\"NHWC\",\n+            dilations=[1, 1, 1, 1])\n+        self.evaluate(t)\n+\n \n @test_util.run_all_without_tensor_float_32(\"Avoid TF32 conv on GPU\")\n class DepthwiseConv2DTest(test.TestCase):\n@@ -2655,7 +2677,7 @@ class DepthwiseConv2DTest(test.TestCase):\n     # numbers from 1.\n     x1 = [f * 1.0 for f in range(1, total_size_1 + 1)]\n     x2 = [f * 1.0 for f in range(1, total_size_2 + 1)]\n-    with self.cached_session() as sess:\n+    with self.cached_session():\n       t1 = constant_op.constant(x1, shape=tensor_in_sizes)\n       t1.set_shape(tensor_in_sizes)\n       t2 = constant_op.constant(x2, shape=filter_in_sizes)\n@@ -2926,7 +2948,7 @@ class DeepConv2DTest(test.TestCase):\n     x1 = np.random.rand(*tensor_in_sizes).astype(np.float32)\n     x2 = np.random.rand(*filter_in_sizes).astype(np.float32)\n \n-    with self.cached_session(use_gpu=False) as sess:\n+    with self.cached_session(use_gpu=False):\n       t1 = constant_op.constant(x1, shape=tensor_in_sizes)\n       t2 = constant_op.constant(x2, shape=filter_in_sizes)\n       strides = [1] + conv_strides + [1]\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-q2c3-jpmc-gfjx",
    "API Signature": "tf.raw_ops.Conv2DBackpropInput(\n    input_sizes,\n    filter,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "input_sizes = tf.constant([65534,65534], shape=[2], dtype=tf.int32)"
  },
  {
    "Title": "\n        `CHECK` fail in `AvgPoolGrad`\n      ",
    "Bug description": "The implementation of  AvgPoolGrad  does not fully validate the input  orig_input_shape . This results in a  CHECK  failure which can be used to trigger a denial of service attack:",
    "Sample Code": "ksize = [1, 2, 2, 1]\nstrides = [1, 2, 2, 1]\npadding = \"VALID\"\ndata_format = \"NHWC\"\norig_input_shape = tf.constant(-536870912, shape=[4], dtype=tf.int32)\ngrad = tf.constant(.0890338004362538, shape=[1,5,7,1], dtype=tf.float64)\n)\ntf.raw_ops.AvgPoolGrad(orig_input_shape=orig_input_shape, grad=grad, ksize=ksize, strides=strides, padding=padding, data_format=data_format)",
    "Code change": [
      "@@ -298,7 +298,7 @@ class AvgPoolingGradOp : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n     const int64_t in_rows = output_shape.dim_size(1);\n     const int64_t in_cols = output_shape.dim_size(2);\n@@ -457,7 +457,7 @@ class AvgPoolingGradOp<GPUDevice, T> : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n \n     if (output_shape.num_elements() == 0) {\n@@ -543,7 +543,7 @@ class AvgPoolingGradOpCustomGPUKernel : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n     if (output_shape.num_elements() == 0) {\n       Tensor* output = nullptr;\n",
      "@@ -2470,6 +2470,22 @@ class PoolingTest(test.TestCase, parameterized.TestCase):\n               inp, grad, argmax, ksize=[1, 1, 1, 1], strides=[1, 1, 1, 1],\n               padding=\"VALID\")\n \n+  def testAvgPoolGradInvalidInputShapeRaiseError(self):\n+    with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n+      with self.cached_session():\n+        orig_input_shape = constant_op.constant(\n+            -536870912, shape=[4], dtype=dtypes.int32)\n+        grad = constant_op.constant(\n+            .0890338004362538, shape=[1, 5, 7, 1], dtype=dtypes.float64)\n+        t = gen_nn_ops.AvgPoolGrad(\n+            orig_input_shape=orig_input_shape,\n+            grad=grad,\n+            ksize=[1, 2, 2, 1],\n+            strides=[1, 2, 2, 1],\n+            padding=\"VALID\",\n+            data_format=\"NHWC\")\n+        self.evaluate(t)\n+\n \n def GetMaxPoolFwdTest(input_size, filter_size, strides, padding):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2475-53vw-vp25",
    "API Signature": "tf.raw_ops.AvgPoolGrad(\n    orig_input_shape,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NHWC',\n    name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Negative input tensor",
    "Category": "Tensor",
    "Argument": "orig_input_shape = tf.constant(-536870912, shape=[4], dtype=tf.int32)"
  },
  {
    "Title": "\n        Segfault in `QuantizedAdd`\n      ",
    "Bug description": "If  QuantizedAdd  is given  min_input  or  max_input  tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "Toutput = tf.qint32\nx = tf.constant(140, shape=[1], dtype=tf.quint8)\ny = tf.constant(26, shape=[10], dtype=tf.quint8)\nmin_x = tf.constant([], shape=[0], dtype=tf.float32)\nmax_x = tf.constant(0, shape=[], dtype=tf.float32)\nmin_y = tf.constant(0, shape=[], dtype=tf.float32)\nmax_y = tf.constant(0, shape=[], dtype=tf.float32)\n)\ntf.raw_ops.QuantizedAdd(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y, Toutput=Toutput)",
    "Code change": [
      "@@ -32,8 +32,21 @@ class QuantizedReluOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -65,8 +78,21 @@ class QuantizedRelu6Op : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n",
      "@@ -55,8 +55,8 @@ TEST_F(QuantizedActivationsTest, TestRelu) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -86,8 +86,8 @@ TEST_F(QuantizedActivationsTest, TestRelu6) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
      "@@ -25,6 +25,7 @@ limitations under the License.\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n@@ -457,10 +458,28 @@ class QuantizedAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& x = context->input(0);\n     const Tensor& y = context->input(1);\n-    const float min_x = context->input(2).flat<float>()(0);\n-    const float max_x = context->input(3).flat<float>()(0);\n-    const float min_y = context->input(4).flat<float>()(0);\n-    const float max_y = context->input(5).flat<float>()(0);\n+    const Tensor& min_x_tensor = context->input(2);\n+    const Tensor& max_x_tensor = context->input(3);\n+    const Tensor& min_y_tensor = context->input(4);\n+    const Tensor& max_y_tensor = context->input(5);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),\n+                errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",\n+                                        min_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),\n+                errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",\n+                                        max_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),\n+                errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",\n+                                        min_y_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),\n+                errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",\n+                                        max_y_tensor.dims()));\n+\n+    const float min_x = min_x_tensor.scalar<float>()();\n+    const float max_x = max_x_tensor.scalar<float>()();\n+    const float min_y = min_y_tensor.scalar<float>()();\n+    const float max_y = max_y_tensor.scalar<float>()();\n \n     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n     if (!bcast.IsValid()) {\n",
      "@@ -206,5 +206,60 @@ class RequantizeOpTest(test_util.TensorFlowTestCase):\n               out_type=dtypes.qint8))\n \n \n+class QuantizedAddOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    x = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.quantized_add(\n+              x=x,\n+              y=y,\n+              min_x=[],\n+              max_x=1.0,\n+              min_y=0.0,\n+              max_y=1.0,\n+              Toutput=dtypes.qint32))\n+\n+\n+class QuantizedReluOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n+class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu6(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v6h3-348g-6h5x",
    "API Signature": "tf.raw_ops.QuantizedAdd(\n    x,\n    y,\n    min_x,\n    max_x,\n    min_y,\n    max_y,\n    Toutput=tf.dtypes.qint32,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "min_x = tf.constant([], shape=[0], dtype=tf.float32)\nmax_x = tf.constant(0, shape=[], dtype=tf.float32)\nmin_y = tf.constant(0, shape=[], dtype=tf.float32)\nmax_y = tf.constant(0, shape=[], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `QuantizedAvgPool`\n      ",
    "Bug description": "If  QuantizedAvgPool  is given  min_input  or  max_input  tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "ksize = [1, 2, 2, 1]\nstrides = [1, 2, 2, 1]\npadding = \"SAME\"\ninput = tf.constant(1, shape=[1,4,4,2], dtype=tf.quint8)\nmin_input = tf.constant([], shape=[0], dtype=tf.float32)\nmax_input = tf.constant(0, shape=[1], dtype=tf.float32)\n)\ntf.raw_ops.QuantizedAvgPool(input=input, min_input=min_input, max_input=max_input, ksize=ksize, strides=strides, padding=padding)",
    "Code change": [
      "@@ -15,18 +15,18 @@ limitations under the License.\n \n // See docs in ../ops/nn_ops.cc.\n \n-#include \"tensorflow/core/framework/op_requires.h\"\n-#include \"tensorflow/core/platform/errors.h\"\n #define EIGEN_USE_THREADS\n \n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/ops_util.h\"\n #include \"tensorflow/core/kernels/pooling_ops_common.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/util/padding.h\"\n #include \"tensorflow/core/util/tensor_format.h\"\n@@ -67,8 +67,20 @@ class QuantizedAvgPoolingOp : public OpKernel {\n       return;\n     }\n \n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+                errors::InvalidArgument(\n+                    \"min_input shape must be rank 0 but is rank \",\n+                    min_input_tensor.dims(),\n+                    \", received shape: \", min_input_tensor.shape()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+                errors::InvalidArgument(\n+                    \"max_input shape must be rank 0 but is rank \",\n+                    max_input_tensor.dims(),\n+                    \", received shape: \", max_input_tensor.shape()));\n+    const float min_input = context->input(1).scalar<float>()();\n+    const float max_input = context->input(2).scalar<float>()();\n \n     OP_REQUIRES(context, params.depth_window == 1,\n                 errors::Unimplemented(\"Non-spatial pooling is not \"\n@@ -119,20 +131,20 @@ class QuantizedMaxPoolingOp : public MaxPoolingOp<Device, T> {\n       : MaxPoolingOp<Device, T>(context) {}\n \n   void Compute(OpKernelContext* context) override {\n-    auto min_input_tensor = context->input(1);\n-    auto max_input_tensor = context->input(2);\n-    OP_REQUIRES(\n-        context, min_input_tensor.NumElements() == 1,\n-        errors::InvalidArgument(\n-            \"min_input must be a scalar float value, got tensor with shape \",\n-            min_input_tensor.shape()));\n-    OP_REQUIRES(\n-        context, max_input_tensor.NumElements() == 1,\n-        errors::InvalidArgument(\n-            \"max_input must be a scalar float value, got tensor with shape \",\n-            max_input_tensor.shape()));\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+                errors::InvalidArgument(\n+                    \"min_input shape must be rank 0 but is rank \",\n+                    min_input_tensor.dims(),\n+                    \", received shape: \", min_input_tensor.shape()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+                errors::InvalidArgument(\n+                    \"max_input shape must be rank 0 but is rank \",\n+                    max_input_tensor.dims(),\n+                    \", received shape: \", max_input_tensor.shape()));\n+    const float min_input = context->input(1).scalar<float>()();\n+    const float max_input = context->input(2).scalar<float>()();\n     MaxPoolingOp<Device, T>::Compute(context);\n     Tensor* output_min = nullptr;\n     OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));\n",
      "@@ -69,8 +69,8 @@ TEST_F(QuantizedPoolingTest, SmallAveragePooling) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -114,8 +114,8 @@ TEST_F(QuantizedPoolingTest, SmallMaxPooling) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
      "@@ -154,6 +154,72 @@ class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):\n               x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))\n \n \n+class QuantizedAvgPoolingOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+    ksize = [1, 1, 1, 1]\n+    strides = [1, 1, 1, 1]\n+    padding = \"SAME\"\n+\n+    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n+                                \"must be.* rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_avg_pool(\n+              input=inputs,\n+              min_input=[],\n+              max_input=1.0,\n+              ksize=ksize,\n+              strides=strides,\n+              padding=padding))\n+\n+    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n+                                \"must be.* rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_avg_pool(\n+              input=inputs,\n+              min_input=0.0,\n+              max_input=[],\n+              ksize=ksize,\n+              strides=strides,\n+              padding=padding))\n+\n+\n+class QuantizedMaxPoolingOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+    ksize = [1, 1, 1, 1]\n+    strides = [1, 1, 1, 1]\n+    padding = \"SAME\"\n+\n+    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n+                                \"must be.* rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_max_pool(\n+              input=inputs,\n+              min_input=[],\n+              max_input=1.0,\n+              ksize=ksize,\n+              strides=strides,\n+              padding=padding))\n+\n+    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n+                                \"must be.* rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_max_pool(\n+              input=inputs,\n+              min_input=0.0,\n+              max_input=[],\n+              ksize=ksize,\n+              strides=strides,\n+              padding=padding))\n+\n+\n class RequantizeOpTest(test_util.TensorFlowTestCase):\n \n   @test_util.run_in_graph_and_eager_modes\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4w68-4x85-mjj9",
    "API Signature": "tf.raw_ops.QuantizedAvgPool(\n    input, min_input, max_input, ksize, strides, padding, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "min_input = tf.constant([], shape=[0], dtype=tf.float32)\nmax_input = tf.constant(0, shape=[1], dtype=tf.float32"
  },
  {
    "Title": "\n        Segfault in `LowerBound` and `UpperBound`\n      ",
    "Bug description": "If  LowerBound  or  UpperBound  is given an empty sorted_inputs  input, it results in a  nullptr  dereference, leading to a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.int64\nsorted_inputs = tf.constant([], shape=[2,2,0,0,0,0,0,2], dtype=tf.float32)\nvalues = tf.constant(0.372660398, shape=[2,4], dtype=tf.float32)\n)\ntf.raw_ops.UpperBound(sorted_inputs=sorted_inputs, values=values, out_type=out_type)",
    "Code change": [
      "@@ -22,6 +22,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/kernels/fill_functor.h\"\n #include \"tensorflow/core/lib/core/bits.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/threadpool.h\"\n@@ -129,6 +130,14 @@ class UpperBoundOp : public OpKernel {\n     auto output = output_t->template flat<OutType>();\n     const auto sorted_inputs = sorted_inputs_t.template flat<T>();\n     const auto values = values_t.template flat<T>();\n+\n+    // For empty inputs, all values will be placed at the zeroth position.\n+    if (sorted_inputs.size() == 0) {\n+      functor::SetZeroFunctor<Device, OutType> set_zero;\n+      set_zero(ctx->eigen_device<Device>(), output);\n+      return;\n+    }\n+\n     OP_REQUIRES_OK(\n         ctx, functor::UpperBoundFunctor<Device, T, OutType>::Compute(\n                  ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),\n@@ -174,6 +183,14 @@ class LowerBoundOp : public OpKernel {\n     auto output = output_t->template flat<OutType>();\n     const auto sorted_inputs = sorted_inputs_t.template flat<T>();\n     const auto values = values_t.template flat<T>();\n+\n+    // For empty inputs, all values will be placed at the zeroth position.\n+    if (sorted_inputs.size() == 0) {\n+      functor::SetZeroFunctor<Device, OutType> set_zero;\n+      set_zero(ctx->eigen_device<Device>(), output);\n+      return;\n+    }\n+\n     OP_REQUIRES_OK(\n         ctx, functor::LowerBoundFunctor<Device, T, OutType>::Compute(\n                  ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),\n",
      "@@ -2060,6 +2060,17 @@ class SortedSearchTest(test_util.TensorFlowTestCase):\n                 side=side,\n                 out_type=dtype), array_ops.zeros([2, 0], dtype))\n \n+  def testZeroInputSize(self):\n+    dtype = dtypes.int32\n+    for side in (\"left\", \"right\"):\n+      with self.subTest(side=side):\n+        self.assertAllEqual(\n+            array_ops.searchsorted(\n+                array_ops.ones([2, 0]),\n+                array_ops.ones([2, 3]),\n+                side=side,\n+                out_type=dtype), array_ops.zeros([2, 3], dtype))\n+\n   def testInt64(self):\n \n     @def_function.function\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qxpx-j395-pw36",
    "API Signature": "tf.raw_ops.LowerBound(\n    sorted_inputs,\n    values,\n    out_type=tf.dtypes.int32,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "sorted_inputs = tf.constant([], shape=[10,0], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `LowerBound` and `UpperBound`\n      ",
    "Bug description": "If  LowerBound  or  UpperBound  is given an empty sorted_inputs  input, it results in a  nullptr  dereference, leading to a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.int64\nsorted_inputs = tf.constant([], shape=[2,2,0,0,0,0,0,2], dtype=tf.float32)\nvalues = tf.constant(0.372660398, shape=[2,4], dtype=tf.float32)\n)\ntf.raw_ops.UpperBound(sorted_inputs=sorted_inputs, values=values, out_type=out_type)",
    "Code change": [
      "@@ -22,6 +22,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/kernels/fill_functor.h\"\n #include \"tensorflow/core/lib/core/bits.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/threadpool.h\"\n@@ -129,6 +130,14 @@ class UpperBoundOp : public OpKernel {\n     auto output = output_t->template flat<OutType>();\n     const auto sorted_inputs = sorted_inputs_t.template flat<T>();\n     const auto values = values_t.template flat<T>();\n+\n+    // For empty inputs, all values will be placed at the zeroth position.\n+    if (sorted_inputs.size() == 0) {\n+      functor::SetZeroFunctor<Device, OutType> set_zero;\n+      set_zero(ctx->eigen_device<Device>(), output);\n+      return;\n+    }\n+\n     OP_REQUIRES_OK(\n         ctx, functor::UpperBoundFunctor<Device, T, OutType>::Compute(\n                  ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),\n@@ -174,6 +183,14 @@ class LowerBoundOp : public OpKernel {\n     auto output = output_t->template flat<OutType>();\n     const auto sorted_inputs = sorted_inputs_t.template flat<T>();\n     const auto values = values_t.template flat<T>();\n+\n+    // For empty inputs, all values will be placed at the zeroth position.\n+    if (sorted_inputs.size() == 0) {\n+      functor::SetZeroFunctor<Device, OutType> set_zero;\n+      set_zero(ctx->eigen_device<Device>(), output);\n+      return;\n+    }\n+\n     OP_REQUIRES_OK(\n         ctx, functor::LowerBoundFunctor<Device, T, OutType>::Compute(\n                  ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),\n",
      "@@ -2060,6 +2060,17 @@ class SortedSearchTest(test_util.TensorFlowTestCase):\n                 side=side,\n                 out_type=dtype), array_ops.zeros([2, 0], dtype))\n \n+  def testZeroInputSize(self):\n+    dtype = dtypes.int32\n+    for side in (\"left\", \"right\"):\n+      with self.subTest(side=side):\n+        self.assertAllEqual(\n+            array_ops.searchsorted(\n+                array_ops.ones([2, 0]),\n+                array_ops.ones([2, 3]),\n+                side=side,\n+                out_type=dtype), array_ops.zeros([2, 3], dtype))\n+\n   def testInt64(self):\n \n     @def_function.function\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qxpx-j395-pw36",
    "API Signature": "tf.raw_ops.UpperBound(\n    sorted_inputs,\n    values,\n    out_type=tf.dtypes.int32,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "sorted_inputs = tf.constant([], shape=[2,2,0,0,0,0,0,2], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `BlockLSTMGradV2`\n      ",
    "Bug description": "The implementation of  BlockLSTMGradV2  does not fully validate its inputs.",
    "Sample Code": "use_peephole = False\nseq_len_max = tf.constant(1, shape=[], dtype=tf.int64)\nx = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\ncs_prev = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nh_prev = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nw = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nwci = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nwcf = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nwco = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nb = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\ni = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\ncs = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nf = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\no = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nci = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nco = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nh = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\ncs_grad = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nh_grad = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\n)\ntf.raw_ops.BlockLSTMGradV2(seq_len_max=seq_len_max, x=x, cs_prev=cs_prev, h_prev=h_prev, w=w, wci=wci, wcf=wcf, wco=wco, b=b, i=i, cs=cs, f=f, o=o, ci=ci, co=co, h=h, cs_grad=cs_grad, h_grad=h_grad, use_peephole=use_peephole)",
    "Code change": [
      "@@ -1138,19 +1138,30 @@ class BlockLSTMGradOp : public OpKernel {\n \n     const Tensor* x;\n     OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x));\n-    OP_REQUIRES(ctx, x->dims() == 3, errors::InvalidArgument(\"x must be 3D\"));\n+    OP_REQUIRES(\n+        ctx, x->dims() == 3,\n+        errors::InvalidArgument(\"x must be rank 3 but is rank \", x->dims()));\n     const int64_t timelen = x->dim_size(0);\n     const int64_t batch_size = x->dim_size(1);\n     const int64_t input_size = x->dim_size(2);\n \n     const Tensor* cs_prev_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));\n+    OP_REQUIRES(ctx, cs_prev_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_prev must be rank 2 but is rank \",\n+                                        cs_prev_tensor->dims()));\n \n     const Tensor* h_prev_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));\n+    OP_REQUIRES(ctx, h_prev_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_prev must be rank 2 but is rank \",\n+                                        h_prev_tensor->dims()));\n \n     const Tensor* w_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w must be rank 2 but is rank \",\n+                                        w_tensor->dims()));\n     const int64_t cell_size = w_tensor->dim_size(1) / 4;\n     OP_REQUIRES(ctx, input_size + cell_size == w_tensor->dim_size(0),\n                 errors::InvalidArgument(\n@@ -1159,15 +1170,27 @@ class BlockLSTMGradOp : public OpKernel {\n \n     const Tensor* wci_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));\n+    OP_REQUIRES(ctx, wci_tensor->dims() == 1,\n+                errors::InvalidArgument(\"wci must be rank 1 but is rank \",\n+                                        wci_tensor->dims()));\n \n     const Tensor* wcf_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));\n+    OP_REQUIRES(ctx, wcf_tensor->dims() == 1,\n+                errors::InvalidArgument(\"wcf must be rank 1 but is rank \",\n+                                        wcf_tensor->dims()));\n \n     const Tensor* wco_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"wco\", &wco_tensor));\n+    OP_REQUIRES(ctx, wco_tensor->dims() == 1,\n+                errors::InvalidArgument(\"wco must be rank 1 but is rank \",\n+                                        wco_tensor->dims()));\n \n     const Tensor* b_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"b\", &b_tensor));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b must be rank 1 but is rank \",\n+                                        b_tensor->dims()));\n     OP_REQUIRES(\n         ctx, cell_size == b_tensor->dim_size(0) / 4,\n         errors::InvalidArgument(\"w and b cell_size don't match: \", cell_size,\n",
      "@@ -1354,6 +1354,58 @@ class LSTMTest(test.TestCase):\n               cell_clip=cell_clip,\n               use_peephole=use_peephole))\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellGradErrorHandling(self):\n+    use_peephole = False\n+    seq_len_max = constant_op.constant(1, shape=[], dtype=dtypes.int64)\n+    x = constant_op.constant(0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.504355371, shape=[1, 1], dtype=dtypes.float32)\n+    w = constant_op.constant(0.504355371, shape=[1, 1], dtype=dtypes.float32)\n+    wci = constant_op.constant(0.504355371, shape=[1], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0.504355371, shape=[1], dtype=dtypes.float32)\n+    wco = constant_op.constant(0.504355371, shape=[1], dtype=dtypes.float32)\n+    b = constant_op.constant(0.504355371, shape=[1], dtype=dtypes.float32)\n+    i = constant_op.constant(0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    cs = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    f = constant_op.constant(0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    o = constant_op.constant(0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    ci = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    co = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    h = constant_op.constant(0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    cs_grad = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    h_grad = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                \"must be rank\"):\n+      self.evaluate(\n+          gen_rnn_ops.block_lstm_grad_v2(\n+              seq_len_max=seq_len_max,\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              i=i,\n+              cs=cs,\n+              f=f,\n+              o=o,\n+              ci=ci,\n+              co=co,\n+              h=h,\n+              cs_grad=cs_grad,\n+              h_grad=h_grad,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-f7r5-q7cx-h668",
    "API Signature": "tf.raw_ops.BlockLSTMGradV2(\n    seq_len_max,\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    i,\n    cs,\n    f,\n    o,\n    ci,\n    co,\n    h,\n    cs_grad,\n    h_grad,\n    use_peephole,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "wci = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nwcf = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nwco = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nb = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK` failures in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation of  FractionalAvgPoolGrad  does not fully validate the input  orig_input_tensor_shape . This results in an overflow that results in a   CHECK  failure which can be used to trigger a denial of service attack.",
    "Sample Code": "overlapping = True\norig_input_tensor_shape = tf.constant(-1879048192, shape=[4], dtype=tf.int64)\nout_backprop = tf.constant([], shape=[0,0,0,0], dtype=tf.float64)\nrow_pooling_sequence = tf.constant(1, shape=[4], dtype=tf.int64)\ncol_pooling_sequence = tf.constant(1, shape=[4], dtype=tf.int64)\n)\ntf.raw_ops.FractionalAvgPoolGrad(orig_input_tensor_shape=orig_input_tensor_shape, out_backprop=out_backprop, row_pooling_sequence=row_pooling_sequence, col_pooling_sequence=col_pooling_sequence, overlapping=overlapping)",
    "Code change": [
      "@@ -12,6 +12,7 @@ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n+\n #define EIGEN_USE_THREADS\n \n #include <algorithm>\n@@ -19,15 +20,15 @@ limitations under the License.\n #include <random>\n #include <vector>\n \n-#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n-\n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n #include \"tensorflow/core/lib/random/random.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n #include \"tensorflow/core/util/guarded_philox_random.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n typedef Eigen::ThreadPoolDevice CPUDevice;\n@@ -241,7 +242,32 @@ class FractionalAvgPoolGradOp : public OpKernel {\n                     orig_input_tensor_shape.NumElements() == 4,\n                 errors::InvalidArgument(\"original input tensor shape must be\"\n                                         \"1-dimensional and 4 elements\"));\n+    int64_t num_elements = 1;\n+    for (int i = 0; i < orig_input_tensor_shape.dims(); i++) {\n+      OP_REQUIRES(context, orig_input_tensor_shape.dim_size(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"orig_input_tensor_shape must be positive, got: \",\n+                      orig_input_tensor_shape.dim_size(i)));\n+      num_elements = MultiplyWithoutOverflow(\n+          num_elements, orig_input_tensor_shape.dim_size(i));\n+      OP_REQUIRES(\n+          context, num_elements > 0,\n+          errors::InvalidArgument(\n+              \"The total elements specified by orig_input_tensor_shape\",\n+              \" is too large. Encountered overflow after multiplying \",\n+              orig_input_tensor_shape.dim_size(i), \", result: \", num_elements));\n+    }\n+\n     const Tensor& out_backprop = context->input(1);\n+    OP_REQUIRES(context, out_backprop.dims() == 4,\n+                errors::InvalidArgument(\"out_backprop must be 4-dimensional\"));\n+    for (int i = 0; i < out_backprop.dims(); i++) {\n+      OP_REQUIRES(context, out_backprop.dim_size(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"out_backprop must be positive for all dimension, got:\",\n+                      out_backprop.dim_size(i)));\n+    }\n+\n     const Tensor& row_seq_tensor = context->input(2);\n     const Tensor& col_seq_tensor = context->input(3);\n \n",
      "@@ -541,6 +541,27 @@ class FractionalAvgPoolGradTest(test.TestCase):\n           delta=1e-2)\n       self.assertLess(gradient_error, error_margin)\n \n+  def testInvalidSeqRaiseErrorForFractionalAvgPoolGrad(self):\n+    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n+      with self.cached_session() as _:\n+        overlapping = True\n+        orig_input_tensor_shape = constant_op.constant(\n+            -1879048192, shape=[4], dtype=dtypes.int64)\n+        out_backprop = constant_op.constant([],\n+                                            shape=[0, 0, 0, 0],\n+                                            dtype=dtypes.float64)\n+        row_pooling_sequence = constant_op.constant(\n+            1, shape=[4], dtype=dtypes.int64)\n+        col_pooling_sequence = constant_op.constant(\n+            1, shape=[4], dtype=dtypes.int64)\n+        t = gen_nn_ops.fractional_avg_pool_grad(\n+            orig_input_tensor_shape=orig_input_tensor_shape,\n+            out_backprop=out_backprop,\n+            row_pooling_sequence=row_pooling_sequence,\n+            col_pooling_sequence=col_pooling_sequence,\n+            overlapping=overlapping)\n+        self.evaluate(t)\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-84jm-4cf3-9jfm",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Negative input tensor",
    "Category": "Tensor",
    "Argument": "orig_input_tensor_shape = tf.constant(-1879048192, shape=[4], dtype=tf.int64)"
  },
  {
    "Title": "\n        `CHECK` failures in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation of  FractionalAvgPoolGrad  does not fully validate the input  orig_input_tensor_shape . This results in an overflow that results in a   CHECK  failure which can be used to trigger a denial of service attack.",
    "Sample Code": "overlapping = True\norig_input_tensor_shape = tf.constant(-1879048192, shape=[4], dtype=tf.int64)\nout_backprop = tf.constant([], shape=[0,0,0,0], dtype=tf.float64)\nrow_pooling_sequence = tf.constant(1, shape=[4], dtype=tf.int64)\ncol_pooling_sequence = tf.constant(1, shape=[4], dtype=tf.int64)\n)\ntf.raw_ops.FractionalAvgPoolGrad(orig_input_tensor_shape=orig_input_tensor_shape, out_backprop=out_backprop, row_pooling_sequence=row_pooling_sequence, col_pooling_sequence=col_pooling_sequence, overlapping=overlapping)",
    "Code change": [
      "@@ -12,6 +12,7 @@ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n+\n #define EIGEN_USE_THREADS\n \n #include <algorithm>\n@@ -19,15 +20,15 @@ limitations under the License.\n #include <random>\n #include <vector>\n \n-#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n-\n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n #include \"tensorflow/core/lib/random/random.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n #include \"tensorflow/core/util/guarded_philox_random.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n typedef Eigen::ThreadPoolDevice CPUDevice;\n@@ -241,7 +242,32 @@ class FractionalAvgPoolGradOp : public OpKernel {\n                     orig_input_tensor_shape.NumElements() == 4,\n                 errors::InvalidArgument(\"original input tensor shape must be\"\n                                         \"1-dimensional and 4 elements\"));\n+    int64_t num_elements = 1;\n+    for (int i = 0; i < orig_input_tensor_shape.dims(); i++) {\n+      OP_REQUIRES(context, orig_input_tensor_shape.dim_size(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"orig_input_tensor_shape must be positive, got: \",\n+                      orig_input_tensor_shape.dim_size(i)));\n+      num_elements = MultiplyWithoutOverflow(\n+          num_elements, orig_input_tensor_shape.dim_size(i));\n+      OP_REQUIRES(\n+          context, num_elements > 0,\n+          errors::InvalidArgument(\n+              \"The total elements specified by orig_input_tensor_shape\",\n+              \" is too large. Encountered overflow after multiplying \",\n+              orig_input_tensor_shape.dim_size(i), \", result: \", num_elements));\n+    }\n+\n     const Tensor& out_backprop = context->input(1);\n+    OP_REQUIRES(context, out_backprop.dims() == 4,\n+                errors::InvalidArgument(\"out_backprop must be 4-dimensional\"));\n+    for (int i = 0; i < out_backprop.dims(); i++) {\n+      OP_REQUIRES(context, out_backprop.dim_size(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"out_backprop must be positive for all dimension, got:\",\n+                      out_backprop.dim_size(i)));\n+    }\n+\n     const Tensor& row_seq_tensor = context->input(2);\n     const Tensor& col_seq_tensor = context->input(3);\n \n",
      "@@ -541,6 +541,27 @@ class FractionalAvgPoolGradTest(test.TestCase):\n           delta=1e-2)\n       self.assertLess(gradient_error, error_margin)\n \n+  def testInvalidSeqRaiseErrorForFractionalAvgPoolGrad(self):\n+    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n+      with self.cached_session() as _:\n+        overlapping = True\n+        orig_input_tensor_shape = constant_op.constant(\n+            -1879048192, shape=[4], dtype=dtypes.int64)\n+        out_backprop = constant_op.constant([],\n+                                            shape=[0, 0, 0, 0],\n+                                            dtype=dtypes.float64)\n+        row_pooling_sequence = constant_op.constant(\n+            1, shape=[4], dtype=dtypes.int64)\n+        col_pooling_sequence = constant_op.constant(\n+            1, shape=[4], dtype=dtypes.int64)\n+        t = gen_nn_ops.fractional_avg_pool_grad(\n+            orig_input_tensor_shape=orig_input_tensor_shape,\n+            out_backprop=out_backprop,\n+            row_pooling_sequence=row_pooling_sequence,\n+            col_pooling_sequence=col_pooling_sequence,\n+            overlapping=overlapping)\n+        self.evaluate(t)\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-84jm-4cf3-9jfm",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "out_backprop = tf.constant([], shape=[0,0,0,0], dtype=tf.float64)"
  },
  {
    "Title": "\n        `CHECK` failures in `AvgPool3DGrad`\n      ",
    "Bug description": "The implementation of  AvgPool3DGradOp  does not fully validate the input  orig_input_shape . This results in an overflow that results in a   CHECK  failure which can be used to trigger a denial of service attack:",
    "Sample Code": "ksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\ndata_format = \"NDHWC\"\norig_input_shape = tf.constant(1879048192, shape=[5], dtype=tf.int32)\ngrad = tf.constant(1, shape=[1,3,2,4,2], dtype=tf.float32)\n)\ntf.raw_ops.AvgPool3DGrad(orig_input_shape=orig_input_shape, grad=grad, ksize=ksize, strides=strides, padding=padding, data_format=data_format)",
    "Code change": [
      "@@ -403,6 +403,7 @@ cc_library(\n         \"//tensorflow/compiler/xla/client:xla_builder\",\n         \"//tensorflow/compiler/xla/client:xla_computation\",\n         \"//tensorflow/compiler/xla/service:hlo\",\n+        \"//tensorflow/core/util:overflow\",\n         \"//tensorflow/core:core_cpu\",\n         \"//tensorflow/core:core_cpu_internal\",\n         \"//tensorflow/core:framework\",\n",
      "@@ -30,6 +30,7 @@ limitations under the License.\n #include \"tensorflow/compiler/xla/status_macros.h\"\n #include \"tensorflow/core/common_runtime/dma_helper.h\"\n #include \"tensorflow/core/platform/errors.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n \n@@ -443,6 +444,16 @@ Status XlaOpKernelContext::ConstantInputAsShape(int index, TensorShape* shape,\n   TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n   std::vector<int64_t> dims;\n   TF_RETURN_IF_ERROR(LiteralToInt64Vector(literal, &dims));\n+\n+  int64_t num_elements = 1;\n+  for (auto i = dims.begin(); i != dims.end(); ++i) {\n+    num_elements = MultiplyWithoutOverflow(num_elements, *i);\n+    if (num_elements < 0)\n+      return errors::InvalidArgument(\n+          \"The total elements specified by orig_input_shape is too large.\",\n+          \"Encountered overflow after multiplying\", *i,\n+          \", result: \", num_elements);\n+  }\n   *shape = TensorShape(dims);\n   return OkStatus();\n }\n",
      "@@ -523,7 +523,7 @@ class AvgPooling3dGradOp : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n \n     Tensor* output;\n",
      "@@ -500,6 +500,7 @@ cuda_py_test(\n     srcs = [\"pooling_ops_3d_test.py\"],\n     deps = [\n         \"//tensorflow/python:client_testlib\",\n+        \"//tensorflow/python:dtypes\",\n         \"//tensorflow/python:framework_for_generated_wrappers\",\n         \"//tensorflow/python:nn_grad\",\n         \"//tensorflow/python:nn_ops\",\n",
      "@@ -18,6 +18,7 @@ import numpy as np\n \n from tensorflow.python.eager import context\n from tensorflow.python.framework import constant_op\n+from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors\n from tensorflow.python.framework import errors_impl\n from tensorflow.python.framework import test_util\n@@ -67,7 +68,7 @@ class PoolingTest(test.TestCase):\n     # Initializes the input tensor with array containing incrementing\n     # numbers from 1.\n     x = [f * 1.0 for f in range(1, total_size + 1)]\n-    with self.cached_session(use_gpu=use_gpu) as sess:\n+    with self.cached_session(use_gpu=use_gpu):\n       t = constant_op.constant(x, shape=input_sizes)\n       window = [1] + list(window) + [1]\n       strides = [1] + list(strides) + [1]\n@@ -124,6 +125,23 @@ class PoolingTest(test.TestCase):\n         padding=\"SAME\",\n         expected=expected_output)\n \n+  def testMaxPool3dGrad(self):\n+    with self.assertRaises(\n+        (errors.ResourceExhaustedError, errors.InvalidArgumentError)):\n+      with self.cached_session():\n+        orig_input_shape = constant_op.constant(\n+            1879048192, shape=[5], dtype=dtypes.int32)\n+        grad = constant_op.constant(\n+            1, shape=[1, 3, 2, 4, 2], dtype=dtypes.float32)\n+        t = gen_nn_ops.AvgPool3DGrad(\n+            orig_input_shape=orig_input_shape,\n+            grad=grad,\n+            ksize=[1, 1, 1, 1, 1],\n+            strides=[1, 1, 1, 1, 1],\n+            padding=\"SAME\",\n+            data_format=\"NDHWC\")\n+        self.evaluate(t)\n+\n   def testMaxPool3dValidPadding(self):\n     expected_output = [40.0, 41.0, 42.0]\n     self._VerifyValues(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wxjj-cgcx-r3vq",
    "API Signature": "tf.raw_ops.AvgPool3DGrad(\n    orig_input_shape,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NDHWC',\n    name=None\n)\n",
    "Score": 0.014184397163120567,
    "Anomaly": "Large input tensor",
    "Category": "Tensor",
    "Argument": "orig_input_shape = tf.constant(1879048192, shape=[5], dtype=tf.int32)"
  },
  {
    "Title": "\n        `CHECK` failures in `UnbatchGradOp`\n      ",
    "Bug description": "The  UnbatchGradOp  function takes an argument  id  that is assumed to be a scalar. A nonscalar  id  can trigger a  CHECK  failure and crash the program.",
    "Sample Code": "import tensorflow as tf\n\n# batch_index's size is not 3\n\ntf.raw_ops.UnbatchGrad(original_input= tf.constant([1]),batch_index=tf.constant([[0,0], ], dtype=tf.int64),grad=tf.constant([1,]),id=tf.constant([1,], dtype=tf.int64))",
    "Code change": [
      "@@ -885,8 +885,13 @@ class UnbatchGradResource : public ResourceBase {\n     const Tensor& data_t = context->input(0);\n     const Tensor& batch_index_t = context->input(1);\n     const Tensor& grad_t = context->input(2);\n+    const Tensor& batch_key_t = context->input(3);\n \n     mutex_lock ml(mu_);\n+    if (batch_key_t.NumElements() != 1) {\n+      return errors::InvalidArgument(\"Expected `id` to be scalar. Received \",\n+                                     batch_key_t.DebugString());\n+    }\n \n     const int64_t batch_key = context->input(3).scalar<int64_t>()();\n     // Mark our tensor as available.\n@@ -902,6 +907,11 @@ class UnbatchGradResource : public ResourceBase {\n             \"batch_index is empty while the tensor isn't.\");\n       }\n       std::unordered_set<int64_t> missing_tensors;\n+      if (batch_index_t.NumElements() != batch_index_t.dim_size(0) * 3) {\n+        return errors::InvalidArgument(\n+            \"batch_index should contain \", batch_index_t.dim_size(0) * 3,\n+            \" elements. Received \", batch_index_t.NumElements());\n+      }\n       const auto batch_index =\n           batch_index_t.shaped<int64_t, 2>({batch_index_t.dim_size(0), 3});\n       for (int i = 0; i < batch_index_t.dim_size(0); ++i) {\n",
      "@@ -20,7 +20,9 @@ import numpy as np\n \n from tensorflow.core.protobuf import config_pb2\n from tensorflow.python.eager import context\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import function\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n@@ -30,6 +32,7 @@ from tensorflow.python.ops import batch_ops\n from tensorflow.python.ops import gen_batch_ops\n from tensorflow.python.ops import gen_functional_ops\n from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import random_ops\n from tensorflow.python.ops import resource_variable_ops\n from tensorflow.python.ops import script_ops\n from tensorflow.python.ops import variables\n@@ -557,6 +560,56 @@ class BatchOpsTest(test.TestCase):\n       # The thread's call should hit the timeout, and thus get 0 results.\n       self.assertEqual(len(thread_results), 0)\n \n+  def testUnbatchGradInvalidId(self):\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      self.evaluate(\n+          gen_batch_ops.unbatch_grad(\n+              original_input=constant_op.constant([1]),\n+              batch_index=constant_op.constant([\n+                  [0, 0, 0],\n+              ], dtype=dtypes.int64),\n+              grad=constant_op.constant([\n+                  1,\n+              ]),\n+              id=constant_op.constant([\n+                  1,\n+                  1,\n+              ], dtype=dtypes.int64)))\n+\n+  def testUnbatchGradInvalidBatchId(self):\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      self.evaluate(\n+          gen_batch_ops.unbatch_grad(\n+              original_input=constant_op.constant([1]),\n+              batch_index=constant_op.constant([\n+                  [0, 0],\n+              ], dtype=dtypes.int64),\n+              grad=constant_op.constant([\n+                  1,\n+              ]),\n+              id=constant_op.constant([\n+                  1,\n+              ], dtype=dtypes.int64)))\n+\n+  def testUnbatchGradInvalidArgs(self):\n+    original_input = random_ops.random_uniform(\n+        shape=(3, 1), dtype=dtypes.float64, maxval=None)\n+    batch_index = random_ops.random_uniform(\n+        shape=(3, 1), dtype=dtypes.int64, maxval=65536)\n+    grad = random_ops.random_uniform(\n+        shape=(3, 1), dtype=dtypes.float64, maxval=None)\n+    batch_id = random_ops.random_uniform(\n+        shape=(3, 1), dtype=dtypes.int64, maxval=65536)\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      self.evaluate(\n+          gen_batch_ops.unbatch_grad(\n+              original_input=original_input,\n+              batch_index=batch_index,\n+              grad=grad,\n+              id=batch_id,\n+              container=\"\",\n+              shared_name=\"\",\n+              name=\"\"))\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h5vq-gw2c-pq47",
    "API Signature": "tf.raw_ops.UnbatchGrad(\n    original_input,\n    batch_index,\n    grad,\n    id,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "id=tf.constant([1,], dtype=tf.int64)"
  },
  {
    "Title": "\n        `CHECK` failure in `AvgPoolOp`\n      ",
    "Bug description": "The  AvgPoolOp  function takes an argument  ksize  that must be positive but is not checked. A negative  ksize  can trigger a  CHECK  failure and crash the program.",
    "Sample Code": "import numpy as np\n\nvalue = np.ones([1, 1, 1, 1])\nksize = [1, 1e20, 1, 1]\nstrides = [1, 1, 1, 1]\npadding = 'SAME'\ndata_format = 'NHWC'\n\n\n\ntf.raw_ops.AvgPool(value=value, ksize=ksize, strides=strides, padding=padding, data_format=data_format)",
    "Code change": [
      "@@ -298,7 +298,7 @@ class AvgPoolingGradOp : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n     const int64_t in_rows = output_shape.dim_size(1);\n     const int64_t in_cols = output_shape.dim_size(2);\n@@ -457,7 +457,7 @@ class AvgPoolingGradOp<GPUDevice, T> : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n \n     if (output_shape.num_elements() == 0) {\n@@ -543,7 +543,7 @@ class AvgPoolingGradOpCustomGPUKernel : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n     if (output_shape.num_elements() == 0) {\n       Tensor* output = nullptr;\n",
      "@@ -2470,6 +2470,22 @@ class PoolingTest(test.TestCase, parameterized.TestCase):\n               inp, grad, argmax, ksize=[1, 1, 1, 1], strides=[1, 1, 1, 1],\n               padding=\"VALID\")\n \n+  def testAvgPoolGradInvalidInputShapeRaiseError(self):\n+    with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n+      with self.cached_session():\n+        orig_input_shape = constant_op.constant(\n+            -536870912, shape=[4], dtype=dtypes.int32)\n+        grad = constant_op.constant(\n+            .0890338004362538, shape=[1, 5, 7, 1], dtype=dtypes.float64)\n+        t = gen_nn_ops.AvgPoolGrad(\n+            orig_input_shape=orig_input_shape,\n+            grad=grad,\n+            ksize=[1, 2, 2, 1],\n+            strides=[1, 2, 2, 1],\n+            padding=\"VALID\",\n+            data_format=\"NHWC\")\n+        self.evaluate(t)\n+\n \n def GetMaxPoolFwdTest(input_size, filter_size, strides, padding):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mgmh-g2v6-mqw5",
    "API Signature": "tf.raw_ops.AvgPool(\n    value, ksize, strides, padding, data_format='NHWC', name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Negative integer list element",
    "Category": "List",
    "Argument": "ksize = [1, 1e20, 1, 1]"
  },
  {
    "Title": "\n        Int overflow in `RaggedRangeOp`\n      ",
    "Bug description": "The  RaggedRangOp  function takes an argument  limits  that is eventually used to construct a  TensorShape  as an  int64 . If  limits  is a very large float, it can overflow when converted to an  int64 . This triggers an  InvalidArgument  but also throws an abort signal that crashes the program.",
    "Sample Code": " tensorflow as tf\ntf.raw_ops.RaggedRange(starts=[1.1,0.1],limits=[10.0,1e20],deltas=[1,1])",
    "Code change": [
      "@@ -12,6 +12,7 @@ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n+#include <cstdint>\n #include <limits>\n #include <memory>\n #include <string>\n@@ -78,8 +79,25 @@ class RaggedRangeOp : public OpKernel {\n       T limit = broadcast_limits ? limits(0) : limits(row);\n       T delta = broadcast_deltas ? deltas(0) : deltas(row);\n       OP_REQUIRES(context, delta != 0, InvalidArgument(\"Requires delta != 0\"));\n-      rt_nested_splits(row + 1) =\n-          rt_nested_splits(row) + RangeSize(start, limit, delta);\n+      int64_t size;  // The number of elements in the specified range.\n+      if (((delta > 0) && (limit < start)) ||\n+          ((delta < 0) && (limit > start))) {\n+        size = 0;\n+      } else if (std::is_integral<T>::value) {\n+        // The following is copied from tensorflow::RangeOp::Compute().\n+        size = Eigen::divup(Eigen::numext::abs(limit - start),\n+                            Eigen::numext::abs(delta));\n+      } else {\n+        // The following is copied from tensorflow::RangeOp::Compute().\n+        auto size_auto =\n+            Eigen::numext::ceil(Eigen::numext::abs((limit - start) / delta));\n+        OP_REQUIRES(\n+            context, size_auto <= std::numeric_limits<int64_t>::max(),\n+            errors::InvalidArgument(\"Requires ((limit - start) / delta) <= \",\n+                                    std::numeric_limits<int64_t>::max()));\n+        size = static_cast<int64_t>(size_auto);\n+      }\n+      rt_nested_splits(row + 1) = rt_nested_splits(row) + size;\n     }\n     SPLITS_TYPE nvals = rt_nested_splits(nrows);\n \n@@ -99,19 +117,6 @@ class RaggedRangeOp : public OpKernel {\n       }\n     }\n   }\n-\n- private:\n-  // Returns the number of elements in the specified range.\n-  SPLITS_TYPE RangeSize(T start, T limit, T delta) {\n-    if (((delta > 0) && (limit < start)) || ((delta < 0) && (limit > start))) {\n-      return 0;\n-    }\n-    // The following is copied from tensorflow::RangeOp::Compute().\n-    return (std::is_integral<T>::value\n-                ? ((std::abs(limit - start) + std::abs(delta) - 1) /\n-                   std::abs(delta))\n-                : std::ceil(std::abs((limit - start) / delta)));\n-  }\n };\n \n #define REGISTER_CPU_KERNEL(TYPE)                                  \\\n",
      "@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include <gtest/gtest.h>\n #include \"tensorflow/core/framework/fake_input.h\"\n #include \"tensorflow/core/framework/node_def_builder.h\"\n #include \"tensorflow/core/framework/shape_inference.h\"\n@@ -77,6 +78,17 @@ TEST_F(RaggedRangeOpTest, FloatValues) {\n       test::AsTensor<float>({0, 2, 4, 6, 5, 6, 5, 4, 3, 2}), 0.1);\n }\n \n+TEST_F(RaggedRangeOpTest, RangeSizeOverflow) {\n+  BuildRaggedRangeGraph<float>();\n+  AddInputFromArray<float>(TensorShape({2}), {1.1, 0.1});    // starts\n+  AddInputFromArray<float>(TensorShape({2}), {10.0, 1e10});  // limits\n+  AddInputFromArray<float>(TensorShape({2}), {1, 1e-10});    // deltas\n+\n+  EXPECT_EQ(absl::StrCat(\"Requires ((limit - start) / delta) <= \",\n+                         std::numeric_limits<int64_t>::max()),\n+            RunOpKernel().error_message());\n+}\n+\n TEST_F(RaggedRangeOpTest, BroadcastDeltas) {\n   BuildRaggedRangeGraph<int>();\n   AddInputFromArray<int>(TensorShape({3}), {0, 5, 8});  // starts\n",
      "@@ -84,8 +84,7 @@ class RaggedRangeOpTest(test_util.TensorFlowTestCase):\n          list(range(5, 15, 3))])\n \n     # Broadcast all arguments.\n-    self.assertAllEqual(\n-        ragged_math_ops.range(0, 5, 1), [list(range(0, 5, 1))])\n+    self.assertAllEqual(ragged_math_ops.range(0, 5, 1), [list(range(0, 5, 1))])\n \n   def testEmptyRanges(self):\n     rt1 = ragged_math_ops.range([0, 5, 3], [0, 3, 5])\n@@ -108,6 +107,10 @@ class RaggedRangeOpTest(test_util.TensorFlowTestCase):\n                                 r'Requires delta != 0'):\n       self.evaluate(ragged_math_ops.range(0, 0, 0))\n \n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                r'Requires \\(\\(limit - start\\) / delta\\) <='):\n+      self.evaluate(ragged_math_ops.range(0.1, 1e10, 1e-10))\n+\n   def testShape(self):\n     self.assertAllEqual(\n         ragged_math_ops.range(0, 0, 1).shape.as_list(), [1, None])\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x989-q2pq-4q5x",
    "API Signature": "tf.raw_ops.RaggedRange(\n    starts,\n    limits,\n    deltas,\n    Tsplits=tf.dtypes.int64,\n    name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Large integer list element",
    "Category": "List",
    "Argument": "limits=[10.0,1e20]"
  },
  {
    "Title": "\n        `CHECK` failure in `TensorListReserve` via missing validation\n      ",
    "Bug description": "In  core/kernels/list_kernels.cc's TensorListReserve ,  num_elements  is assumed to be a tensor of size 1. When a  num_elements  of more than 1 element is provided, then  tf.raw_ops.TensorListReserve  fails the  CHECK_EQ  in  CheckIsAlignedAndSingleElement .",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.TensorListReserve(element_shape=(1,1), num_elements=tf.constant([1,1], dtype=tf.int32), element_dtype=tf.int8)",
    "Code change": [
      "@@ -31,9 +31,11 @@ limitations under the License.\n #include \"tensorflow/core/framework/allocator.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/tensor_types.h\"\n #include \"tensorflow/core/framework/variant.h\"\n #include \"tensorflow/core/framework/variant_op_registry.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -322,6 +324,11 @@ class TensorListReserve : public OpKernel {\n   void Compute(OpKernelContext* c) override {\n     PartialTensorShape element_shape;\n     OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(0), &element_shape));\n+    OP_REQUIRES(\n+        c, TensorShapeUtils::IsScalar(c->input(1).shape()),\n+        errors::InvalidArgument(\n+            \"The num_elements to reserve must be a tensor size 1, but got \",\n+            c->input(1).shape()));\n     int32_t num_elements = c->input(1).scalar<int32>()();\n     OP_REQUIRES(c, num_elements >= 0,\n                 errors::InvalidArgument(\"The num_elements to reserve must be a \"\n",
      "@@ -94,6 +94,16 @@ class ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n       l = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n       self.evaluate(l)\n \n+  def testTensorListReserveWithNonScalarNumElements(self):\n+    # list_kernels.cc in tf/core/kernels raises InvalidArgumentError, and\n+    # tf_ops_n_z.cc in tf/compiler/mlir/tf/ir raises UnknownError.\n+    with self.assertRaises((errors.InvalidArgumentError, errors.UnknownError)):\n+      l = list_ops.tensor_list_reserve(\n+          element_dtype=dtypes.float32,\n+          element_shape=[2, 3],\n+          num_elements=constant_op.constant([1, 1]))\n+      self.evaluate(l)\n+\n   def testPopUninitializedTensorUseListElementShape(self):\n     l = list_ops.tensor_list_reserve(\n         element_dtype=dtypes.float32, element_shape=[2, 3], num_elements=3)\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v5xg-3q2c-c2r4",
    "API Signature": "tf.raw_ops.TensorListReserve(\n    element_shape, num_elements, element_dtype, name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "num_elements=tf.constant([1,1], dtype=tf.int32)"
  },
  {
    "Title": "\n        `CHECK` failure in `SobolSample` via missing validation\n      ",
    "Bug description": "The implementation of SobolSampleOp is vulnerable to a denial of service via CHECK-failure (assertion failure) caused by assuming  input(0) ,  input(1) , and  input(2)  to be scalar.",
    "Sample Code": " tensorflow as tf\ntf.raw_ops.SobolSample(dim=tf.constant([1,0]), num_results=tf.constant([1]), skip=tf.constant([1]))",
    "Code change": [
      "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"sobol_data.h\"  // from @sobol_data\n #include \"tensorflow/core/framework/device_base.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/lib/core/threadpool.h\"\n #include \"tensorflow/core/platform/platform_strings.h\"\n \n@@ -134,8 +135,14 @@ class SobolSampleOp : public OpKernel {\n       : OpKernel(context) {}\n \n   void Compute(OpKernelContext* context) override {\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n+                errors::InvalidArgument(\"dim must be a scalar\"));\n     int32_t dim = context->input(0).scalar<int32_t>()();\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n+                errors::InvalidArgument(\"num_results must be a scalar\"));\n     int32_t num_results = context->input(1).scalar<int32_t>()();\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n+                errors::InvalidArgument(\"skip must be a scalar\"));\n     int32_t skip = context->input(2).scalar<int32_t>()();\n \n     OP_REQUIRES(context, dim >= 1,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-97p7-w86h-vcf9",
    "API Signature": "tf.raw_ops.SobolSample(\n    dim,\n    num_results,\n    skip,\n    dtype=tf.dtypes.float32,\n    name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "dim=tf.constant([1,0]), num_results=tf.constant([1]), skip=tf.constant([1])"
  },
  {
    "Title": "\n        `CHECK` failure in tf.reshape via overflows\n      ",
    "Bug description": "The implementation of tf.reshape op in TensorFlow is vulnerable to a denial of service via CHECK-failure (assertion failure) caused by overflowing the number of elements in a tensor:",
    "Sample Code": " tensorflow as tf\n\ntf.reshape(tensor=[[1]],shape=tf.constant([0 for i in range(255)], dtype=tf.int64))",
    "Code change": [
      "@@ -45,6 +45,11 @@ class ReshapeOp : public OpKernel {\n          TensorShapeUtils::IsScalar(sizes.shape())),\n         errors::InvalidArgument(\"sizes input must be 1-D, not \",\n                                 sizes.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, sizes.NumElements() < TensorShape::MaxDimensions(),\n+        errors::InvalidArgument(\"too many dimensions: must be < \",\n+                                TensorShape::MaxDimensions(), \", but received \",\n+                                sizes.NumElements()));\n \n     // Compute the output shape.  Determine product of specified\n     // dimensions, and find the index of the unspecified one.\n",
      "@@ -351,6 +351,15 @@ class OperatorShapeTest(test_util.TensorFlowTestCase):\n                                 \"must be a tensor with a single value\"):\n       array_ops.expand_dims(1, axis=[0, 1])\n \n+  def testReshapeWithManyDims(self):\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                \"too many dimensions\"):\n+      self.evaluate(\n+          array_ops.reshape(\n+              tensor=[[1]],\n+              shape=constant_op.constant([1 for i in range(254)],\n+                                         dtype=dtypes.int64)))\n+\n \n @test_util.with_eager_op_as_function\n class ReverseV2Test(test_util.TensorFlowTestCase):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-f4w6-h4f5-wx45",
    "API Signature": "tf.reshape(\n    tensor, shape, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "shape=tf.constant([0 for i in range(255)]"
  },
  {
    "Title": "\n        Segfault if `tf.histogram_fixed_width` is called with NaN values\n      ",
    "Bug description": "The implementation of  tf.histogram_fixed_width  is vulnerable to a crash when the values array contain  NaN  elements:",
    "Sample Code": "import numpy as np\n\n\n\ntf.histogram_fixed_width(values=np.nan, value_range=[1,2])",
    "Code change": [
      "@@ -50,6 +50,15 @@ struct HistogramFixedWidthFunctor<CPUDevice, T, Tout> {\n                         static_cast<double>(nbins);\n     const double nbins_minus_1 = static_cast<double>(nbins - 1);\n \n+    // We cannot handle NANs in the algorithm below (due to the case to int32)\n+    const Eigen::Tensor<int32, 1, 1> nans_tensor =\n+        values.isnan().template cast<int32>();\n+    const Eigen::Tensor<int32, 0, 1> reduced_tensor = nans_tensor.sum();\n+    const int num_nans = reduced_tensor(0);\n+    if (num_nans > 0) {\n+      return errors::InvalidArgument(\"Histogram values must not contain NaN\");\n+    }\n+\n     // The calculation is done by finding the slot of each value in `values`.\n     // With [a, b]:\n     //   step = (b - a) / nbins\n@@ -98,12 +107,12 @@ class HistogramFixedWidthOp : public OpKernel {\n     const auto nbins = nbins_tensor.scalar<int32>()();\n \n     OP_REQUIRES(\n-        ctx, (value_range(0) < value_range(1)),\n+        ctx, value_range(0) < value_range(1),\n         errors::InvalidArgument(\"value_range should satisfy value_range[0] < \"\n                                 \"value_range[1], but got '[\",\n                                 value_range(0), \", \", value_range(1), \"]'\"));\n     OP_REQUIRES(\n-        ctx, (nbins > 0),\n+        ctx, nbins > 0,\n         errors::InvalidArgument(\"nbins should be a positive number, but got '\",\n                                 nbins, \"'\"));\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xrp2-fhq4-4q3w",
    "API Signature": "tf.histogram_fixed_width(\n    values,\n    value_range,\n    nbins=100,\n    dtype=tf.dtypes.int32,\n    name=None\n)\n",
    "Score": 0.0035460992907801418,
    "Anomaly": "NaN input tensor",
    "Category": "Tensor",
    "Argument": "values=np.nan"
  },
  {
    "Title": "\n        Denial of service in `tf.ragged.constant` due to lack of validation\n      ",
    "Bug description": "The implementation of  tf.ragged.constant  does not fully validate the input arguments. This results in a denial of service by consuming all available memory:",
    "Sample Code": " tensorflow as tf\ntf.ragged.constant(pylist=[],ragged_rank=8968073515812833920)",
    "Code change": [
      "@@ -188,6 +188,9 @@ def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,\n     if max_depth > scalar_depth:\n       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"\n                        \"than scalar value nesting\" % pylist)\n+    if ragged_rank is not None and max_depth < ragged_rank:\n+      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"\n+                       f\"ragged_rank={ragged_rank}\")\n \n   # If both inner_shape and ragged_rank were specified, then check that\n   # they are compatible with pylist.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cwpm-f78v-7m5c",
    "API Signature": "tf.ragged.constant([[0], [1, 2]]).shape",
    "Score": 0.024822695035460994,
    "Anomaly": "Large integer argument",
    "Category": "Integer",
    "Argument": "ragged_rank=8968073515812833920"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `Conv3DBackpropFilterV2`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.UnsortedSegmentJoin  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.strings.unsorted_segment_join(\n  inputs=['123'],\n  segment_ids=[0],\n  ],\n  num_segments=-1)",
    "Code change": [
      "@@ -94,6 +94,8 @@ class UnsortedSegmentJoinOp : public OpKernel {\n                 errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n+    OP_REQUIRES(context, num_segments > 0,\n+                errors::InvalidArgument(\"Number of segments must be positive\"));\n     OP_REQUIRES(context, segment_dims != 0,\n                 errors::InvalidArgument(\"Segment_id cannot have rank 0\"));\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hx9q-2mx4-m4pg",
    "API Signature": "tf.strings.unsorted_segment_join(\n    inputs, segment_ids, num_segments, separator='', name=None\n)\n",
    "Score": 0.03900709219858156,
    "Anomaly": "Negative integer argument",
    "Category": "Integer",
    "Argument": "num_segments=-1"
  },
  {
    "Title": "\n        Segfault and OOB write due to incomplete validation in `EditDistance`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.EditDistance  has incomplete validation. Users can pass negative values to cause a segmentation fault based denial of service:",
    "Sample Code": "hypothesis_indices = tf.constant(-1250999896764, shape=[3, 3], dtype=tf.int64) \nhypothesis_values = tf.constant(0, shape=[3], dtype=tf.int64)\nhypothesis_shape = tf.constant(0, shape=[3], dtype=tf.int64)\n\ntruth_indices = tf.constant(-1250999896764, shape=[3, 3], dtype=tf.int64)\ntruth_values = tf.constant(2, shape=[3], dtype=tf.int64)\ntruth_shape = tf.constant(2, shape=[3], dtype=tf.int64) \n\ntf.raw_ops.EditDistance(\n  hypothesis_indices=hypothesis_indices,\n  hypothesis_values=hypothesis_values,\n  hypothesis_shape=hypothesis_shape,\n  truth_indices=truth_indices,\n  truth_values=truth_values,\n  ,\n  truth_shape=truth_shape)",
    "Code change": [
      "@@ -203,9 +203,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) =\n@@ -218,9 +218,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) = hypothesis_seq.size();\n@@ -232,9 +232,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n@@ -248,9 +248,9 @@ class EditDistanceOp : public OpKernel {\n       auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                     output_strides.begin(), int64_t{0});\n       OP_REQUIRES(\n-          ctx, loc < output_elements,\n+          ctx, 0 <= loc && loc < output_elements,\n           errors::Internal(\"Got an inner product \", loc,\n-                           \" which would require in writing to outside of the \"\n+                           \" which would require writing to outside of the \"\n                            \"buffer for the output tensor (max elements \",\n                            output_elements, \")\"));\n       output_t(loc) = hypothesis_seq.size();\n@@ -266,9 +266,9 @@ class EditDistanceOp : public OpKernel {\n       auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                     output_strides.begin(), int64_t{0});\n       OP_REQUIRES(\n-          ctx, loc < output_elements,\n+          ctx, 0 <= loc && loc < output_elements,\n           errors::Internal(\"Got an inner product \", loc,\n-                           \" which would require in writing to outside of the \"\n+                           \" which would require writing to outside of the \"\n                            \"buffer for the output tensor (max elements \",\n                            output_elements, \")\"));\n       output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n",
      "@@ -207,6 +207,24 @@ class EditDistanceTest(test.TestCase):\n         normalize=True,\n         expected_output=expected_output)\n \n+  def testEditDistanceBadIndices(self):\n+    hypothesis_indices = np.full((3, 3), -1250999896764, dtype=np.int64)\n+    hypothesis_values = np.empty(3, dtype=np.int64)\n+    hypothesis_shape = np.empty(3, dtype=np.int64)\n+    truth_indices = np.full((3, 3), -1250999896764, dtype=np.int64)\n+    truth_values = np.full([3], 2, dtype=np.int64)\n+    truth_shape = np.full([3], 2, dtype=np.int64)\n+    expected_output = []  # dummy; ignored\n+\n+    self._testEditDistance(\n+        hypothesis=(hypothesis_indices, hypothesis_values, hypothesis_shape),\n+        truth=(truth_indices, truth_values, truth_shape),\n+        normalize=False,\n+        expected_output=expected_output,\n+        expected_err_re=(r\"inner product -\\d+ which would require writing \"\n+                         \"to outside of the buffer for the output tensor\")\n+    )\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2r2f-g8mw-9gvr",
    "API Signature": "tf.raw_ops.EditDistance(\n    hypothesis_indices,\n    hypothesis_values,\n    hypothesis_shape,\n    truth_indices,\n    truth_values,\n    truth_shape,\n    normalize=True,\n    name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Negative input tensor",
    "Category": "Tensor",
    "Argument": "hypothesis_indices = tf.constant(-1250999896764, shape=[3, 3], dtype=tf.int64), truth_indices = tf.constant(-1250999896764, shape=[3, 3], dtype=tf.int64)"
  },
  {
    "Title": "\n        Integer overflow in `SpaceToBatchND`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SpaceToBatchND  (in all backends such as XLA and handwritten kernels) is vulnerable to an integer overflow:",
    "Sample Code": "input = tf.constant(-3.5e+35, shape=[10,19,22], dtype=tf.float32)\nblock_shape = tf.constant(-1879048192, shape=[2], dtype=tf.int64)\npaddings = tf.constant(0, shape=[2,2], dtype=tf.int32)\n)\ntf.raw_ops.SpaceToBatchND(input=input, block_shape=block_shape, paddings=paddings)",
    "Code change": [
      "@@ -17,6 +17,7 @@\n import numpy as np\n \n from tensorflow.compiler.tests import xla_test\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gen_array_ops\n@@ -145,6 +146,29 @@ class SpaceToBatchTest(xla_test.XLATestCase):\n     self._testOne(x_np, block_size, x_out)\n \n \n+class SpaceToBatchNDErrorHandlingTest(xla_test.XLATestCase):\n+\n+  def testInvalidBlockShape(self):\n+    with self.assertRaisesRegex(ValueError, \"block_shape must be positive\"):\n+      with self.session() as sess, self.test_scope():\n+        tf_in = constant_op.constant(\n+            -3.5e+35, shape=[10, 20, 20], dtype=dtypes.float32)\n+        block_shape = constant_op.constant(-10, shape=[2], dtype=dtypes.int64)\n+        paddings = constant_op.constant(0, shape=[2, 2], dtype=dtypes.int32)\n+        sess.run(array_ops.space_to_batch_nd(tf_in, block_shape, paddings))\n+\n+  def testOutputSizeOutOfBounds(self):\n+    with self.assertRaisesRegex(ValueError,\n+                                \"Negative.* dimension size caused by overflow\"):\n+      with self.session() as sess, self.test_scope():\n+        tf_in = constant_op.constant(\n+            -3.5e+35, shape=[10, 19, 22], dtype=dtypes.float32)\n+        block_shape = constant_op.constant(\n+            1879048192, shape=[2], dtype=dtypes.int64)\n+        paddings = constant_op.constant(0, shape=[2, 2], dtype=dtypes.int32)\n+        sess.run(array_ops.space_to_batch_nd(tf_in, block_shape, paddings))\n+\n+\n class SpaceToBatchNDTest(xla_test.XLATestCase):\n   \"\"\"Tests input-output pairs for the SpaceToBatchND and BatchToSpaceND ops.\"\"\"\n \n",
      "@@ -211,6 +211,7 @@ tf_kernel_library(\n         \"//tensorflow/core/kernels:stateful_random_ops_header\",\n         \"//tensorflow/core/kernels:stateless_random_ops_v2_header\",\n         \"//tensorflow/core/tpu:tpu_defs\",\n+        \"//tensorflow/core/util:overflow\",\n         \"//tensorflow/stream_executor/lib\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n",
      "@@ -17,6 +17,7 @@ limitations under the License.\n #include \"tensorflow/compiler/tf2xla/xla_op_kernel.h\"\n #include \"tensorflow/compiler/tf2xla/xla_op_registry.h\"\n #include \"tensorflow/compiler/xla/client/xla_builder.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n namespace {\n@@ -60,10 +61,14 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n     int64_t pad_end = paddings.Get<int64_t>({i, 1});\n     OP_REQUIRES(ctx, pad_start >= 0 && pad_end >= 0,\n                 errors::InvalidArgument(\"Paddings must be non-negative\"));\n+    OP_REQUIRES(ctx, block_shape[i] >= 1,\n+                errors::InvalidArgument(\n+                    \"All values in block_shape must be positive, got value, \",\n+                    block_shape[i], \" at index \", i, \".\"));\n     dim->set_edge_padding_low(pad_start);\n     dim->set_edge_padding_high(pad_end);\n     padded_shape[1 + i] += pad_start + pad_end;\n-    block_num_elems *= block_shape[i];\n+    block_num_elems = MultiplyWithoutOverflow(block_num_elems, block_shape[i]);\n   }\n   // Don't pad the remainder dimensions.\n   for (int i = 0; i < remainder_shape.size(); ++i) {\n@@ -72,6 +77,16 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n   OP_REQUIRES(ctx, block_num_elems > 0,\n               errors::InvalidArgument(\n                   \"The product of the block dimensions must be positive\"));\n+  const int64_t batch_size = input_shape[0];\n+  const int64_t output_dim =\n+      MultiplyWithoutOverflow(batch_size, block_num_elems);\n+  if (output_dim < 0) {\n+    OP_REQUIRES(\n+        ctx, output_dim >= 0,\n+        errors::InvalidArgument(\"Negative output dimension size caused by \"\n+                                \"overflow when multiplying \",\n+                                batch_size, \" and \", block_num_elems));\n+  }\n \n   xla::XlaOp padded =\n       xla::Pad(input, XlaHelpers::Zero(b, input_dtype), padding_config);\n@@ -85,7 +100,6 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n   //       padded_shape[M] / block_shape[M-1],\n   //       block_shape[M-1]] +\n   //      remaining_shape\n-  const int64_t batch_size = input_shape[0];\n   std::vector<int64_t> reshaped_padded_shape(input_rank + block_rank);\n   reshaped_padded_shape[0] = batch_size;\n   for (int i = 0; i < block_rank; ++i) {\n@@ -134,7 +148,7 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n   // Determine the length of the prefix of block dims that can be combined\n   // into the batch dimension due to having no padding and block_shape=1.\n   std::vector<int64_t> output_shape(input_rank);\n-  output_shape[0] = batch_size * block_num_elems;\n+  output_shape[0] = output_dim;\n   for (int i = 0; i < block_rank; ++i) {\n     output_shape[1 + i] = padded_shape[1 + i] / block_shape[i];\n   }\n",
      "@@ -891,6 +891,7 @@ cc_library(\n         \"//tensorflow/core/lib/strings:scanner\",\n         \"//tensorflow/core/lib/strings:str_util\",\n         \"//tensorflow/core/platform:macros\",\n+        \"//tensorflow/core/util:overflow\",\n         \"@com_google_absl//absl/memory\",\n     ],\n )\n",
      "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"tensorflow/core/lib/strings/numbers.h\"\n #include \"tensorflow/core/lib/strings/scanner.h\"\n #include \"tensorflow/core/lib/strings/str_util.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n namespace shape_inference {\n@@ -1111,7 +1112,7 @@ Status InferenceContext::Multiply(DimensionHandle first,\n     *out = UnknownDim();\n   } else {\n     // Invariant: Both values are known and greater than 1.\n-    const int64_t product = first_value * second_value;\n+    const int64_t product = MultiplyWithoutOverflow(first_value, second_value);\n     if (product < 0) {\n       return errors::InvalidArgument(\n           \"Negative dimension size caused by overflow when multiplying \",\n",
      "@@ -29,6 +29,7 @@ load(\n load(\n     \"//third_party/mkl:build_defs.bzl\",\n     \"if_mkl\",\n+    \"mkl_deps\",\n )\n \n # buildifier: disable=same-origin-load\n@@ -61,10 +62,6 @@ load(\n     \"//tensorflow/core/platform:build_config_root.bzl\",\n     \"tf_cuda_tests_tags\",\n )\n-load(\n-    \"//third_party/mkl:build_defs.bzl\",\n-    \"mkl_deps\",\n-)\n load(\"@local_config_cuda//cuda:build_defs.bzl\", \"if_cuda\")\n load(\n     \"@local_config_rocm//rocm:build_defs.bzl\",\n@@ -4569,6 +4566,7 @@ tf_kernel_library(\n         \"//tensorflow/core:framework\",\n         \"//tensorflow/core:lib\",\n         \"//tensorflow/core/framework:bounds_check\",\n+        \"//tensorflow/core/util:overflow\",\n         \"//third_party/eigen3\",\n     ],\n )\n",
      "@@ -21,8 +21,6 @@ limitations under the License.\n #include <string>\n #include <utility>\n \n-#include \"tensorflow/core/kernels/spacetobatch_functor.h\"\n-\n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n@@ -31,8 +29,10 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/tensor_types.h\"\n #include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/kernels/spacetobatch_functor.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/types.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n \n@@ -99,7 +99,13 @@ Status SpaceToBatchOpCompute(OpKernelContext* context,\n   // Compute the product of the block_shape values.\n   int64_t block_shape_product = 1;\n   for (int block_dim = 0; block_dim < block_dims; ++block_dim) {\n-    block_shape_product *= block_shape[block_dim];\n+    if (block_shape[block_dim] < 1) {\n+      return errors::InvalidArgument(\n+          \"All values in block_shape must be positive, got value, \",\n+          block_shape[block_dim], \" at index \", block_dim, \".\");\n+    }\n+    block_shape_product =\n+        MultiplyWithoutOverflow(block_shape_product, block_shape[block_dim]);\n   }\n   if (block_shape_product <= 0) {\n     return errors::InvalidArgument(\n@@ -131,8 +137,14 @@ Status SpaceToBatchOpCompute(OpKernelContext* context,\n   // The actual output shape exposed to callers.\n   TensorShape external_output_shape;\n \n-  external_output_shape.AddDim(orig_input_tensor.dim_size(0) *\n-                               block_shape_product);\n+  const int64_t output_shape = MultiplyWithoutOverflow(\n+      orig_input_tensor.dim_size(0), block_shape_product);\n+  if (output_shape < 0) {\n+    return errors::InvalidArgument(\n+        \"Negative output dimension size caused by overflow when multiplying \",\n+        orig_input_tensor.dim_size(0), \" and \", block_shape_product);\n+  }\n+  external_output_shape.AddDim(output_shape);\n \n   int64_t input_batch_size = orig_input_tensor.dim_size(0);\n   for (int block_dim = 0; block_dim < removed_prefix_block_dims; ++block_dim) {\n",
      "@@ -533,6 +533,9 @@ tf_cuda_library(\n cc_library(\n     name = \"overflow\",\n     hdrs = [\"overflow.h\"],\n+    visibility = [\n+        \"//tensorflow:internal\",\n+    ],\n     deps = [\n         \"//tensorflow/core/platform:logging\",\n         \"//tensorflow/core/platform:macros\",\n",
      "@@ -16,7 +16,9 @@\n \n import numpy as np\n \n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import tensor_util\n from tensorflow.python.framework import test_util\n@@ -516,6 +518,27 @@ class SpaceToBatchNDErrorHandlingTest(test.TestCase):\n             dtypes.float32, shape=(3, 2, 3, 2)), [2, 3], [[1, 1], [0, 0]])\n     self.assertEqual([3 * 2 * 3, 2, 1, 2], t.get_shape().as_list())\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testInvalidBlockShape(self):\n+    tf_in = constant_op.constant(\n+        -3.5e+35, shape=[10, 20, 20], dtype=dtypes.float32)\n+    block_shape = constant_op.constant(-10, shape=[2], dtype=dtypes.int64)\n+    paddings = constant_op.constant(0, shape=[2, 2], dtype=dtypes.int32)\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"block_shape must be positive\"):\n+      array_ops.space_to_batch_nd(tf_in, block_shape, paddings)\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def testOutputSizeOutOfBounds(self):\n+    tf_in = constant_op.constant(\n+        -3.5e+35, shape=[10, 19, 22], dtype=dtypes.float32)\n+    block_shape = constant_op.constant(\n+        1879048192, shape=[2], dtype=dtypes.int64)\n+    paddings = constant_op.constant(0, shape=[2, 2], dtype=dtypes.int32)\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Negative.* dimension size caused by overflow\"):\n+      array_ops.space_to_batch_nd(tf_in, block_shape, paddings)\n+\n \n class SpaceToBatchGradientTest(test.TestCase, PythonOpImpl):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jjm6-4vf7-cjh4",
    "API Signature": "tf.raw_ops.SpaceToBatchND(\n    input, block_shape, paddings, name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Negative input tensor",
    "Category": "Tensor",
    "Argument": "block_shape = tf.constant(-1879048192, shape=[2], dtype=tf.int64)"
  },
  {
    "Title": "\n        Missing validation results in undefined behavior in `QuantizedConv2D`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.QuantizedConv2D  does not fully validate the input arguments:",
    "Sample Code": "input = tf.constant(1, shape=[1, 2, 3, 3], dtype=tf.quint8)\nfilter = tf.constant(1, shape=[1, 2, 3, 3], dtype=tf.quint8)\n\n# bad args\nmin_input = tf.constant([], shape=[0], dtype=tf.float32)\nmax_input = tf.constant(0, shape=[], dtype=tf.float32)\nmin_filter = tf.constant(0, shape=[], dtype=tf.float32)\nmax_filter = tf.constant(0, shape=[], dtype=tf.float32)\n\ntf.raw_ops.QuantizedConv2D(\n  input=input,\n  filter=filter,\n  min_input=min_input,\n  max_input=max_input,\n  min_filter=min_filter,\n  max_filter=max_filter, \n  strides=[1, 1, 1, 1],\n  ],\n  padding=\"SAME\")",
    "Code change": [
      "@@ -18,8 +18,6 @@ limitations under the License.\n #include <algorithm>\n #include <vector>\n \n-#include \"tensorflow/core/platform/errors.h\"\n-\n #define EIGEN_USE_THREADS\n \n #define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\n@@ -32,6 +30,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/kernels/reference_gemm.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/util/padding.h\"\n \n namespace tensorflow {\n@@ -499,11 +498,26 @@ class QuantizedConv2DOp : public OpKernel {\n \n     // For 2D convolution, there should be 4 dimensions.\n     OP_REQUIRES(context, input.dims() == 4,\n-                errors::InvalidArgument(\"input must be 4-dimensional\",\n-                                        input.shape().DebugString()));\n+                errors::InvalidArgument(\"input must be rank 4 but is rank \",\n+                                        input.shape().dims()));\n     OP_REQUIRES(context, filter.dims() == 4,\n-                errors::InvalidArgument(\"filter must be 4-dimensional: \",\n-                                        filter.shape().DebugString()));\n+                errors::InvalidArgument(\"filter must be rank 4 but is rank \",\n+                                        filter.shape().dims()));\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(2).shape()),\n+                errors::InvalidArgument(\"min_input must be rank 0 but is rank \",\n+                                        context->input(2).shape().dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(3).shape()),\n+                errors::InvalidArgument(\"max_input must be rank 0 but is rank \",\n+                                        context->input(3).shape().dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(context->input(4).shape()),\n+        errors::InvalidArgument(\"min_filter must be rank 0 but is rank \",\n+                                context->input(4).shape().dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(context->input(5).shape()),\n+        errors::InvalidArgument(\"max_filter must be rank 0 but is rank \",\n+                                context->input(5).shape().dims()));\n \n     const float min_input = context->input(2).flat<float>()(0);\n     const float max_input = context->input(3).flat<float>()(0);\n",
      "@@ -91,10 +91,10 @@ TEST_F(QuantizedConv2DTest, Small) {\n                             image_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(filter_quantized.shape(),\n                             filter_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {image_min});\n-  AddInputFromArray<float>(TensorShape({1}), {image_max});\n-  AddInputFromArray<float>(TensorShape({1}), {filter_min});\n-  AddInputFromArray<float>(TensorShape({1}), {filter_max});\n+  AddInputFromArray<float>(TensorShape({}), {image_min});\n+  AddInputFromArray<float>(TensorShape({}), {image_max});\n+  AddInputFromArray<float>(TensorShape({}), {filter_min});\n+  AddInputFromArray<float>(TensorShape({}), {filter_max});\n   TF_ASSERT_OK(RunOpKernel());\n \n   // We're sliding the 3x3 filter across the 3x4 image, with accesses outside\n@@ -158,10 +158,10 @@ TEST_F(QuantizedConv2DTest, Small32Bit) {\n   AddInputFromArray<quint8>(\n       TensorShape({filter_size, filter_size, depth, filter_count}),\n       {10, 40, 70, 20, 50, 80, 30, 60, 90});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n \n   TF_ASSERT_OK(RunOpKernel());\n   const int expected_width = image_width;\n@@ -201,10 +201,10 @@ TEST_F(QuantizedConv2DTest, OddPadding) {\n   AddInputFromArray<quint8>(\n       TensorShape({filter_size, filter_size, depth, filter_count}),\n       {1, 2, 3, 4, 5, 6, 7, 8, 9});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n \n   TF_ASSERT_OK(RunOpKernel());\n   const int expected_width = image_width / stride;\n@@ -244,10 +244,10 @@ TEST_F(QuantizedConv2DTest, OddPaddingBatch) {\n   AddInputFromArray<quint8>(\n       TensorShape({filter_size, filter_size, depth, filter_count}),\n       {1, 2, 3, 4, 5, 6, 7, 8, 9});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n \n   TF_ASSERT_OK(RunOpKernel());\n   const int expected_width = image_width / stride;\n@@ -302,10 +302,10 @@ TEST_F(QuantizedConv2DTest, SmallWithNoZero) {\n                             image_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(filter_quantized.shape(),\n                             filter_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {image_min});\n-  AddInputFromArray<float>(TensorShape({1}), {image_max});\n-  AddInputFromArray<float>(TensorShape({1}), {filter_min});\n-  AddInputFromArray<float>(TensorShape({1}), {filter_max});\n+  AddInputFromArray<float>(TensorShape({}), {image_min});\n+  AddInputFromArray<float>(TensorShape({}), {image_max});\n+  AddInputFromArray<float>(TensorShape({}), {filter_min});\n+  AddInputFromArray<float>(TensorShape({}), {filter_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const int expected_width = image_width;\n   const int expected_height = image_height * filter_count;\n",
      "@@ -18,6 +18,8 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n+from tensorflow.python.ops import math_ops\n from tensorflow.python.ops import nn_ops\n from tensorflow.python.platform import test\n \n@@ -196,6 +198,71 @@ class Conv2DTest(test.TestCase):\n         padding=\"SAME\",\n         expected=expected_output)\n \n+  def _testBadInputSize(self,\n+                        tin=None,\n+                        tfilter=None,\n+                        min_input=None,\n+                        max_input=None,\n+                        min_filter=None,\n+                        max_filter=None,\n+                        error_regex=\"\"):\n+    strides = [1, 1, 1, 1]\n+    padding = \"SAME\"\n+    if tin is None:\n+      tin = math_ops.cast(\n+          constant_op.constant(1, shape=[1, 2, 3, 3]), dtype=dtypes.quint8)\n+\n+    if tfilter is None:\n+      tfilter = math_ops.cast(\n+          constant_op.constant(1, shape=[1, 2, 3, 3]), dtype=dtypes.quint8)\n+\n+    if min_input is None:\n+      min_input = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+\n+    if max_input is None:\n+      max_input = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+\n+    if min_filter is None:\n+      min_filter = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+\n+    if max_filter is None:\n+      max_filter = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                error_regex):\n+      self.evaluate(\n+          nn_ops.quantized_conv2d(\n+              tin,\n+              tfilter,\n+              out_type=dtypes.qint32,\n+              strides=strides,\n+              padding=padding,\n+              min_input=min_input,\n+              max_input=max_input,\n+              min_filter=min_filter,\n+              max_filter=max_filter))\n+\n+  def testBadInputSizes(self):\n+    self._testBadInputSize(\n+        tin=math_ops.cast(\n+            constant_op.constant(1, shape=[1, 2]), dtype=dtypes.quint8),\n+        error_regex=\"must be rank 4\")\n+    self._testBadInputSize(\n+        tfilter=math_ops.cast(\n+            constant_op.constant(1, shape=[1, 2]), dtype=dtypes.quint8),\n+        error_regex=\"must be rank 4\")\n+    self._testBadInputSize(\n+        min_input=constant_op.constant(0, shape=[1], dtype=dtypes.float32),\n+        error_regex=\"must be rank 0\")\n+    self._testBadInputSize(\n+        max_input=constant_op.constant(0, shape=[1], dtype=dtypes.float32),\n+        error_regex=\"must be rank 0\")\n+    self._testBadInputSize(\n+        min_filter=constant_op.constant(0, shape=[1], dtype=dtypes.float32),\n+        error_regex=\"must be rank 0\")\n+    self._testBadInputSize(\n+        max_filter=constant_op.constant(0, shape=[1], dtype=dtypes.float32),\n+        error_regex=\"must be rank 0\")\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-pqhm-4wvf-2jg8",
    "API Signature": "tf.raw_ops.QuantizedConv2D(\n    input,\n    filter,\n    min_input,\n    max_input,\n    min_filter,\n    max_filter,\n    strides,\n    padding,\n    out_type=tf.dtypes.qint32,\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "min_input = tf.constant([], shape=[0], dtype=tf.float32)\nmax_input = tf.constant(0, shape=[], dtype=tf.float32)\nmin_filter = tf.constant(0, shape=[], dtype=tf.float32)\nmax_filter = tf.constant(0, shape=[], dtype=tf.float32)"
  },
  {
    "Title": "\n        Missing validation results in undefined behavior in `SparseTensorDenseAdd\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SparseTensorDenseAdd  does not fully validate the input arguments:",
    "Sample Code": "a_indices = tf.constant(0, shape=[17, 2], dtype=tf.int64)\na_values = tf.constant([], shape=[0], dtype=tf.float32)\na_shape = tf.constant([6, 12], shape=[2], dtype=tf.int64)\n\nb = tf.constant(-0.223668531, shape=[6, 12], dtype=tf.float32)\n\ntf.raw_ops.SparseTensorDenseAdd(\n    (\n    a_indices=a_indices, a_values=a_values, a_shape=a_shape, b=b)",
    "Code change": [
      "@@ -18,6 +18,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/sparse_tensor_dense_add_op.h\"\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n@@ -47,6 +48,17 @@ Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n         a_values->shape().DebugString(), \" and \",\n         a_shape->shape().DebugString());\n   }\n+  int64_t nnz = a_indices->dim_size(0);\n+  int64_t ndims = a_indices->dim_size(1);\n+  if (a_values->dim_size(0) != nnz) {\n+    return errors::InvalidArgument(\"Dimensions \", nnz, \" and \",\n+                                   a_values->dim_size(0),\n+                                   \" are not compatible\");\n+  }\n+  if (a_shape->dim_size(0) != ndims) {\n+    return errors::InvalidArgument(\"Dimensions \", ndims, \" and \",\n+                                   a_shape->dim_size(0), \" are not compatible\");\n+  }\n   if (a_shape->NumElements() != b->dims()) {\n     return errors::InvalidArgument(\n         \"Two operands have different ranks; received: \", a_shape->NumElements(),\n@@ -61,6 +73,24 @@ Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n           a_shape_flat(i), \" vs dense side \", b->dim_size(i));\n     }\n   }\n+\n+  // Check for invalid indices.\n+  const auto a_indices_mat = a_indices->flat_inner_dims<Index>();\n+\n+  for (int64_t zidx = 0; zidx < nnz; ++zidx) {\n+    for (int64_t didx = 0; didx < ndims; ++didx) {\n+      const Index idx = a_indices_mat(zidx, didx);\n+      if (idx < 0 || idx >= a_shape_flat(didx)) {\n+        return errors::InvalidArgument(\n+            \"Sparse tensor has an invalid index on dimension \", didx,\n+            \": \"\n+            \"a_indices(\",\n+            zidx, \",\", didx, \") = \", idx,\n+            \", dense tensor shape: \", a_shape_flat);\n+      }\n+    }\n+  }\n+\n   return Status::OK();\n }\n \n",
      "@@ -189,7 +189,6 @@ class SparseAddTest(test.TestCase):\n                                                     [(nnz,), (n, m)], s, (n, m))\n       self.assertLess(err, 1e-3)\n \n-  @test_util.run_deprecated_v1\n   def testInvalidSparseTensor(self):\n     with test_util.force_cpu():\n       shape = [2, 2]\n@@ -201,12 +200,49 @@ class SparseAddTest(test.TestCase):\n           [[1, 3]],  # ...so is 3.\n       ]:\n         sparse = sparse_tensor.SparseTensorValue(bad_idx, val, shape)\n-        s = sparse_ops.sparse_add(sparse, dense)\n-\n-        with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n-                                    \"invalid index\"):\n+        with self.assertRaisesRegex(\n+            (ValueError, errors_impl.InvalidArgumentError), \"invalid index\"):\n+          s = sparse_ops.sparse_add(sparse, dense)\n           self.evaluate(s)\n \n+  def _testSparseDenseInvalidInputs(self,\n+                                    a_indices,\n+                                    a_values,\n+                                    a_shape,\n+                                    b,\n+                                    expected_error=\"\"):\n+    # Public API call to sparse-dense add.\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                expected_error):\n+      a = sparse_tensor.SparseTensor(a_indices, a_values, a_shape)\n+      self.evaluate(sparse_ops.sparse_add(a, b))\n+    # Directly call generated kernel, by-passing SparseTensor validation.\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                expected_error):\n+      self.evaluate(\n+          sparse_ops.gen_sparse_ops.sparse_tensor_dense_add(\n+              a_indices, a_values, a_shape, b))\n+\n+  def testSparseDenseInvalidInputs(self):\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(0, shape=[17, 2], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[5], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"Dimensions 17 and 5 are not compatible\")\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(0, shape=[17, 4], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[17], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"Dimensions 4 and 2 are not compatible\")\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(7, shape=[17, 2], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[17], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"invalid index\")\n+\n ######################## Benchmarking code\n \n \n",
      "@@ -665,7 +665,7 @@ class SparseFillEmptyRowsTest(test_util.TensorFlowTestCase):\n class SparseAddTest(test_util.TensorFlowTestCase):\n \n   def testValuesInVariable(self):\n-    indices = constant_op.constant([[1]], dtype=dtypes.int64)\n+    indices = constant_op.constant([[0]], dtype=dtypes.int64)\n     values = variables.Variable([1], trainable=False, dtype=dtypes.float32)\n     shape = constant_op.constant([1], dtype=dtypes.int64)\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rc9w-5c64-9vqq",
    "API Signature": "tf.raw_ops.SparseTensorDenseAdd(\n    a_indices, a_values, a_shape, b, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "a_values = tf.constant([], shape=[0], dtype=tf.float32)\na_shape = tf.constant([6, 12], shape=[2], dtype=tf.int64) a_indices = tf.constant(0, shape=[17, 2], dtype=tf.int64)"
  },
  {
    "Title": "\n        Undefined behavior when users supply invalid resource handles\n      ",
    "Bug description": "Multiple TensorFlow operations misbehave in eager mode when the resource handle provided to them is invalid:",
    "Sample Code": " tensorflow as tf\n\ntf.summary.flush(writer=())",
    "Code change": [
      "@@ -304,6 +304,9 @@ Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n     const Tensor* tensor;\n     // TODO(fishx): Avoid blocking here.\n     TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));\n+    if (tensor->NumElements() == 0) {\n+      return errors::InvalidArgument(\"Empty resource handle\");\n+    }\n     const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);\n     device_name = handle.device();\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5wpj-c6f7-24x8",
    "API Signature": "tf.raw_ops.QueueIsClosedV2(\n    handle, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "handle=[]"
  },
  {
    "Title": "\n        Undefined behavior when users supply invalid resource handles\n      ",
    "Bug description": "Multiple TensorFlow operations misbehave in eager mode when the resource handle provided to them is invalid:",
    "Sample Code": " tensorflow as tf\n\ntf.summary.flush(writer=())",
    "Code change": [
      "@@ -304,6 +304,9 @@ Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n     const Tensor* tensor;\n     // TODO(fishx): Avoid blocking here.\n     TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));\n+    if (tensor->NumElements() == 0) {\n+      return errors::InvalidArgument(\"Empty resource handle\");\n+    }\n     const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);\n     device_name = handle.device();\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5wpj-c6f7-24x8",
    "API Signature": "tf.summary.flush(\n    writer=None, name=None\n)\n",
    "Score": 0.0035460992907801418,
    "Anomaly": "Empty input argument",
    "Category": "tf.summary.SummaryWriter",
    "Argument": "writer=()"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `Conv3DBackpropFilterV2`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.Conv3DBackpropFilterV2  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.Conv3DBackpropFilterV2(\n  input=tf.constant(.5053710941, shape=[2,2,2,2,1], dtype=tf.float16),\n  filter_sizes=tf.constant(0, shape=[], dtype=tf.int32),\n  out_backprop=tf.constant(.5053710941, shape=[2,2,2,2,1], dtype=tf.float16),\n  strides=[1, 1, 1, 1, 1],\n  padding=\"VALID\",\n  data_format=\"NDHWC\",\n  ,\n  dilations=[1, 1, 1, 1, 1])",
    "Code change": [
      "@@ -741,6 +741,10 @@ class Conv3DBackpropFilterOp : public OpKernel {\n     TensorShape filter_shape;\n     if (takes_shape_) {\n       const Tensor& filter_sizes = context->input(1);\n+      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),\n+                  errors::InvalidArgument(\n+                      \"filter_sizes shape must be rank 1 but is rank \",\n+                      filter_sizes.shape().dims()));\n       OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                   filter_sizes.vec<int32>(), &filter_shape));\n     } else {\n@@ -875,6 +879,10 @@ class Conv3DCustomBackpropFilterOp : public OpKernel {\n     TensorShape filter_shape;\n     if (takes_shape_) {\n       const Tensor& filter_sizes = context->input(1);\n+      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),\n+                  errors::InvalidArgument(\n+                      \"filter_sizes shape must be rank 1 but is rank \",\n+                      filter_sizes.shape().dims()));\n       OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                   filter_sizes.vec<int32>(), &filter_shape));\n     } else {\n@@ -1638,6 +1646,10 @@ class Conv3DBackpropFilterOp<GPUDevice, T> : public OpKernel {\n     TensorShape filter_shape;\n     if (takes_shape_) {\n       const Tensor& filter_sizes = context->input(1);\n+      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),\n+                  errors::InvalidArgument(\n+                      \"filter_sizes shape must be rank 1 but is rank \",\n+                      filter_sizes.shape().dims()));\n       OP_REQUIRES_OK(context, tensor::MakeShape(filter_sizes, &filter_shape));\n     } else {\n       filter_shape = context->input(1).shape();\n",
      "@@ -18,6 +18,7 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gradient_checker\n@@ -58,6 +59,23 @@ class Conv3DBackpropFilterV2GradTest(test.TestCase):\n           err_tolerance = 1e-3\n           self.assertLess(err, err_tolerance)\n \n+  def testBadFilterShape(self):\n+    strides = [1, 1, 1, 1, 1]\n+    padding = \"VALID\"\n+    tin = constant_op.constant(\n+        .5053710941, shape=[2, 2, 2, 2, 1], dtype=dtypes.float32)\n+    filter_sizes = constant_op.constant(0, shape=[], dtype=dtypes.int32)\n+    out_backprop = constant_op.constant(\n+        .5053710941, shape=[2, 2, 2, 2, 1], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      nn_ops.conv3d_backprop_filter_v2(\n+          input=tin,\n+          filter_sizes=filter_sizes,\n+          out_backprop=out_backprop,\n+          strides=strides,\n+          padding=padding)\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5v77-j66x-4c4g",
    "API Signature": "tf.raw_ops.Conv3DBackpropFilterV2(\n    input,\n    filter_sizes,\n    out_backprop,\n    strides,\n    padding,\n    data_format='NDHWC',\n    dilations=[1, 1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "filter_sizes=tf.constant(0, shape=[], dtype=tf.int32)"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
      "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
      "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
      "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
      "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
      "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
      "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
      "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
      "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
      "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
      "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "wci=tf.constant(0, shape=[], dtype=tf.float32),"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
      "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
      "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "wcf=tf.constant(0, shape=[17], dtype=tf.float32),"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
      "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
      "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
      "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
      "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `SparseTensorToCSRSparseMatrix`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SparseTensorToCSRSparseMatrix  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "indices = tf.constant(53, shape=[3], dtype=tf.int64)\nvalues = tf.constant(0.554979503, shape=[218650], dtype=tf.float32)\ndense_shape = tf.constant(53, shape=[3], dtype=tf.int64)\n    \ntf.raw_ops.SparseTensorToCSRSparseMatrix(\n  indices=indices,\n  values=values,\n  ,\n  dense_shape=dense_shape)",
    "Code change": [
      "@@ -67,6 +67,13 @@ class SparseTensorToCSRSparseMatrixCPUOp : public OpKernel {\n     const Tensor& values = ctx->input(1);\n     const Tensor& dense_shape = ctx->input(2);\n     const int rank = dense_shape.NumElements();\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsVector(dense_shape.shape()),\n+        errors::InvalidArgument(\"dense_shape must be rank 1 but got rank\",\n+                                dense_shape.shape().dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices.shape()),\n+                errors::InvalidArgument(\"indices must be rank 2 but got rank\",\n+                                        indices.shape().dims()));\n     OP_REQUIRES(ctx, rank == 2 || rank == 3,\n                 errors::InvalidArgument(\"SparseTensor must have rank 2 or 3; \",\n                                         \"but indices has rank: \", rank));\n",
      "@@ -168,6 +168,25 @@ class CSRSparseMatrixOpsTest(test.TestCase):\n     self.assertAllClose(a_values, a_st_rt_value.values)\n     self.assertAllEqual(a_dense_shape, a_st_rt_value.dense_shape)\n \n+  def testSparseTensorConversionInvalidInputShapes(self):\n+    values = constant_op.constant(\n+        0.554979503, shape=[5], dtype=dtypes.float32)\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      indices = constant_op.constant(0, shape=[5, 2], dtype=dtypes.int64)\n+      dense_shape = constant_op.constant(53, shape=[], dtype=dtypes.int64)\n+      csr = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n+          indices=indices, values=values, dense_shape=dense_shape)\n+      self.evaluate(csr)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 2\"):\n+      indices = constant_op.constant(0, shape=[5], dtype=dtypes.int64)\n+      dense_shape = constant_op.constant(53, shape=[1], dtype=dtypes.int64)\n+      csr = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n+          indices=indices, values=values, dense_shape=dense_shape)\n+      self.evaluate(csr)\n+\n   # TODO(b/139491352): Add handle_data propagation to array_ops.identity.\n   @test_util.run_deprecated_v1\n   def testCSRSparseMatrixResourceVariable(self):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mg66-qvc5-rm93",
    "API Signature": "tf.raw_ops.SparseTensorToCSRSparseMatrix(\n    indices, values, dense_shape, name=None\n)\n",
    "Score": 0.02127659574468085,
    "Anomaly": "Scalar input tensor",
    "Category": "Tensor",
    "Argument": "indices = tf.constant(53, shape=[3], dtype=tf.int64)"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `SparseTensorToCSRSparseMatrix`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SparseTensorToCSRSparseMatrix  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "indices = tf.constant(53, shape=[3], dtype=tf.int64)\nvalues = tf.constant(0.554979503, shape=[218650], dtype=tf.float32)\ndense_shape = tf.constant(53, shape=[3], dtype=tf.int64)\n    \ntf.raw_ops.SparseTensorToCSRSparseMatrix(\n  indices=indices,\n  values=values,\n  ,\n  dense_shape=dense_shape)",
    "Code change": [
      "@@ -67,6 +67,13 @@ class SparseTensorToCSRSparseMatrixCPUOp : public OpKernel {\n     const Tensor& values = ctx->input(1);\n     const Tensor& dense_shape = ctx->input(2);\n     const int rank = dense_shape.NumElements();\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsVector(dense_shape.shape()),\n+        errors::InvalidArgument(\"dense_shape must be rank 1 but got rank\",\n+                                dense_shape.shape().dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices.shape()),\n+                errors::InvalidArgument(\"indices must be rank 2 but got rank\",\n+                                        indices.shape().dims()));\n     OP_REQUIRES(ctx, rank == 2 || rank == 3,\n                 errors::InvalidArgument(\"SparseTensor must have rank 2 or 3; \",\n                                         \"but indices has rank: \", rank));\n",
      "@@ -168,6 +168,25 @@ class CSRSparseMatrixOpsTest(test.TestCase):\n     self.assertAllClose(a_values, a_st_rt_value.values)\n     self.assertAllEqual(a_dense_shape, a_st_rt_value.dense_shape)\n \n+  def testSparseTensorConversionInvalidInputShapes(self):\n+    values = constant_op.constant(\n+        0.554979503, shape=[5], dtype=dtypes.float32)\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      indices = constant_op.constant(0, shape=[5, 2], dtype=dtypes.int64)\n+      dense_shape = constant_op.constant(53, shape=[], dtype=dtypes.int64)\n+      csr = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n+          indices=indices, values=values, dense_shape=dense_shape)\n+      self.evaluate(csr)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 2\"):\n+      indices = constant_op.constant(0, shape=[5], dtype=dtypes.int64)\n+      dense_shape = constant_op.constant(53, shape=[1], dtype=dtypes.int64)\n+      csr = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n+          indices=indices, values=values, dense_shape=dense_shape)\n+      self.evaluate(csr)\n+\n   # TODO(b/139491352): Add handle_data propagation to array_ops.identity.\n   @test_util.run_deprecated_v1\n   def testCSRSparseMatrixResourceVariable(self):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mg66-qvc5-rm93",
    "API Signature": "tf.raw_ops.SparseTensorToCSRSparseMatrix(\n    indices, values, dense_shape, name=None\n)\n",
    "Score": 0.02127659574468085,
    "Anomaly": "Scalar input tensor",
    "Category": "Tensor",
    "Argument": "values = tf.constant(0.554979503, shape=[218650], dtype=tf.float32)"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `LoadAndRemapMatrix`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LoadAndRemapMatrix  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "ckpt_path = tf.constant(\n    \"/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0\", shape=[], dtype=tf.string)\nold_tensor_name = tf.constant(\n    \"/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0\", shape=[], dtype=tf.string)\n\nrow_remapping = tf.constant(0, shape=[], dtype=tf.int64)\ncol_remapping = tf.constant(3, shape=[3], dtype=tf.int64)\ninitializing_values = tf.constant([], shape=[0, 1], dtype=tf.float32)\n\ntf.raw_ops.LoadAndRemapMatrix(\n  ckpt_path=ckpt_path,\n  old_tensor_name=old_tensor_name,\n  row_remapping=row_remapping,\n  col_remapping=col_remapping,\n  initializing_values=initializing_values,\n  num_rows=1,\n  ,\n  num_cols=1)",
    "Code change": [
      "@@ -74,6 +74,11 @@ class LoadAndRemapMatrixOp : public OpKernel {\n     std::vector<bool> row_id_present;\n     const Tensor* row_remapping_t;\n     OP_REQUIRES_OK(context, context->input(\"row_remapping\", &row_remapping_t));\n+    OP_REQUIRES(\n+        context, row_remapping_t->dims() == 1,\n+        errors::InvalidArgument(\"The `row_remapping` tensor must be 1-D, got \"\n+                                \"a tensor of shape \",\n+                                row_remapping_t->shape().DebugString()));\n     const auto row_remapping = row_remapping_t->vec<int64_t>();\n     OP_REQUIRES(context, row_remapping.size() == num_rows_,\n                 errors::InvalidArgument(strings::StrCat(\n",
      "@@ -227,6 +227,32 @@ class LoadAndRemapMatrixTest(test.TestCase):\n           np.reshape(initializing_values, (num_rows, num_cols)),\n           self.evaluate(remapped_matrix))\n \n+  def test_load_and_remap_invalid_dims(self):\n+    ckpt_path = constant_op.constant(\n+        '/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0',\n+        shape=[],\n+        dtype=dtypes.string)\n+    old_tensor_name = constant_op.constant(\n+        '/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0',\n+        shape=[],\n+        dtype=dtypes.string)\n+    row_remapping = constant_op.constant(0, shape=[], dtype=dtypes.int64)\n+    col_remapping = constant_op.constant(3, shape=[3], dtype=dtypes.int64)\n+    initializing_values = constant_op.constant([],\n+                                               shape=[0, 1],\n+                                               dtype=dtypes.float32)\n+    with self.cached_session(), self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError), 'tensor must be 1-D'):\n+      self.evaluate(\n+          gen_checkpoint_ops.load_and_remap_matrix(\n+              ckpt_path=ckpt_path,\n+              old_tensor_name=old_tensor_name,\n+              row_remapping=row_remapping,\n+              col_remapping=col_remapping,\n+              initializing_values=initializing_values,\n+              num_rows=1,\n+              num_cols=1))\n+\n   @test_util.run_deprecated_v1\n   def test_load_and_remap_invalid_remapping(self):\n     \"\"\"Tests that errors are raised when an ID maps to multiple new IDs.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-p9rc-rmr5-529j",
    "API Signature": "tf.raw_ops.LoadAndRemapMatrix(\n    ckpt_path,\n    old_tensor_name,\n    row_remapping,\n    col_remapping,\n    initializing_values,\n    num_rows,\n    num_cols,\n    max_rows_in_memory=-1,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "initializing_values = tf.constant([], shape=[0, 1], dtype=tf.float32)"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `UnsortedSegmentJoin`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.UnsortedSegmentJoin  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.UnsortedSegmentJoin(\n  inputs=tf.constant(\"this\", shape=[12], dtype=tf.string),\n  segment_ids=tf.constant(0, shape=[12], dtype=tf.int64),\n  ),\n  num_segments=tf.constant(0, shape=[12], dtype=tf.int64))",
    "Code change": [
      "@@ -92,6 +92,9 @@ class UnsortedSegmentJoinOp : public OpKernel {\n     const Tensor& num_segments_tensor = context->input(2);\n     OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,\n                 errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n+    OP_REQUIRES(context,\n+                TensorShapeUtils::IsScalar(num_segments_tensor.shape()),\n+                errors::InvalidArgument(\"Number of segments must be a scalar\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n     OP_REQUIRES(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hrg5-737c-2p56",
    "API Signature": "tf.raw_ops.UnsortedSegmentJoin(\n    inputs, segment_ids, num_segments, separator='', name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "num_segments=tf.constant(0, shape=[12], dtype=tf.int64))"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `StagePeek`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.StagePeek  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "index = tf.constant([], shape=[0], dtype=tf.int32)\n)\ntf.raw_ops.StagePeek(index=index, dtypes=[tf.int32])",
    "Code change": [
      "@@ -258,6 +258,8 @@ class StagePeekOp : public OpKernel {\n     core::ScopedUnref scope(buf);\n     Buffer::Tuple tuple;\n \n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(ctx->input(0).shape()),\n+                errors::InvalidArgument(\"index must be scalar\"));\n     std::size_t index = ctx->input(0).scalar<int>()();\n \n     OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));\n",
      "@@ -13,6 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n@@ -134,6 +135,16 @@ class StageTest(test.TestCase):\n       for i in range(10):\n         self.assertTrue(sess.run(peek, feed_dict={p: i}) == [i])\n \n+  def testPeekBadIndex(self):\n+    stager = data_flow_ops.StagingArea([\n+        dtypes.int32,\n+    ], shapes=[[10]])\n+    stager.put([array_ops.zeros([10], dtype=dtypes.int32)])\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                'must be scalar'):\n+      self.evaluate(stager.peek([]))\n+\n   @test_util.run_deprecated_v1\n   def testSizeAndClear(self):\n     with ops.Graph().as_default() as G:\n",
      "@@ -1737,7 +1737,7 @@ class BaseStagingArea:\n \n     # Sanity check number of values\n     if not len(vals) <= len(self._dtypes):\n-      raise ValueError(f\"Unexpected number of inputs {len(vals)} vs\"\n+      raise ValueError(f\"Unexpected number of inputs {len(vals)} vs \"\n                        f\"{len(self._dtypes)}\")\n \n     tensors = []\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h48f-q7rw-hvr7",
    "API Signature": "tf.raw_ops.StagePeek(\n    index,\n    dtypes,\n    capacity=0,\n    memory_limit=0,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "index = tf.constant([], shape=[0], dtype=tf.int32)"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `GetSessionTensor`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.GetSessionTensor  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "handle = tf.constant(\"[]\", shape=[0], dtype=tf.string)\n)\ntf.raw_ops.GetSessionTensor(handle=handle)",
    "Code change": [
      "@@ -98,6 +98,8 @@ class GetSessionTensorOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& handle = ctx->input(0);\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),\n+                errors::InvalidArgument(\"handle must be scalar\"));\n     const string& name = handle.scalar<tstring>()();\n     Tensor val;\n     auto session_state = ctx->session_state();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fv25-wrff-wf86",
    "API Signature": "tf.raw_ops.GetSessionTensor(\n    handle, dtype, name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "handle = tf.constant(\"[]\", shape=[0], dtype=tf.string)"
  },
  {
    "Title": "\n        Missing validation causes denial of service via `DeleteSessionTensor`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.DeleteSessionTensor  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "handle = tf.constant(\"[]\", shape=[0], dtype=tf.string)\n)\ntf.raw_ops.DeleteSessionTensor(handle=handle)",
    "Code change": [
      "@@ -134,6 +134,8 @@ class DeleteSessionTensorOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& handle = ctx->input(0);\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),\n+                errors::InvalidArgument(\"`handle` must be scalar\"));\n     const string& name = handle.scalar<tstring>()();\n     auto session_state = ctx->session_state();\n     OP_REQUIRES(ctx, session_state != nullptr,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h5g4-ppwx-48q2",
    "API Signature": "tf.raw_ops.DeleteSessionTensor(\n    handle, name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "handle = tf.constant(\"[]\", shape=[0], dtype=tf.string)"
  },
  {
    "Title": "\n        Missing validation crashes `QuantizeAndDequantizeV4Grad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.QuantizeAndDequantizeV4Grad  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n  gradients=tf.constant(1, shape=[2,2], dtype=tf.float64),\n  input=tf.constant(1, shape=[2,2], dtype=tf.float64),\n  input_min=tf.constant([], shape=[0], dtype=tf.float64),\n  input_max=tf.constant(-10, shape=[], dtype=tf.float64),\n  ),\n  axis=-1)",
    "Code change": [
      "@@ -174,13 +174,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n     OP_REQUIRES(ctx,\n                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                 errors::InvalidArgument(\n-                    \"Input min tensor must have dimension 1. Recieved \",\n+                    \"Input min tensor must have dimension 0 or 1. Received \",\n                     input_min_tensor.dims(), \".\"));\n     const Tensor& input_max_tensor = ctx->input(3);\n     OP_REQUIRES(ctx,\n                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                 errors::InvalidArgument(\n-                    \"Input max tensor must have dimension 1. Recieved \",\n+                    \"Input max tensor must have dimension 0 or 1. Received \",\n                     input_max_tensor.dims(), \".\"));\n     if (axis_ != -1) {\n       OP_REQUIRES(\n@@ -203,6 +203,12 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n \n     if (axis_ == -1) {\n+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n+                  errors::InvalidArgument(\n+                      \"input_min must be a scalar if axis is unspecified\"));\n+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n+                  errors::InvalidArgument(\n+                      \"input_max must be a scalar if axis is unspecified\"));\n       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n         input.template flat<T>(), input_min_tensor.scalar<T>(),\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h2wq-prv9-2f56",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n    gradients, input, input_min, input_max, axis=-1, name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "input_min=tf.constant([], shape=[0], dtype=tf.float64),\ninput_max=tf.constant(-10, shape=[], dtype=tf.float64),"
  },
  {
    "Title": "\n        Missing validation causes `TensorSummaryV2` to crash\n      ",
    "Bug description": "The implementation of  tf.raw_ops.TensorSummaryV2  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "import tensorflow as tf\n\ntf.raw_ops.TensorSummaryV2(\n  tag=np.array('test'),\n  tensor=np.array(3),\n  ),\n  serialized_summary_metadata=tf.io.encode_base64(np.empty((0))))",
    "Code change": [
      "@@ -36,6 +36,10 @@ class SummaryTensorOpV2 : public OpKernel {\n                 errors::InvalidArgument(\"tag must be scalar\"));\n     const Tensor& tensor = c->input(1);\n     const Tensor& serialized_summary_metadata_tensor = c->input(2);\n+    OP_REQUIRES(\n+        c,\n+        TensorShapeUtils::IsScalar(serialized_summary_metadata_tensor.shape()),\n+        errors::InvalidArgument(\"serialized_summary_metadata must be scalar\"));\n \n     Summary s;\n     Summary::Value* v = s.add_value();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2p9q-h29j-3f5v",
    "API Signature": null,
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": " serialized_summary_metadata=tf.io.encode_base64(np.empty((0)))"
  },
  {
    "Title": "\n        Missing validation causes `tf.sparse.split` to crash when `axis` is a tuple\n      ",
    "Bug description": "The implementation of  tf.sparse.split  does not fully validate the input arguments. Hence, a malicious user can trigger a denial of service via a segfault or a heap OOB read:",
    "Sample Code": "data = tf.random.uniform([1, 32, 32], dtype=tf.float32)\naxis = [1, 2]\nx = tf.sparse.from_dense(data)\n)\nresult = tf.sparse.split(x,3, axis=axis)",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-43q8-3fv7-pr5x",
    "API Signature": "tf.sparse.split(\n    sp_input=None, num_split=None, axis=None, name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "axis = [1, 2]"
  },
  {
    "Title": "\n        Integer overflow leading to crash in `SparseCountSparseOutput`\n      ",
    "Bug description": "The  implementation of   can be made to crash a TensorFlow process by an integer overflow whose result is then used in a memory allocation:",
    "Sample Code": "import numpy as np\n    \ntf.raw_ops.SparseCountSparseOutput(\n  indices=[[1,1]],\n  values=[2],\n  dense_shape=[2 ** 31, 2 ** 32],\n  weights=[1],\n  binary_output=True,\n  minlength=-1,\n  maxlength=-1,\n  ,\n  name=None)",
    "Code change": [
      "@@ -13,6 +13,8 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include <limits>\n+\n #include \"absl/container/flat_hash_map.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/op_requires.h\"\n@@ -23,6 +25,9 @@ limitations under the License.\n \n namespace tensorflow {\n \n+// Don't allocate too large `BatchedMap<T>` objects\n+static int kMaxBatches = std::numeric_limits<int>::max();\n+\n template <class T>\n using BatchedMap = std::vector<absl::flat_hash_map<int64_t, T>>;\n \n@@ -235,6 +240,10 @@ class SparseCount : public OpKernel {\n \n     bool is_1d = shape.NumElements() == 1;\n     int num_batches = is_1d ? 1 : shape_vector(0);\n+    OP_REQUIRES(\n+        context, 0 < num_batches && num_batches < kMaxBatches,\n+        errors::InvalidArgument(\"Cannot allocate \", num_batches,\n+                                \" batches, is the dense shape too wide?\"));\n \n     const auto values_values = values.flat<T>();\n     const auto weight_values = weights.flat<W>();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x4qx-4fjv-hmw6",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Large integer list element",
    "Category": "List",
    "Argument": "dense_shape=[2 ** 31, 2 ** 32],"
  },
  {
    "Title": "\n        Reference binding to null pointer in `QuantizedMaxPool`\n      ",
    "Bug description": "The  implementation of   has an undefined behavior where user controlled inputs can trigger a reference binding to null pointer.",
    "Sample Code": "tf.raw_ops.QuantizedMaxPool(\n    input = tf.constant([[[[4]]]], dtype=tf.quint8),\n    min_input = [],\n    max_input = [1],\n    ksize = [1, 1, 1, 1],\n    strides = [1, 1, 1, 1],\n    padding = \"SAME\", name=None\n)\n)",
    "Code change": [
      "@@ -15,6 +15,8 @@ limitations under the License.\n \n // See docs in ../ops/nn_ops.cc.\n \n+#include \"tensorflow/core/framework/op_requires.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #define EIGEN_USE_THREADS\n \n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n@@ -117,6 +119,18 @@ class QuantizedMaxPoolingOp : public MaxPoolingOp<Device, T> {\n       : MaxPoolingOp<Device, T>(context) {}\n \n   void Compute(OpKernelContext* context) override {\n+    auto min_input_tensor = context->input(1);\n+    auto max_input_tensor = context->input(2);\n+    OP_REQUIRES(\n+        context, min_input_tensor.NumElements() == 1,\n+        errors::InvalidArgument(\n+            \"min_input must be a scalar float value, got tensor with shape \",\n+            min_input_tensor.shape()));\n+    OP_REQUIRES(\n+        context, max_input_tensor.NumElements() == 1,\n+        errors::InvalidArgument(\n+            \"max_input must be a scalar float value, got tensor with shape \",\n+            max_input_tensor.shape()));\n     const float min_input = context->input(1).flat<float>()(0);\n     const float max_input = context->input(2).flat<float>()(0);\n     MaxPoolingOp<Device, T>::Compute(context);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-3mw4-6rj6-74g5",
    "API Signature": "tf.raw_ops.QuantizedMaxPool(\n    input, min_input, max_input, ksize, strides, padding, name=None\n)\n",
    "Score": 0.0035460992907801418,
    "Anomaly": "Non scalar input float",
    "Category": "Float",
    "Argument": "min_input = [],max_input = [1],"
  },
  {
    "Title": "\n        Division by zero in `FractionalMaxPool`\n      ",
    "Bug description": "The  implementation of   can be made to crash a TensorFlow process via a division by 0:",
    "Sample Code": "import numpy as np\n\ntf.raw_ops.FractionalMaxPool(\n  value=tf.constant(value=[[[[1, 4, 2, 3]]]], dtype=tf.int64),\n  pooling_ratio=[1.0, 1.44, 1.73, 1.0],\n  pseudo_random=False,\n  overlapping=False,\n  deterministic=False,\n  seed=0,\n  seed2=0,\n  ,\n  name=None)",
    "Code change": [
      "@@ -83,6 +83,13 @@ class FractionalMaxPoolOp : public OpKernel {\n     std::vector<int> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n       input_size[i] = tensor_in.dim_size(i);\n+\n+      OP_REQUIRES(\n+          context, input_size[i] >= pooling_ratio_[i],\n+          errors::InvalidArgument(\"Pooling ratio is higher than input \"\n+                                  \"dimension size for dimension \",\n+                                  i, \". Input dim size: \", input_size[i],\n+                                  \" pooling ratio: \", pooling_ratio_[i]));\n     }\n     // Output size.\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n",
      "@@ -20,6 +20,7 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gen_nn_ops\n@@ -319,6 +320,24 @@ class FractionalMaxPoolTest(test.TestCase):\n       nn_ops.fractional_max_pool(\n           rand_mat, [1, 1.5, 1.5, 1], seed=1, seed2=1, deterministic=True)\n \n+  def testPoolingRatio(self):\n+    with self.cached_session() as _:\n+      with self.assertRaisesRegex(\n+          errors.InvalidArgumentError,\n+          r\"Pooling ratio is higher than input dimension size for dimension 1.*\"\n+      ):\n+        result = nn_ops.gen_nn_ops.fractional_max_pool(\n+            value=constant_op.constant(\n+                value=[[[[1, 4, 2, 3]]]], dtype=dtypes.int64),\n+            pooling_ratio=[1.0, 1.44, 1.73, 1.0],\n+            pseudo_random=False,\n+            overlapping=False,\n+            deterministic=False,\n+            seed=0,\n+            seed2=0,\n+            name=None)\n+        self.evaluate(result)\n+\n \n class FractionalMaxPoolGradTest(test.TestCase):\n   \"\"\"Tests for FractionalMaxPoolGrad.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-87v6-crgm-2gfj",
    "API Signature": "tf.raw_ops.FractionalMaxPool(\n    value,\n    pooling_ratio,\n    pseudo_random=False,\n    overlapping=False,\n    deterministic=False,\n    seed=0,\n    seed2=0,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": " value=tf.constant(value=[[[[1, 4, 2, 3]]]], dtype=tf.int64),\n  pooling_ratio=[1.0, 1.44, 1.73, 1.0]"
  },
  {
    "Title": "\n        Integer overflows in `AddManySparseToTensorsMap`\n      ",
    "Bug description": "The  implementation of   is vulnerable to an integer overflow which results in a  CHECK -fail when building new  TensorShape  objects (so, an assert failure based denial of service):",
    "Sample Code": "import numpy as np\n\ntf.raw_ops.AddManySparseToTensorsMap(\n    sparse_indices=[(0,0),(0,1),(0,2),(4,3),(5,0),(5,1)],\n    sparse_values=[1,1,1,1,1,1],\n    sparse_shape=[2**32,2**32],\n    container='',\n    shared_name='',\n    ,\n    name=None)",
    "Code change": [
      "@@ -231,16 +231,29 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n                 errors::InvalidArgument(\n                     \"Input indices should be a matrix but received shape \",\n                     input_indices->shape().DebugString()));\n-\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                 errors::InvalidArgument(\n                     \"Input values should be a vector but received shape \",\n                     input_values->shape().DebugString()));\n-\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                 errors::InvalidArgument(\n                     \"Input shape should be a vector but received shape \",\n                     input_shape->shape().DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Number of values must match first dimension of indices. \", \"Got \",\n+            input_values->shape().dim_size(0),\n+            \" values, indices shape: \", input_indices->shape().DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", input_shape->shape().dim_size(0),\n+            \" dimensions, indices shape: \",\n+            input_indices->shape().DebugString()));\n \n     int rank = input_shape->NumElements();\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6445-fm66-fvq2",
    "API Signature": "tf.raw_ops.AddManySparseToTensorsMap(\n    sparse_indices,\n    sparse_values,\n    sparse_shape,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "    sparse_indices=[(0,0),(0,1),(0,2),(4,3),(5,0),(5,1)],\n    sparse_values=[1,1,1,1,1,1],\n    sparse_shape=[2**32,2**32],"
  },
  {
    "Title": "\n        Integer overflows in most sparse component-wise ops\n      ",
    "Bug description": "The  implementations of   are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or  CHECK -fails when building new  TensorShape  objects (so, assert failures based denial of service):",
    "Sample Code": "import numpy as np\n\ntf.raw_ops.SparseDenseCwiseDiv(\n    sp_indices=np.array([[9]]),\n    sp_values=np.array([5]),\n    sp_shape=np.array([92233720368., 92233720368]),\n    ]),\n    dense=np.array([4]))",
    "Code change": [
      "@@ -78,11 +78,24 @@ class SparseDenseBinaryOpShared : public OpKernel {\n                     \"but received shapes: \",\n                     values_t->shape().DebugString(), \" and \",\n                     shape_t->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsVector(shape_t->shape()),\n+        errors::InvalidArgument(\"Input sp_shape must be a vector. Got: \",\n+                                shape_t->shape().DebugString()));\n     OP_REQUIRES(\n         ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n         errors::InvalidArgument(\n             \"The first dimension of values and indices should match. (\",\n             values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n+    OP_REQUIRES(\n+        ctx, shape_t->shape().dim_size(0) == indices_t->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", shape_t->shape().dim_size(0),\n+            \" dimensions, indices shape: \", indices_t->shape().DebugString()));\n+    OP_REQUIRES(ctx, shape_t->NumElements() > 0,\n+                errors::InvalidArgument(\n+                    \"The shape argument requires at least one element.\"));\n \n     const auto indices_mat = indices_t->matrix<int64_t>();\n     const auto shape_vec = shape_t->vec<int64_t>();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rrx2-r989-2c43",
    "API Signature": "tf.raw_ops.SparseDenseCwiseDiv(\n    sp_indices, sp_values, sp_shape, dense, name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Non vector input",
    "Category": NaN,
    "Argument": "sp_shape=np.array([92233720368., 92233720368]),"
  },
  {
    "Title": "\n        Integer overflows in most sparse component-wise ops\n      ",
    "Bug description": "The  implementations of   are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or  CHECK -fails when building new  TensorShape  objects (so, assert failures based denial of service):",
    "Sample Code": "import numpy as np\n\ntf.raw_ops.SparseDenseCwiseDiv(\n    sp_indices=np.array([[9]]),\n    sp_values=np.array([5]),\n    sp_shape=np.array([92233720368., 92233720368]),\n    ]),\n    dense=np.array([4]))",
    "Code change": [
      "@@ -78,11 +78,24 @@ class SparseDenseBinaryOpShared : public OpKernel {\n                     \"but received shapes: \",\n                     values_t->shape().DebugString(), \" and \",\n                     shape_t->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsVector(shape_t->shape()),\n+        errors::InvalidArgument(\"Input sp_shape must be a vector. Got: \",\n+                                shape_t->shape().DebugString()));\n     OP_REQUIRES(\n         ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n         errors::InvalidArgument(\n             \"The first dimension of values and indices should match. (\",\n             values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n+    OP_REQUIRES(\n+        ctx, shape_t->shape().dim_size(0) == indices_t->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", shape_t->shape().dim_size(0),\n+            \" dimensions, indices shape: \", indices_t->shape().DebugString()));\n+    OP_REQUIRES(ctx, shape_t->NumElements() > 0,\n+                errors::InvalidArgument(\n+                    \"The shape argument requires at least one element.\"));\n \n     const auto indices_mat = indices_t->matrix<int64_t>();\n     const auto shape_vec = shape_t->vec<int64_t>();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rrx2-r989-2c43",
    "API Signature": "tf.raw_ops.SparseDenseCwiseDiv(\n    sp_indices, sp_values, sp_shape, dense, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": NaN,
    "Argument": "sp_indices=np.array([[9]]),"
  },
  {
    "Title": "\n        OOM due to integer overflow in `StringNGrams`\n      ",
    "Bug description": "The  implementation of   can be used to trigger a denial of service attack by causing an OOM condition after an integer overflow:",
    "Sample Code": "tf.raw_ops.StringNGrams(\n  data=['123456'],\n  data_splits=[0,1],\n  separator='a'*15,\n  ngram_widths=[],\n  left_pad='',\n  right_pad='',\n  pad_width=-5, \n  , \n  preserve_short_sequences=True)",
    "Code change": [
      "@@ -152,6 +152,16 @@ class StringNGramsOp : public tensorflow::OpKernel {\n         // We don't have to worry about dynamic padding sizes here: if padding\n         // was dynamic, every sequence would have had sufficient padding to\n         // generate at least one ngram.\n+\n+        // If reached here, pad_width should be > 0, pad_width_ = -1,\n+        // which indicates max(ngram_widths) - 1 cannot be used here since\n+        // ngram_width is not known.\n+        OP_REQUIRES(\n+            context, pad_width_ >= 0,\n+            errors::InvalidArgument(\"Pad width should be >= 0 when \"\n+                                    \"preserve_short_sequences is True and \"\n+                                    \"ngram_widths are not provided, got \",\n+                                    pad_width_));\n         int ngram_width = data_length + 2 * pad_width_;\n         auto output_start = &ngrams_data[output_start_idx];\n         int num_ngrams = 1;\n",
      "@@ -28,7 +28,6 @@ from tensorflow.python.platform import test\n \n \n @test_util.run_all_in_graph_and_eager_modes\n-@test_util.disable_tfrt\n class RawOpsTest(test.TestCase, parameterized.TestCase):\n \n   def testSimple(self):\n@@ -63,8 +62,9 @@ class RawOpsTest(test.TestCase, parameterized.TestCase):\n   @parameterized.parameters([[0, 8]], [[-1, 6]])\n   def testStringNGramsBadDataSplits(self, splits):\n     data = [\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\"]\n-    with self.assertRaisesRegex(errors.InvalidArgumentError,\n-                                \"Invalid split value\"):\n+    with self.assertRaisesRegex(\n+        errors.InvalidArgumentError,\n+        r\"Invalid split value|First split value must be 0\"):\n       self.evaluate(\n           gen_string_ops.string_n_grams(\n               data=data,\n@@ -76,6 +76,25 @@ class RawOpsTest(test.TestCase, parameterized.TestCase):\n               pad_width=0,\n               preserve_short_sequences=False))\n \n+  def testStringSplit(self):\n+    data = [\"123456\"]\n+    data_splits = [0, 1]\n+    separator = \"a\" * 15\n+    ngram_widths = []\n+    pad_width = -5\n+    left_pad = right_pad = \"\"\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                \"Pad width should be >= 0\"):\n+      self.evaluate(gen_string_ops.string_n_grams(\n+          data=data,\n+          data_splits=data_splits,\n+          separator=separator,\n+          ngram_widths=ngram_widths,\n+          left_pad=left_pad,\n+          right_pad=right_pad,\n+          pad_width=pad_width,\n+          preserve_short_sequences=True))\n+\n   def testGetSessionHandle(self):\n     if context.executing_eagerly():\n       with self.assertRaisesRegex(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-98j8-c9q4-r38g",
    "API Signature": "tf.raw_ops.StringNGrams(\n    data,\n    data_splits,\n    separator,\n    ngram_widths,\n    left_pad,\n    right_pad,\n    pad_width,\n    preserve_short_sequences,\n    name=None\n)\n",
    "Score": 0.03900709219858156,
    "Anomaly": "Negative integer argument",
    "Category": "Integer",
    "Argument": "pad_width=-5, "
  },
  {
    "Title": "\n        OOM in `ThreadPoolHandle`\n      ",
    "Bug description": "The  implementation of   can be used to trigger a denial of service attack by allocating too much memory:",
    "Sample Code": " tensorflow as tf\ny = tf.raw_ops.ThreadPoolHandle(num_threads=0x60000000,display_name='tf')",
    "Code change": [
      "@@ -39,6 +39,22 @@ namespace experimental {\n     PrivateThreadPoolDatasetOp::kDatasetType;\n /* static */ constexpr const char* const PrivateThreadPoolDatasetOp::kDatasetOp;\n \n+namespace {\n+// To prevent integer overflow issues when allocating threadpool memory for an\n+// unreasonable number of threads.\n+constexpr int kThreadLimit = 65536;\n+\n+Status ValidateNumThreads(int32_t num_threads) {\n+  if (num_threads < 0) {\n+    return errors::InvalidArgument(\"`num_threads` must be >= 0\");\n+  }\n+  if (num_threads >= kThreadLimit) {\n+    return errors::InvalidArgument(\"`num_threads` must be < \", kThreadLimit);\n+  }\n+  return Status::OK();\n+}\n+}  // namespace\n+\n class ThreadPoolResource : public ResourceBase {\n  public:\n   ThreadPoolResource(Env* env, const ThreadOptions& thread_options,\n@@ -83,9 +99,7 @@ class ThreadPoolHandleOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_threads\", &num_threads_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"max_intra_op_parallelism\",\n                                      &max_intra_op_parallelism_));\n-    OP_REQUIRES(\n-        ctx, num_threads_ > 0,\n-        errors::InvalidArgument(\"`num_threads` must be greater than zero.\"));\n+    OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads_));\n   }\n \n   // The resource is deleted from the resource manager only when it is private\n@@ -531,8 +545,7 @@ void PrivateThreadPoolDatasetOp::MakeDatasetFromOptions(OpKernelContext* ctx,\n                                                         DatasetBase* input,\n                                                         int32_t num_threads,\n                                                         DatasetBase** output) {\n-  OP_REQUIRES(ctx, num_threads >= 0,\n-              errors::InvalidArgument(\"`num_threads` must be >= 0\"));\n+  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));\n   *output = new Dataset(ctx,\n                         DatasetContext(DatasetContext::Params(\n                             {PrivateThreadPoolDatasetOp::kDatasetType,\n@@ -546,8 +559,7 @@ void PrivateThreadPoolDatasetOp::MakeDataset(OpKernelContext* ctx,\n   int64_t num_threads = 0;\n   OP_REQUIRES_OK(\n       ctx, ParseScalarArgument<int64_t>(ctx, \"num_threads\", &num_threads));\n-  OP_REQUIRES(ctx, num_threads >= 0,\n-              errors::InvalidArgument(\"`num_threads` must be >= 0\"));\n+  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));\n   *output = new Dataset(ctx, input, num_threads);\n }\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c582-c96p-r5cq",
    "API Signature": "tf.raw_ops.ThreadPoolHandle(\n    num_threads,\n    display_name,\n    max_intra_op_parallelism=1,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Large integer argument",
    "Category": "Integer",
    "Argument": "num_threads=0x60000000"
  },
  {
    "Title": "\n        Type confusion in shape inference for `ConcatV2`\n      ",
    "Bug description": "The  implementation of shape inference for   can be used to trigger a denial of service attack via a segfault caused by a type confusion:",
    "Sample Code": "@\ndef test():\n  y = tf.raw_ops.ConcatV2(\n    values=[[1,2,3],[4,5,6]],\n    axis = 0xb500005b)\n  return y\n\n\n\ntest()",
    "Code change": [
      "@@ -2005,7 +2005,7 @@ Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n   }\n \n   // Minimum required number of dimensions.\n-  const int min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n+  const int64 min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n \n   ShapeHandle output_before;\n   ShapeHandle output_after;\n",
      "@@ -16,6 +16,7 @@\n \n import numpy as np\n \n+from tensorflow.python.eager import def_function\n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors_impl\n@@ -570,6 +571,17 @@ class ConcatOpTest(test.TestCase):\n         t2 = [2]\n         gen_array_ops.concat_v2([t1, t2], 1).eval()\n \n+  def testConcatInvalidAxisInTfFunction(self):\n+\n+    @def_function.function\n+    def concat_wrapper():\n+      y = gen_array_ops.concat_v2(\n+          values=[[1, 2, 3], [4, 5, 6]], axis=0xb500005b)\n+      return y\n+\n+    with self.assertRaises(ValueError):\n+      concat_wrapper()\n+\n   def testConcatNegativeAxis(self):\n     with test_util.use_gpu():\n       t1 = [[1, 2, 3], [4, 5, 6]]\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m4hf-j54p-p353",
    "API Signature": "tf.raw_ops.ConcatV2(\n    values, axis, name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Large integer argument",
    "Category": "Integer",
    "Argument": "axis = 0xb500005b"
  },
  {
    "Title": "\n        Overflow and divide by zero in `UnravelIndex`\n      ",
    "Bug description": "The  implementation of   is vulnerable to a division by zero caused by an integer overflow bug:",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.UnravelIndex(indices=-0x100000,dims=[0x100000,0x100000])",
    "Code change": [
      "@@ -13,6 +13,10 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include <cstdint>\n+\n+#include \"tensorflow/core/framework/types.pb.h\"\n+#include \"tensorflow/core/platform/types.h\"\n #define EIGEN_USE_THREADS\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n@@ -35,7 +39,8 @@ typedef Eigen::ThreadPoolDevice CPUDevice;\n template <typename Tidx>\n class UnravelIndexOp : public OpKernel {\n  public:\n-  explicit UnravelIndexOp(OpKernelConstruction* ctx) : OpKernel(ctx) {}\n+  explicit UnravelIndexOp(OpKernelConstruction* ctx)\n+      : OpKernel(ctx), dtidx_(DataTypeToEnum<Tidx>::v()) {}\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& indices_tensor = ctx->input(0);\n@@ -54,12 +59,31 @@ class UnravelIndexOp : public OpKernel {\n \n     auto dims = dims_tensor.vec<Tidx>();\n     // Make sure dims does not contain a zero\n+    double prod = 1;\n+    uint64_t limit;\n+    if (dtidx_ == DataType::DT_INT64) {\n+      limit = kint64max;\n+    } else {\n+      limit = kint32max;\n+    }\n+\n     for (int i = 0; i < dims.size(); i++) {\n       OP_REQUIRES(\n           ctx, dims(i) != 0,\n           errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"\n                                   \"but dims contains zero at index \",\n                                   i));\n+      OP_REQUIRES(ctx, dims(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"Input dims cannot be negative. Got dim = \", dims(i),\n+                      \" at index \", i));\n+      // Check interger overflow\n+      OP_REQUIRES(\n+          ctx, prod <= limit / dims(i),\n+          errors::InvalidArgument(\"Input dims product is causing integer \"\n+                                  \"overflow: (\",\n+                                  dims, \")\"));\n+      prod = (prod * dims(i));\n     }\n \n     // Check to make sure indices is not out of boundary\n@@ -132,6 +156,7 @@ class UnravelIndexOp : public OpKernel {\n                strides_shifted.reshape(reshape).broadcast(bcast);\n     }\n   }\n+  const DataType dtidx_;\n };\n \n #define REGISTER_KERNEL(type)                                               \\\n",
      "@@ -1580,6 +1580,20 @@ class UnravelIndexTest(test_util.TensorFlowTestCase):\n           dims = constant_op.constant([3, 0], dtype=dtype)\n           self.evaluate(array_ops.unravel_index(indices=indices, dims=dims))\n \n+  def testUnravelIndexIntegerOverflow(self):\n+    with self.cached_session():\n+      for dtype in [dtypes.int32, dtypes.int64]:\n+        with self.assertRaisesRegex(\n+            errors.InvalidArgumentError,\n+            r\"Input dims product is causing integer overflow\"):\n+          indices = constant_op.constant(-0x100000, dtype=dtype)\n+          if dtype == dtypes.int32:\n+            value = 0x10000000\n+          else:\n+            value = 0x7FFFFFFFFFFFFFFF\n+          dims = constant_op.constant([value, value], dtype=dtype)\n+          self.evaluate(array_ops.unravel_index(indices=indices, dims=dims))\n+\n \n class GuaranteeConstOpTest(test_util.TensorFlowTestCase):\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-34f9-hjfq-rr8j",
    "API Signature": "tf.raw_ops.UnravelIndex(\n    indices, dims, name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Large integer list element",
    "Category": "List",
    "Argument": "dims=[0x100000,0x100000]"
  },
  {
    "Title": "\n        Heap OOB access in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The  implementation of   does not consider cases where the input tensors are invalid allowing an attacker to read from outside of bounds of heap:",
    "Sample Code": "@\ndef test():\n  y = tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape=[2,2,2,2],\n    out_backprop=[[[[1,2], [3, 4], [5, 6]], [[7, 8], [9,10], [11,12]]]],\n    row_pooling_sequence=[-10,1,2,3],\n    col_pooling_sequence=[1,2,3,4],\n    overlapping=True)\n  return y\n    \n\n    \ntest()",
    "Code change": [
      "@@ -311,15 +311,26 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     for (int64_t b = 0; b < out_batch; ++b) {\n       for (int64_t r = 0; r < out_rows; ++r) {\n         const int64_t in_row_start = row_seq_tensor_flat(r);\n+\n         int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)\n                                           : row_seq_tensor_flat(r + 1) - 1;\n         in_row_end = std::min(in_row_end, in_max_row_index);\n+        OP_REQUIRES(context, in_row_start >= 0 && in_row_end >= 0,\n+                    errors::InvalidArgument(\n+                        \"Row sequence tensor values must not be negative, got \",\n+                        row_seq_tensor_flat));\n+\n         for (int64_t c = 0; c < out_cols; ++c) {\n           const int64_t in_col_start = col_seq_tensor_flat(c);\n           int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)\n                                             : col_seq_tensor_flat(c + 1) - 1;\n           in_col_end = std::min(in_col_end, in_max_col_index);\n \n+          OP_REQUIRES(\n+              context, in_col_start >= 0 && in_col_end >= 0,\n+              errors::InvalidArgument(\n+                  \"Column sequence tensor values must not be negative, got \",\n+                  col_seq_tensor_flat));\n           const int64_t num_elements_in_pooling_cell =\n               (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);\n           const int64_t out_index = (b * out_rows + r) * out_cols + c;\n",
      "@@ -20,6 +20,7 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gen_nn_ops\n@@ -306,6 +307,32 @@ class FractionalAvgTest(test.TestCase):\n           input_b, row_seq, col_seq, overlapping)\n       self.assertSequenceEqual(expected.shape, actual.shape)\n \n+  def testNegativeSeqValuesForGradOp(self):\n+    with self.assertRaisesRegex(\n+        errors.InvalidArgumentError,\n+        r\"Row sequence tensor values must not be negative.*\"):\n+      y = nn_ops.gen_nn_ops.fractional_avg_pool_grad(\n+          orig_input_tensor_shape=[2, 2, 2, 2],\n+          out_backprop=[[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11,\n+                                                                      12]]]],\n+          row_pooling_sequence=[-10, 1, 2, 3],\n+          col_pooling_sequence=[1, 2, 3, 4],\n+          overlapping=True)\n+\n+      self.evaluate(y)\n+      with self.assertRaisesRegex(\n+          errors.InvalidArgumentError,\n+          r\"Column sequence tensor values must not be negative.*\"):\n+        z = nn_ops.gen_nn_ops.fractional_avg_pool_grad(\n+            orig_input_tensor_shape=[2, 2, 2, 2],\n+            out_backprop=[[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11,\n+                                                                        12]]]],\n+            row_pooling_sequence=[10, 1, 2, 3],\n+            col_pooling_sequence=[1, 2, -3, 4],\n+            overlapping=True)\n+\n+        self.evaluate(z)\n+\n \n class FractionalAvgPoolGradTest(test.TestCase):\n   \"\"\"Tests for FractionalAvgPoolGrad.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vjg4-v33c-ggc4",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Negative integer list element",
    "Category": "List",
    "Argument": "row_pooling_sequence=[-10,1,2,3],\ncol_pooling_sequence=[1,2,3,4],"
  },
  {
    "Title": "\n        Integer overflow in shape inference for `Dequantize`\n      ",
    "Bug description": "The  implementation of shape inference for   is vulnerable to an integer overflow weakness:",
    "Sample Code": "input = tf.constant([1,1],dtype=tf.qint32)\n\n@\ndef test():\n  y = tf.raw_ops.Dequantize(\n    input=input,\n    min_range=[1.0],\n    max_range=[10.0],\n    mode='MIN_COMBINED',\n    narrow_range=False,\n    axis=2**31-1,\n    dtype=tf.bfloat16)\n  return y\n\n\n\ntest()",
    "Code change": [
      "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/framework/types.pb.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/types.h\"\n #include \"tensorflow/core/util/mirror_pad_mode.h\"\n #include \"tensorflow/core/util/padding.h\"\n #include \"tensorflow/core/util/strided_slice_op.h\"\n@@ -3028,6 +3029,12 @@ REGISTER_OP(\"Dequantize\")\n         return errors::InvalidArgument(\"axis should be at least -1, got \",\n                                        axis);\n       }\n+      auto input_dims = c->Rank(c->input(0));\n+      if (axis > input_dims) {\n+        return errors::InvalidArgument(\n+            \"Axis must be less than input dimension(\", input_dims, \"), got \",\n+            axis);\n+      }\n       const int minmax_rank = (axis == -1) ? 0 : 1;\n       TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n       ShapeHandle minmax;\n@@ -3035,6 +3042,13 @@ REGISTER_OP(\"Dequantize\")\n       TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));\n       if (axis != -1) {\n         ShapeHandle input;\n+        if (axis >= kint32max) {\n+          // Check int32 max bound for a corner case to prevent integer flow\n+          // when input actually has kint32max rank and above bound check is not\n+          // triggered.\n+          return errors::InvalidArgument(\n+              \"Axis cannot be >= kint32max value, got \", axis);\n+        }\n         TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n         DimensionHandle depth;\n         TF_RETURN_IF_ERROR(\n",
      "@@ -1704,6 +1704,21 @@ class QuantizeAndDequantizeTest(test_util.TensorFlowTestCase):\n       output_grad = gradient_checker_v2.compute_gradient(f, [input_tensor])\n       self.assertAllClose(output_grad[0], np.zeros([1, 4, 4]))\n \n+  def testOutOfBoundAxis(self):\n+    input_tensor = constant_op.constant([1., 1.])\n+    input_min = [0]\n+    input_max = [1]\n+    q_input, _, _ = array_ops.quantize(input_tensor, 0, 1, dtypes.qint32)\n+    error = (errors.InvalidArgumentError, ValueError)\n+    with self.assertRaisesRegex(error,\n+                                r\".*Axis must be less than input dimension.*\"):\n+      self.evaluate(\n+          gen_array_ops.dequantize(\n+              input=q_input,\n+              min_range=input_min,\n+              max_range=input_max,\n+              axis=2**31 - 1))\n+\n \n @test_util.run_all_in_graph_and_eager_modes\n class SortedSearchTest(test_util.TensorFlowTestCase):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c6fh-56w7-fvjw",
    "API Signature": "tf.raw_ops.Dequantize(\n    input,\n    min_range,\n    max_range,\n    mode='MIN_COMBINED',\n    narrow_range=False,\n    axis=-1,\n    dtype=tf.dtypes.float32,\n    name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Large integer argument",
    "Category": "Integer",
    "Argument": "axis=2**31-1,"
  },
  {
    "Title": "\n        Heap OOB read in shape inference for `ReverseSequence`\n      ",
    "Bug description": "The  implementation of shape inference for   does not fully validate the value of  batch_dim  and can result in a heap OOB read:",
    "Sample Code": "@\ndef test():\n  y = tf.raw_ops.ReverseSequence(\n    input = ['aaa','bbb'],\n    seq_lengths = [1,1,1],\n    seq_dim = -10,\n    batch_dim = -10 )\n  return y\n    \n\n    \ntest()",
    "Code change": [
      "@@ -1653,11 +1653,21 @@ REGISTER_OP(\"ReverseSequence\")\n         return errors::InvalidArgument(\n             \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);\n       }\n+\n       if (seq_dim >= input_rank) {\n         return errors::InvalidArgument(\n             \"seq_dim must be < input rank: \", seq_dim, \" vs. \", input_rank);\n       }\n \n+      // To prevent out of bound access when calling c->Dim(input, batch_dim),\n+      // batch_dim range [-1 * input rank, input rank) is allowed. However,\n+      // the op implementation has a stricter bound for batch_dim requiring >= 0\n+      // value. Thus, perform strict check here.\n+      if (batch_dim < 0) {\n+        return errors::InvalidArgument(\"batch_dim must be >=0, got \",\n+                                       batch_dim);\n+      }\n+\n       DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);\n       TF_RETURN_IF_ERROR(\n           c->Merge(batch_dim_dim, c->Dim(seq_lens_shape, 0), &batch_dim_dim));\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6gmv-pjp9-p8w8",
    "API Signature": "tf.raw_ops.ReverseSequence(\n    input, seq_lengths, seq_dim, batch_dim=0, name=None\n)\n",
    "Score": 0.03900709219858156,
    "Anomaly": "Negative integer argument",
    "Category": "Integer",
    "Argument": "batch_dim = -10"
  },
  {
    "Title": "\n        Floating point division by 0 when executing convolution operators\n      ",
    "Bug description": "The  estimator for the cost of some convolution operations  can be made to execute a division by 0:",
    "Sample Code": "@\ndef test():\n  y=tf.raw_ops.AvgPoolGrad(\n    orig_input_shape=[1,1,1,1],\n    grad=[[[[1.0],[1.0],[1.0]]],[[[2.0],[2.0],[2.0]]],[[[3.0],[3.0],[3.0]]]],\n    ksize=[1,1,1,1],\n    strides=[1,1,1,0],\n    padding='VALID',\n    data_format='NCHW')\n  return y\n\n\n\ntest()",
    "Code change": [
      "@@ -355,6 +355,7 @@ tf_cc_test(\n         \"//tensorflow/core:protos_all_cc\",\n         \"//tensorflow/core:test\",\n         \"//tensorflow/core:test_main\",\n+        \"//tensorflow/core/platform:status_matchers\",\n     ],\n )\n \n",
      "@@ -2153,7 +2153,7 @@ OpInfo::TensorProperties OpLevelCostEstimator::DescribeTensor(\n }\n \n /* static */\n-OpLevelCostEstimator::ConvolutionDimensions\n+StatusOr<OpLevelCostEstimator::ConvolutionDimensions>\n OpLevelCostEstimator::OpDimensionsFromInputs(\n     const TensorShapeProto& original_image_shape, const OpInfo& op_info,\n     bool* found_unknown_shapes) {\n@@ -2190,6 +2190,11 @@ OpLevelCostEstimator::OpDimensionsFromInputs(\n   std::vector<int64_t> strides = GetStrides(op_info);\n   int64_t sx = strides[x_index];\n   int64_t sy = strides[y_index];\n+  if (sx == 0 || sy == 0) {\n+    return errors::InvalidArgument(\n+        \"Stride must be > 0 for Height and Width, but got (\", sy, \", \", sx,\n+        \")\");\n+  }\n   const auto padding = GetPadding(op_info);\n \n   int64_t ox = GetOutputSize(ix, kx, sx, padding);\n@@ -2206,8 +2211,9 @@ Status OpLevelCostEstimator::PredictMaxPool(const OpContext& op_context,\n   bool found_unknown_shapes = false;\n   const auto& op_info = op_context.op_info;\n   // x: op_info.inputs(0)\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n   // kx * ky - 1 comparisons per output (kx * xy > 1)\n   // or 1 copy per output (kx * k1 = 1).\n   int per_output_ops = dims.kx * dims.ky == 1 ? 1 : dims.kx * dims.ky - 1;\n@@ -2248,8 +2254,9 @@ Status OpLevelCostEstimator::PredictMaxPoolGrad(const OpContext& op_context,\n                                    op_info.ShortDebugString());\n   }\n \n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n \n   int64_t ops = 0;\n   if (dims.kx == 1 && dims.ky == 1) {\n@@ -2324,8 +2331,9 @@ Status OpLevelCostEstimator::PredictAvgPool(const OpContext& op_context,\n   bool found_unknown_shapes = false;\n   const auto& op_info = op_context.op_info;\n   // x: op_info.inputs(0)\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n \n   // kx * ky - 1 additions and 1 multiplication per output.\n   int64_t ops = dims.batch * dims.ox * dims.oy * dims.oz * dims.kx * dims.ky;\n@@ -2382,8 +2390,9 @@ Status OpLevelCostEstimator::PredictAvgPoolGrad(const OpContext& op_context,\n     found_unknown_shapes = true;\n   }\n \n-  ConvolutionDimensions dims =\n-      OpDimensionsFromInputs(x_shape, op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(\n+      ConvolutionDimensions dims,\n+      OpDimensionsFromInputs(x_shape, op_info, &found_unknown_shapes));\n \n   int64_t ops = 0;\n   if (dims.kx <= dims.sx && dims.ky <= dims.sy) {\n@@ -2409,8 +2418,9 @@ Status OpLevelCostEstimator::PredictFusedBatchNorm(\n   // offset: op_info.inputs(2)\n   // mean: op_info.inputs(3)  --> only for inference\n   // variance: op_info.inputs(4) --> only for inference\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n   const bool is_training = IsTraining(op_info);\n \n   int64_t ops = 0;\n@@ -2459,8 +2469,9 @@ Status OpLevelCostEstimator::PredictFusedBatchNormGrad(\n   // scale: op_info.inputs(2)\n   // mean: op_info.inputs(3)\n   // variance or inverse of variance: op_info.inputs(4)\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(1).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(1).shape(), op_info,\n+                                             &found_unknown_shapes));\n \n   int64_t ops = 0;\n   const auto rsqrt_cost = Eigen::internal::functor_traits<\n",
      "@@ -290,7 +290,7 @@ class OpLevelCostEstimator {\n       bool* found_unknown_shapes);\n \n   // For Pooling, FusedBatchNorm, and their grad ops.\n-  static ConvolutionDimensions OpDimensionsFromInputs(\n+  static StatusOr<ConvolutionDimensions> OpDimensionsFromInputs(\n       const TensorShapeProto& original_image_shape, const OpInfo& op_info,\n       bool* found_unknown_shapes);\n \n",
      "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/tensor_shape.pb.h\"\n #include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/platform/status_matchers.h\"\n #include \"tensorflow/core/platform/test.h\"\n #include \"tensorflow/core/protobuf/device_properties.pb.h\"\n \n@@ -558,9 +559,10 @@ class OpLevelCostEstimatorTest : public ::testing::Test {\n     }\n \n     bool found_unknown_shapes;\n-    auto dims = OpLevelCostEstimator::OpDimensionsFromInputs(\n-        op_context.op_info.inputs(0).shape(), op_context.op_info,\n-        &found_unknown_shapes);\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto dims, OpLevelCostEstimator::OpDimensionsFromInputs(\n+                       op_context.op_info.inputs(0).shape(), op_context.op_info,\n+                       &found_unknown_shapes));\n     Padding padding_enum;\n     if (padding == \"VALID\") {\n       padding_enum = Padding::VALID;\n@@ -581,6 +583,38 @@ class OpLevelCostEstimatorTest : public ::testing::Test {\n     EXPECT_EQ(padding_enum, dims.padding);\n   }\n \n+  StatusOr<OpLevelCostEstimator::ConvolutionDimensions>\n+  CallOpDimensionsFromInputs(const int n, const int h, const int w, const int c,\n+                             const int kx, const int ky, const int sx,\n+                             const int sy, const string& data_format,\n+                             const string& padding) {\n+    OpContext op_context;\n+\n+    const std::vector<int> x = {n, h, w, c};\n+    const std::vector<int> ksize = {1, kx, ky, 1};\n+    std::vector<int> strides;\n+    if (data_format == \"NHWC\") {\n+      strides = {1, sy, sx, 1};\n+    } else {\n+      strides = {1, 1, sy, sx};\n+    }\n+\n+    auto& op_info = op_context.op_info;\n+    SetCpuDevice(&op_info);\n+    op_info.set_op(\"MaxPool\");\n+\n+    DescribeTensor4D(x[0], x[1], x[2], x[3], op_info.add_inputs());\n+    auto* attr = op_info.mutable_attr();\n+    SetAttrValue(data_format, &(*attr)[\"data_format\"]);\n+    SetAttrValue(padding, &(*attr)[\"padding\"]);\n+    SetAttrValue(strides, &(*attr)[\"strides\"]);\n+    SetAttrValue(ksize, &(*attr)[\"ksize\"]);\n+    bool found_unknown_shapes;\n+    return OpLevelCostEstimator::OpDimensionsFromInputs(\n+        op_context.op_info.inputs(0).shape(), op_context.op_info,\n+        &found_unknown_shapes);\n+  }\n+\n   OpLevelCostEstimator estimator_;\n };\n \n@@ -1383,6 +1417,26 @@ TEST_F(OpLevelCostEstimatorTest, OpDimensionsFromInputs) {\n   }\n }\n \n+TEST_F(OpLevelCostEstimatorTest, OpDimensionsFromInputsError) {\n+  std::vector<string> paddings = {\"VALID\", \"SAME\"};\n+  std::vector<string> formats = {\"NHWC\", \"NCHW\"};\n+  for (const auto& p : paddings) {\n+    for (const auto& f : formats) {\n+      // n, h, w, c, kx, ky, sx, sy, data_format, padding.\n+      ASSERT_THAT(\n+          CallOpDimensionsFromInputs(10, 14, 14, 3840, 3, 3, 0, 2, f, p),\n+          testing::StatusIs(\n+              error::INVALID_ARGUMENT,\n+              \"Stride must be > 0 for Height and Width, but got (2, 0)\"));\n+      ASSERT_THAT(\n+          CallOpDimensionsFromInputs(10, 14, 14, 3840, 3, 3, 2, 0, f, p),\n+          testing::StatusIs(\n+              error::INVALID_ARGUMENT,\n+              \"Stride must be > 0 for Height and Width, but got (0, 2)\"));\n+    }\n+  }\n+}\n+\n TEST_F(OpLevelCostEstimatorTest, PredictMaxPool) {\n   auto predict_max_pool = [this](const int n, const int in, const int c,\n                                  const int k, const int s,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v3f7-j968-4h5f",
    "API Signature": "tf.raw_ops.AvgPoolGrad(\n    orig_input_shape,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NHWC',\n    name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Negative integer list element",
    "Category": "List",
    "Argument": "strides=[1,1,1,0],"
  },
  {
    "Title": "\n        `SparseFillEmptyRows` heap OOB\n      ",
    "Bug description": "The  implementation  of  SparseFillEmptyRows  can be made to trigger a heap OOB access:",
    "Sample Code": "data=tf.raw_ops.SparseFillEmptyRows(\n  indices=[[0,0],[0,0],[0,0]],\n  values=['sssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss'],\n  dense_shape=[5,3],\n  ],\n  default_value='o')",
    "Code change": [
      "@@ -24,11 +24,13 @@ limitations under the License.\n #include <vector>\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/util/sparse/sparse_tensor.h\"\n \n namespace tensorflow {\n@@ -222,6 +224,12 @@ void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                     errors::InvalidArgument(\"values must be a vector, saw: \",\n                                             values_t.shape().DebugString()),\n                     done);\n+  OP_REQUIRES_ASYNC(\n+      context, indices_t.dim_size(0) == values_t.dim_size(0),\n+      errors::InvalidArgument(\"The length of `values` (\", values_t.dim_size(0),\n+                              \") must match the first dimension of `indices` (\",\n+                              indices_t.dim_size(0), \").\"),\n+      done);\n   OP_REQUIRES_ASYNC(\n       context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n       errors::InvalidArgument(\"default_value must be a scalar, saw: \",\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rg3m-hqc5-344v",
    "API Signature": "tf.raw_ops.SparseFillEmptyRows(\n    indices, values, dense_shape, default_value, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "indices=[[0,0],[0,0],[0,0]],\nvalues=['sssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss'],"
  },
  {
    "Title": "\n        Segfault due to negative splits in `SplitV`\n      ",
    "Bug description": "The  implementation  of  SplitV  can trigger a segfault is an attacker supplies negative arguments:",
    "Sample Code": "tf.raw_ops.SplitV(\n  value=tf.constant([]),\n  size_splits=[-1, -2]\n  ,axis=0,\n  ,\n  num_split=2)",
    "Code change": [
      "@@ -138,6 +138,13 @@ class SplitVOpBase : public OpKernel {\n       (*split_sizes_vec)[neg_one_dim] = input_size_split_dim - determined_size;\n     }\n \n+    for (int i = 0; i < split_sizes_vec->size(); ++i) {\n+      const Tlen& split_size = (*split_sizes_vec)[i];\n+      OP_REQUIRES(context, split_size >= Tlen(0),\n+                  errors::InvalidArgument(\"Split size at index \", i,\n+                                          \" must be >= 0. Got: \", split_size));\n+    }\n+\n     // Special case 2: split along the 1st dimension. The requirements are that\n     // either we are splitting the outer dimension of two or more such that\n     // every outer subpart is aligned or that the split sizes mean that they are\n",
      "@@ -681,6 +681,12 @@ REGISTER_OP(\"SplitV\")\n           if (data[i] == -1 && c->ValueKnown(split_dim_size)) {\n             size = split_dim_size - total_size;\n           }\n+          // If we have a negative known size (either explicit, or computed\n+          // via -1), then the split sizes are invalid.\n+          if (size < -1 || (size == -1 && c->ValueKnown(split_dim_size))) {\n+            return errors::InvalidArgument(\"Split size at index \", i,\n+                                           \" must be >= 0. Got: \", size);\n+          }\n           TF_RETURN_IF_ERROR(\n               c->ReplaceDim(input, split_dim, c->MakeDim(size), &output_shape));\n           c->set_output(i, output_shape);\n",
      "@@ -384,6 +384,24 @@ class SplitOpTest(test.TestCase):\n                                   \"must have exactly one element\"):\n         sess.run(y, {x: np.array([], dtype=np.int32), splits: [4, 11, 15]})\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testNegativeSizes(self):\n+    x = constant_op.constant([1, 2, 3], dtypes.float32)\n+    # A size of -1 signifies to determine size based on sum of other splits.\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                \"Split size at index 1 must be >= 0. Got: -2\"):\n+      splits = [-1, -2]\n+      self.evaluate(array_ops.split(x, splits, axis=0))\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def testBadSplitSizes(self):\n+    x = constant_op.constant([1, 2], dtypes.float32)\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                \"Determined shape must either match input\"\n+                                \"|can't split axis\"):\n+      splits = [1, 2]\n+      self.evaluate(array_ops.split(x, splits, axis=0))\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cpf4-wx82-gxp6",
    "API Signature": "tf.raw_ops.SplitV(\n    value, size_splits, axis, num_split, name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Negative integer list element",
    "Category": "List",
    "Argument": "size_splits=[-1, -2]"
  },
  {
    "Title": "\n        Access to invalid memory during shape inference in `Cudnn*` ops\n      ",
    "Bug description": "The  shape inference code  for the  Cudnn*  operations in TensorFlow can be tricked into accessing invalid memory, via a heap buffer overflow:",
    "Sample Code": "@\ndef func():\n  return tf.raw_ops.CudnnRNNV3(\n    input=[0.1, 0.1],\n    input_h=[0.5],\n    input_c=[0.1, 0.1, 0.1], \n    params=[0.5, 0.5],\n    sequence_lengths=[-1, 0, 1])\n  \n])\n  \nfunc() ",
    "Code change": [
      "@@ -81,11 +81,17 @@ REGISTER_OP(\"CudnnRNN\")\n     .Attr(\"seed2: int = 0\")\n     .Attr(\"is_training: bool = true\")\n     .SetShapeFn([](InferenceContext* c) {\n+      ShapeHandle unused;\n       auto input_shape = c->input(0);\n       auto input_h_shape = c->input(1);\n+      TF_RETURN_IF_ERROR(c->WithRank(input_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(input_h_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 1, &unused));\n+\n       auto seq_length = c->Dim(input_shape, 0);\n       auto batch_size = c->Dim(input_shape, 1);\n       auto num_units = c->Dim(input_h_shape, 2);\n+\n       string direction;\n       TF_RETURN_IF_ERROR(c->GetAttr(\"direction\", &direction));\n       string rnn_mode;\n@@ -124,8 +130,13 @@ REGISTER_OP(\"CudnnRNNV2\")\n     .Attr(\"seed2: int = 0\")\n     .Attr(\"is_training: bool = true\")\n     .SetShapeFn([](InferenceContext* c) {\n+      ShapeHandle unused;\n       auto input_shape = c->input(0);\n       auto input_h_shape = c->input(1);\n+      TF_RETURN_IF_ERROR(c->WithRank(input_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(input_h_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 1, &unused));\n+\n       auto seq_length = c->Dim(input_shape, 0);\n       auto batch_size = c->Dim(input_shape, 1);\n       auto num_units = c->Dim(input_h_shape, 2);\n@@ -171,16 +182,26 @@ REGISTER_OP(\"CudnnRNNV3\")\n     .Attr(\"is_training: bool = true\")\n     .Attr(\"time_major: bool = true\")\n     .SetShapeFn([](InferenceContext* c) {\n+      ShapeHandle unused;\n       auto input_shape = c->input(0);\n       auto input_h_shape = c->input(1);\n       auto input_c_shape = c->input(2);\n+      TF_RETURN_IF_ERROR(c->WithRank(input_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(input_h_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 1, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(c->input(4), 1, &unused));\n+\n       auto max_seq_length = c->Dim(input_shape, 0);\n       auto batch_size = c->Dim(input_shape, 1);\n       auto num_units = c->Dim(input_h_shape, 2);\n+\n       string direction;\n       TF_RETURN_IF_ERROR(c->GetAttr(\"direction\", &direction));\n       string rnn_mode;\n       TF_RETURN_IF_ERROR(c->GetAttr(\"rnn_mode\", &rnn_mode));\n+      if (rnn_mode == \"lstm\") {\n+        TF_RETURN_IF_ERROR(c->WithRank(input_c_shape, 3, &unused));\n+      }\n       int dir_count = (direction == \"bidirectional\") ? 2 : 1;\n       DimensionHandle output_size;\n       TF_RETURN_IF_ERROR(c->Multiply(num_units, dir_count, &output_size));\n",
      "@@ -68,6 +68,11 @@ TEST(CudnnRNNOpsTest, ForwardLstm_ShapeFn) {\n                    .Attr(\"direction\", \"unidirectional\")\n                    .Finalize(&op.node_def));\n   INFER_OK(op, input_shapes_desc, output_shapes_desc);\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[];[?,?,?];[?,?,?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[];[?,?,?];[?]\");\n+  // Disabled because the kernel does not check shape of input_c.\n+  // INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[?,?,?];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[?,?,?];[]\");\n }\n \n TEST(CudnnRNNOpsTest, ForwardV2Lstm_ShapeFn) {\n@@ -100,6 +105,11 @@ TEST(CudnnRNNOpsTest, ForwardV2Lstm_ShapeFn) {\n                    .Attr(\"direction\", \"unidirectional\")\n                    .Finalize(&op.node_def));\n   INFER_OK(op, input_shapes_desc, output_shapes_desc);\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[];[?,?,?];[?,?,?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[];[?,?,?];[?]\");\n+  // Disabled because the kernel does not check shape of input_c.\n+  // INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[?,?,?];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[?,?,?];[]\");\n }\n \n TEST(CudnnRNNOpsTest, ForwardV3Lstm_ShapeFn) {\n@@ -137,6 +147,52 @@ TEST(CudnnRNNOpsTest, ForwardV3Lstm_ShapeFn) {\n                    .Attr(\"direction\", \"unidirectional\")\n                    .Finalize(&op.node_def));\n   INFER_OK(op, input_shapes_desc, output_shapes_desc);\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[];[?,?,?];[?,?,?];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[];[?,?,?];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[?,?,?];[];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[?,?,?];[];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[?,?,?];[?];[]\");\n+}\n+\n+TEST(CudnnRNNOpsTest, ForwardV3Gru) {\n+  int max_seq_length = 2;\n+  int batch_size = 3;\n+  int num_units = 4;\n+  int num_layers = 5;\n+  int dir_count = 1;\n+  std::vector<int> input_shape = {max_seq_length, batch_size, num_units};\n+  std::vector<int> input_h_shape = {num_layers * dir_count, batch_size,\n+                                    num_units};\n+  std::vector<int> input_c_shape = {num_layers * dir_count, batch_size,\n+                                    num_units};\n+  std::vector<int> output_shape = {max_seq_length, batch_size,\n+                                   num_units * dir_count};\n+  std::vector<int> seq_lengths_shape = {batch_size};\n+  auto shape_to_str = [](const std::vector<int>& v) {\n+    return strings::StrCat(\"[\", absl::StrJoin(v, \",\"), \"]\");\n+  };\n+  string input_shapes_desc = strings::StrCat(\n+      shape_to_str(input_shape), \";\", shape_to_str(input_h_shape), \";\",\n+      shape_to_str(input_c_shape), \";\", \"[?]\", \";\",\n+      shape_to_str(seq_lengths_shape));\n+  string output_shapes_desc = \"[d0_0,d0_1,d1_2];in1;[];?;?\";\n+\n+  ShapeInferenceTestOp op(\"CudnnRNNV3\");\n+  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"CudnnRNNV3\")\n+                   .Input({\"input\", 0, DT_FLOAT})\n+                   .Input({\"input_h\", 0, DT_FLOAT})\n+                   .Input({\"input_c\", 0, DT_FLOAT})\n+                   .Input({\"params\", 0, DT_FLOAT})\n+                   .Input({\"sequence_lengths\", 0, DT_INT32})\n+                   .Attr(\"rnn_mode\", \"gru\")\n+                   .Attr(\"input_mode\", \"auto_select\")\n+                   .Attr(\"direction\", \"unidirectional\")\n+                   .Finalize(&op.node_def));\n+  INFER_OK(op, input_shapes_desc, output_shapes_desc);\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[];[?,?,?];[];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[];[];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[];[];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[];[?];[]\");\n }\n \n }  // end namespace tensorflow\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cqv6-3phm-hcwx",
    "API Signature": "tf.raw_ops.CudnnRNNV3(\n    input,\n    input_h,\n    input_c,\n    params,\n    sequence_lengths,\n    rnn_mode='lstm',\n    input_mode='linear_input',\n    direction='unidirectional',\n    dropout=0,\n    seed=0,\n    seed2=0,\n    num_proj=0,\n    is_training=True,\n    time_major=True,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "input=[0.1, 0.1],\ninput_h=[0.5],"
  },
  {
    "Title": "\n        Integer division by 0 in `tf.raw_ops.AllToAll`\n      ",
    "Bug description": "The  shape inference code for   can be made to execute a division by 0:",
    "Sample Code": "@\ndef func():\n  return tf.raw_ops.AllToAll(\n    input=[0.0, 0.1652, 0.6543],\n    group_assignment=[1, -1],\n    concat_dimension=0,\n    split_dimension=0,\n    split_count=0)\n\n)\n\nfunc()",
    "Code change": [
      "@@ -32,6 +32,7 @@ REGISTER_OP(\"AllToAll\")\n     .Attr(\"split_count: int\")\n     .SetShapeFn([](InferenceContext* c) {\n       ShapeHandle input = c->input(0);\n+      ShapeHandle group_assignment = c->input(1);\n       if (!c->RankKnown(input)) {\n         c->set_output(0, c->UnknownShape());\n         return Status::OK();\n@@ -42,6 +43,21 @@ REGISTER_OP(\"AllToAll\")\n       int split_dimension;\n       int split_count;\n       TF_RETURN_IF_ERROR(c->GetAttr(\"split_count\", &split_count));\n+      if (split_count < 1) {\n+        return errors::InvalidArgument(\"split_count \", split_count,\n+                                       \" must at least be one.\");\n+      }\n+      if (c->RankKnown(group_assignment) && c->Rank(group_assignment) != 2) {\n+        return errors::InvalidArgument(\"group_assignment must have rank 2.\");\n+      }\n+      DimensionHandle num_replicas_per_group = c->Dim(group_assignment, 1);\n+      if (c->ValueKnown(num_replicas_per_group) &&\n+          (c->Value(num_replicas_per_group) != split_count)) {\n+        return errors::InvalidArgument(\n+            \"split_count \", split_count,\n+            \" must equal the size of the second dimension of group_assignment \",\n+            c->Value(num_replicas_per_group));\n+      }\n \n       TF_RETURN_IF_ERROR(c->GetAttr(\"concat_dimension\", &concat_dimension));\n \n@@ -65,6 +81,12 @@ REGISTER_OP(\"AllToAll\")\n           dims[i] = c->MakeDim(c->Value(dims[i]) * split_count);\n         }\n         if (i == split_dimension) {\n+          if (c->ValueKnown(dims[i]) &&\n+              (c->Value(dims[i]) % split_count != 0)) {\n+            return errors::InvalidArgument(\n+                \"input dimension \", c->Value(dims[i]),\n+                \" not divisible by split_count \", split_count);\n+          }\n           dims[i] = c->MakeDim(c->Value(dims[i]) / split_count);\n         }\n       }\n",
      "@@ -32,6 +32,7 @@ from tensorflow.python.platform import test\n from tensorflow.python.tpu import tpu\n from tensorflow.python.tpu import tpu_feed\n from tensorflow.python.tpu import training_loop\n+from tensorflow.python.tpu.ops import tpu_ops\n \n \n class TPUContextTest(test.TestCase):\n@@ -165,6 +166,51 @@ class TPUGraphPruneTest(test.TestCase):\n         graph.get_operation_by_name(\"import/y\").get_attr(\n             tpu._TPU_REPLICATE_ATTR)\n \n+\n+class TPUOpsTest(test.TestCase):\n+\n+  def test_all_to_all_zero_split_count(self):\n+    with self.assertRaisesRegex(\n+        ValueError, \"split_count 0 must at least be one\"):\n+      tpu_ops.all_to_all(\n+          x=[0.0, 0.1652, 0.6543],\n+          group_assignment=[1, -1],\n+          concat_dimension=0,\n+          split_dimension=0,\n+          split_count=0)\n+\n+  def test_all_to_all_group_assignment_wrong_shape(self):\n+    with self.assertRaisesRegex(\n+        ValueError, \"group_assignment must have rank 2\"):\n+      tpu_ops.all_to_all(\n+          x=[0.0, 0.1652, 0.6543],\n+          group_assignment=[1, -1],\n+          concat_dimension=0,\n+          split_dimension=0,\n+          split_count=2)\n+\n+  def test_all_to_all_split_count_not_equal_to_group_assignment_shape(self):\n+    with self.assertRaisesRegex(\n+        ValueError, \"split_count 1 must equal the size of the second dimension \"\n+        \"of group_assignment 2\"):\n+      tpu_ops.all_to_all(\n+          x=[0.0, 0.1652, 0.6543],\n+          group_assignment=[[0, 1], [2, 3]],\n+          concat_dimension=0,\n+          split_dimension=0,\n+          split_count=1)\n+\n+  def test_all_to_all_split_count_not_divide_input_shape(self):\n+    with self.assertRaisesRegex(\n+        ValueError, \"input dimension 3 not divisible by split_count 2\"):\n+      tpu_ops.all_to_all(\n+          x=[[0.0], [0.1652], [0.6543]],\n+          group_assignment=[[0, 1], [2, 3]],\n+          concat_dimension=1,\n+          split_dimension=0,\n+          split_count=2)\n+\n+\n def do_einsum():\n   a = array_ops.placeholder(dtype=dtypes.float32, name=\"a\", shape=[2, 3, 4])\n   b = array_ops.placeholder(dtype=dtypes.float32, name=\"b\", shape=[2, 4, 5])\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9crf-c6qr-r273",
    "API Signature": "tf.raw_ops.AllToAll(\n    input,\n    group_assignment,\n    concat_dimension,\n    split_dimension,\n    split_count,\n    name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Zero integer argument",
    "Category": "Integer",
    "Argument": "split_count=0"
  },
  {
    "Title": "\n        Use after free / memory leak in `CollectiveReduceV2`\n      ",
    "Bug description": "The  async implementation  of  CollectiveReduceV2  suffers from a memory leak and a use after free:",
    "Sample Code": "tf.raw_ops.CollectiveReduceV2(\n  input=[],\n  group_size=[-10, -10, -10],\n  group_key=[-10, -10],\n  instance_key=[-10],\n  ordering_token=[],\n  merge_op='Mul',\n  ,\n  final_op='Div')",
    "Code change": [
      "@@ -494,15 +494,17 @@ class CollectiveOpV2Kernel : public AsyncOpKernel {\n                               const Tensor& group_size, const Tensor& group_key,\n                               const Tensor& instance_key) {\n     if (group_size.dims() > 0) {\n-      return errors::Internal(\"Unexpected dimensions on input group_size, got \",\n-                              group_size.shape().DebugString());\n+      return errors::InvalidArgument(\n+          \"Unexpected dimensions on input group_size, got \",\n+          group_size.shape().DebugString());\n     }\n     if (group_key.dims() > 0) {\n-      return errors::Internal(\"Unexpected dimensions on input group_key, got \",\n-                              group_key.shape().DebugString());\n+      return errors::InvalidArgument(\n+          \"Unexpected dimensions on input group_key, got \",\n+          group_key.shape().DebugString());\n     }\n     if (instance_key.dims() > 0) {\n-      return errors::Internal(\n+      return errors::InvalidArgument(\n           \"Unexpected dimensions on input instance_key, got \",\n           instance_key.shape().DebugString());\n     }\n@@ -625,7 +627,7 @@ class CollectiveReduceV2OpKernel : public CollectiveOpV2Kernel {\n                                               /*group_size*/ c->input(1),\n                                               /*group_key*/ c->input(2),\n                                               /*instance_key*/ c->input(3)),\n-                         done);\n+                         done_with_cleanup);\n     col_params->instance.shape = c->input(0).shape();\n     col_params->merge_op = merge_op_.get();\n     col_params->final_op = final_op_.get();\n@@ -855,14 +857,15 @@ class CollectiveInitializeCommunicatorOpKernel : public AsyncOpKernel {\n \n   Status CheckInputs(Tensor group_size_t, Tensor group_key_t) {\n     if (group_size_t.dims() > 0) {\n-      return errors::Internal(\n+      return errors::InvalidArgument(\n           \"Unexpected dimensions on input group_size. \"\n           \"It shoulbe a scalar, got tensor with shape \",\n           group_size_t.shape().DebugString());\n     }\n     if (group_key_t.dims() > 0) {\n-      return errors::Internal(\"Unexpected dimensions on input group_key, got \",\n-                              group_key_t.shape().DebugString());\n+      return errors::InvalidArgument(\n+          \"Unexpected dimensions on input group_key, got \",\n+          group_key_t.shape().DebugString());\n     }\n \n     auto group_size = group_size_t.unaligned_flat<int32>()(0);\n@@ -1084,7 +1087,7 @@ class CollectiveReduceV3OpKernel : public CollectiveOpV3Kernel {\n     };\n     core::RefCountPtr<CollectiveGroupResource> resource;\n     OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n-                         done);\n+                         done_with_cleanup);\n \n     Tensor group_assignment = c->input(2);\n \n@@ -1134,7 +1137,7 @@ class CollectiveAllToAllV3OpKernel : public CollectiveOpV3Kernel {\n     };\n     core::RefCountPtr<CollectiveGroupResource> resource;\n     OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n-                         done);\n+                         done_with_cleanup);\n \n     Tensor group_assignment = c->input(2);\n \n",
      "@@ -1182,6 +1182,69 @@ class InputPipelineTest(test.TestCase):\n     self.assertAllEqual(self.evaluate(f()), [[3.], [3.]])\n \n \n+@combinations.generate(\n+    combinations.times(\n+        combinations.combine(collective_op=[\n+            combinations.NamedObject('all_reduce_v2',\n+                                     CollectiveOpsV2.all_reduce),\n+            combinations.NamedObject('all_gather_v2',\n+                                     CollectiveOpsV2.all_gather)\n+        ]), device_combination))\n+class InvalidInputTest(test.TestCase, parameterized.TestCase):\n+\n+  def setUp(self):\n+    _setup_context()\n+    super().setUp()\n+\n+  def testInvalidGroupKey(self, collective_op, device, communication):\n+    dev0 = '/device:%s:0' % device\n+    group_size = 2\n+    group_key = [100]\n+    instance_key = 100\n+    in_tensor = constant_op.constant([1.])\n+\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      with ops.device(dev0):\n+        collective_op(\n+            in_tensor,\n+            group_size,\n+            group_key,\n+            instance_key,\n+            communication_hint=communication)\n+\n+  def testInvalidGroupSize(self, collective_op, device, communication):\n+    dev0 = '/device:%s:0' % device\n+    group_size = -2\n+    group_key = 100\n+    instance_key = 100\n+    in_tensor = constant_op.constant([1.])\n+\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      with ops.device(dev0):\n+        collective_op(\n+            in_tensor,\n+            group_size,\n+            group_key,\n+            instance_key,\n+            communication_hint=communication)\n+\n+  def testInvalidInstanceKey(self, collective_op, device, communication):\n+    dev0 = '/device:%s:0' % device\n+    group_size = 2\n+    group_key = 100\n+    instance_key = [100]\n+    in_tensor = constant_op.constant([1.])\n+\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      with ops.device(dev0):\n+        collective_op(\n+            in_tensor,\n+            group_size,\n+            group_key,\n+            instance_key,\n+            communication_hint=communication)\n+\n+\n class CollectiveOpsV3Test(test.TestCase, parameterized.TestCase):\n \n   def setUp(self):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gpfh-jvf9-7wg5",
    "API Signature": "tf.raw_ops.CollectiveReduceV2(\n    input,\n    group_size,\n    group_key,\n    instance_key,\n    ordering_token,\n    merge_op,\n    final_op,\n    communication_hint='auto',\n    timeout_seconds=0,\n    max_subdivs_per_device=-1,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "group_size=[-10, -10, -10],\ngroup_key=[-10, -10],"
  },
  {
    "Title": "\n        Undefined behavior via `nullptr` reference binding in sparse matrix multiplication\n      ",
    "Bug description": "The  code for sparse matrix multiplication  is vulnerable to undefined behavior via binding a reference to  nullptr :",
    "Sample Code": "tf.raw_ops.SparseMatMul(\n  a=[[1.0,1.0,1.0]],\n  b=[[],[],[]],\n  transpose_a=False,\n  transpose_b=False,\n  a_is_sparse=False, \n  , \n  b_is_sparse=True)",
    "Code change": [
      "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/fill_functor.h\"\n #include \"tensorflow/core/lib/core/blocking_counter.h\"\n #include \"tensorflow/core/lib/core/threadpool.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/macros.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n@@ -980,9 +981,18 @@ class SparseMatMulOp : public OpKernel {\n                 errors::InvalidArgument(\n                     \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                     \", b: \", b.shape().DebugString()));\n+    OP_REQUIRES(ctx, m >= 0 && n >= 0 && k >= 0,\n+                errors::InvalidArgument(\n+                    \"Matrix dimensions cannot be negative: a: \",\n+                    a.shape().DebugString(), \", b: \", b.shape().DebugString()));\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n \n+    // Return early if at least one of the output dimension size is 0.\n+    if (m == 0 || n == 0) {\n+      return;\n+    }\n+\n     if (k == 0) {\n       // If the inner dimension k in the matrix multiplication is zero, we fill\n       // the output with zeros.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4f99-p9c2-3j8x",
    "API Signature": "tf.raw_ops.SparseMatMul(\n    a,\n    b,\n    transpose_a=False,\n    transpose_b=False,\n    a_is_sparse=False,\n    b_is_sparse=False,\n    name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Zero integer list element",
    "Category": "List",
    "Argument": "a=[[1.0,1.0,1.0]],\nb=[[],[],[]],"
  },
  {
    "Title": "\n        Heap buffer overflow in `Transpose`\n      ",
    "Bug description": "The  shape inference function for   is vulnerable to a heap buffer overflow:",
    "Sample Code": "@\ndef test():\n  y = tf.raw_ops.Transpose(x=[1,2,3,4],perm=[-10])\n  return y\n\n\n\ntest()",
    "Code change": [
      "@@ -168,7 +168,7 @@ Status TransposeShapeFn(InferenceContext* c) {\n \n     for (int32_t i = 0; i < rank; ++i) {\n       int64_t in_idx = data[i];\n-      if (in_idx >= rank) {\n+      if (in_idx >= rank || in_idx <= -rank) {\n         return errors::InvalidArgument(\"perm dim \", in_idx,\n                                        \" is out of range of input rank \", rank);\n       }\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-3ff2-r28g-w7h9",
    "API Signature": "tf.raw_ops.Transpose(\n    x, perm, name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Negative integer list element",
    "Category": "List",
    "Argument": "perm=[-10]"
  },
  {
    "Title": "\n        Null pointer exception in `DeserializeSparse`\n      ",
    "Bug description": "The  shape inference code for   can trigger a null pointer dereference:",
    "Sample Code": "dataset = tf.data.Dataset.range(3)\n  \n@                 \ndef test():                  \n  y = tf.raw_ops.DeserializeSparse(\n    serialized_sparse=tf.data.experimental.to_variant(dataset),\n    dtype=tf.int32)\n\n)\n\ntest()",
    "Code change": [
      "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/common_shape_fns.h\"\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/shape_inference.h\"\n+#include \"tensorflow/core/framework/types.pb.h\"\n #include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n@@ -159,6 +160,8 @@ REGISTER_OP(\"DeserializeSparse\")\n     .Attr(\"Tserialized: {string, variant} = DT_STRING\")\n     .SetShapeFn([](InferenceContext* c) {\n       // serialized sparse is [?, ..., ?, 3] vector.\n+      ShapeHandle unused_shape;\n+      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &unused_shape));\n       DimensionHandle unused;\n       TF_RETURN_IF_ERROR(c->WithValue(c->Dim(c->input(0), -1), 3, &unused));\n       c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,\n",
      "@@ -16,10 +16,12 @@\n \n import numpy as np\n \n+from tensorflow.python.eager import def_function\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import sparse_tensor as sparse_tensor_lib\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import gen_resource_variable_ops\n from tensorflow.python.ops import sparse_ops\n from tensorflow.python.platform import test\n \n@@ -460,6 +462,18 @@ class SerializeSparseTest(test.TestCase):\n     self._testDeserializeFailsInvalidProtoHelper(\n         sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n \n+  def testDeserializeInvalidVariant(self):\n+    mu = gen_resource_variable_ops.mutex_v2()\n+    mu_lock = gen_resource_variable_ops.mutex_lock(mutex=mu)\n+\n+    @def_function.function\n+    def f():\n+      return sparse_ops.deserialize_sparse(\n+          serialized_sparse=mu_lock, dtype=dtypes.int32)\n+\n+    with self.assertRaisesRegex(ValueError, r\"Shape must be at least rank 1\"):\n+      f()\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x3v8-c8qx-3j3r",
    "API Signature": "tf.raw_ops.DeserializeSparse(\n    serialized_sparse, dtype, name=None\n)\n",
    "Score": 0.02127659574468085,
    "Anomaly": "Scalar input tensor",
    "Category": "Tensor",
    "Argument": "dataset = tf.data.Dataset.range(3)"
  },
  {
    "Title": "\n        Reference binding to `nullptr` in `tf.ragged.cross`\n      ",
    "Bug description": "The  shape inference code for   has an undefined behavior due to binding a reference to  nullptr . In the following scenario, this results in a crash:",
    "Sample Code": "@                 \ndef test():     \n  y = tf.ragged.cross([tf.ragged.constant([['1']]),'2'])\n  return y                   \n                             \n                   \n                             \ntest()        ",
    "Code change": [
      "@@ -99,6 +99,13 @@ REGISTER_OP(\"RaggedCross\")\n       int dense_start = num_ragged * 2 + num_sparse * 3;\n       for (int i = 0; i < dense_types.size(); ++i) {\n         ShapeHandle dense_input = c->input(i + dense_start);\n+        int32 rank = c->Rank(dense_input);\n+        if (rank == InferenceContext::kUnknownRank) {\n+          continue;\n+        } else if (rank != 2) {\n+          return errors::InvalidArgument(\n+              \"tf.ragged.cross only supports inputs with rank=2\");\n+        }\n         int64_t batch_size = c->Value(c->Dim(dense_input, 0));\n         if (batch_size != InferenceContext::kUnknownDim) {\n           ShapeHandle row_splits = c->Vector(batch_size + 1);\n",
      "@@ -18,10 +18,12 @@ from absl.testing import parameterized\n \n import numpy as np\n \n+from tensorflow.python.eager import def_function\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import sparse_tensor\n+from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import sparse_ops\n from tensorflow.python.ops.ragged import ragged_array_ops\n@@ -358,6 +360,16 @@ class RaggedCrossOpTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n                   dense_const([[2], [3]])],\n           exception=(ValueError, errors.InvalidArgumentError),\n           message='inputs must all have the same batch dimension size'),\n+      dict(\n+          testcase_name='3DDenseTensor',\n+          inputs=[dense_const([[[1]]])],\n+          exception=(ValueError, errors.InvalidArgumentError),\n+          message='tf.ragged.cross only supports inputs with rank=2'),\n+      dict(\n+          testcase_name='0DDenseTensor',\n+          inputs=[dense_const(1)],\n+          exception=(ValueError, errors.InvalidArgumentError),\n+          message='tf.ragged.cross only supports inputs with rank=2'),\n   ])\n   def testStaticError(self, inputs, exception=ValueError, message=None):\n     with self.assertRaisesRegex(exception, message):\n@@ -368,17 +380,36 @@ class RaggedCrossOpTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n           testcase_name='3DRaggedTensor',\n           inputs=[ragged_const([[[1]]], ragged_rank=1)],\n           message='tf.ragged.cross only supports inputs with rank=2'),\n+      dict(\n+          testcase_name='0DDenseTensor',\n+          inputs=[dense_const(1)],\n+          signature=[[tensor_spec.TensorSpec(None, dtypes.int32)]],\n+          exception=(ValueError, errors.InvalidArgumentError),\n+          message='tf.ragged.cross only supports inputs with rank=2'),\n+      dict(\n+          testcase_name='1DDenseTensor',\n+          inputs=[dense_const([1])],\n+          signature=[[tensor_spec.TensorSpec(None, dtypes.int32)]],\n+          exception=(ValueError, errors.InvalidArgumentError),\n+          message='tf.ragged.cross only supports inputs with rank=2'),\n       dict(\n           testcase_name='3DDenseTensor',\n           inputs=[dense_const([[[1]]])],\n+          signature=[[tensor_spec.TensorSpec(None, dtypes.int32)]],\n+          exception=(ValueError, errors.InvalidArgumentError),\n           message='tf.ragged.cross only supports inputs with rank=2'),\n   ])\n   def testRuntimeError(self,\n                        inputs,\n                        exception=errors.InvalidArgumentError,\n-                       message=None):\n+                       message=None,\n+                       signature=None):\n+    @def_function.function(input_signature=signature)\n+    def fn(x):\n+      return ragged_array_ops.cross(x)\n+\n     with self.assertRaisesRegex(exception, message):\n-      self.evaluate(ragged_array_ops.cross(inputs))\n+      self.evaluate(fn(inputs))\n \n   def _ragged_to_sparse(self, t):\n     if ragged_tensor.is_ragged(t):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vwhq-49r4-gj9v",
    "API Signature": "tf.ragged.cross(\n    inputs, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "[tf.ragged.constant([['1']]),'2']"
  },
  {
    "Title": "\n        Heap OOB in shape inference for `QuantizeV2`\n      ",
    "Bug description": "The  shape inference code for   can trigger a read outside of bounds of heap allocated array:",
    "Sample Code": "@\ndef test():\n  data=tf.raw_ops.QuantizeV2(\n    input=[1.0,1.0],\n    min_range=[1.0,10.0],\n    max_range=[1.0,10.0],\n    T=tf.qint32,\n    mode='MIN_COMBINED',\n    round_mode='HALF_TO_EVEN',\n    narrow_range=False,\n    axis=-100,\n    ensure_minimum_range=10)\n  return data\n\n\n\ntest()",
    "Code change": [
      "@@ -2559,6 +2559,9 @@ Status QuantizeV2Shape(InferenceContext* c) {\n   if (!s.ok() && s.code() != error::NOT_FOUND) {\n     return s;\n   }\n+  if (axis < -1) {\n+    return errors::InvalidArgument(\"axis should be at least -1, got \", axis);\n+  }\n   const int minmax_rank = (axis == -1) ? 0 : 1;\n   TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n   ShapeHandle minmax;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cvgx-3v3q-m36c",
    "API Signature": "tf.raw_ops.QuantizeV2(\n    input,\n    min_range,\n    max_range,\n    T,\n    mode='MIN_COMBINED',\n    round_mode='HALF_AWAY_FROM_ZERO',\n    narrow_range=False,\n    axis=-1,\n    ensure_minimum_range=0.01,\n    name=None\n)\n",
    "Score": 0.03900709219858156,
    "Anomaly": "Negative integer argument",
    "Category": "Integer",
    "Argument": "axis=-100,"
  },
  {
    "Title": "\n        Heap OOB read in all `tf.raw_ops.QuantizeAndDequantizeV*` ops\n      ",
    "Bug description": "The  shape inference functions for the   can trigger a read outside of bounds of heap allocated array as illustrated in the following sets of PoCs:",
    "Sample Code": "@\ndef test():\n  data=tf.raw_ops.QuantizeAndDequantizeV2(\n    input=[1.0,1.0],\n    input_min=[1.0,10.0],\n    input_max=[1.0,10.0],\n    signed_input=False,\n    num_bits=10,\n    range_given=False,\n    round_mode='HALF_TO_EVEN',\n    narrow_range=False,\n    axis=-100)\n  return data\n\n\n\ntest()",
    "Code change": [
      "@@ -2863,7 +2863,10 @@ REGISTER_OP(\"QuantizeAndDequantizeV2\")\n       ShapeHandle minmax;\n       TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n       TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n-      if (axis != -1) {\n+      if (axis < -1) {\n+        return errors::InvalidArgument(\"axis should be at least -1, got \",\n+                                       axis);\n+      } else if (axis != -1) {\n         ShapeHandle input;\n         TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n         DimensionHandle depth;\n@@ -2895,7 +2898,10 @@ REGISTER_OP(\"QuantizeAndDequantizeV4\")\n       ShapeHandle minmax;\n       TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n       TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n-      if (axis != -1) {\n+      if (axis < -1) {\n+        return errors::InvalidArgument(\"axis should be at least -1, got \",\n+                                       axis);\n+      } else if (axis != -1) {\n         ShapeHandle input;\n         TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n         DimensionHandle depth;\n@@ -2923,7 +2929,10 @@ REGISTER_OP(\"QuantizeAndDequantizeV4Grad\")\n       ShapeHandle minmax;\n       TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));\n       TF_RETURN_IF_ERROR(c->Merge(c->input(3), minmax, &minmax));\n-      if (axis != -1) {\n+      if (axis < -1) {\n+        return errors::InvalidArgument(\"axis should be at least -1, got \",\n+                                       axis);\n+      } else if (axis != -1) {\n         ShapeHandle input;\n         TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n         DimensionHandle depth;\n@@ -2956,7 +2965,10 @@ REGISTER_OP(\"QuantizeAndDequantizeV3\")\n       ShapeHandle minmax;\n       TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n       TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n-      if (axis != -1) {\n+      if (axis < -1) {\n+        return errors::InvalidArgument(\"axis should be at least -1, got \",\n+                                       axis);\n+      } else if (axis != -1) {\n         ShapeHandle input;\n         TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n         DimensionHandle depth;\n",
      "@@ -1374,6 +1374,8 @@ TEST(ArrayOpsTest, QuantizeAndDequantizeV2_ShapeFn) {\n   INFER_ERROR(\"Shapes must be equal rank, but are 1 and 0\", op,\n               \"[1,2,?,4,5];[];[1]\");\n   INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1,2,?,4,5];[1];[1]\");\n+  (*op.node_def.mutable_attr())[\"axis\"].set_i(-2);\n+  INFER_ERROR(\"axis should be at least -1, got -2\", op, \"?;?;?\");\n }\n \n TEST(ArrayOpsTest, SpaceToBatch_ShapeFn) {\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-49rx-x2rw-pc6f",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n    gradients, input, input_min, input_max, axis=-1, name=None\n)\n",
    "Score": 0.03900709219858156,
    "Anomaly": "Negative integer argument",
    "Category": "Integer",
    "Argument": "axis=-100,"
  },
  {
    "Title": "\n        FPE in `ParallelConcat`\n      ",
    "Bug description": "The  implementation of   misses some input validation and can produce a division by 0:",
    "Sample Code": "@\ndef test():\n  y = tf.raw_ops.ParallelConcat(values=[['tf']],shape=0)\n  return y\n\n\n\ntest()",
    "Code change": [
      "@@ -71,6 +71,15 @@ class ParallelConcatUpdate : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     auto value = ctx->input(0);\n+    // Value should be at least rank 1. Also the 0th dimension should be\n+    // at least loc_.\n+    OP_REQUIRES(ctx, value.dims() >= 1,\n+                errors::InvalidArgument(\"value should be at least rank 1.\"));\n+    OP_REQUIRES(\n+        ctx, value.dim_size(0) > loc_,\n+        errors::InvalidArgument(\"0th dimension of value = \", value.dim_size(0),\n+                                \" is less than loc_=\", loc_));\n+\n     auto update = ctx->input(1);\n \n     OP_REQUIRES(\n",
      "@@ -16,12 +16,16 @@\n \n import numpy as np\n \n+from tensorflow.python import tf2\n from tensorflow.python.eager import context\n+from tensorflow.python.eager import def_function\n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import gen_array_ops\n from tensorflow.python.ops import gradient_checker_v2\n from tensorflow.python.platform import test\n \n@@ -69,6 +73,19 @@ class StackOpTest(test.TestCase):\n             c = array_ops.parallel_stack(xs)\n             self.assertAllEqual(c, data)\n \n+  def testParallelConcatShapeZero(self):\n+    if not tf2.enabled():\n+      self.skipTest(\"only fails in TF2\")\n+\n+    @def_function.function\n+    def f():\n+      y = gen_array_ops.parallel_concat(values=[[\"tf\"]], shape=0)\n+      return y\n+\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                r\"0th dimension of value .* is less than\"):\n+      f()\n+\n   def testSimpleParallelGPU(self):\n     # tf.parallel_stack is only supported in graph mode.\n     with ops.Graph().as_default():\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-7v94-64hj-m82h",
    "API Signature": "tf.raw_ops.ParallelConcat(\n    values, shape, name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "shape=0"
  },
  {
    "Title": "\n        Heap OOB read in `tf.raw_ops.SparseCountSparseOutput`\n      ",
    "Bug description": "The  shape inference functions for   can trigger a read outside of bounds of heap allocated array:",
    "Sample Code": "@\ndef func():\n  return tf.raw_ops.SparseCountSparseOutput(\n    indices=[1],\n    values=[[1]],\n    dense_shape=[10],\n    weights=[],\n    binary_output= True)\n\n)\n\nfunc()",
    "Code change": [
      "@@ -41,6 +41,8 @@ Status DenseCountSparseOutputShapeFn(InferenceContext *c) {\n }\n \n Status SparseCountSparseOutputShapeFn(InferenceContext *c) {\n+  ShapeHandle unused;\n+  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n   auto rank = c->Dim(c->input(0), 1);\n   auto nvals = c->UnknownDim();\n   c->set_output(0, c->Matrix(nvals, rank));  // out.indices\n",
      "@@ -831,6 +831,25 @@ class TestSparseCountFailureModes(test.TestCase):\n       self.evaluate(bincount_ops.sparse_bincount(x, weights=weights, axis=-1))\n \n \n+class RawOpsHeapOobTest(test.TestCase, parameterized.TestCase):\n+\n+  @test_util.run_v1_only(\"Test security error\")\n+  def testSparseCountSparseOutputBadIndicesShapeTooSmall(self):\n+    indices = [1]\n+    values = [[1]]\n+    weights = []\n+    dense_shape = [10]\n+    with self.assertRaisesRegex(ValueError,\n+                                \"Shape must be rank 2 but is rank 1 for\"):\n+      self.evaluate(\n+          gen_count_ops.SparseCountSparseOutput(\n+              indices=indices,\n+              values=values,\n+              dense_shape=dense_shape,\n+              weights=weights,\n+              binary_output=True))\n+\n+\n @test_util.run_all_in_graph_and_eager_modes\n @test_util.disable_tfrt\n class RawOpsTest(test.TestCase, parameterized.TestCase):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m342-ff57-4jcc",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "indices=[1]"
  },
  {
    "Title": "\n        Overflow/crash in `tf.range`\n      ",
    "Bug description": "While calculating the size of the output within the  tf.range  kernel, there is a conditional statement of type  int64 = condition ? int64 : double . Due to C++ implicit conversion rules, both branches of the condition will be cast to  double  and the result would be truncated before the assignment. This result in overflows:",
    "Sample Code": " tensorflow as tf\n\ntf.range(start=-1e+38, limit=1)",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xrqm-fpgr-6hhx",
    "API Signature": null,
    "Score": 0.024822695035460994,
    "Anomaly": "Large integer argument",
    "Category": "Integer",
    "Argument": "start=-1e+38"
  },
  {
    "Title": "\n        Overflow/crash in `tf.range`\n      ",
    "Bug description": "While calculating the size of the output within the  tf.range  kernel, there is a conditional statement of type  int64 = condition ? int64 : double . Due to C++ implicit conversion rules, both branches of the condition will be cast to  double  and the result would be truncated before the assignment. This result in overflows:",
    "Sample Code": " tensorflow as tf\n\ntf.range(start=-1e+38, limit=1)",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xrqm-fpgr-6hhx",
    "API Signature": null,
    "Score": 0.03900709219858156,
    "Anomaly": "Negative integer argument",
    "Category": "Integer",
    "Argument": "start=-1e+38"
  },
  {
    "Title": "\n        Overflow/crash in `tf.image.resize` when size is large\n      ",
    "Bug description": "If  tf.image.resize  is called with a large input argument then the TensorFlow process will crash due to a  CHECK -failure caused by an overflow.",
    "Sample Code": "import numpy as np\n\ntf.keras.layers.UpSampling2D(\n  size=1610637938,\n  data_format='channels_first',\n  ,\n  interpolation='bilinear')(np.ones((5,1,1,1)))",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5hx2-qx8j-qjqm",
    "API Signature": "tf.keras.layers.UpSampling2D(\n    size=(2, 2), data_format=None, interpolation='nearest', **kwargs\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Large integer argument",
    "Category": "Integer",
    "Argument": "size=1610637938,"
  },
  {
    "Title": "\n        Overflow/crash in `tf.tile` when tiling tensor is large\n      ",
    "Bug description": "If  tf.tile  is called with a large input argument then the TensorFlow process will crash due to a  CHECK -failure caused by an overflow.",
    "Sample Code": "import numpy as np\n\ntf.keras.backend.tile(x=np.ones((1,1,1)), n=[100000000,100000000, 100000000])",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2p25-55c9-h58q",
    "API Signature": null,
    "Score": 0.031914893617021274,
    "Anomaly": "Large integer list element",
    "Category": "List",
    "Argument": "n=[100000000,100000000, 100000000]"
  },
  {
    "Title": "\n        Incomplete validation in `tf.summary.create_file_writer`\n      ",
    "Bug description": "If  tf.summary.create_file_writer  is called with non-scalar arguments code crashes due to a  CHECK -fail.",
    "Sample Code": "import numpy as np\n\ntf.summary.create_file_writer(logdir='', flush_millis=np.ones((1,2)))",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gh8h-7j2j-qv4f",
    "API Signature": "tf.summary.create_file_writer(\n    logdir,\n    max_queue=None,\n    flush_millis=None,\n    filename_suffix=None,\n    name=None,\n    experimental_trackable=False\n)\n",
    "Score": 0.010638297872340425,
    "Anomaly": "Empty string",
    "Category": "String",
    "Argument": "logdir=''"
  },
  {
    "Title": "\n        Crash in `max_pool3d` when size argument is 0 or negative\n      ",
    "Bug description": "The Keras pooling layers can trigger a segfault if the size of the pool is 0 or if a dimension is negative:",
    "Sample Code": "pool_size = [2, 2, 0]\nlayer = tf.keras.layers.MaxPooling3D(strides=1, pool_size=pool_size)\ninput_tensor = tf.random.uniform([3, 4, 10, 11, 12], dtype=tf.float32)\n)\nres = layer(input_tensor)",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m539-j985-hcr8",
    "API Signature": null,
    "Score": 0.03900709219858156,
    "Anomaly": "Negative integer argument",
    "Category": "Integer",
    "Argument": "pool_size = [2, 2, 0]"
  },
  {
    "Title": "\n        Crash in `tf.math.segment_*` operations\n      ",
    "Bug description": "The implementation of  tf.math.segment_*  operations results in a  CHECK -fail related abort (and denial of service) if a segment id in  segment_ids  is large.",
    "Sample Code": "tf.math.segment_max(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\ntf.math.segment_min(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\ntf.math.segment_mean(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])    \ntf.math.segment_sum(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\n])\ntf.math.segment_prod(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cq76-mxrc-vchh",
    "API Signature": "tf.math.segment_max(\n    data, segment_ids, name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Large integer list element",
    "Category": "List",
    "Argument": "segment_ids=[1676240524292489355]"
  },
  {
    "Title": "\n        Crash in `tf.math.segment_*` operations\n      ",
    "Bug description": "The implementation of  tf.math.segment_*  operations results in a  CHECK -fail related abort (and denial of service) if a segment id in  segment_ids  is large.",
    "Sample Code": "tf.math.segment_max(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\ntf.math.segment_min(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\ntf.math.segment_mean(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])    \ntf.math.segment_sum(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\n])\ntf.math.segment_prod(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cq76-mxrc-vchh",
    "API Signature": "tf.math.segment_min(\n    data, segment_ids, name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Large integer list element",
    "Category": "List",
    "Argument": "segment_ids=[1676240524292489355]"
  },
  {
    "Title": "\n        Crash in `tf.math.segment_*` operations\n      ",
    "Bug description": "The implementation of  tf.math.segment_*  operations results in a  CHECK -fail related abort (and denial of service) if a segment id in  segment_ids  is large.",
    "Sample Code": "tf.math.segment_max(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\ntf.math.segment_min(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\ntf.math.segment_mean(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])    \ntf.math.segment_sum(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\n])\ntf.math.segment_prod(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cq76-mxrc-vchh",
    "API Signature": "tf.math.segment_mean(\n    data, segment_ids, name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Large integer list element",
    "Category": "List",
    "Argument": "segment_ids=[1676240524292489355]"
  },
  {
    "Title": "\n        Crash in `tf.math.segment_*` operations\n      ",
    "Bug description": "The implementation of  tf.math.segment_*  operations results in a  CHECK -fail related abort (and denial of service) if a segment id in  segment_ids  is large.",
    "Sample Code": "tf.math.segment_max(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\ntf.math.segment_min(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\ntf.math.segment_mean(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])    \ntf.math.segment_sum(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\n])\ntf.math.segment_prod(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cq76-mxrc-vchh",
    "API Signature": "tf.math.segment_sum(\n    data, segment_ids, name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Large integer list element",
    "Category": "List",
    "Argument": "segment_ids=[1676240524292489355]"
  },
  {
    "Title": "\n        Crash in `tf.math.segment_*` operations\n      ",
    "Bug description": "The implementation of  tf.math.segment_*  operations results in a  CHECK -fail related abort (and denial of service) if a segment id in  segment_ids  is large.",
    "Sample Code": "tf.math.segment_max(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\ntf.math.segment_min(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\ntf.math.segment_mean(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])    \ntf.math.segment_sum(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])\n])\ntf.math.segment_prod(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cq76-mxrc-vchh",
    "API Signature": "tf.math.segment_prod(\n    data, segment_ids, name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Large integer list element",
    "Category": "List",
    "Argument": "segment_ids=[1676240524292489355]"
  },
  {
    "Title": "\n        Heap OOB in TFLite's `Gather*` implementations\n      ",
    "Bug description": "TFLite's  GatherNd  does not support negative indices but there are no checks for this situation.",
    "Sample Code": "import numpy as np\ntf.compat.v1.disable_v2_behavior()\n\nparams = tf.compat.v1.placeholder(name=\"params\", dtype=tf.int64, shape=(1,))\nindices = tf.compat.v1.placeholder(name=\"indices\", dtype=tf.int64, shape=())\n\nout = tf.gather(params, indices, name='out')\n\nwith tf.compat.v1.Session() as sess:\n   converter = tf.compat.v1.lite.TFLiteConverter.from_session(sess, [params, indices], [out])\n   tflite_model = converter.convert()\n\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nparams_data = np.reshape(np.array([1], dtype=np.int64), newshape=(1,))\nindices_data = np.reshape(np.array(-10, dtype=np.int64), newshape=())\ninterpreter.set_tensor(input_details[0]['index'], params_data)\ninterpreter.set_tensor(input_details[1]['index'], indices_data)\n\n)\n\ninterpreter.invoke()",
    "Code change": [
      "@@ -123,6 +123,17 @@ TfLiteStatus GatherNdString(const TfLiteTensor* params,\n template <typename IndicesT>\n TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                           const TfLiteTensor* indices, TfLiteTensor* output) {\n+  bool indices_has_only_positive_elements = true;\n+  const auto* indices_values = GetTensorData<IndicesT>(indices);\n+  const size_t num_indices = indices->bytes / sizeof(IndicesT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indices_values[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   switch (params->type) {\n     case kTfLiteFloat32:\n       return GatherNd<float, IndicesT>(params, indices, output);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jwf9-w5xm-f437",
    "API Signature": null,
    "Score": 0.024822695035460994,
    "Anomaly": "Negative input tensor",
    "Category": "Tensor",
    "Argument": "indices_data = np.reshape(np.array(-10, dtype=np.int64), newshape=())"
  },
  {
    "Title": "\n        Missing validation in shape inference for `Dequantize`\n      ",
    "Bug description": "The shape inference code for  tf.raw_ops.Dequantize  has a vulnerability that could trigger a denial of service via a segfault if an attacker provides invalid arguments:",
    "Sample Code": "tf.compat.v1.disable_v2_behavior()\ntf.raw_ops.Dequantize(\n  input_tensor = tf.constant(-10.0, dtype=tf.float32),\n  input_tensor = tf.cast(input_tensor, dtype=tf.quint8),\n  min_range = tf.constant([], shape=[0], dtype=tf.float32),\n  max_range = tf.constant([], shape=[0], dtype=tf.float32),\n  mode  = 'MIN_COMBINED',\n  narrow_range=False,\n  axis=-10,\n  ,\n  dtype=tf.dtypes.float32)",
    "Code change": [
      "@@ -2990,6 +2990,10 @@ REGISTER_OP(\"Dequantize\")\n       if (!s.ok() && s.code() != error::NOT_FOUND) {\n         return s;\n       }\n+      if (axis < -1) {\n+        return errors::InvalidArgument(\"axis should be at least -1, got \",\n+                                       axis);\n+      }\n       const int minmax_rank = (axis == -1) ? 0 : 1;\n       TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n       ShapeHandle minmax;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qfpc-5pjr-mh26",
    "API Signature": "tf.raw_ops.Dequantize(\n    input,\n    min_range,\n    max_range,\n    mode='MIN_COMBINED',\n    narrow_range=False,\n    axis=-1,\n    dtype=tf.dtypes.float32,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Integer",
    "Argument": "axis=-10,"
  },
  {
    "Title": "\n        Division by 0 in most convolution operators\n      ",
    "Bug description": "Most implementations of convolution operators in TensorFlow are affected by a division by 0 vulnerability where an attacker can trigger a denial of service via a crash:",
    "Sample Code": "tf.compat.v1.disable_v2_behavior()\ntf.raw_ops.Conv2D(\n  input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),\n  filter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),\n  strides = [1, 1, 1, 1],\n  ],\n  padding = \"SAME\")",
    "Code change": [
      "@@ -672,6 +672,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -681,6 +683,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n       int64_t num_groups = input_depth_value / filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,\n@@ -816,6 +820,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -825,6 +831,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\n       int64_t num_groups = input_depth_value / filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,\n@@ -2456,6 +2464,9 @@ Status SparseReduceShapeFn(InferenceContext* c) {\n \n     int64_t ndims = shape_vec.size();\n     absl::flat_hash_set<int64> axes;\n+    if (ndims == 0)\n+      return errors::InvalidArgument(\n+          \"Number of dims in shape tensor must not be 0\");\n     for (int i = 0; i < axes_vec.size(); i++) {\n       axes.insert((axes_vec(i) + ndims) % ndims);\n     }\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9c8h-2mv3-49ww",
    "API Signature": "tf.raw_ops.Conv2D(\n    input,\n    filter,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "filter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),"
  },
  {
    "Title": "\n        Division by 0 in most convolution operators\n      ",
    "Bug description": "Most implementations of convolution operators in TensorFlow are affected by a division by 0 vulnerability where an attacker can trigger a denial of service via a crash:",
    "Sample Code": "tf.compat.v1.disable_v2_behavior()\ntf.raw_ops.Conv2D(\n  input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),\n  filter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),\n  strides = [1, 1, 1, 1],\n  ],\n  padding = \"SAME\")",
    "Code change": [
      "@@ -672,6 +672,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -681,6 +683,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n       int64_t num_groups = input_depth_value / filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,\n@@ -816,6 +820,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -825,6 +831,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\n       int64_t num_groups = input_depth_value / filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,\n@@ -2456,6 +2464,9 @@ Status SparseReduceShapeFn(InferenceContext* c) {\n \n     int64_t ndims = shape_vec.size();\n     absl::flat_hash_set<int64> axes;\n+    if (ndims == 0)\n+      return errors::InvalidArgument(\n+          \"Number of dims in shape tensor must not be 0\");\n     for (int i = 0; i < axes_vec.size(); i++) {\n       axes.insert((axes_vec(i) + ndims) % ndims);\n     }\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9c8h-2mv3-49ww",
    "API Signature": "tf.raw_ops.Conv2D(\n    input,\n    filter,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),"
  },
  {
    "Title": "\n        Reference binding to nullptr in shape inference\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in  tf.raw_ops.SparseFillEmptyRows :",
    "Sample Code": "tf.compat.v1.disable_v2_behavior()\ntf.raw_ops.SparseFillEmptyRows(\n  indices = tf.constant([], shape=[0, 0], dtype=tf.int64),\n  values = tf.constant([], shape=[0], dtype=tf.int64),\n  dense_shape = tf.constant([], shape=[0], dtype=tf.int64),\n  ),\n  default_value = 0)",
    "Code change": [
      "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/common_shape_fns.h\"\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/shape_inference.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -619,6 +620,8 @@ REGISTER_OP(\"SparseFillEmptyRows\")\n       DimensionHandle unused_dim;\n       TF_RETURN_IF_ERROR(c->Merge(c->Dim(input_indices, 1),\n                                   c->Dim(input_shape, 0), &unused_dim));\n+      if (c->Value(c->NumElements(input_shape)) == 0)\n+        return errors::InvalidArgument(\"dense_shape must not be empty\");\n       ShapeHandle output_indices =\n           c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));\n       ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v768-w7m9-2vmm",
    "API Signature": "tf.raw_ops.SparseFillEmptyRows(\n    indices, values, dense_shape, default_value, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "dense_shape = tf.constant([], shape=[0], dtype=tf.int64),"
  },
  {
    "Title": "\n        Incomplete validation in `MaxPoolGrad`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a segmentation fault in  tf.raw_ops.MaxPoolGrad  caused by missing validation:",
    "Sample Code": "tf.raw_ops.MaxPoolGrad(\n  orig_input = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  orig_output = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  grad = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  ksize = [1, 16, 16, 1],\n  strides = [1, 16, 18, 1],\n  padding = \"EXPLICIT\",\n  ,\n  explicit_paddings = [0, 0, 14, 3, 15, 5, 0, 0])",
    "Code change": [
      "@@ -74,6 +74,7 @@ static void SpatialMaxPoolWithArgMaxHelper(\n         errors::Internal(\"SpatialMaxPoolWithArgMaxHelper requires Targmax \"\n                          \"to be int64 when input_backprop != nullptr\"));\n   }\n+  if (tensor_in.NumElements() == 0 || output->NumElements() == 0) return;\n \n   typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n       ConstEigenMatrixMap;\n@@ -949,6 +950,10 @@ class MaxPoolingWithArgmaxOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& tensor_in = context->input(0);\n+    OP_REQUIRES(context, tensor_in.dims() == 4,\n+                errors::InvalidArgument(\"tensor_in must be 4-dimensional (2)\"));\n+    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n+                errors::InvalidArgument(\"tensor_in must not be empty (2)\"));\n \n     PoolParameters params{context,\n                           ksize_,\n",
      "@@ -171,6 +171,8 @@ PoolParameters::PoolParameters(OpKernelContext* context,\n     pad_depth = 0;\n     out_depth = depth;\n   } else {\n+    OP_REQUIRES(context, depth_window > 0,\n+                errors::InvalidArgument(\"depth_window must not be 0\"));\n     // Our current version of depthwise max pooling does not support\n     // any padding, and expects the depth_window to equal the\n     // depth_stride (no overlapping).\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-7ghq-fvr3-pj2x",
    "API Signature": "tf.raw_ops.MaxPoolGrad(\n    orig_input,\n    orig_output,\n    grad,\n    ksize,\n    strides,\n    padding,\n    explicit_paddings=[],\n    data_format='NHWC',\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "orig_input = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),"
  },
  {
    "Title": "\n        Incomplete validation in `MaxPoolGrad`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a segmentation fault in  tf.raw_ops.MaxPoolGrad  caused by missing validation:",
    "Sample Code": "tf.raw_ops.MaxPoolGrad(\n  orig_input = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  orig_output = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  grad = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  ksize = [1, 16, 16, 1],\n  strides = [1, 16, 18, 1],\n  padding = \"EXPLICIT\",\n  ,\n  explicit_paddings = [0, 0, 14, 3, 15, 5, 0, 0])",
    "Code change": [
      "@@ -74,6 +74,7 @@ static void SpatialMaxPoolWithArgMaxHelper(\n         errors::Internal(\"SpatialMaxPoolWithArgMaxHelper requires Targmax \"\n                          \"to be int64 when input_backprop != nullptr\"));\n   }\n+  if (tensor_in.NumElements() == 0 || output->NumElements() == 0) return;\n \n   typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n       ConstEigenMatrixMap;\n@@ -949,6 +950,10 @@ class MaxPoolingWithArgmaxOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& tensor_in = context->input(0);\n+    OP_REQUIRES(context, tensor_in.dims() == 4,\n+                errors::InvalidArgument(\"tensor_in must be 4-dimensional (2)\"));\n+    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n+                errors::InvalidArgument(\"tensor_in must not be empty (2)\"));\n \n     PoolParameters params{context,\n                           ksize_,\n",
      "@@ -171,6 +171,8 @@ PoolParameters::PoolParameters(OpKernelContext* context,\n     pad_depth = 0;\n     out_depth = depth;\n   } else {\n+    OP_REQUIRES(context, depth_window > 0,\n+                errors::InvalidArgument(\"depth_window must not be 0\"));\n     // Our current version of depthwise max pooling does not support\n     // any padding, and expects the depth_window to equal the\n     // depth_stride (no overlapping).\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-7ghq-fvr3-pj2x",
    "API Signature": "tf.raw_ops.MaxPoolGrad(\n    orig_input,\n    orig_output,\n    grad,\n    ksize,\n    strides,\n    padding,\n    explicit_paddings=[],\n    data_format='NHWC',\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "orig_input = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),"
  },
  {
    "Title": "\n        `CHECK`-fail in `MapStage`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in  tf.raw_ops.MapStage :",
    "Sample Code": "tf.raw_ops.MapStage(\n  key=tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64),\n  indices=tf.constant((0), dtype=tf.int32),\n  values=[tf.constant((0), dtype=tf.int32)],\n  dtypes=[tf.int32,\n  tf.int64],\n  capacity=0,\n  memory_limit=0,\n  container='',\n  ,\n  shared_name='')",
    "Code change": [
      "@@ -527,6 +527,8 @@ class MapStageOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->input(\"key\", &key_tensor));\n     OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));\n     OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));\n+    OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\n+                errors::InvalidArgument(\"key must not be empty\"));\n \n     // Create copy for insertion into Staging Area\n     Tensor key(*key_tensor);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-278g-rq84-9hmg",
    "API Signature": "tf.raw_ops.MapStage(\n    key,\n    indices,\n    values,\n    dtypes,\n    capacity=0,\n    memory_limit=0,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "key=tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64),"
  },
  {
    "Title": "\n        Heap OOB in `SdcaOptimizerV2`\n      ",
    "Bug description": "An attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to  tf.raw_ops.SdcaOptimizerV2 :",
    "Sample Code": "tf.raw_ops.SdcaOptimizerV2(\n  sparse_example_indices=[[1]],\n  sparse_feature_indices=[[1]],\n  sparse_feature_values=[[1.0,2.0]],\n  dense_features=[[1.0]],\n  example_weights=[1.0],\n  example_labels=[],\n  sparse_indices=[1],\n  sparse_weights=[1.0],\n  dense_weights=[[1.0]],\n  example_state_data=[[100.0,100.0,100.0,100.0]],\n  loss_type='logistic_loss',\n  l1=100.0,\n  l2=100.0,\n  num_loss_partitions=1,\n  num_inner_iterations=1,\n  ,\n  adaptive=True)       ",
    "Code change": [
      "@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\n   const Tensor* example_labels_t;\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n   auto example_labels = example_labels_t->flat<float>();\n+  if (example_labels.size() != num_examples) {\n+    return errors::InvalidArgument(\"Expected \", num_examples,\n+                                   \" example labels but got \",\n+                                   example_labels.size());\n+  }\n \n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5hj3-vjjf-f5m7",
    "API Signature": "tf.raw_ops.SdcaOptimizerV2(\n    sparse_example_indices,\n    sparse_feature_indices,\n    sparse_feature_values,\n    dense_features,\n    example_weights,\n    example_labels,\n    sparse_indices,\n    sparse_weights,\n    dense_weights,\n    example_state_data,\n    loss_type,\n    l1,\n    l2,\n    num_loss_partitions,\n    num_inner_iterations,\n    adaptive=True,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "example_labels=[],"
  },
  {
    "Title": "\n        Reference binding to nullptr in map operations\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in  tf.raw_ops.Map*  and  tf.raw_ops.OrderedMap*  operations:",
    "Sample Code": "tf.raw_ops.MapPeek(\n  key=tf.constant([8],dtype=tf.int64),\n  indices=[],\n  dtypes=[tf.int32],\n  capacity=8,\n  ,\n  memory_limit=128)",
    "Code change": [
      "@@ -210,9 +210,9 @@ class StagingMap : public ResourceBase {\n                                    const OptionalTuple& tuple)\n       TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {\n     if (tuple[index].has_value()) {\n-      return Status(errors::InvalidArgument(\n+      return errors::InvalidArgument(\n           \"The tensor for index '\", index, \"' for key '\", key.scalar<int64>()(),\n-          \"' was already initialized '\", dtypes_.size(), \"'.\"));\n+          \"' was already initialized '\", dtypes_.size(), \"'.\");\n     }\n \n     return Status::OK();\n@@ -220,6 +220,10 @@ class StagingMap : public ResourceBase {\n \n   // Check that the indices are strictly ordered\n   Status check_index_ordering(const Tensor& indices) {\n+    if (indices.NumElements() == 0) {\n+      return errors::InvalidArgument(\"Indices are empty\");\n+    }\n+\n     auto findices = indices.flat<int>();\n \n     for (std::size_t i = 0; i < findices.dimension(0) - 1; ++i) {\n@@ -227,8 +231,7 @@ class StagingMap : public ResourceBase {\n         continue;\n       }\n \n-      return Status(\n-          errors::InvalidArgument(\"Indices are not strictly ordered\"));\n+      return errors::InvalidArgument(\"Indices are not strictly ordered\");\n     }\n \n     return Status::OK();\n@@ -238,10 +241,10 @@ class StagingMap : public ResourceBase {\n   Status check_memory_limit(std::size_t bytes)\n       TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {\n     if (has_memory_limit() && bytes > memory_limit_) {\n-      return Status(errors::ResourceExhausted(\n+      return errors::ResourceExhausted(\n           \"Attempted to insert tensors with combined size of '\", bytes,\n           \"' bytes into Staging Area with a memory limit of '\", memory_limit_,\n-          \"'.\"));\n+          \"'.\");\n     }\n \n     return Status::OK();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qr82-2c78-4m8h",
    "API Signature": "tf.raw_ops.MapPeek(\n    key,\n    indices,\n    dtypes,\n    capacity=0,\n    memory_limit=0,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Empty list",
    "Category": "List",
    "Argument": "indices=[],"
  },
  {
    "Title": "\n        Heap OOB in `UpperBound` and `LowerBound`\n      ",
    "Bug description": "An attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to  tf.raw_ops.UpperBound :",
    "Sample Code": "tf.raw_ops.UpperBound(\n  sorted_input=[1,2,3],\n  values=tf.constant(value=[[0,0,0],[1,1,1],[2,2,2]],dtype=tf.int64),\n  ),\n  out_type=tf.int64)",
    "Code change": [
      "@@ -86,6 +86,10 @@ class UpperBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    // inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     // must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n@@ -127,6 +131,10 @@ class LowerBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    // inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     // must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9697-98pf-4rw7",
    "API Signature": "tf.raw_ops.UpperBound(\n    sorted_inputs,\n    values,\n    out_type=tf.dtypes.int32,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "sorted_input=[1,2,3],"
  },
  {
    "Title": "\n        Heap OOB in `UpperBound` and `LowerBound`\n      ",
    "Bug description": "An attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to  tf.raw_ops.UpperBound :",
    "Sample Code": "tf.raw_ops.UpperBound(\n  sorted_input=[1,2,3],\n  values=tf.constant(value=[[0,0,0],[1,1,1],[2,2,2]],dtype=tf.int64),\n  ),\n  out_type=tf.int64)",
    "Code change": [
      "@@ -86,6 +86,10 @@ class UpperBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    // inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     // must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n@@ -127,6 +131,10 @@ class LowerBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    // inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     // must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9697-98pf-4rw7",
    "API Signature": "tf.raw_ops.LowerBound(\n    sorted_inputs,\n    values,\n    out_type=tf.dtypes.int32,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "sorted_input=[1,2,3],"
  },
  {
    "Title": "\n        Crash in NMS ops caused by integer conversion to unsigned\n      ",
    "Bug description": "An attacker can cause denial of service in applications serving models using  tf.raw_ops.NonMaxSuppressionV5  by triggering a division by 0:",
    "Sample Code": "tf.raw_ops.NonMaxSuppressionV5(\n  boxes=[[[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]],[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]],[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]]]],\n  scores=[[[1.0,2.0,3.0],[1.0,2.0,3.0],[1.0,2.0,3.0]]],\n  max_output_size_per_class=-1,\n  max_total_size=10,\n  iou_threshold=score_threshold=0.5,\n  pad_per_class=True,\n  ,\n  clip_boxes=True)",
    "Code change": [
      "@@ -169,6 +169,8 @@ void DoNonMaxSuppressionOp(OpKernelContext* context, const Tensor& scores,\n                            bool pad_to_max_output_size = false,\n                            int* ptr_num_valid_outputs = nullptr) {\n   const int output_size = max_output_size.scalar<int>()();\n+  OP_REQUIRES(context, output_size >= 0,\n+              errors::InvalidArgument(\"output size must be non-negative\"));\n \n   std::vector<T> scores_data(num_boxes);\n   std::copy_n(scores.flat<T>().data(), num_boxes, scores_data.begin());\n@@ -768,6 +770,9 @@ class NonMaxSuppressionV4Op : public OpKernel {\n         context, scores, num_boxes, max_output_size, iou_threshold_val,\n         score_threshold_val, dummy_soft_nms_sigma, similarity_fn,\n         return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);\n+    if (!context->status().ok()) {\n+      return;\n+    }\n \n     // Allocate scalar output tensor for number of indices computed.\n     Tensor* num_outputs_t = nullptr;\n@@ -845,6 +850,9 @@ class NonMaxSuppressionV5Op : public OpKernel {\n         context, scores, num_boxes, max_output_size, iou_threshold_val,\n         score_threshold_val, soft_nms_sigma_val, similarity_fn,\n         return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);\n+    if (!context->status().ok()) {\n+      return;\n+    }\n \n     // Allocate scalar output tensor for number of indices computed.\n     Tensor* num_outputs_t = nullptr;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vmjw-c2vp-p33c",
    "API Signature": "tf.raw_ops.NonMaxSuppressionV5(\n    boxes,\n    scores,\n    max_output_size,\n    iou_threshold,\n    score_threshold,\n    soft_nms_sigma,\n    pad_to_max_output_size=False,\n    name=None\n)\n",
    "Score": 0.03900709219858156,
    "Anomaly": "Negative integer argument",
    "Category": "Integer",
    "Argument": "max_output_size=-1,"
  },
  {
    "Title": "\n        Crash in NMS ops caused by integer conversion to unsigned\n      ",
    "Bug description": "An attacker can cause denial of service in applications serving models using  tf.raw_ops.NonMaxSuppressionV5  by triggering a division by 0:",
    "Sample Code": "tf.raw_ops.NonMaxSuppressionV5(\n  boxes=[[[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]],[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]],[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]]]],\n  scores=[[[1.0,2.0,3.0],[1.0,2.0,3.0],[1.0,2.0,3.0]]],\n  max_output_size_per_class=-1,\n  max_total_size=10,\n  iou_threshold=score_threshold=0.5,\n  pad_per_class=True,\n  ,\n  clip_boxes=True)",
    "Code change": [
      "@@ -169,6 +169,8 @@ void DoNonMaxSuppressionOp(OpKernelContext* context, const Tensor& scores,\n                            bool pad_to_max_output_size = false,\n                            int* ptr_num_valid_outputs = nullptr) {\n   const int output_size = max_output_size.scalar<int>()();\n+  OP_REQUIRES(context, output_size >= 0,\n+              errors::InvalidArgument(\"output size must be non-negative\"));\n \n   std::vector<T> scores_data(num_boxes);\n   std::copy_n(scores.flat<T>().data(), num_boxes, scores_data.begin());\n@@ -768,6 +770,9 @@ class NonMaxSuppressionV4Op : public OpKernel {\n         context, scores, num_boxes, max_output_size, iou_threshold_val,\n         score_threshold_val, dummy_soft_nms_sigma, similarity_fn,\n         return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);\n+    if (!context->status().ok()) {\n+      return;\n+    }\n \n     // Allocate scalar output tensor for number of indices computed.\n     Tensor* num_outputs_t = nullptr;\n@@ -845,6 +850,9 @@ class NonMaxSuppressionV5Op : public OpKernel {\n         context, scores, num_boxes, max_output_size, iou_threshold_val,\n         score_threshold_val, soft_nms_sigma_val, similarity_fn,\n         return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);\n+    if (!context->status().ok()) {\n+      return;\n+    }\n \n     // Allocate scalar output tensor for number of indices computed.\n     Tensor* num_outputs_t = nullptr;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vmjw-c2vp-p33c",
    "API Signature": "tf.raw_ops.CombinedNonMaxSuppression(\n    boxes,\n    scores,\n    max_output_size_per_class,\n    max_total_size,\n    iou_threshold,\n    score_threshold,\n    pad_per_class=False,\n    clip_boxes=True,\n    name=None\n)\n",
    "Score": 0.03900709219858156,
    "Anomaly": "Negative integer argument",
    "Category": "Integer",
    "Argument": "max_output_size=-1,"
  },
  {
    "Title": "\n        FPE in `tf.raw_ops.UnravelIndex`\n      ",
    "Bug description": "An attacker can cause denial of service in applications serving models using  tf.raw_ops.UnravelIndex  by triggering a division by 0:",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.UnravelIndex(indices=-1, dims=[1,0,2])",
    "Code change": [
      "@@ -53,6 +53,14 @@ class UnravelIndexOp : public OpKernel {\n                                 dims_tensor.shape().DebugString(), \"\\\"\"));\n \n     auto dims = dims_tensor.vec<Tidx>();\n+    // Make sure dims does not contain a zero\n+    for (int i = 0; i < dims.size(); i++) {\n+      OP_REQUIRES(\n+          ctx, dims(i) != 0,\n+          errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"\n+                                  \"but dims contains zero at index \",\n+                                  i));\n+    }\n \n     // Chek to make sure indices is not out of boundary\n     Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();\n",
      "@@ -1575,7 +1575,7 @@ class UnravelIndexTest(test_util.TensorFlowTestCase):\n     with self.cached_session():\n       for dtype in [dtypes.int32, dtypes.int64]:\n         with self.assertRaisesRegex(errors.InvalidArgumentError,\n-                                    \"index is out of bound as with dims\"):\n+                                    \"dims cannot contain a dim of zero\"):\n           indices = constant_op.constant([2, 5, 7], dtype=dtype)\n           dims = constant_op.constant([3, 0], dtype=dtype)\n           self.evaluate(array_ops.unravel_index(indices=indices, dims=dims))\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2wmv-37vq-52g5",
    "API Signature": "tf.raw_ops.UnravelIndex(\n    indices, dims, name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Zero integer list element",
    "Category": "Integer",
    "Argument": "dims=[1,0,2]"
  },
  {
    "Title": "\n        Reference binding to nullptr in unicode encoding\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in  tf.raw_ops.UnicodeEncode :",
    "Sample Code": "from tensorflow.python.ops import gen_string_ops\n\ngen_string_ops.unicode_encode(\n  input_values=[],\n  input_splits=[],\n  output_encoding='UTF-8',\n  errors='ignore',\n  ,\n  replacement_char='a')",
    "Code change": [
      "@@ -533,6 +533,10 @@ class UnicodeEncodeOp : public OpKernel {\n     const Tensor& input_splits = context->input(1);\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n \n+    OP_REQUIRES(\n+        context, input_splits.NumElements() > 0,\n+        errors::InvalidArgument(\"Input_splits should contain elements, but \"\n+                                \"given input_values has 0 elements\"));\n     // Operation will treat first argument in input_splits as if it were zero\n     // regardless of its actual value since splits should begin with zero and\n     // end with the length of the input values vector.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-w74j-v8xh-3w5h",
    "API Signature": null,
    "Score": 0.024822695035460994,
    "Anomaly": "Empty list",
    "Category": "List",
    "Argument": "input_splits=[],"
  },
  {
    "Title": "\n        Reference binding to nullptr in `RaggedTensorToVariant`\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in  tf.raw_ops.RaggedTensorToVariant :",
    "Sample Code": "tf.raw_ops.RaggedTensorToVariant(\n  rt_nested_splits=[],\n  rt_dense_values=[1,2,3],\n  ],\n  batched_input=True)",
    "Code change": [
      "@@ -157,6 +157,12 @@ class RaggedTensorToVariantOp : public OpKernel {\n       return;\n     }\n \n+    // Checked here instead of at input in case batched_input_ is false\n+    OP_REQUIRES(context, ragged_nested_splits_len > 0,\n+                errors::InvalidArgument(\n+                    \"rt_nested_splits must be a list of one or more, but \"\n+                    \"received rt_nested_splits of length 0.\"));\n+\n     // Unbatch the Ragged Tensor and encode the components.\n     std::vector<RaggedTensorVariant> unbatched_ragged_input;\n     auto batched_splits_top_vec =\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-w4xf-2pqw-5mq7",
    "API Signature": "tf.raw_ops.RaggedTensorToVariant(\n    rt_nested_splits, rt_dense_values, batched_input, name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Empty list",
    "Category": "List",
    "Argument": "rt_nested_splits=[],"
  },
  {
    "Title": "\n        Incomplete validation in MKL requantization\n      ",
    "Bug description": "Due to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "from tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  [],\n  out_type=tf.int)",
    "Code change": [
      "@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v82p-hv3v-p6qp",
    "API Signature": "tf.raw_ops.RequantizationRangePerChannel(\n    input, input_min, input_max, clip_value_max, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "input=[],"
  },
  {
    "Title": "\n        Incomplete validation in MKL requantization\n      ",
    "Bug description": "Due to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "from tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  [],\n  out_type=tf.int)",
    "Code change": [
      "@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v82p-hv3v-p6qp",
    "API Signature": "tf.raw_ops.RequantizationRangePerChannel(\n    input, input_min, input_max, clip_value_max, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "input_min=[-100,-100,-100,-100,-100],\ninput_max=[-100,-100,-100],"
  },
  {
    "Title": "\n        Incomplete validation in MKL requantization\n      ",
    "Bug description": "Due to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "from tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  [],\n  out_type=tf.int)",
    "Code change": [
      "@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v82p-hv3v-p6qp",
    "API Signature": "tf.raw_ops.RequantizationRangePerChannel(\n    input, input_min, input_max, clip_value_max, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "input=[],\ninput_min=[-100,-100,-100,-100,-100],"
  },
  {
    "Title": "\n        Incomplete validation in MKL requantization\n      ",
    "Bug description": "Due to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "from tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  [],\n  out_type=tf.int)",
    "Code change": [
      "@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v82p-hv3v-p6qp",
    "API Signature": null,
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],"
  },
  {
    "Title": "\n        Incomplete validation in MKL requantization\n      ",
    "Bug description": "Due to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "from tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  [],\n  out_type=tf.int)",
    "Code change": [
      "@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v82p-hv3v-p6qp",
    "API Signature": null,
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "input=[],"
  },
  {
    "Title": "\n        Incomplete validation in `QuantizeV2`\n      ",
    "Bug description": "Due to incomplete validation in  tf.raw_ops.QuantizeV2 , an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "tf.raw_ops.QuantizeV2(\n  input=[1,2,3],\n  min_range=[1,2],\n  max_range=[],\n  T=tf.qint32,\n  mode='SCALED',\n  round_mode='HALF_AWAY_FROM_ZERO',\n  narrow_range=False,\n  axis=1,\n  ,\n  ensure_minimum_range=3)",
    "Code change": [
      "@@ -113,7 +113,50 @@ class QuantizeV2Op : public OpKernel {\n \n     int num_slices = 1;\n     if (axis_ > -1) {\n+      OP_REQUIRES(\n+          ctx, input.dims() > axis_,\n+          errors::InvalidArgument(\n+              \"Axis is on a zero-based index, so its value must always be less \"\n+              \"than number of input's dims, but given axis value was \",\n+              axis_, \" and input's dims was \", input.dims()));\n       num_slices = input.dim_size(axis_);\n+      OP_REQUIRES(ctx, input_min_range.dims() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but min_range dims are \",\n+                      input_min_range.dims()));\n+      OP_REQUIRES(ctx, input_min_range.dim_size(0) == num_slices,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but min_range is a 1-D tensor of size \",\n+                      input_min_range.dim_size(0),\n+                      \" and input's axis dimension is of size \", num_slices));\n+      OP_REQUIRES(ctx, input_max_range.dims() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but max_range dims are \",\n+                      input_max_range.dims()));\n+      OP_REQUIRES(ctx, input_max_range.dim_size(0) == num_slices,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but max_range is a 1-D tensor of size \",\n+                      input_max_range.dim_size(0),\n+                      \" and input's axis dimension is of size \", num_slices));\n+    } else {\n+      OP_REQUIRES(ctx, input_min_range.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is not specified, min_range must contain a \"\n+                      \"single float element, but it contains \",\n+                      input_min_range.NumElements(), \" elements\"));\n+      OP_REQUIRES(ctx, input_max_range.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is not specified, max_range must contain a \"\n+                      \"single float element, but it contains \",\n+                      input_max_range.NumElements(), \" elements\"));\n     }\n \n     const TensorShape& minmax_shape = ctx->input(1).shape();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-g25h-jr74-qp5j",
    "API Signature": "tf.raw_ops.QuantizeV2(\n    input,\n    min_range,\n    max_range,\n    T,\n    mode='MIN_COMBINED',\n    round_mode='HALF_AWAY_FROM_ZERO',\n    narrow_range=False,\n    axis=-1,\n    ensure_minimum_range=0.01,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "min_range=[1,2],\nmax_range=[],"
  },
  {
    "Title": "\n        Heap OOB in boosted trees\n      ",
    "Bug description": "An attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to  BoostedTreesSparseCalculateBestFeatureSplit :",
    "Sample Code": "tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit(\n  node_id_range=[0,10],\n  stats_summary_indices=[[1, 2, 3, 0x1000000]],\n  stats_summary_values=[1.0],\n  stats_summary_shape=[1,1,1,1],\n  l1=l2=[1.0],\n  tree_complexity=[0.5],\n  min_node_weight=[1.0],\n  logits_dimension=3,\n  ,\n  split_type='inequality')                                                                                                                                                                                                                                                                ",
    "Code change": [
      "@@ -1050,6 +1050,13 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\n       const int32_t feature_dim = stats_summary_indices(idx, 1);\n       const int32_t bucket_id = stats_summary_indices(idx, 2);\n       const int32_t stat_dim = stats_summary_indices(idx, 3);\n+      OP_REQUIRES(context, stat_dim < stats_dims,\n+                  errors::InvalidArgument(\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\n+                      \"stats_summary_indices, cannot be greater than stats \"\n+                      \"dims, the last value in stats_summary_shape, which was \",\n+                      stats_dims, \". At index (\", idx,\n+                      \", 4), stats_summary_indices contains value \", stat_dim));\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\n       auto& b_map = f_insert_result.first->second;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-r4c4-5fpq-56wg",
    "API Signature": "tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit(\n    node_id_range,\n    stats_summary_indices,\n    stats_summary_values,\n    stats_summary_shape,\n    l1,\n    l2,\n    tree_complexity,\n    min_node_weight,\n    logits_dimension,\n    split_type='inequality',\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "  stats_summary_indices=[[1, 2, 3, 0x1000000]],\n  stats_summary_values=[1.0],\n  stats_summary_shape=[1,1,1,1],"
  },
  {
    "Title": "\n        Crash caused by integer conversion to unsigned\n      ",
    "Bug description": "An attacker can cause a denial of service in  boosted_trees_create_quantile_stream_resource  by using negative arguments:",
    "Sample Code": "from tensorflow.python.ops import gen_boosted_trees_ops\nimport numpy as np\n\nv= tf.Variable([0.0, 0.0, 0.0, 0.0, 0.0])\ngen_boosted_trees_ops.boosted_trees_create_quantile_stream_resource(\n  quantile_stream_resource_handle = v.handle,\n  epsilon = [74.82224],\n  num_streams = [-49], \n  ], \n  max_elements = np.int32(586))",
    "Code change": [
      "@@ -116,6 +116,9 @@ class BoostedTreesCreateQuantileStreamResourceOp : public OpKernel {\n     const Tensor* num_streams_t;\n     OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\n     int64_t num_streams = num_streams_t->scalar<int64>()();\n+    OP_REQUIRES(context, num_streams >= 0,\n+                errors::InvalidArgument(\n+                    \"Num_streams input cannot be a negative integer\"));\n \n     auto result =\n         new QuantileStreamResource(epsilon, max_elements_, num_streams);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gf88-j2mg-cc82",
    "API Signature": null,
    "Score": 0.028368794326241134,
    "Anomaly": "Negative integer list element",
    "Category": "List",
    "Argument": "num_streams = [-49],"
  },
  {
    "Title": "\n        Division by 0 in inplace operations\n      ",
    "Bug description": "An attacker can cause a floating point exception by calling inplace operations with crafted arguments that would result in a division by 0:",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.InplaceSub(x=[],i=[-99,-1,-1],v=[1,1,1])",
    "Code change": [
      "@@ -225,7 +225,7 @@ class InplaceOpBase : public OpKernel {\n \n     Tensor y = x;  // This creates an alias intentionally.\n     // Skip processing if tensors are empty.\n-    if (x.NumElements() > 0 || v.NumElements() > 0) {\n+    if (x.NumElements() > 0 && v.NumElements() > 0) {\n       OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));\n     }\n     ctx->set_output(0, y);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cm5x-837x-jf3c",
    "API Signature": "tf.raw_ops.InplaceSub(\n    x, i, v, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "x=[]"
  },
  {
    "Title": "\n        Reference binding to nullptr and heap OOB in binary cwise ops\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in all binary cwise operations that don't require broadcasting (e.g., gradients of binary cwise operations):",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.SqrtGrad(y=[4, 16],dy=[])",
    "Code change": [
      "@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& in0 = ctx->input(0);\n     const Tensor& in1 = ctx->input(1);\n+    OP_REQUIRES(\n+        ctx, in0.NumElements() == in1.NumElements(),\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\n+                                \"same number of elements, got \",\n+                                in0.NumElements(), \" and \", in1.NumElements()));\n     auto in0_flat = in0.flat<Tin>();\n     auto in1_flat = in1.flat<Tin>();\n     const Device& eigen_device = ctx->eigen_device<Device>();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-q3g3-h9r4-prrc",
    "API Signature": "tf.raw_ops.SqrtGrad(\n    y, dy, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "y=[4, 16]\ndy=[]"
  },
  {
    "Title": "\n        Reference binding to nullptr in `MatrixSetDiagV*` ops\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in all operations of type  tf.raw_ops.MatrixSetDiagV* :",
    "Sample Code": "tf.raw_ops.MatrixSetDiagV3(\n  input=[1,2,3],\n  diagonal=[1,1],\n  k=[],\n  [],\n  align='RIGHT_LEFT')",
    "Code change": [
      "@@ -70,6 +70,9 @@ class MatrixSetDiagOp : public OpKernel {\n                   errors::InvalidArgument(\n                       \"diag_index must be a scalar or vector, received shape: \",\n                       diag_index.shape().DebugString()));\n+      OP_REQUIRES(\n+          context, diag_index.NumElements() > 0,\n+          errors::InvalidArgument(\"diag_index must have at least one element\"));\n       lower_diag_index = diag_index.flat<int32>()(0);\n       upper_diag_index = lower_diag_index;\n       if (TensorShapeUtils::IsVector(diag_index.shape())) {\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6p5r-g9mq-ggh2",
    "API Signature": "tf.raw_ops.MatrixSetDiagV3(\n    input, diagonal, k, align='RIGHT_LEFT', name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "k=[],"
  },
  {
    "Title": "\n        Reference binding to nullptr in `MatrixDiagV*` ops\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in all operations of type  tf.raw_ops.MatrixDiagV* :",
    "Sample Code": "tf.raw_ops.MatrixDiagV3(\n  diagonal=[1,0],\n  k=[],\n  num_rows=[1,2,3],\n  num_cols=[4,5],\n  padding_value=[],\n  [],\n  align='RIGHT_RIGHT')",
    "Code change": [
      "@@ -73,6 +73,9 @@ class MatrixDiagPartOp : public OpKernel {\n                   errors::InvalidArgument(\n                       \"diag_index must be a scalar or vector, received shape: \",\n                       diag_index.shape().DebugString()));\n+      OP_REQUIRES(context, diag_index.NumElements() > 0,\n+                  errors::InvalidArgument(\n+                      \"Expected diag_index to have at least 1 element\"));\n       lower_diag_index = diag_index.flat<int32>()(0);\n       upper_diag_index = lower_diag_index;\n       if (TensorShapeUtils::IsVector(diag_index.shape())) {\n@@ -179,6 +182,9 @@ class MatrixDiagOp : public OpKernel {\n                   errors::InvalidArgument(\n                       \"diag_index must be a scalar or vector, received shape: \",\n                       diag_index.shape().DebugString()));\n+      OP_REQUIRES(context, diag_index.NumElements() > 0,\n+                  errors::InvalidArgument(\n+                      \"Expected diag_index to have at least 1 element\"));\n       lower_diag_index = diag_index.flat<int32>()(0);\n       upper_diag_index = lower_diag_index;\n       if (TensorShapeUtils::IsVector(diag_index.shape())) {\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5xwc-mrhx-5g3m",
    "API Signature": "tf.raw_ops.MatrixDiagV3(\n    diagonal,\n    k,\n    num_rows,\n    num_cols,\n    padding_value,\n    align='RIGHT_LEFT',\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "k=[],"
  },
  {
    "Title": "\n        Reference binding to nullptr in `RaggedTensorToSparse`\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in  tf.raw_ops.RaggedTensorToSparse :",
    "Sample Code": "tf.raw_ops.RaggedTensorToSparse(\n  rt_nested_splits=[[0, 38, 0]],\n  ]],\n  rt_dense_values=[])",
    "Code change": [
      "@@ -21,6 +21,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -38,7 +39,8 @@ class RaggedTensorToSparseOp : public OpKernel {\n     OP_REQUIRES_OK(\n         context, context->input_list(\"rt_nested_splits\", &rt_nested_splits_in));\n     const int rt_nested_splits_len = rt_nested_splits_in.size();\n-    DCHECK_GT(rt_nested_splits_len, 0);  // Enforced by REGISTER_OP.\n+    OP_REQUIRES(context, rt_nested_splits_len > 0,\n+                errors::InvalidArgument(\"rt_nested_splits must be non empty\"));\n     std::vector<ConstFlatSplits> rt_nested_splits;\n     rt_nested_splits.reserve(rt_nested_splits_len);\n     for (int i = 0; i < rt_nested_splits_len; ++i) {\n@@ -162,6 +164,14 @@ class RaggedTensorToSparseOp : public OpKernel {\n       if (rt_nested_splits[i](0) != 0) {\n         return InvalidArgument(\"First value of ragged splits must be 0.\");\n       }\n+      for (int j = 1; j < rt_nested_splits[i].size(); ++j) {\n+        if (rt_nested_splits[i](j) < rt_nested_splits[i](j - 1)) {\n+          return InvalidArgument(\n+              \"Ragged splits should be non decreasing, but we got \",\n+              rt_nested_splits[i](j - 1), \" followed by \",\n+              rt_nested_splits[i](j));\n+        }\n+      }\n       if (i > 0) {\n         SPLITS_TYPE last_split =\n             rt_nested_splits[i - 1](rt_nested_splits[i - 1].size() - 1);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4xfp-4pfp-89wg",
    "API Signature": "tf.raw_ops.RaggedTensorToSparse(\n    rt_nested_splits, rt_dense_values, name=None\n)\n",
    "Score": 0.0035460992907801418,
    "Anomaly": "Non increasing order of elements",
    "Category": "List",
    "Argument": "rt_nested_splits=[[0, 38, 0]],"
  },
  {
    "Title": "\n        Heap OOB in `ResourceScatterUpdate`\n      ",
    "Bug description": "An attacker can trigger a read from outside of bounds of heap allocated data by sending invalid arguments to  tf.raw_ops.ResourceScatterUpdate :",
    "Sample Code": "v = tf.Variable([b'vvv'])\ntf.raw_ops.ResourceScatterUpdate(\n  resource=v.handle,\n  indices=[0],\n  ],\n  updates=['1', '2', '3', '4', '5'])",
    "Code change": [
      "@@ -955,11 +955,12 @@ class ResourceScatterUpdateOp : public OpKernel {\n                         params->dim_size(0), \")\"));\n       } else {\n         int64_t num_updates = updates.NumElements();\n-        OP_REQUIRES(c, num_updates % N == 0,\n-                    errors::InvalidArgument(\n-                        \"shape of indices (\", indices.shape().DebugString(),\n-                        \") is not compatible with the shape of updates (\",\n-                        updates.shape().DebugString(), \")\"));\n+        OP_REQUIRES(\n+            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n+            errors::InvalidArgument(\n+                \"The shape of indices (\", indices.shape().DebugString(),\n+                \") must be a prefix of the shape of updates (\",\n+                updates.shape().DebugString(), \")\"));\n         auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n \n         functor::ScatterFunctor<Device, T, Index, op> functor;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-7fvx-3jfc-2cpc",
    "API Signature": "tf.raw_ops.ResourceScatterUpdate(\n    resource, indices, updates, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "indices=[0],\nupdates=['1', '2', '3', '4', '5']"
  },
  {
    "Title": "\n        Heap OOB and CHECK fail in `ResourceGather`\n      ",
    "Bug description": "An attacker can trigger a crash via a  CHECK -fail in debug builds of TensorFlow using  tf.raw_ops.ResourceGather  or a read from outside the bounds of heap allocated data in the same API in a release build:",
    "Sample Code": "tensor = tf.constant(value=[[1,2],[3,4],[5,6]],shape=(3,2),dtype=tf.uint32)\nv = tf.Variable(tensor)\ntf.raw_ops.ResourceGather(\n  resource=v.handle,\n  indices=[0],\n  dtype=tf.uint32,\n  batch_dims=10,\n  ,\n  validate_indices=False)",
    "Code change": [
      "@@ -660,6 +660,11 @@ class ResourceGatherOp : public OpKernel {\n     OP_REQUIRES(\n         c, TensorShapeUtils::IsVectorOrHigher(params.shape()),\n         errors::InvalidArgument(\"params must be at least 1 dimensional\"));\n+    OP_REQUIRES(\n+        c, params.shape().dims() >= batch_dims_,\n+        errors::InvalidArgument(\"params must have at least \", batch_dims_,\n+                                \" (batch_dims) dimensions but it has shape \",\n+                                params.shape().DebugString()));\n \n     // Check that we have enough index space\n     const int64_t N = indices.NumElements();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2r8p-fg3c-wcj4",
    "API Signature": "tf.raw_ops.ResourceGather(\n    resource, indices, dtype, batch_dims=0, validate_indices=True, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Integer",
    "Argument": "batch_dims=10,"
  },
  {
    "Title": "\n        Division by 0 in `ResourceGather`\n      ",
    "Bug description": "An attacker can trigger a crash via a floating point exception in  tf.raw_ops.ResourceGather :",
    "Sample Code": "tensor = tf.constant(value=[[]],shape=(0,1),dtype=tf.uint32)\nv = tf.Variable(tensor)\ntf.raw_ops.ResourceGather(\n  resource=v.handle,\n  indices=[0],\n  dtype=tf.uint32,\n  batch_dims=1,\n  ,\n  validate_indices=False)",
    "Code change": [
      "@@ -710,7 +710,8 @@ class ResourceGatherOp : public OpKernel {\n         copy_functor(c->eigen_device<Device>(), tmp_indices.flat<Index>(),\n                      indices.flat<Index>());\n \n-        AddBatchOffsets(&tmp_indices, params);\n+        AddBatchOffsets(c, &tmp_indices, params);\n+        if (!c->status().ok()) return;\n         op_indices = &tmp_indices;\n       }\n \n@@ -742,11 +743,17 @@ class ResourceGatherOp : public OpKernel {\n   // Example: batch_dims = 1, indices = [[0, 1, 2], [0, 1, 2]]\n   // If indexing into a params dimension of size 4, then the indices will become\n   // [0, 1, 2, 4, 5, 6]\n-  void AddBatchOffsets(Tensor* indices, const Tensor& params) {\n+  void AddBatchOffsets(OpKernelContext* ctx, Tensor* indices,\n+                       const Tensor& params) {\n     int64_t batch_size = 1;  // The size of all batch dimensions.\n     for (int idx = 0; idx < batch_dims_; ++idx) {\n       batch_size *= params.dim_size(idx);\n     }\n+    OP_REQUIRES(\n+        ctx, batch_size != 0,\n+        errors::InvalidArgument(\n+            \"Inner size of indices would result in batch_size of 0 and a \",\n+            \"division by 0 in the implementation. This is illegal\"));\n \n     auto indices_flat = indices->flat<Index>();\n     int64_t const index_inner_size = indices->NumElements() / batch_size;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qjj8-32p7-h289",
    "API Signature": "tf.raw_ops.ResourceGather(\n    resource, indices, dtype, batch_dims=0, validate_indices=True, name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Zero integer list element",
    "Category": "List",
    "Argument": "indices=[0],"
  },
  {
    "Title": "\n        Heap buffer overflow in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation for  tf.raw_ops.FractionalAvgPoolGrad  can be tricked into accessing data outside of bounds of heap allocated buffers:",
    "Sample Code": "tf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=[0,1,2,3],\n  out_backprop = np.array([[[[541],[541]],[[541],[541]]]]),\n  row_pooling_sequence=[0, 0, 0, 0, 0],\n  col_pooling_sequence=[-2, 0, 0, 2, 0],\n  ],\n  overlapping=True)",
    "Code change": [
      "@@ -271,6 +271,18 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64_t in_rows = orig_input_tensor_shape_flat(1);\n     const int64_t in_cols = orig_input_tensor_shape_flat(2);\n     const int64_t in_depth = orig_input_tensor_shape_flat(3);\n+    OP_REQUIRES(\n+        context, in_batch != 0,\n+        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_rows != 0,\n+        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_cols != 0,\n+        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_depth != 0,\n+        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n \n     constexpr int tensor_in_and_out_dims = 4;\n     // Transform orig_input_tensor_shape into TensorShape\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hpv4-7p9c-mvfr",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Zero integer list element",
    "Category": "List",
    "Argument": "orig_input_tensor_shape=[0,1,2,3],"
  },
  {
    "Title": "\n        Heap buffer overflow in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation for  tf.raw_ops.FractionalAvgPoolGrad  can be tricked into accessing data outside of bounds of heap allocated buffers:",
    "Sample Code": "tf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=[0,1,2,3],\n  out_backprop = np.array([[[[541],[541]],[[541],[541]]]]),\n  row_pooling_sequence=[0, 0, 0, 0, 0],\n  col_pooling_sequence=[-2, 0, 0, 2, 0],\n  ],\n  overlapping=True)",
    "Code change": [
      "@@ -271,6 +271,18 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64_t in_rows = orig_input_tensor_shape_flat(1);\n     const int64_t in_cols = orig_input_tensor_shape_flat(2);\n     const int64_t in_depth = orig_input_tensor_shape_flat(3);\n+    OP_REQUIRES(\n+        context, in_batch != 0,\n+        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_rows != 0,\n+        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_cols != 0,\n+        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_depth != 0,\n+        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n \n     constexpr int tensor_in_and_out_dims = 4;\n     // Transform orig_input_tensor_shape into TensorShape\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hpv4-7p9c-mvfr",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Zero integer list element",
    "Category": "List",
    "Argument": "row_pooling_sequence=[0, 0, 0, 0, 0],"
  },
  {
    "Title": "\n        Heap buffer overflow in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation for  tf.raw_ops.FractionalAvgPoolGrad  can be tricked into accessing data outside of bounds of heap allocated buffers:",
    "Sample Code": "tf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=[0,1,2,3],\n  out_backprop = np.array([[[[541],[541]],[[541],[541]]]]),\n  row_pooling_sequence=[0, 0, 0, 0, 0],\n  col_pooling_sequence=[-2, 0, 0, 2, 0],\n  ],\n  overlapping=True)",
    "Code change": [
      "@@ -271,6 +271,18 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64_t in_rows = orig_input_tensor_shape_flat(1);\n     const int64_t in_cols = orig_input_tensor_shape_flat(2);\n     const int64_t in_depth = orig_input_tensor_shape_flat(3);\n+    OP_REQUIRES(\n+        context, in_batch != 0,\n+        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_rows != 0,\n+        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_cols != 0,\n+        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_depth != 0,\n+        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n \n     constexpr int tensor_in_and_out_dims = 4;\n     // Transform orig_input_tensor_shape into TensorShape\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hpv4-7p9c-mvfr",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Negative integer list element",
    "Category": "List",
    "Argument": "col_pooling_sequence=[-2, 0, 0, 2, 0],"
  },
  {
    "Title": "\n        Null pointer dereference in `SparseTensorSliceDataset`\n      ",
    "Bug description": "When a user does not supply arguments that determine a valid sparse tensor,  tf.raw_ops.SparseTensorSliceDataset  implementation can be made to dereference a null pointer:",
    "Sample Code": "tf.raw_ops.SparseTensorSliceDataset(\n  indices=[[],[],[]],\n  values=[1,2,3],\n  ],\n  dense_shape=[3,3])",
    "Code change": [
      "@@ -241,6 +241,17 @@ class SparseTensorSliceDatasetOp : public DatasetOpKernel {\n                 errors::InvalidArgument(\n                     \"Input indices should be a matrix but received shape \",\n                     indices->shape().DebugString()));\n+\n+    const auto num_indices = indices->NumElements();\n+    const auto num_values = values->NumElements();\n+    if (num_indices == 0 || num_values == 0) {\n+      OP_REQUIRES(ctx, num_indices == num_values,\n+                  errors::InvalidArgument(\n+                      \"If indices or values are empty, the other one must also \"\n+                      \"be. Got indices of shape \",\n+                      indices->shape().DebugString(), \" and values of shape \",\n+                      values->shape().DebugString()));\n+    }\n     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                 errors::InvalidArgument(\n                     \"Input values should be a vector but received shape \",\n",
      "@@ -118,6 +118,26 @@ class FromSparseTensorSlicesTest(test_base.DatasetTestBase,\n       with self.assertRaises(errors.OutOfRangeError):\n         sess.run(get_next)\n \n+  @combinations.generate(combinations.combine(tf_api_version=1, mode=[\"graph\"]))\n+  def testEmptySparseTensorSlicesInvalid(self):\n+    \"\"\"Test a dataset based on invalid `tf.sparse.SparseTensor`.\"\"\"\n+    st = array_ops.sparse_placeholder(dtypes.float64)\n+    iterator = dataset_ops.make_initializable_iterator(\n+        dataset_ops.Dataset.from_sparse_tensor_slices(st))\n+    init_op = iterator.initializer\n+\n+    with self.cached_session() as sess:\n+      # Test with an empty sparse tensor but with non empty values.\n+      empty_indices = np.empty((0, 4), dtype=np.int64)\n+      non_empty_values = [1, 2, 3, 4]\n+      empty_dense_shape = [0, 4, 37, 9]\n+      sparse_feed = sparse_tensor.SparseTensorValue(empty_indices,\n+                                                    non_empty_values,\n+                                                    empty_dense_shape)\n+      # Here, we expect the test to fail when running the feed.\n+      with self.assertRaises(errors.InvalidArgumentError):\n+        sess.run(init_op, feed_dict={st: sparse_feed})\n+\n   @combinations.generate(combinations.combine(tf_api_version=2, mode=[\"eager\"]))\n   def testFromSparseTensorSlicesError(self):\n     with self.assertRaises(AttributeError):\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c5x2-p679-95wc",
    "API Signature": "tf.raw_ops.SparseTensorSliceDataset(\n    indices, values, dense_shape, name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Empty list",
    "Category": "List",
    "Argument": "indices=[[],[],[]],"
  },
  {
    "Title": "\n        Bad alloc in `StringNGrams` caused by integer conversion\n      ",
    "Bug description": "The implementation of  tf.raw_ops.StringNGrams  is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value.",
    "Sample Code": "tf.raw_ops.StringNGrams(\n  data=['',''],\n  data_splits=[0,2],\n  separator=' '*100,\n  ngram_widths=[-80,0,0,-60],\n  left_pad=' ',\n  right_pad=' ',\n  pad_width=100,\n  ,\n  preserve_short_sequences=False)",
    "Code change": [
      "@@ -53,6 +53,12 @@ class StringNGramsOp : public tensorflow::OpKernel {\n   }\n \n   void Compute(tensorflow::OpKernelContext* context) override {\n+    for (int ngram_width : ngram_widths_) {\n+      OP_REQUIRES(\n+          context, ngram_width > 0,\n+          errors::InvalidArgument(\"ngram_widths must contain positive values\"));\n+    }\n+\n     const tensorflow::Tensor* data;\n     OP_REQUIRES_OK(context, context->input(\"data\", &data));\n     const auto& input_data = data->flat<tstring>().data();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h6jh-7gv5-28vg",
    "API Signature": "tf.raw_ops.StringNGrams(\n    data,\n    data_splits,\n    separator,\n    ngram_widths,\n    left_pad,\n    right_pad,\n    pad_width,\n    preserve_short_sequences,\n    name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Negative integer list element",
    "Category": "List",
    "Argument": "ngram_widths=[-80,0,0,-60],"
  },
  {
    "Title": "\n        Integer overflow due to conversion to unsigned\n      ",
    "Bug description": "The implementation of  tf.raw_ops.QuantizeAndDequantizeV4Grad  is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value.",
    "Sample Code": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n  gradients=[1.0,2.0],\n  input=[1.0,1.0],\n  input_min=[0.0],\n  input_max=[10.0],\n  ],\n  axis=-100)",
    "Code change": [
      "@@ -158,6 +158,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n     Tensor* input_backprop = nullptr;\n     OP_REQUIRES_OK(ctx,\n                    ctx->allocate_output(0, input.shape(), &input_backprop));\n+    OP_REQUIRES(\n+        ctx, axis_ >= -1,\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n+    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n+                errors::InvalidArgument(\n+                    \"Axis should be -1 or 0 or a positive value less than \",\n+                    input.shape().dims(), \"but given axis value was \", axis_));\n \n     OP_REQUIRES(\n         ctx, input.IsSameSize(gradient),\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9w2p-5mgw-p94c",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n    gradients, input, input_min, input_max, axis=-1, name=None\n)\n",
    "Score": 0.03900709219858156,
    "Anomaly": "Negative integer argument",
    "Category": "Integer",
    "Argument": "axis=-100,"
  },
  {
    "Title": "\n        Null pointer dereference in `MatrixDiagPartOp`\n      ",
    "Bug description": "If a user does not provide a valid padding value to  tf.raw_ops.MatrixDiagPartOp , then the code triggers a null pointer dereference (if input is empty) or produces invalid behavior, ignoring all values after the first:",
    "Sample Code": "tf.raw_ops.MatrixDiagPartV2(\n  input=tf.ones(2,dtype=tf.int32),\n  k=tf.ones(2,dtype=tf.int32),\n  ),\n  padding_value=[])",
    "Code change": [
      "@@ -89,7 +89,10 @@ class MatrixDiagPartOp : public OpKernel {\n           upper_diag_index = diag_index.flat<int32>()(1);\n         }\n       }\n-      padding_value = context->input(2).flat<T>()(0);\n+      const Tensor& padding_in = context->input(2);\n+      OP_REQUIRES(context, padding_in.NumElements() == 1,\n+                  errors::InvalidArgument(\"Padding must be scalar.\"));\n+      padding_value = padding_in.flat<T>()(0);\n     }\n     const TensorShape& input_shape = input.shape();\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fcwc-p4fc-c5cc",
    "API Signature": "tf.raw_ops.MatrixDiagPartV2(\n    input, k, padding_value, name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "padding_value=[]"
  },
  {
    "Title": "\n        `std::abort` raised from `TensorListReserve`\n      ",
    "Bug description": "Providing a negative element to  num_elements  list argument of   tf.raw_ops.TensorListReserve  causes the runtime to abort the process due to reallocating a  std::vector  to have a negative number of elements:",
    "Sample Code": "tf.raw_ops.TensorListReserve(\n  element_shape = tf.constant([1]),\n  num_elements=tf.constant([-1]),\n  ]),\n  element_dtype = tf.int32)",
    "Code change": [
      "@@ -302,6 +302,10 @@ class TensorListReserve : public OpKernel {\n     PartialTensorShape element_shape;\n     OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(0), &element_shape));\n     int32 num_elements = c->input(1).scalar<int32>()();\n+    OP_REQUIRES(c, num_elements >= 0,\n+                errors::InvalidArgument(\"The num_elements to reserve must be a \"\n+                                        \"non negative number, but got \",\n+                                        num_elements));\n     TensorList output;\n     output.element_shape = element_shape;\n     output.element_dtype = element_dtype_;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-27j5-4p9v-pp67",
    "API Signature": "tf.raw_ops.TensorListReserve(\n    element_shape, num_elements, element_dtype, name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Negative input tensor",
    "Category": "Tensor",
    "Argument": "num_elements=tf.constant([-1]"
  },
  {
    "Title": "\n        Heap OOB in `RaggedGather`\n      ",
    "Bug description": "If the arguments to  tf.raw_ops.RaggedGather  don't determine a valid ragged tensor code can trigger a read from outside of bounds of heap allocated buffers.",
    "Sample Code": "tf.raw_ops.RaggedGather(\n  params_nested_splits = [0,0,0],\n  params_dense_values = [1,1],\n  indices = [0,0,9,0,0],\n  ],\n  OUTPUT_RAGGED_RANK=0)",
    "Code change": [
      "@@ -58,15 +58,21 @@ class RaggedGatherOpBase : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     // Get the input Tensors.\n+\n     OpInputList params_nested_splits_in;\n     OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",\n                                                 &params_nested_splits_in));\n+    OP_REQUIRES(\n+        context, params_nested_splits_in.size() > 0,\n+        errors::InvalidArgument(\"params_nested_splits must be non empty\"));\n+\n     const Tensor& params_dense_values_in =\n         context->input(params_nested_splits_in.size());\n     const Tensor& indices_in =\n         context->input(params_nested_splits_in.size() + 1);\n \n-    DCHECK_GT(params_nested_splits_in.size(), 0);  // Enforced by REGISTER_OP.\n+    OP_REQUIRES(context, params_nested_splits_in[0].dims() > 0,\n+                errors::InvalidArgument(\"Split tensors must not be scalars\"));\n     SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;\n     OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9c8h-vvrj-w2p8",
    "API Signature": "tf.raw_ops.RaggedGather(\n    params_nested_splits,\n    params_dense_values,\n    indices,\n    OUTPUT_RAGGED_RANK,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "  params_nested_splits = [0,0,0],\n  params_dense_values = [1,1],\n  indices = [0,0,9,0,0],"
  },
  {
    "Title": "\n        Division by 0 in `ResourceScatterDiv`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.ResourceScatterDiv  is vulnerable to a division by 0 error:",
    "Sample Code": "v= tf.Variable([1,2,3])\ntf.raw_ops.ResourceScatterDiv(\n  resource=v.handle,\n  indices=[1],\n  ],\n  updates=[0])",
    "Code change": [
      "@@ -873,6 +873,35 @@ TF_CALL_GPU_NUMBER_TYPES(REGISTER_GATHER_ND_GPU);\n #undef REGISTER_GATHER_ND_ALL_INDICES\n #undef REGISTER_GATHER_ND_FULL\n \n+namespace {\n+\n+template <typename Device>\n+bool isCPUDevice() {\n+  return false;\n+}\n+\n+template <>\n+bool isCPUDevice<CPUDevice>() {\n+  return true;\n+}\n+\n+template <typename T>\n+bool ValidateInput(const Tensor& updates) {\n+  const auto updates_flat = updates.flat<T>();\n+  const T zero(0);\n+  for (int i = 0; i < updates.NumElements(); i++) {\n+    if (updates_flat(i) == zero) return false;\n+  }\n+  return true;\n+}\n+\n+template <>\n+bool ValidateInput<Variant>(const Tensor& updates) {\n+  return true;\n+}\n+\n+}  // namespace\n+\n template <typename Device, typename T, typename Index, scatter_op::UpdateOp op>\n class ResourceScatterUpdateOp : public OpKernel {\n  public:\n@@ -939,6 +968,12 @@ class ResourceScatterUpdateOp : public OpKernel {\n                                 \" indexing: \", params->dim_size(0), \" > \",\n                                 std::numeric_limits<Index>::max()));\n \n+    // Prevent division by 0\n+    if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {\n+      OP_REQUIRES(c, ValidateInput<T>(updates),\n+                  errors::InvalidArgument(\"updates must not contain 0\"));\n+    }\n+\n     if (N > 0) {\n       auto indices_flat = indices.flat<Index>();\n       auto params_flat = params->flat_outer_dims<T>();\n",
      "@@ -175,8 +175,9 @@ class ShardedVariableTest(test.TestCase, parameterized.TestCase):\n                             'scatter_update')\n   def test_scatter_ops_even_partition(self, op):\n     v = variables_lib.Variable(array_ops.zeros((30, 1)))\n+    # Make sure values does not contain 0 due to testing `scatter_div`!\n     sparse_delta = ops.IndexedSlices(\n-        values=constant_op.constant([[0.], [1.], [2.], [3.], [4.]]),\n+        values=constant_op.constant([[1.], [2.], [3.], [4.], [5.]]),\n         indices=constant_op.constant([0, 10, 12, 21, 22]))\n \n     v0 = variables_lib.Variable(array_ops.zeros((10, 1)))\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-ch4f-829c-v5pw",
    "API Signature": "tf.raw_ops.ResourceScatterDiv(\n    resource, indices, updates, name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Zero integer list element",
    "Category": "List",
    "Argument": "updates=[0]"
  },
  {
    "Title": "\n        Integer division by 0 in sparse reshaping\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SparseReshape  can be made to trigger an integral division by 0 exception:",
    "Sample Code": "tf.raw_ops.SparseReshape(\n  input_indices = np.ones((1,3)),\n  input_shape = np.array([1,1,0]),\n  ]),\n  new_shape = np.array([1,0]))",
    "Code change": [
      "@@ -174,6 +174,12 @@ void ReshapeSparseTensor(OpKernelContext *context,\n                                           TensorShape({nnz, output_rank}),\n                                           &result_indices));\n   if (nnz > 0) {\n+    OP_REQUIRES(\n+        context, dense_size > 0 && product > 0,\n+        errors::InvalidArgument(\n+            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\n+            input_shape.DebugString(), \") or output shape (\",\n+            output_shape.DebugString(), \") is empty\"));\n     OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                 context, input_shape, output_shape,\n                                 input_indices_in.matrix<int64>(),\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-95xm-g58g-3p88",
    "API Signature": "tf.raw_ops.SparseReshape(\n    input_indices, input_shape, new_shape, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Numpy array",
    "Argument": "input_shape = np.array([1,1,0]),\nnew_shape = np.array([1,0])"
  },
  {
    "Title": "\n        Null pointer dereference and heap OOB read in operations restoring tensors\n      ",
    "Bug description": "When restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer:",
    "Sample Code": "tf.raw_ops.Restore(\n  file_pattern=['/tmp'],\n  tensor_name=['x'], \n  default_value=21,\n  dt=tf.int,\n  ,\n  preferred_shard=42)",
    "Code change": [
      "@@ -151,11 +151,18 @@ void RestoreTensor(OpKernelContext* context,\n         context, size == 1,\n         errors::InvalidArgument(\n             \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n-            size, \"elements\"));\n+            size, \" elements\"));\n   }\n   const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n \n   const Tensor& tensor_name_t = context->input(1);\n+  {\n+    const int64_t size = tensor_name_t.NumElements();\n+    OP_REQUIRES(context, size > restore_index,\n+                errors::InvalidArgument(\n+                    \"Input 1 (file_pattern) must be a have at least \",\n+                    restore_index + 1, \" elements\"));\n+  }\n   const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n \n   // If we cannot find a cached reader we will allocate our own.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gh6x-4whr-2qv4",
    "API Signature": "tf.raw_ops.Restore(\n    file_pattern, tensor_name, dt, preferred_shard=-1, name=None\n)\n",
    "Score": 0.010638297872340425,
    "Anomaly": "Empty string",
    "Category": "String",
    "Argument": "tensor_name=[]"
  },
  {
    "Title": "\n        Null pointer dereference and heap OOB read in operations restoring tensors\n      ",
    "Bug description": "When restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer:",
    "Sample Code": "tf.raw_ops.Restore(\n  file_pattern=['/tmp'],\n  tensor_name=['x'], \n  default_value=21,\n  dt=tf.int,\n  ,\n  preferred_shard=42)",
    "Code change": [
      "@@ -151,11 +151,18 @@ void RestoreTensor(OpKernelContext* context,\n         context, size == 1,\n         errors::InvalidArgument(\n             \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n-            size, \"elements\"));\n+            size, \" elements\"));\n   }\n   const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n \n   const Tensor& tensor_name_t = context->input(1);\n+  {\n+    const int64_t size = tensor_name_t.NumElements();\n+    OP_REQUIRES(context, size > restore_index,\n+                errors::InvalidArgument(\n+                    \"Input 1 (file_pattern) must be a have at least \",\n+                    restore_index + 1, \" elements\"));\n+  }\n   const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n \n   // If we cannot find a cached reader we will allocate our own.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gh6x-4whr-2qv4",
    "API Signature": "tf.raw_ops.RestoreSlice(\n    file_pattern,\n    tensor_name,\n    shape_and_slice,\n    dt,\n    preferred_shard=-1,\n    name=None\n)\n",
    "Score": 0.010638297872340425,
    "Anomaly": "Empty string",
    "Category": "String",
    "Argument": "tensor_name=[]"
  },
  {
    "Title": "\n        Null pointer dereference in `RaggedTensorToTensor`\n      ",
    "Bug description": "Sending invalid argument for  row_partition_types  of  tf.raw_ops.RaggedTensorToTensor  API results in a null pointer dereference and undefined behavior:",
    "Sample Code": "tf.raw_ops.RaggedTensorToTensor(\n  shape=1,\n  values=10,\n  default_value=21,\n  row_partition_tensors=tf.constant([0,0,0,0]),\n  ]),\n  row_partition_types=[])",
    "Code change": [
      "@@ -348,6 +348,9 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n   Status GetFirstDimensionSize(OpKernelContext* context, INDEX_TYPE* result) {\n     const Tensor first_partition_tensor =\n         context->input(kFirstPartitionInputIndex);\n+    if (row_partition_types_.empty()) {\n+      return errors::InvalidArgument(\"No row_partition_types given.\");\n+    }\n     const RowPartitionType first_partition_type = row_partition_types_[0];\n     switch (first_partition_type) {\n       case RowPartitionType::FIRST_DIM_SIZE:\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hwr7-8gxx-fj5p",
    "API Signature": "tf.raw_ops.RaggedTensorToTensor(\n    shape,\n    values,\n    default_value,\n    row_partition_tensors,\n    row_partition_types,\n    name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Empty list",
    "Category": "List",
    "Argument": "row_partition_types=[]"
  },
  {
    "Title": "\n        Null pointer dereference in `CompressElement`\n      ",
    "Bug description": "It is possible to trigger a null pointer dereference in TensorFlow by passing an invalid input to  tf.raw_ops.CompressElement :",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.CompressElement(components=[[]])",
    "Code change": [
      "@@ -29,9 +29,10 @@ Status CompressElement(const std::vector<Tensor>& element,\n   int64 total_size = 0;\n   for (auto& component : element) {\n     if (DataTypeCanUseMemcpy(component.dtype())) {\n-      // Some datatypes can be memcopied, allowing us to save two copies\n-      // (AsProtoTensorContent and SerializeToArray).\n-      total_size += DMAHelper::buffer(&component)->size();\n+      const TensorBuffer* buffer = DMAHelper::buffer(&component);\n+      if (buffer) {\n+        total_size += buffer->size();\n+      }\n     } else {\n       non_memcpy_components.emplace_back();\n       component.AsProtoTensorContent(&non_memcpy_components.back());\n@@ -53,8 +54,10 @@ Status CompressElement(const std::vector<Tensor>& element,\n     component.shape().AsProto(metadata->mutable_tensor_shape());\n     if (DataTypeCanUseMemcpy(component.dtype())) {\n       const TensorBuffer* buffer = DMAHelper::buffer(&component);\n-      memcpy(position, buffer->data(), buffer->size());\n-      metadata->set_tensor_size_bytes(buffer->size());\n+      if (buffer) {\n+        memcpy(position, buffer->data(), buffer->size());\n+        metadata->set_tensor_size_bytes(buffer->size());\n+      }\n     } else {\n       TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];\n       proto.SerializeToArray(position, proto.ByteSizeLong());\n@@ -94,8 +97,13 @@ Status UncompressElement(const CompressedElement& compressed,\n     if (DataTypeCanUseMemcpy(metadata.dtype())) {\n       out->emplace_back(metadata.dtype(), metadata.tensor_shape());\n       TensorBuffer* buffer = DMAHelper::buffer(&out->back());\n-      iov[i].iov_base = buffer->data();\n-      iov[i].iov_len = buffer->size();\n+      if (buffer) {\n+        iov[i].iov_base = buffer->data();\n+        iov[i].iov_len = buffer->size();\n+      } else {\n+        iov[i].iov_base = nullptr;\n+        iov[i].iov_len = 0;\n+      }\n     } else {\n       // Allocate an empty Tensor. We will fill it out later after\n       // uncompressing into the tensor_proto_str.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c9qf-r67m-p7cg",
    "API Signature": "tf.raw_ops.CompressElement(\n    components, name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Empty list",
    "Category": "List",
    "Argument": "components=[[]]"
  },
  {
    "Title": "\n        Floating point exception in `SparseDenseCwiseDiv`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SparseDenseCwiseDiv  is vulnerable to a division by 0 error:",
    "Sample Code": "import numpy as np\n\ntf.raw_ops.SparseDenseCwiseDiv( \n  sp_indices=np.array([[4]]),\n  sp_values=np.array([-400]),\n  sp_shape=np.array([647.]),\n  ]),\n  dense=np.array([0]))",
    "Code change": [
      "@@ -114,7 +114,10 @@ class SparseDenseBinaryOpShared : public OpKernel {\n     OP_REQUIRES_OK(\n         ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                 &dense_gathered));\n-\n+    bool op_is_div = false;\n+    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {\n+      op_is_div = true;\n+    }\n     // Pulls relevant entries from the dense side, with reshape and broadcasting\n     // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n     // up memory.\n@@ -143,6 +146,12 @@ class SparseDenseBinaryOpShared : public OpKernel {\n           errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                   \"dense side with broadcasted shape\"));       \\\n       dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n+      if (op_is_div) {                                                         \\\n+        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\\n+                    errors::InvalidArgument(                                   \\\n+                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\\n+                        \"but input dense tensor contains zero \"));             \\\n+      }                                                                        \\\n     }                                                                          \\\n     break;                                                                     \\\n   }\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hp4c-x6r7-6555",
    "API Signature": "tf.raw_ops.SparseDenseCwiseDiv(\n    sp_indices, sp_values, sp_shape, dense, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Numpy array",
    "Argument": "dense=np.array([0])"
  },
  {
    "Title": "\n        Segfault in `tf.raw_ops.SparseCountSparseOutput`\n      ",
    "Bug description": "Passing invalid arguments (e.g., discovered via fuzzing) to  tf.raw_ops.SparseCountSparseOutput  results in segfault.",
    "Sample Code": "",
    "Code change": [
      "@@ -192,6 +192,10 @@ class SparseCount : public OpKernel {\n               \"; values shape: \", values.shape().DebugString()));\n     }\n \n+    OP_REQUIRES(context, shape.NumElements() != 0,\n+                errors::InvalidArgument(\n+                    \"The shape argument requires at least one element.\"));\n+\n     bool is_1d = shape.NumElements() == 1;\n     int num_batches = is_1d ? 1 : shape.flat<int64>()(0);\n     int num_values = values.NumElements();\n@@ -212,6 +216,14 @@ class SparseCount : public OpKernel {\n \n     for (int idx = 0; idx < num_values; ++idx) {\n       int batch = is_1d ? 0 : indices_values(idx, 0);\n+      if (batch >= num_batches) {\n+        OP_REQUIRES(context, batch < num_batches,\n+                    errors::InvalidArgument(\n+                        \"Indices value along the first dimension must be \",\n+                        \"lower than the first index of the shape.\", \"Got \",\n+                        batch, \" as batch and \", num_batches,\n+                        \" as the first dimension of the shape.\"));\n+      }\n       const auto& value = values_values(idx);\n       if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\n         if (binary_output_) {\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wvjw-p9f5-vq28",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Empty list",
    "Category": "List",
    "Argument": "dense_shape=[]"
  },
  {
    "Title": "\n        Crash in `tf.strings.substr` due to `CHECK`-fail\n      ",
    "Bug description": "An attacker can cause a denial of service via  CHECK -fail in   tf.strings.substr  with invalid arguments:",
    "Sample Code": " tensorflow as tf\ntf.strings.substr(input='abc', len=1, pos=[1,2])",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mmq6-q8r3-48fm",
    "API Signature": "tf.strings.substr(\n    input, pos, len, unit='BYTE', name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "len=1\npos=[1,-1]"
  },
  {
    "Title": "\n        Crash in `tf.transpose` with complex inputs\n      ",
    "Bug description": "Passing a complex argument to  tf.transpose  at the same time as passing  conjugate=True  argument results in a crash:",
    "Sample Code": " tensorflow as tf\ntf.transpose(conjugate=True, a=complex(1))",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xqfj-cr6q-pc8w",
    "API Signature": "tf.transpose(\n    a, perm=None, conjugate=False, name='transpose'\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Input combination",
    "Category": "Input combination",
    "Argument": "conjugate=True\na=complex(1)"
  },
  {
    "Title": "\n        Interpreter crash from `tf.io.decode_raw`\n      ",
    "Bug description": "The implementation of  tf.io.decode_raw  produces incorrect results and crashes the Python interpreter when combining  fixed_length  and wider datatypes.",
    "Sample Code": " tensorflow as tf\n\ntf.io.decode_raw(tf.constant([\"1\",\"2\",\"3\",\"4\"]), tf.uint16, fixed_length=4)",
    "Code change": [
      "@@ -19,6 +19,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/common_shape_fns.h\"\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/shape_inference.h\"\n \n namespace tensorflow {\n@@ -83,14 +84,13 @@ class DecodePaddedRawOp : public OpKernel {\n     // can copy the memory directly.\n     if (!convert_data_endianness_ || sizeof(T) == 1) {\n       for (int64 i = 0; i < flat_in.size(); ++i) {\n-        const T* in_data = reinterpret_cast<const T*>(flat_in(i).data());\n-\n-        if (flat_in(i).size() > fixed_length) {\n-          memcpy(out_data, in_data, fixed_length);\n-        } else {\n-          memcpy(out_data, in_data, flat_in(i).size());\n-        }\n-        out_data += fixed_length;\n+        const auto to_copy =\n+            std::min(flat_in(i).size(), static_cast<size_t>(fixed_length));\n+        memcpy(out_data, flat_in(i).data(), to_copy);\n+        // Note: increase out_data by width since it's already of type T* so\n+        // each shift amount is implicitly multiplied by sizeof(T) according to\n+        // pointer arithmetic rules.\n+        out_data += width;\n       }\n     } else {\n       // Otherwise, the data is not in the host's byte order, and rather than a\n@@ -105,7 +105,10 @@ class DecodePaddedRawOp : public OpKernel {\n              p_in += sizeof(T), p_out += sizeof(T)) {\n           std::reverse_copy(p_in, p_in + sizeof(T), p_out);\n         }\n-        out_data += fixed_length;\n+        // Note: increase out_data by width since it's already of type T* so\n+        // each shift amount is implicitly multiplied by sizeof(T) according to\n+        // pointer arithmetic rules.\n+        out_data += width;\n       }\n     }\n   }\n",
      "@@ -850,8 +850,8 @@ def decode_raw(input_bytes,\n                name=None):\n   r\"\"\"Convert raw bytes from input tensor into numeric tensors.\n \n-  The input tensor is interpreted as a sequence of bytes. These bytes are then\n-  decoded as numbers in the format specified by `out_type`.\n+  Every component of the input tensor is interpreted as a sequence of bytes.\n+  These bytes are then decoded as numbers in the format specified by `out_type`.\n \n   >>> tf.io.decode_raw(tf.constant(\"1\"), tf.uint8)\n   <tf.Tensor: shape=(1,), dtype=uint8, numpy=array([49], dtype=uint8)>\n@@ -909,22 +909,35 @@ def decode_raw(input_bytes,\n   >>> tf.io.decode_raw(tf.constant([\"1212\"]), tf.uint16, fixed_length=4)\n   <tf.Tensor: shape=(1, 2), dtype=uint16, numpy=array([[12849, 12849]], ...\n \n-  Note: There is currently a bug in `fixed_length` that can result in data loss:\n-\n-  >>> # truncated to length of type as it matches fixed_length\n-  >>> tf.io.decode_raw(tf.constant([\"1212\"]), tf.uint16, fixed_length=2)\n-  <tf.Tensor: shape=(1, 1), dtype=uint16, numpy=array([[12849]], dtype=uint16)>\n-  >>> # ignores the second component\n-  >>> tf.io.decode_raw(tf.constant([\"12\",\"34\"]), tf.uint16, fixed_length=2)\n-  <tf.Tensor: shape=(2, 1), dtype=uint16, numpy=\n-  array([[12849],\n-         [    0]], dtype=uint16)>\n-  >>> tf.io.decode_raw(tf.constant([\"12\",\"34\"]), tf.uint16, fixed_length=4)\n-  <tf.Tensor: shape=(2, 2), dtype=uint16, numpy=\n-  array([[12849,     0],\n-         [    0,     0]], dtype=uint16)>\n-\n-  This will be fixed on a future release of TensorFlow.\n+  If the input value is larger than `fixed_length`, it is truncated:\n+\n+  >>> x=''.join([chr(1), chr(2), chr(3), chr(4)])\n+  >>> tf.io.decode_raw(x, tf.uint16, fixed_length=2)\n+  <tf.Tensor: shape=(1,), dtype=uint16, numpy=array([513], dtype=uint16)>\n+  >>> hex(513)\n+  '0x201'\n+\n+  If `little_endian` and `fixed_length` are specified, truncation to the fixed\n+  length occurs before endianness conversion:\n+\n+  >>> x=''.join([chr(1), chr(2), chr(3), chr(4)])\n+  >>> tf.io.decode_raw(x, tf.uint16, fixed_length=2, little_endian=False)\n+  <tf.Tensor: shape=(1,), dtype=uint16, numpy=array([258], dtype=uint16)>\n+  >>> hex(258)\n+  '0x102'\n+\n+  If input values all have the same length, then specifying `fixed_length`\n+  equal to the size of the strings should not change output:\n+\n+  >>> x = [\"12345678\", \"87654321\"]\n+  >>> tf.io.decode_raw(x, tf.int16)\n+  <tf.Tensor: shape=(2, 4), dtype=int16, numpy=\n+  array([[12849, 13363, 13877, 14391],\n+         [14136, 13622, 13108, 12594]], dtype=int16)>\n+  >>> tf.io.decode_raw(x, tf.int16, fixed_length=len(x[0]))\n+  <tf.Tensor: shape=(2, 4), dtype=int16, numpy=\n+  array([[12849, 13363, 13877, 14391],\n+         [14136, 13622, 13108, 12594]], dtype=int16)>\n \n   Args:\n     input_bytes:\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-8pmx-p244-g88h",
    "API Signature": "tf.io.decode_raw(\n    input_bytes, out_type, little_endian=True, fixed_length=None, name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Input combination",
    "Category": "Input combination",
    "Argument": "tf.uint16\nfixed_length=4"
  },
  {
    "Title": "\n        Incomplete validation in `tf.raw_ops.CTCLoss`\n      ",
    "Bug description": "Incomplete validation in  tf.raw_ops.CTCLoss  allows an attacker to trigger an OOB read from heap:",
    "Sample Code": "inputs = tf.constant([], shape=[0, 2, 11], dtype=tf.float32)\nlabels_indices = tf.constant([], shape=[0, 2], dtype=tf.int64)\nlabels_values = tf.constant([], shape=[0], dtype=tf.int32)\nsequence_length = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\n\ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=False, ctc_merge_repeated=False,\n                   ,\n                   ignore_longer_outputs_than_inputs=False)",
    "Code change": [
      "@@ -109,6 +109,9 @@ class CTCLossOp : public OpKernel {\n \n     const TensorShape& inputs_shape = inputs->shape();\n     const int64 max_time = inputs_shape.dim_size(0);\n+    OP_REQUIRES(ctx, max_time != 0,\n+                errors::InvalidArgument(\n+                    \"Max time or first dimension of input cannot be 0.\"));\n     const int64 batch_size = inputs_shape.dim_size(1);\n     const int64 num_classes_raw = inputs_shape.dim_size(2);\n     OP_REQUIRES(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vvg4-vgrv-xfr7",
    "API Signature": "tf.raw_ops.CTCLoss(\n    inputs,\n    labels_indices,\n    labels_values,\n    sequence_length,\n    preprocess_collapse_repeated=False,\n    ctc_merge_repeated=True,\n    ignore_longer_outputs_than_inputs=False,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "inputs = tf.constant([], shape=[10, 16, 0], dtype=tf.float32)"
  },
  {
    "Title": "\n        Incomplete validation in `tf.raw_ops.CTCLoss`\n      ",
    "Bug description": "Incomplete validation in  tf.raw_ops.CTCLoss  allows an attacker to trigger an OOB read from heap:",
    "Sample Code": "inputs = tf.constant([], shape=[0, 2, 11], dtype=tf.float32)\nlabels_indices = tf.constant([], shape=[0, 2], dtype=tf.int64)\nlabels_values = tf.constant([], shape=[0], dtype=tf.int32)\nsequence_length = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\n\ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=False, ctc_merge_repeated=False,\n                   ,\n                   ignore_longer_outputs_than_inputs=False)",
    "Code change": [
      "@@ -109,6 +109,9 @@ class CTCLossOp : public OpKernel {\n \n     const TensorShape& inputs_shape = inputs->shape();\n     const int64 max_time = inputs_shape.dim_size(0);\n+    OP_REQUIRES(ctx, max_time != 0,\n+                errors::InvalidArgument(\n+                    \"Max time or first dimension of input cannot be 0.\"));\n     const int64 batch_size = inputs_shape.dim_size(1);\n     const int64 num_classes_raw = inputs_shape.dim_size(2);\n     OP_REQUIRES(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vvg4-vgrv-xfr7",
    "API Signature": "tf.raw_ops.CTCLoss(\n    inputs,\n    labels_indices,\n    labels_values,\n    sequence_length,\n    preprocess_collapse_repeated=False,\n    ctc_merge_repeated=True,\n    ignore_longer_outputs_than_inputs=False,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "labels_indices = tf.constant([], shape=[8, 0], dtype=tf.int64)"
  },
  {
    "Title": "\n        Incomplete validation in `tf.raw_ops.CTCLoss`\n      ",
    "Bug description": "Incomplete validation in  tf.raw_ops.CTCLoss  allows an attacker to trigger an OOB read from heap:",
    "Sample Code": "inputs = tf.constant([], shape=[0, 2, 11], dtype=tf.float32)\nlabels_indices = tf.constant([], shape=[0, 2], dtype=tf.int64)\nlabels_values = tf.constant([], shape=[0], dtype=tf.int32)\nsequence_length = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\n\ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=False, ctc_merge_repeated=False,\n                   ,\n                   ignore_longer_outputs_than_inputs=False)",
    "Code change": [
      "@@ -109,6 +109,9 @@ class CTCLossOp : public OpKernel {\n \n     const TensorShape& inputs_shape = inputs->shape();\n     const int64 max_time = inputs_shape.dim_size(0);\n+    OP_REQUIRES(ctx, max_time != 0,\n+                errors::InvalidArgument(\n+                    \"Max time or first dimension of input cannot be 0.\"));\n     const int64 batch_size = inputs_shape.dim_size(1);\n     const int64 num_classes_raw = inputs_shape.dim_size(2);\n     OP_REQUIRES(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vvg4-vgrv-xfr7",
    "API Signature": "tf.raw_ops.CTCLoss(\n    inputs,\n    labels_indices,\n    labels_values,\n    sequence_length,\n    preprocess_collapse_repeated=False,\n    ctc_merge_repeated=True,\n    ignore_longer_outputs_than_inputs=False,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "labels_indices = tf.constant([], shape=[0, 2], dtype=tf.int64)\nlabels_values = tf.constant([], shape=[0], dtype=tf.int32)"
  },
  {
    "Title": "\n        Heap buffer overflow in `BandedTriangularSolve`\n      ",
    "Bug description": "An attacker can trigger a heap buffer overflow in Eigen implementation of  tf.raw_ops.BandedTriangularSolve :",
    "Sample Code": "import numpy as np\n  \nmatrix_array = np.array([])\nmatrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(0,1)),dtype=tf.float32)\nrhs_array = np.array([1,1])\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(1,2)),dtype=tf.float32)\n)\ntf.raw_ops.BandedTriangularSolve(matrix=matrix_tensor,rhs=rhs_tensor)",
    "Code change": [
      "@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\n                                           \" for dimension \", i));\n     }\n \n+    OP_REQUIRES(\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\n+        errors::InvalidArgument(\n+            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\n     const int num_dims = a_indices_t->dim_size(1);\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\n     const auto b_indices_mat = b_indices_t->matrix<int64>();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2xgj-xhgf-ggjv",
    "API Signature": "tf.raw_ops.BandedTriangularSolve(\n    matrix, rhs, lower=True, adjoint=False, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "matrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(0,1)),dtype=tf.float32)\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(1,2)),dtype=tf.float32)"
  },
  {
    "Title": "\n        Invalid validation in `QuantizeAndDequantizeV2`\n      ",
    "Bug description": "The validation in  tf.raw_ops.QuantizeAndDequantizeV2  allows invalid values for  axis  argument:",
    "Sample Code": "input_tensor = tf.constant([0.0], shape=[1], dtype=float)\ninput_min = tf.constant(-10.0)\ninput_max = tf.constant(-10.0)\n\ntf.raw_ops.QuantizeAndDequantizeV2(\n  input=input_tensor, input_min=input_min, input_max=input_max,\n  signed_input=False, num_bits=1, range_given=False, round_mode='HALF_TO_EVEN',\n  ,\n  narrow_range=False, axis=-2)",
    "Code change": [
      "@@ -72,6 +72,9 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(\n+        ctx, axis_ >= -1,\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n     OP_REQUIRES(\n         ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n         errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mq5c-prh3-3f3h",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV2(\n    input,\n    input_min,\n    input_max,\n    signed_input=True,\n    num_bits=8,\n    range_given=False,\n    round_mode='HALF_TO_EVEN',\n    narrow_range=False,\n    axis=-1,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "axis=-2"
  },
  {
    "Title": "\n        Incomplete validation in `SparseReshape`\n      ",
    "Bug description": "Incomplete validation in  SparseReshape  results in a denial of service based on a  CHECK -failure.",
    "Sample Code": "input_indices = tf.constant(41, shape=[1, 1], dtype=tf.int64)\ninput_shape = tf.zeros([11], dtype=tf.int64)\nnew_shape = tf.zeros([1], dtype=tf.int64)\n\ntf.raw_ops.SparseReshape(input_indices=input_indices,\n    input_shape=input_shape,\n    ,\n    new_shape=new_shape)",
    "Code change": [
      "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/reshape_util.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -38,6 +39,17 @@ class SparseReshapeOp : public OpKernel {\n   explicit SparseReshapeOp(OpKernelConstruction* context) : OpKernel(context) {}\n \n   void Compute(OpKernelContext* context) override {\n+    const Tensor& input_indices_in = context->input(0);\n+    const Tensor& input_shape_in = context->input(1);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n+                errors::InvalidArgument(\"Input must be a matrix.\"));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n+                errors::InvalidArgument(\"Input shape must be a vector.\"));\n+    OP_REQUIRES(context,\n+                input_indices_in.dim_size(1) == input_shape_in.dim_size(0),\n+                errors::InvalidArgument(\n+                    \"Input tensor rank must match input shape length.\"));\n     ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),\n                                 context->input(2), 0 /* output indices index */,\n                                 1 /* output shape index */);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9rpc-5v9q-5r7f",
    "API Signature": "tf.raw_ops.SparseReshape(\n    input_indices, input_shape, new_shape, name=None\n)\n",
    "Score": 0.02127659574468085,
    "Anomaly": "Scalar input tensor",
    "Category": "Tensor",
    "Argument": "input_indices = tf.constant(41, shape=[1, 1], dtype=tf.int64)"
  },
  {
    "Title": "\n        Incomplete validation in `SparseReshape`\n      ",
    "Bug description": "Incomplete validation in  SparseReshape  results in a denial of service based on a  CHECK -failure.",
    "Sample Code": "input_indices = tf.constant(41, shape=[1, 1], dtype=tf.int64)\ninput_shape = tf.zeros([11], dtype=tf.int64)\nnew_shape = tf.zeros([1], dtype=tf.int64)\n\ntf.raw_ops.SparseReshape(input_indices=input_indices,\n    input_shape=input_shape,\n    ,\n    new_shape=new_shape)",
    "Code change": [
      "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/reshape_util.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -38,6 +39,17 @@ class SparseReshapeOp : public OpKernel {\n   explicit SparseReshapeOp(OpKernelConstruction* context) : OpKernel(context) {}\n \n   void Compute(OpKernelContext* context) override {\n+    const Tensor& input_indices_in = context->input(0);\n+    const Tensor& input_shape_in = context->input(1);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n+                errors::InvalidArgument(\"Input must be a matrix.\"));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n+                errors::InvalidArgument(\"Input shape must be a vector.\"));\n+    OP_REQUIRES(context,\n+                input_indices_in.dim_size(1) == input_shape_in.dim_size(0),\n+                errors::InvalidArgument(\n+                    \"Input tensor rank must match input shape length.\"));\n     ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),\n                                 context->input(2), 0 /* output indices index */,\n                                 1 /* output shape index */);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9rpc-5v9q-5r7f",
    "API Signature": "tf.raw_ops.SparseReshape(\n    input_indices, input_shape, new_shape, name=None\n)\n",
    "Score": 0.02127659574468085,
    "Anomaly": "Scalar input tensor",
    "Category": "Tensor",
    "Argument": "input_shape = tf.zeros([11], dtype=tf.int64)"
  },
  {
    "Title": "\n        Incomplete validation in `SparseReshape`\n      ",
    "Bug description": "Incomplete validation in  SparseReshape  results in a denial of service based on a  CHECK -failure.",
    "Sample Code": "input_indices = tf.constant(41, shape=[1, 1], dtype=tf.int64)\ninput_shape = tf.zeros([11], dtype=tf.int64)\nnew_shape = tf.zeros([1], dtype=tf.int64)\n\ntf.raw_ops.SparseReshape(input_indices=input_indices,\n    input_shape=input_shape,\n    ,\n    new_shape=new_shape)",
    "Code change": [
      "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/reshape_util.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -38,6 +39,17 @@ class SparseReshapeOp : public OpKernel {\n   explicit SparseReshapeOp(OpKernelConstruction* context) : OpKernel(context) {}\n \n   void Compute(OpKernelContext* context) override {\n+    const Tensor& input_indices_in = context->input(0);\n+    const Tensor& input_shape_in = context->input(1);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n+                errors::InvalidArgument(\"Input must be a matrix.\"));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n+                errors::InvalidArgument(\"Input shape must be a vector.\"));\n+    OP_REQUIRES(context,\n+                input_indices_in.dim_size(1) == input_shape_in.dim_size(0),\n+                errors::InvalidArgument(\n+                    \"Input tensor rank must match input shape length.\"));\n     ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),\n                                 context->input(2), 0 /* output indices index */,\n                                 1 /* output shape index */);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9rpc-5v9q-5r7f",
    "API Signature": "tf.raw_ops.SparseReshape(\n    input_indices, input_shape, new_shape, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "new_shape = tf.zeros([1], dtype=tf.int64)"
  },
  {
    "Title": "\n        Incomplete validation in `SparseSparseMinimum`\n      ",
    "Bug description": "Incomplete validation in  SparseAdd  results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:",
    "Sample Code": "a_indices = tf.ones([45, 92], dtype=tf.int64)\na_values = tf.ones([45], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)\nb_values = tf.ones([1], dtype=tf.int64)\nb_shape = tf.ones([1], dtype=tf.int64)\n                    \ntf.raw_ops.SparseSparseMinimum(a_indices=a_indices,\n    a_values=a_values,\n    a_shape=a_shape,\n    b_indices=b_indices,\n    b_values=b_values,\n    ,\n    b_shape=b_shape)",
    "Code change": [
      "@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\n                                           \" for dimension \", i));\n     }\n \n+    OP_REQUIRES(\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\n+        errors::InvalidArgument(\n+            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\n     const int num_dims = a_indices_t->dim_size(1);\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\n     const auto b_indices_mat = b_indices_t->matrix<int64>();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gv26-jpj9-c8gq",
    "API Signature": "tf.raw_ops.SparseSparseMinimum(\n    a_indices, a_values, a_shape, b_indices, b_values, b_shape, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "a_indices = tf.ones([45, 92], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)"
  },
  {
    "Title": "\n        Incomplete validation in `SparseSparseMinimum`\n      ",
    "Bug description": "Incomplete validation in  SparseAdd  results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:",
    "Sample Code": "a_indices = tf.ones([45, 92], dtype=tf.int64)\na_values = tf.ones([45], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)\nb_values = tf.ones([1], dtype=tf.int64)\nb_shape = tf.ones([1], dtype=tf.int64)\n                    \ntf.raw_ops.SparseSparseMinimum(a_indices=a_indices,\n    a_values=a_values,\n    a_shape=a_shape,\n    b_indices=b_indices,\n    b_values=b_values,\n    ,\n    b_shape=b_shape)",
    "Code change": [
      "@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\n                                           \" for dimension \", i));\n     }\n \n+    OP_REQUIRES(\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\n+        errors::InvalidArgument(\n+            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\n     const int num_dims = a_indices_t->dim_size(1);\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\n     const auto b_indices_mat = b_indices_t->matrix<int64>();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gv26-jpj9-c8gq",
    "API Signature": "tf.raw_ops.SparseSparseMinimum(\n    a_indices, a_values, a_shape, b_indices, b_values, b_shape, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "a_indices = tf.ones([45, 92], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)"
  },
  {
    "Title": "\n        Incomplete validation in `SparseSparseMinimum`\n      ",
    "Bug description": "Incomplete validation in  SparseAdd  results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:",
    "Sample Code": "a_indices = tf.ones([45, 92], dtype=tf.int64)\na_values = tf.ones([45], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)\nb_values = tf.ones([1], dtype=tf.int64)\nb_shape = tf.ones([1], dtype=tf.int64)\n                    \ntf.raw_ops.SparseSparseMinimum(a_indices=a_indices,\n    a_values=a_values,\n    a_shape=a_shape,\n    b_indices=b_indices,\n    b_values=b_values,\n    ,\n    b_shape=b_shape)",
    "Code change": [
      "@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\n                                           \" for dimension \", i));\n     }\n \n+    OP_REQUIRES(\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\n+        errors::InvalidArgument(\n+            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\n     const int num_dims = a_indices_t->dim_size(1);\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\n     const auto b_indices_mat = b_indices_t->matrix<int64>();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gv26-jpj9-c8gq",
    "API Signature": "tf.raw_ops.SparseSparseMinimum(\n    a_indices, a_values, a_shape, b_indices, b_values, b_shape, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "a_indices = tf.ones([45, 92], dtype=tf.int64)\na_values = tf.ones([45], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)\nb_values = tf.ones([1], dtype=tf.int64)\nb_shape = tf.ones([1], dtype=tf.int64)"
  },
  {
    "Title": "\n        Incomplete validation in `SparseAdd`\n      ",
    "Bug description": "Incomplete validation in  SparseAdd  results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:",
    "Sample Code": "a_indices = tf.zeros([10, 97], dtype=tf.int64)\na_values = tf.zeros([10], dtype=tf.int64)\na_shape = tf.zeros([0], dtype=tf.int64)\n\nb_indices = tf.zeros([0, 0], dtype=tf.int64)\nb_values = tf.zeros([0], dtype=tf.int64)\nb_shape = tf.zeros([0], dtype=tf.int64)\n  \nthresh = 0\n\ntf.raw_ops.SparseAdd(a_indices=a_indices,\n                    a_values=a_values,\n                    a_shape=a_shape,\n                    b_indices=b_indices,\n                    b_values=b_values,\n                    b_shape=b_shape,\n                    ,\n                    thresh=thresh)",
    "Code change": [
      "@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n@@ -101,6 +102,10 @@ class SparseAddOp : public OpKernel {\n     std::vector<T> out_values;\n     const int num_dims = a_shape->dim_size(0);\n \n+    OP_REQUIRES(ctx, num_dims > 0,\n+                errors::InvalidArgument(\"Invalid input_a shape. Received: \",\n+                                        a_shape->DebugString()));\n+\n     // The input and output sparse tensors are assumed to be ordered along\n     // increasing dimension number.\n     int64 i = 0, j = 0;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cjc7-49v2-jp64",
    "API Signature": "tf.raw_ops.SparseAdd(\n    a_indices,\n    a_values,\n    a_shape,\n    b_indices,\n    b_values,\n    b_shape,\n    thresh,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "a_indices = tf.zeros([10, 97], dtype=tf.int64)\na_values = tf.zeros([10], dtype=tf.int64)"
  },
  {
    "Title": "\n        Incomplete validation in `SparseAdd`\n      ",
    "Bug description": "Incomplete validation in  SparseAdd  results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:",
    "Sample Code": "a_indices = tf.zeros([10, 97], dtype=tf.int64)\na_values = tf.zeros([10], dtype=tf.int64)\na_shape = tf.zeros([0], dtype=tf.int64)\n\nb_indices = tf.zeros([0, 0], dtype=tf.int64)\nb_values = tf.zeros([0], dtype=tf.int64)\nb_shape = tf.zeros([0], dtype=tf.int64)\n  \nthresh = 0\n\ntf.raw_ops.SparseAdd(a_indices=a_indices,\n                    a_values=a_values,\n                    a_shape=a_shape,\n                    b_indices=b_indices,\n                    b_values=b_values,\n                    b_shape=b_shape,\n                    ,\n                    thresh=thresh)",
    "Code change": [
      "@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n@@ -101,6 +102,10 @@ class SparseAddOp : public OpKernel {\n     std::vector<T> out_values;\n     const int num_dims = a_shape->dim_size(0);\n \n+    OP_REQUIRES(ctx, num_dims > 0,\n+                errors::InvalidArgument(\"Invalid input_a shape. Received: \",\n+                                        a_shape->DebugString()));\n+\n     // The input and output sparse tensors are assumed to be ordered along\n     // increasing dimension number.\n     int64 i = 0, j = 0;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cjc7-49v2-jp64",
    "API Signature": "tf.raw_ops.SparseAdd(\n    a_indices,\n    a_values,\n    a_shape,\n    b_indices,\n    b_values,\n    b_shape,\n    thresh,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "a_shape = tf.zeros([0], dtype=tf.int64)\nb_indices = tf.zeros([0, 0], dtype=tf.int64)\nb_values = tf.zeros([0], dtype=tf.int64)\nb_shape = tf.zeros([0], dtype=tf.int64)"
  },
  {
    "Title": "\n        Heap OOB and null pointer dereference in `RaggedTensorToTensor`\n      ",
    "Bug description": "Due to lack of validation in  tf.raw_ops.RaggedTensorToTensor , an attacker can exploit an undefined behavior if input arguments are empty:",
    "Sample Code": "shape = tf.constant([-1, -1], shape=[2], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\ndefault_value = tf.constant(404, dtype=tf.int64)\nrow = tf.constant([269, 404, 0, 0, 0, 0, 0], shape=[7], dtype=tf.int64)\nrows = [row]\ntypes = ['ROW_SPLITS']\n\ntf.raw_ops.RaggedTensorToTensor(\n  shape=shape, values=values, default_value=default_value, \n  , \n  row_partition_tensors=rows, row_partition_types=types)",
    "Code change": [
      "@@ -208,7 +208,7 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n   }\n \n   void CalculateOutputIndexRowSplit(\n-      const RowPartitionTensor& row_split,\n+      OpKernelContext* context, const RowPartitionTensor& row_split,\n       const vector<INDEX_TYPE>& parent_output_index,\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n       vector<INDEX_TYPE>* result) {\n@@ -233,7 +233,8 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n       }\n     }\n     if (row_split_size > 0) {\n-      DCHECK_EQ(result->size(), row_split(row_split_size - 1));\n+      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),\n+                  errors::InvalidArgument(\"Invalid row split size.\"));\n     }\n   }\n \n@@ -259,7 +260,7 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n   // result[7] = -1 because parent_output_index[value_rowids[6]] == -1\n   // result[8] = parent_output_index[value_rowids[7]]\n   void CalculateOutputIndexValueRowID(\n-      const RowPartitionTensor& value_rowids,\n+      OpKernelContext* context, const RowPartitionTensor& value_rowids,\n       const vector<INDEX_TYPE>& parent_output_index,\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n       vector<INDEX_TYPE>* result) {\n@@ -293,7 +294,8 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n       }\n       result->push_back(current_output_index);\n     }\n-    DCHECK_EQ(result->size(), value_rowids.size());\n+    OP_REQUIRES(context, result->size() == value_rowids.size(),\n+                errors::InvalidArgument(\"Invalid row ids.\"));\n   }\n \n   Status CalculateOutputIndex(OpKernelContext* context, int dimension,\n@@ -307,13 +309,13 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n     switch (partition_type) {\n       case RowPartitionType::VALUE_ROWIDS:\n         CalculateOutputIndexValueRowID(\n-            row_partition_tensor, parent_output_index, output_index_multiplier,\n-            output_size, result);\n+            context, row_partition_tensor, parent_output_index,\n+            output_index_multiplier, output_size, result);\n         return tensorflow::Status::OK();\n       case RowPartitionType::ROW_SPLITS:\n-        CalculateOutputIndexRowSplit(row_partition_tensor, parent_output_index,\n-                                     output_index_multiplier, output_size,\n-                                     result);\n+        CalculateOutputIndexRowSplit(\n+            context, row_partition_tensor, parent_output_index,\n+            output_index_multiplier, output_size, result);\n         return tensorflow::Status::OK();\n       default:\n         return errors::InvalidArgument(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rgvq-pcvf-hx75",
    "API Signature": "tf.raw_ops.RaggedTensorToTensor(\n    shape,\n    values,\n    default_value,\n    row_partition_tensors,\n    row_partition_types,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "values = tf.constant([], shape=[0], dtype=tf.int64)"
  },
  {
    "Title": "\n        Division by zero in TFLite's implementation of `BatchToSpaceNd`\n      ",
    "Bug description": "The implementation of the  BatchToSpaceNd  TFLite operator is  vulnerable to a division by zero error :",
    "Sample Code": "",
    "Code change": [
      "@@ -78,6 +78,7 @@ TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n   int output_batch_size = input_size->data[0];\n   for (int dim = 0; dim < spatial_dims_num; ++dim) {\n     // Number of batch must be multiple of (block_shape[dim]).\n+    TF_LITE_ENSURE(context, block_shape[dim] != 0);\n     TF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);\n     output_batch_size = output_batch_size / block_shape[dim];\n     output_size->data[dim + 1] = input_size->data[dim + 1] * block_shape[dim] -\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cfx7-2xpc-8w4h",
    "API Signature": null,
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "N.A"
  },
  {
    "Title": "\n        Division by zero in TFLite's implementation of `SpaceToBatchNd`\n      ",
    "Bug description": "The implementation of the  SpaceToBatchNd  TFLite operator is  vulnerable to a division by zero error :",
    "Sample Code": "",
    "Code change": [
      "@@ -79,6 +79,7 @@ TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n   for (int dim = 0; dim < spatial_dims_num; ++dim) {\n     int final_dim_size = (input_size->data[dim + 1] + paddings_data[dim * 2] +\n                           paddings_data[dim * 2 + 1]);\n+    TF_LITE_ENSURE(context, block_shape[dim] != 0);\n     TF_LITE_ENSURE_EQ(context, final_dim_size % block_shape[dim], 0);\n     output_size->data[dim + 1] = final_dim_size / block_shape[dim];\n     output_batch_size *= block_shape[dim];\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v52p-hfjf-wg88",
    "API Signature": "tf.raw_ops.SpaceToBatchND(\n    input, block_shape, paddings, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "N.A"
  },
  {
    "Title": "\n        Division by zero in TFLite's implementation of `Split`\n      ",
    "Bug description": "The implementation of the  Split  TFLite operator is  vulnerable to a division by zero error :",
    "Sample Code": "",
    "Code change": [
      "@@ -60,6 +60,7 @@ TfLiteStatus ResizeOutputTensors(TfLiteContext* context, TfLiteNode* node,\n   TF_LITE_ENSURE(context, axis_value < NumDimensions(input));\n \n   const int input_size = SizeOfDimension(input, axis_value);\n+  TF_LITE_ENSURE(context, num_splits != 0);\n   TF_LITE_ENSURE_MSG(context, input_size % num_splits == 0,\n                      \"Not an even split\");\n   const int slice_size = input_size / num_splits;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-97wf-p777-86jq",
    "API Signature": "tf.split(\n    value, num_or_size_splits, axis=0, num=None, name='split'\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Zero integer argument",
    "Category": "Integer",
    "Argument": "num_or_size_splits=0"
  },
  {
    "Title": "\n        Division by zero in TFLite's implementation of `OneHot`\n      ",
    "Bug description": "The implementation of the  OneHot  TFLite operator is  vulnerable to a division by zero error :",
    "Sample Code": "",
    "Code change": [
      "@@ -69,6 +69,11 @@ void OneHotComputeImpl(const OneHotContext& op_context) {\n   for (int i = 0; i < op_context.axis; ++i) {\n     prefix_dim_size *= op_context.indices->dims->data[i];\n   }\n+  if (prefix_dim_size == 0) {\n+    // If indices tensor is degenerate, return a degenerate tensor, just like\n+    // TensorFlow does.\n+    return;\n+  }\n   const int suffix_dim_size = NumElements(op_context.indices) / prefix_dim_size;\n   const int depth = *op_context.depth->data.i32;\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-j8qh-3xrq-c825",
    "API Signature": "tf.one_hot(\n    indices,\n    depth,\n    on_value=None,\n    off_value=None,\n    axis=None,\n    dtype=None,\n    name=None\n)\n",
    "Score": 0.031914893617021274,
    "Anomaly": "Zero integer list element",
    "Category": "List",
    "Argument": "indices=[1,1,0,1],"
  },
  {
    "Title": "\n        Heap buffer overflow and undefined behavior in `FusedBatchNorm`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.FusedBatchNorm  is vulnerable to a heap buffer overflow:",
    "Sample Code": "import numpy as np\n\nx = tf.zeros([10, 10, 10, 1], dtype=tf.float32)\nscale = tf.constant([], shape=[0], dtype=tf.float32)\noffset = tf.constant([], shape=[0], dtype=tf.float32)\nmean = tf.constant([], shape=[0], dtype=tf.float32)\nvariance = tf.constant([], shape=[0], dtype=tf.float32)\nepsilon = 0.0\nexponential_avg_factor = 0.0\ndata_format = \"NHWC\"\nis_training = False\n\ntf.raw_ops.FusedBatchNorm(\n  x=x, scale=scale, offset=offset, mean=mean, variance=variance, \n  epsilon=epsilon, exponential_avg_factor=exponential_avg_factor,\n  ,\n  data_format=data_format, is_training=is_training)",
    "Code change": [
      "@@ -1282,6 +1282,32 @@ class FusedBatchNormOpBase : public OpKernel {\n                   errors::InvalidArgument(\"Error during tensor copy.\"));\n     }\n \n+    const auto num_channels = GetTensorDim(x, tensor_format_, 'C');\n+    OP_REQUIRES(\n+        context, scale.NumElements() == num_channels,\n+        errors::InvalidArgument(\"scale must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                scale.NumElements(), \" and \", num_channels));\n+    OP_REQUIRES(\n+        context, offset.NumElements() == num_channels,\n+        errors::InvalidArgument(\"offset must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                offset.NumElements(), \" and \", num_channels));\n+    if (estimated_mean.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"mean must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_mean.NumElements(), \" and \", num_channels));\n+    }\n+    if (estimated_variance.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"variance must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_variance.NumElements(), \" and \", num_channels));\n+    }\n+\n     if (has_side_input_) {\n       OP_REQUIRES(context, side_input->shape() == x.shape(),\n                   errors::InvalidArgument(\n@@ -1294,7 +1320,7 @@ class FusedBatchNormOpBase : public OpKernel {\n       // NOTE(ezhulenev): This requirement is coming from implementation\n       // details of cudnnBatchNormalizationForwardTrainingEx.\n       OP_REQUIRES(\n-          context, !is_training_ || x.dim_size(3) % 4 == 0,\n+          context, !is_training_ || num_channels % 4 == 0,\n           errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\n                                   \"channel dimension to be a multiple of 4.\"));\n     }\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9xh4-23q4-v6wr",
    "API Signature": "tf.raw_ops.FusedBatchNorm(\n    x,\n    scale,\n    offset,\n    mean,\n    variance,\n    epsilon=0.0001,\n    exponential_avg_factor=1,\n    data_format='NHWC',\n    is_training=True,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "scale = tf.constant([0.0], shape=[1], dtype=tf.float32)\noffset = tf.constant([0.0], shape=[1], dtype=tf.float32)\nmean = tf.constant([0.0], shape=[1], dtype=tf.float32)\nvariance = tf.constant([0.0], shape=[1], dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK`-fail due to integer overflow\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in  caused by an integer overflow in constructing a new tensor shape:",
    "Sample Code": "input_layer = 2**60-1\nsparse_data = tf.raw_ops.SparseSplit(\n    split_dim=1, \n    indices=[(0, 0), (0, 1), (0, 2), \n    (4, 3), (5, 0), (5, 1)],\n    values=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n    shape=(input_layer, input_layer),\n    num_split=2,\n    name=None\n    )\n    )",
    "Code change": [
      "@@ -63,11 +63,18 @@ class SparseSplitOp : public OpKernel {\n                                         input_shape.vec<int64>()(axis),\n                                         \"), got \", num_split_));\n \n+    // Prevent overflow by constructing the dense shape separately\n+    TensorShape dense_shape;\n+    const auto input_shape_flat = input_shape.flat<int64>();\n+    for (int i = 0; i < input_shape.NumElements(); i++) {\n+      OP_REQUIRES_OK(context,\n+                     dense_shape.AddDimWithStatus(input_shape_flat(i)));\n+    }\n+\n     sparse::SparseTensor sparse_tensor;\n     OP_REQUIRES_OK(context,\n-                   sparse::SparseTensor::Create(\n-                       input_indices, input_values,\n-                       TensorShape(input_shape.vec<int64>()), &sparse_tensor));\n+                   sparse::SparseTensor::Create(input_indices, input_values,\n+                                                dense_shape, &sparse_tensor));\n \n     std::vector<sparse::SparseTensor> outputs;\n     OP_REQUIRES_OK(context, sparse::SparseTensor::Split<T>(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xvjm-fvxx-q3hv",
    "API Signature": "tf.raw_ops.SparseSplit(\n    split_dim, indices, values, shape, num_split, name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Large integer argument",
    "Category": "Integer",
    "Argument": "import tensorflow as tf\n\ninput_layer = 2**60-1\nsparse_data = tf.raw_ops.SparseSplit(\n    split_dim=1, \n    indices=[(0, 0), (0, 1), (0, 2), \n    (4, 3), (5, 0), (5, 1)],\n    values=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n    shape=(input_layer, input_layer),\n    num_split=2,\n    name=None\n    )"
  },
  {
    "Title": "\n        Heap OOB read in `tf.raw_ops.Dequantize`\n      ",
    "Bug description": "Due to lack of validation in  tf.raw_ops.Dequantize , an attacker can trigger a read from outside of bounds of heap allocated data:",
    "Sample Code": "input_tensor=tf.constant(\n  [75, 75, 75, 75, -6, -9, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10], shape=[5, 10], dtype=tf.int32)\ninput_tensor=tf.cast(input_tensor, dtype=tf.quint8)\nmin_range = tf.constant([-10], shape=[1], dtype=tf.float32)\nmax_range = tf.constant([24, 758, 758, 758, 758], shape=[5], dtype=tf.float32)\n  \ntf.raw_ops.Dequantize( \n  input=input_tensor, min_range=min_range, max_range=max_range, mode='SCALED',\n  ,\n  narrow_range=True, axis=0, dtype=tf.dtypes.float32)",
    "Code change": [
      "@@ -98,6 +98,18 @@ class DequantizeOp : public OpKernel {\n     if (axis_ > -1) {\n       num_slices = input.dim_size(axis_);\n     }\n+    OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,\n+                errors::InvalidArgument(\n+                    \"input_min_tensor must have as many elements as input on \"\n+                    \"the dequantization axis (\",\n+                    axis_, \"), got \", input_min_tensor.NumElements(),\n+                    \", expected \", num_slices));\n+    OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,\n+                errors::InvalidArgument(\n+                    \"input_max_tensor must have as many elements as input on \"\n+                    \"the dequantization axis (\",\n+                    axis_, \"), got \", input_max_tensor.NumElements(),\n+                    \", expected \", num_slices));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c45w-2wxr-pp53",
    "API Signature": "tf.raw_ops.Dequantize(\n    input,\n    min_range,\n    max_range,\n    mode='MIN_COMBINED',\n    narrow_range=False,\n    axis=-1,\n    dtype=tf.dtypes.float32,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "min_range = tf.constant([-10], shape=[1], dtype=tf.float32)\nmax_range = tf.constant([24, 758, 758, 758, 758], shape=[5], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `CTCBeamSearchDecoder`\n      ",
    "Bug description": "Due to lack of validation in  tf.raw_ops.CTCBeamSearchDecoder , an attacker can trigger denial of service via segmentation faults:",
    "Sample Code": "inputs = tf.constant([], shape=[18, 8, 0], dtype=tf.float32)\nsequence_length = tf.constant([11, -43, -92, 11, -89, -83, -35, -100],\nshape=[8], dtype=tf.int32)\nbeam_width = 10\ntop_paths = 3\nmerge_repeated = True\n\ntf.raw_ops.CTCBeamSearchDecoder(\n  inputs=inputs, sequence_length=sequence_length, beam_width=beam_width,\n  ,\n  top_paths=top_paths, merge_repeated=merge_repeated)",
    "Code change": [
      "@@ -70,6 +70,9 @@ class CTCDecodeHelper {\n     if (inputs_shape.dims() != 3) {\n       return errors::InvalidArgument(\"inputs is not a 3-Tensor\");\n     }\n+    if (inputs_shape.num_elements() == 0) {\n+      return errors::InvalidArgument(\"inputs must not be empty\");\n+    }\n \n     const int64 max_time = inputs_shape.dim_size(0);\n     const int64 batch_size = inputs_shape.dim_size(1);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vq2r-5xvm-3hc3",
    "API Signature": "tf.raw_ops.CTCBeamSearchDecoder(\n    inputs,\n    sequence_length,\n    beam_width,\n    top_paths,\n    merge_repeated=True,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "inputs = tf.constant([], shape=[18, 8, 0], dtype=tf.float32)"
  },
  {
    "Title": "\n        Heap buffer overflow in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.FractionalAvgPoolGrad  is vulnerable to a heap buffer overflow:",
    "Sample Code": "orig_input_tensor_shape = tf.constant([1, 3, 2, 3], shape=[4], dtype=tf.int64)\nout_backprop = tf.constant([2], shape=[1, 1, 1, 1], dtype=tf.int64)\nrow_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\ncol_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\n\n\ntf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=orig_input_tensor_shape, out_backprop=out_backprop,\n  row_pooling_sequence=row_pooling_sequence,\n  ,\n  col_pooling_sequence=col_pooling_sequence, overlapping=False)",
    "Code change": [
      "@@ -250,6 +250,19 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64 out_cols = out_backprop.dim_size(2);\n     const int64 out_depth = out_backprop.dim_size(3);\n \n+    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,\n+                errors::InvalidArgument(\"Given out_backprop shape \",\n+                                        out_backprop.shape().DebugString(),\n+                                        \", row_seq_tensor must have at least \",\n+                                        out_rows + 1, \" elements, but got \",\n+                                        row_seq_tensor.NumElements()));\n+    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,\n+                errors::InvalidArgument(\"Given out_backprop shape \",\n+                                        out_backprop.shape().DebugString(),\n+                                        \", col_seq_tensor must have at least \",\n+                                        out_cols + 1, \" elements, but got \",\n+                                        col_seq_tensor.NumElements()));\n+\n     auto row_seq_tensor_flat = row_seq_tensor.flat<int64>();\n     auto col_seq_tensor_flat = col_seq_tensor.flat<int64>();\n     auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64>();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6f89-8j54-29xf",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.02127659574468085,
    "Anomaly": "Scalar input tensor",
    "Category": "Tensor",
    "Argument": "row_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\ncol_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)"
  },
  {
    "Title": "\n        Undefined behavior and `CHECK`-fail in `FractionalMaxPoolGrad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.FractionalMaxPoolGrad  triggers an undefined behavior if one of the input tensors is empty:",
    "Sample Code": "orig_input = tf.constant([1], shape=[1], dtype=tf.int64)\norig_output = tf.constant([1], shape=[1], dtype=tf.int64)\nout_backprop = tf.constant([1, 1], shape=[2, 1, 1, 1], dtype=tf.int64)\nrow_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64) \ncol_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\n\ntf.raw_ops.FractionalMaxPoolGrad(\n  orig_input=orig_input, orig_output=orig_output, out_backprop=out_backprop,\n  row_pooling_sequence=row_pooling_sequence,\n  ,\n  col_pooling_sequence=col_pooling_sequence, overlapping=False)",
    "Code change": [
      "@@ -235,6 +235,20 @@ class FractionalMaxPoolGradOp : public OpKernel {\n \n     // Just to make it similar to FractionalMaxPoolOp.\n     constexpr int tensor_in_and_out_dims = 4;\n+    OP_REQUIRES(\n+        context, tensor_in.dims() == tensor_in_and_out_dims,\n+        errors::InvalidArgument(\"orig_input should be a tensor of rank 4, got \",\n+                                tensor_in.DebugString()));\n+    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n+                errors::InvalidArgument(\"orig_input must not be empty, got \",\n+                                        tensor_in.DebugString()));\n+    OP_REQUIRES(context, tensor_out.dims() == tensor_in_and_out_dims,\n+                errors::InvalidArgument(\n+                    \"orig_output should be a tensor of rank 4, got \",\n+                    tensor_out.DebugString()));\n+    OP_REQUIRES(context, tensor_out.NumElements() > 0,\n+                errors::InvalidArgument(\"orig_output must not be empty, got \",\n+                                        tensor_out.DebugString()));\n     std::vector<int64> input_size(tensor_in_and_out_dims);\n     std::vector<int64> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x8h6-xgqx-jqgp",
    "API Signature": "tf.raw_ops.FractionalMaxPoolGrad(\n    orig_input,\n    orig_output,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "orig_output = tf.constant([], dtype=tf.int64) "
  },
  {
    "Title": "\n        Heap buffer overflow in `AvgPool3DGrad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.AvgPool3DGrad  is vulnerable to a heap buffer overflow:",
    "Sample Code": "orig_input_shape = tf.constant([10, 6, 3, 7, 7], shape=[5], dtype=tf.int32)\ngrad = tf.constant([0.01, 0, 0], shape=[3, 1, 1, 1, 1], dtype=tf.float32)\nksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\n\ntf.raw_ops.AvgPool3DGrad(\n  orig_input_shape=orig_input_shape, grad=grad, ksize=ksize, strides=strides,\n  ,\n  padding=padding)",
    "Code change": [
      "@@ -383,6 +383,19 @@ struct LaunchAvgPooling3dGradOp<CPUDevice, T> {\n                      const std::array<int64, 3>& output_shape,\n                      const std::array<int64, 3>& padding,\n                      TensorFormat data_format, Tensor* output) {\n+    OP_REQUIRES(\n+        context, tensor_in_shape.dim_size(0) == out_backprop.dim_size(0),\n+        errors::InvalidArgument(\n+            \"Expected first dimension of tensor_in_shape and \"\n+            \"out_backprop to match, got \",\n+            tensor_in_shape.dim_size(0), \" and \", out_backprop.dim_size(0)));\n+    OP_REQUIRES(\n+        context, tensor_in_shape.dim_size(4) == out_backprop.dim_size(4),\n+        errors::InvalidArgument(\n+            \"Expected last dimension of tensor_in_shape and \"\n+            \"out_backprop to match, got \",\n+            tensor_in_shape.dim_size(4), \" and \", out_backprop.dim_size(4)));\n+\n     output->flat<T>().setZero();\n     std::array<int64, 3> input_size = {{tensor_in_shape.dim_size(3),\n                                         tensor_in_shape.dim_size(2),\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v6r6-84gr-92rm",
    "API Signature": "tf.raw_ops.AvgPool3DGrad(\n    orig_input_shape,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NDHWC',\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "orig_input_shape = tf.constant([10, 6, 3, 7, 7], shape=[5], dtype=tf.int32)\ngrad = tf.constant([0.01, 0, 0], shape=[3, 1, 1, 1, 1], dtype=tf.float32)"
  },
  {
    "Title": "\n        Heap buffer overflow in `MaxPool3DGradGrad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPool3DGradGrad  is vulnerable to a heap buffer overflow:",
    "Sample Code": "values = [0.01] * 11\norig_input = tf.constant(values, shape=[11, 1, 1, 1, 1], dtype=tf.float32)\norig_output = tf.constant([0.01], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\ngrad = tf.constant([0.01], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\nksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\n\ntf.raw_ops.MaxPool3DGradGrad(\n    orig_input=orig_input, orig_output=orig_output, grad=grad, ksize=ksize,\n    ,\n    strides=strides, padding=padding)",
    "Code change": [
      "@@ -693,6 +693,7 @@ class MaxPooling3dGradGradOp : public OpKernel {\n \n     Pool3dParameters params{context,  ksize_,       stride_,\n                             padding_, data_format_, tensor_in.shape()};\n+    if (!context->status().ok()) return;  // params is invalid\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n@@ -710,6 +711,17 @@ class MaxPooling3dGradGradOp : public OpKernel {\n         context, out_grad_backprop.NumElements() > 0,\n         errors::InvalidArgument(\"received empty tensor out_grad_backprop: \",\n                                 out_grad_backprop.DebugString()));\n+    OP_REQUIRES(context,\n+                tensor_in.NumElements() == out_grad_backprop.NumElements(),\n+                errors::InvalidArgument(\"tensor_in and out_grad_backprop must \"\n+                                        \"have same number of elements, got <\",\n+                                        tensor_in.DebugString(), \"> and <\",\n+                                        out_grad_backprop.DebugString(), \">\"));\n+    OP_REQUIRES(\n+        context, tensor_out.NumElements() == output->NumElements(),\n+        errors::InvalidArgument(\n+            \"tensor_out and output must have same number of elements, got <\",\n+            tensor_out.DebugString(), \"> and <\", output->DebugString(), \">\"));\n \n     LaunchMaxPooling3dGradGradOp<Device, T>::launch(\n         context, params, tensor_in, tensor_out, out_grad_backprop, output);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-7cqx-92hp-x6wh",
    "API Signature": "tf.raw_ops.MaxPool3DGradGrad(\n    orig_input,\n    orig_output,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NDHWC',\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "orig_input = tf.constant(values, shape=[11, 1, 1, 1, 1], dtype=tf.float32)\ngrad = tf.constant([0.01], shape=[1, 1, 1, 1, 1], dtype=tf.float32)"
  },
  {
    "Title": "\n        Undefined behavior in `MaxPool3DGradGrad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPool3DGradGrad  exhibits undefined behavior by dereferencing null pointers backing attacker-supplied empty tensors:",
    "Sample Code": "orig_input = tf.constant([0.0], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\norig_output = tf.constant([0.0], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\ngrad = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)\nksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\n\ntf.raw_ops.MaxPool3DGradGrad(\n    orig_input=orig_input, orig_output=orig_output, grad=grad, ksize=ksize,\n    ,\n    strides=strides, padding=padding)",
    "Code change": [
      "@@ -698,6 +698,19 @@ class MaxPooling3dGradGradOp : public OpKernel {\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                 {2}, 0, tensor_out.shape(), &output));\n \n+    // Given access patterns in LaunchMaxPooling3dGradGradOp, these tensors must\n+    // have elements.\n+    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n+                errors::InvalidArgument(\"received empty tensor tensor_in: \",\n+                                        tensor_in.DebugString()));\n+    OP_REQUIRES(context, tensor_out.NumElements() > 0,\n+                errors::InvalidArgument(\"received empty tensor tensor_out: \",\n+                                        tensor_out.DebugString()));\n+    OP_REQUIRES(\n+        context, out_grad_backprop.NumElements() > 0,\n+        errors::InvalidArgument(\"received empty tensor out_grad_backprop: \",\n+                                out_grad_backprop.DebugString()));\n+\n     LaunchMaxPooling3dGradGradOp<Device, T>::launch(\n         context, params, tensor_in, tensor_out, out_grad_backprop, output);\n   }\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-828x-qc2p-wprq",
    "API Signature": "tf.raw_ops.MaxPool3DGradGrad(\n    orig_input,\n    orig_output,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NDHWC',\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "grad = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)"
  },
  {
    "Title": "\n        Division by 0 in `MaxPoolGradWithArgmax`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPoolGradWithArgmax  is vulnerable to a division by 0:",
    "Sample Code": "input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\ngrad = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\nargmax = tf.constant([], shape=[0], dtype=tf.int64)\nksize = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\n\ntf.raw_ops.MaxPoolGradWithArgmax(\n  input=input, grad=grad, argmax=argmax, ksize=ksize, strides=strides,\n  ,\n  padding='SAME', include_batch_in_index=False)",
    "Code change": [
      "@@ -1088,6 +1088,8 @@ class MaxPoolingGradWithArgmaxOp : public OpKernel {\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                 {0}, 0, out_shape, &grad_out));\n \n+    if (out_shape.num_elements() == 0) return;  // nothing to be done\n+\n     LaunchMaxPoolingGradWithArgmax<Device, T>::launch(\n         context, params, grad_in, argmax, grad_out, include_batch_in_index_);\n   }\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9vpm-rcf4-9wqw",
    "API Signature": "tf.raw_ops.MaxPoolGradWithArgmax(\n    input,\n    grad,\n    argmax,\n    ksize,\n    strides,\n    padding,\n    include_batch_in_index=False,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\ngrad = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\nargmax = tf.constant([], shape=[0], dtype=tf.int64)"
  },
  {
    "Title": "\n        Overflow/denial of service in `tf.raw_ops.ReverseSequence`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.ReverseSequence  allows for stack overflow and/or  CHECK -fail based denial of service.",
    "Sample Code": "input = tf.zeros([1, 1, 1], dtype=tf.int32)\nseq_lengths = tf.constant([0], shape=[1], dtype=tf.int32)\n\ntf.raw_ops.ReverseSequence(\n    (\n    input=input, seq_lengths=seq_lengths, seq_dim=-2, batch_dim=0)",
    "Code change": [
      "@@ -115,6 +115,10 @@ class ReverseSequenceOp : public OpKernel {\n       : OpKernel(context) {\n     OP_REQUIRES_OK(context, context->GetAttr(\"batch_dim\", &batch_dim_));\n     OP_REQUIRES_OK(context, context->GetAttr(\"seq_dim\", &seq_dim_));\n+    OP_REQUIRES(context, batch_dim_ >= 0,\n+                errors::InvalidArgument(\"Invalid batch_dim \", batch_dim_));\n+    OP_REQUIRES(context, seq_dim_ >= 0,\n+                errors::InvalidArgument(\"Invalid seq_dim \", seq_dim_));\n   }\n \n   void Compute(OpKernelContext* context) override {\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6qgm-fv6v-rfpv",
    "API Signature": "tf.raw_ops.ReverseSequence(\n    input, seq_lengths, seq_dim, batch_dim=0, name=None\n)\n",
    "Score": 0.03900709219858156,
    "Anomaly": "Negative integer argument",
    "Category": "Integer",
    "Argument": "seq_dim=-2"
  },
  {
    "Title": "\n        Reference binding to nullptr in `SdcaOptimizer`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SdcaOptimizer  triggers undefined behavior due to dereferencing a null pointer:",
    "Sample Code": "sparse_example_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_indices = [tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_values = []\n\ndense_features = []\ndense_weights = []\n\nexample_weights = tf.constant((0.0), dtype=tf.float32)\nexample_labels = tf.constant((0.0), dtype=tf.float32)\n\nsparse_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_weights = [tf.constant((0.0), dtype=tf.float32), tf.constant((0.0), dtype=tf.float32)]\n  \nexample_state_data = tf.constant([0.0, 0.0, 0.0, 0.0], shape=[1, 4], dtype=tf.float32)\n  \ntf.raw_ops.SdcaOptimizer(\n  sparse_example_indices=sparse_example_indices,\n  sparse_feature_indices=sparse_feature_indices,\n  sparse_feature_values=sparse_feature_values, dense_features=dense_features,\n  example_weights=example_weights, example_labels=example_labels, \n  sparse_indices=sparse_indices, sparse_weights=sparse_weights, \n  dense_weights=dense_weights, example_state_data=example_state_data,\n  loss_type=\"logistic_loss\", l1=0.0, l2=0.0, num_loss_partitions=1,\n  ,\n  num_inner_iterations=1, adaptative=False)",
    "Code change": [
      "@@ -99,6 +99,10 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {\n   OpInputList sparse_weights_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(\"sparse_weights\", &sparse_weights_inputs));\n+  if (sparse_indices_inputs.size() != sparse_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"sparse_indices and sparse_weights must have the same length, got \",\n+        sparse_indices_inputs.size(), \" and \", sparse_weights_inputs.size());\n   OpInputList dense_weights_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(\"dense_weights\", &dense_weights_inputs));\n@@ -106,10 +110,20 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {\n   OpOutputList sparse_weights_outputs;\n   TF_RETURN_IF_ERROR(context->output_list(\"out_delta_sparse_weights\",\n                                           &sparse_weights_outputs));\n+  if (sparse_weights_outputs.size() != sparse_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"out_delta_sparse_weights and sparse_weights must have the same \"\n+        \"length, got \",\n+        sparse_weights_outputs.size(), \" and \", sparse_weights_inputs.size());\n \n   OpOutputList dense_weights_outputs;\n   TF_RETURN_IF_ERROR(\n       context->output_list(\"out_delta_dense_weights\", &dense_weights_outputs));\n+  if (dense_weights_outputs.size() != dense_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"out_delta_dense_weights and dense_weights must have the same length, \"\n+        \"got \",\n+        dense_weights_outputs.size(), \" and \", dense_weights_inputs.size());\n \n   for (int i = 0; i < sparse_weights_inputs.size(); ++i) {\n     Tensor* delta_t;\n@@ -327,13 +341,28 @@ Status Examples::Initialize(OpKernelContext* const context,\n   OpInputList sparse_example_indices_inputs;\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                          &sparse_example_indices_inputs));\n+  if (sparse_example_indices_inputs.size() != num_sparse_features)\n+    return errors::InvalidArgument(\n+        \"Expected \", num_sparse_features,\n+        \" tensors in sparse_example_indices but got \",\n+        sparse_example_indices_inputs.size());\n   OpInputList sparse_feature_indices_inputs;\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                          &sparse_feature_indices_inputs));\n+  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n+    return errors::InvalidArgument(\n+        \"Expected \", num_sparse_features,\n+        \" tensors in sparse_feature_indices but got \",\n+        sparse_feature_indices_inputs.size());\n   OpInputList sparse_feature_values_inputs;\n   if (num_sparse_features_with_values > 0) {\n     TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                            &sparse_feature_values_inputs));\n+    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n+      return errors::InvalidArgument(\n+          \"Expected \", num_sparse_features_with_values,\n+          \" tensors in sparse_feature_values but got \",\n+          sparse_feature_values_inputs.size());\n   }\n \n   const Tensor* example_weights_t;\n@@ -400,6 +429,13 @@ Status Examples::CreateSparseFeatureRepresentation(\n           sparse_example_indices_inputs[i].template flat<int64>();\n       auto feature_indices =\n           sparse_feature_indices_inputs[i].template flat<int64>();\n+      if (example_indices.size() != feature_indices.size()) {\n+        mutex_lock l(mu);\n+        result = errors::InvalidArgument(\n+            \"Found mismatched example_indices and feature_indices [\",\n+            example_indices, \"] vs [\", feature_indices, \"]\");\n+        return;\n+      }\n \n       // Parse features for each example. Features for a particular example\n       // are at the offsets (start_id, end_id]\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5gqf-456p-4836",
    "API Signature": "tf.raw_ops.SdcaOptimizer(\n    sparse_example_indices,\n    sparse_feature_indices,\n    sparse_feature_values,\n    dense_features,\n    example_weights,\n    example_labels,\n    sparse_indices,\n    sparse_weights,\n    dense_weights,\n    example_state_data,\n    loss_type,\n    l1,\n    l2,\n    num_loss_partitions,\n    num_inner_iterations,\n    adaptative=True,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "sparse_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_weights = [tf.constant((0.0), dtype=tf.float32), tf.constant((0.0), dtype=tf.float32)]"
  },
  {
    "Title": "\n        Reference binding to nullptr in `SdcaOptimizer`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SdcaOptimizer  triggers undefined behavior due to dereferencing a null pointer:",
    "Sample Code": "sparse_example_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_indices = [tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_values = []\n\ndense_features = []\ndense_weights = []\n\nexample_weights = tf.constant((0.0), dtype=tf.float32)\nexample_labels = tf.constant((0.0), dtype=tf.float32)\n\nsparse_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_weights = [tf.constant((0.0), dtype=tf.float32), tf.constant((0.0), dtype=tf.float32)]\n  \nexample_state_data = tf.constant([0.0, 0.0, 0.0, 0.0], shape=[1, 4], dtype=tf.float32)\n  \ntf.raw_ops.SdcaOptimizer(\n  sparse_example_indices=sparse_example_indices,\n  sparse_feature_indices=sparse_feature_indices,\n  sparse_feature_values=sparse_feature_values, dense_features=dense_features,\n  example_weights=example_weights, example_labels=example_labels, \n  sparse_indices=sparse_indices, sparse_weights=sparse_weights, \n  dense_weights=dense_weights, example_state_data=example_state_data,\n  loss_type=\"logistic_loss\", l1=0.0, l2=0.0, num_loss_partitions=1,\n  ,\n  num_inner_iterations=1, adaptative=False)",
    "Code change": [
      "@@ -99,6 +99,10 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {\n   OpInputList sparse_weights_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(\"sparse_weights\", &sparse_weights_inputs));\n+  if (sparse_indices_inputs.size() != sparse_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"sparse_indices and sparse_weights must have the same length, got \",\n+        sparse_indices_inputs.size(), \" and \", sparse_weights_inputs.size());\n   OpInputList dense_weights_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(\"dense_weights\", &dense_weights_inputs));\n@@ -106,10 +110,20 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {\n   OpOutputList sparse_weights_outputs;\n   TF_RETURN_IF_ERROR(context->output_list(\"out_delta_sparse_weights\",\n                                           &sparse_weights_outputs));\n+  if (sparse_weights_outputs.size() != sparse_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"out_delta_sparse_weights and sparse_weights must have the same \"\n+        \"length, got \",\n+        sparse_weights_outputs.size(), \" and \", sparse_weights_inputs.size());\n \n   OpOutputList dense_weights_outputs;\n   TF_RETURN_IF_ERROR(\n       context->output_list(\"out_delta_dense_weights\", &dense_weights_outputs));\n+  if (dense_weights_outputs.size() != dense_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"out_delta_dense_weights and dense_weights must have the same length, \"\n+        \"got \",\n+        dense_weights_outputs.size(), \" and \", dense_weights_inputs.size());\n \n   for (int i = 0; i < sparse_weights_inputs.size(); ++i) {\n     Tensor* delta_t;\n@@ -327,13 +341,28 @@ Status Examples::Initialize(OpKernelContext* const context,\n   OpInputList sparse_example_indices_inputs;\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                          &sparse_example_indices_inputs));\n+  if (sparse_example_indices_inputs.size() != num_sparse_features)\n+    return errors::InvalidArgument(\n+        \"Expected \", num_sparse_features,\n+        \" tensors in sparse_example_indices but got \",\n+        sparse_example_indices_inputs.size());\n   OpInputList sparse_feature_indices_inputs;\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                          &sparse_feature_indices_inputs));\n+  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n+    return errors::InvalidArgument(\n+        \"Expected \", num_sparse_features,\n+        \" tensors in sparse_feature_indices but got \",\n+        sparse_feature_indices_inputs.size());\n   OpInputList sparse_feature_values_inputs;\n   if (num_sparse_features_with_values > 0) {\n     TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                            &sparse_feature_values_inputs));\n+    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n+      return errors::InvalidArgument(\n+          \"Expected \", num_sparse_features_with_values,\n+          \" tensors in sparse_feature_values but got \",\n+          sparse_feature_values_inputs.size());\n   }\n \n   const Tensor* example_weights_t;\n@@ -400,6 +429,13 @@ Status Examples::CreateSparseFeatureRepresentation(\n           sparse_example_indices_inputs[i].template flat<int64>();\n       auto feature_indices =\n           sparse_feature_indices_inputs[i].template flat<int64>();\n+      if (example_indices.size() != feature_indices.size()) {\n+        mutex_lock l(mu);\n+        result = errors::InvalidArgument(\n+            \"Found mismatched example_indices and feature_indices [\",\n+            example_indices, \"] vs [\", feature_indices, \"]\");\n+        return;\n+      }\n \n       // Parse features for each example. Features for a particular example\n       // are at the offsets (start_id, end_id]\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5gqf-456p-4836",
    "API Signature": "tf.raw_ops.SdcaOptimizer(\n    sparse_example_indices,\n    sparse_feature_indices,\n    sparse_feature_values,\n    dense_features,\n    example_weights,\n    example_labels,\n    sparse_indices,\n    sparse_weights,\n    dense_weights,\n    example_state_data,\n    loss_type,\n    l1,\n    l2,\n    num_loss_partitions,\n    num_inner_iterations,\n    adaptative=True,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "sparse_example_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_indices = [tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64), tf.constant((0), dtype=tf.int64)]"
  },
  {
    "Title": "\n        Memory corruption in `DrawBoundingBoxesV2`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPoolGradWithArgmax  can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:",
    "Sample Code": "images = tf.fill([10, 96, 0, 1], 0.)\nboxes = tf.fill([10, 53, 0], 0.)\ncolors = tf.fill([0, 1], 0.)\n\n)\n\ntf.raw_ops.DrawBoundingBoxesV2(images=images, boxes=boxes, colors=colors)",
    "Code change": [
      "@@ -73,6 +73,12 @@ class DrawBoundingBoxesOp : public OpKernel {\n         errors::InvalidArgument(\"Channel depth should be either 1 (GRY), \"\n                                 \"3 (RGB), or 4 (RGBA)\"));\n \n+    OP_REQUIRES(\n+        context, boxes.dim_size(2) == 4,\n+        errors::InvalidArgument(\n+            \"The size of the third dimension of the box must be 4. Received: \",\n+            boxes.dim_size(2)));\n+\n     const int64 batch_size = images.dim_size(0);\n     const int64 height = images.dim_size(1);\n     const int64 width = images.dim_size(2);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-whr9-vfh2-7hm6",
    "API Signature": "tf.raw_ops.DrawBoundingBoxesV2(\n    images, boxes, colors, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "boxes = tf.fill([10, 53, 0], 0.)"
  },
  {
    "Title": "\n        Heap out of bounds read in `RequantizationRange`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPoolGradWithArgmax  can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:",
    "Sample Code": "input = tf.constant([1], shape=[1], dtype=tf.qint32) \ninput_max = tf.constant([], dtype=tf.float32)\ninput_min = tf.constant([], dtype=tf.float32)\n\n)\n\ntf.raw_ops.RequantizationRange(input=input, input_min=input_min, input_max=input_max)",
    "Code change": [
      "@@ -46,6 +46,10 @@ class RequantizationRangeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(ctx, ctx->input(1).NumElements() > 0,\n+                errors::InvalidArgument(\"Input min must not be empty.\"));\n+    OP_REQUIRES(ctx, ctx->input(2).NumElements() > 0,\n+                errors::InvalidArgument(\"Input max must not be empty.\"));\n     const float input_min_float = ctx->input(1).flat<float>()(0);\n     const float input_max_float = ctx->input(2).flat<float>()(0);\n     Tensor* output_min = nullptr;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-3h8m-483j-7xxm",
    "API Signature": "tf.raw_ops.RequantizationRange(\n    input, input_min, input_max, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "input_max = tf.constant([], dtype=tf.float32)\ninput_min = tf.constant([], dtype=tf.float32)"
  },
  {
    "Title": "\n        Heap out of bounds read in `MaxPoolGradWithArgmax`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPoolGradWithArgmax  can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:",
    "Sample Code": "input = tf.constant([10.0, 10.0, 10.0], shape=[1, 1, 3, 1], dtype=tf.float32)\ngrad = tf.constant([10.0, 10.0, 10.0, 10.0], shape=[1, 1, 1, 4], dtype=tf.float32)\nargmax = tf.constant([1], shape=[1], dtype=tf.int64)\nksize = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\n  \ntf.raw_ops.MaxPoolGradWithArgmax(\n  input=input, grad=grad, argmax=argmax, ksize=ksize, strides=strides,\n  ,\n  padding='SAME', include_batch_in_index=False)",
    "Code change": [
      "@@ -1014,6 +1014,9 @@ struct LaunchMaxPoolingGradWithArgmax<CPUDevice, T> {\n         const int input_start = start * input_size_per_batch;\n         const int input_end = limit * input_size_per_batch;\n         for (int64 index = input_start; index < input_end; index++) {\n+          if (index >= argmax.NumElements()) {\n+            break;\n+          }\n           int64 grad_out_index = argmax_flat(index);\n           if (!include_batch_in_index) {\n             const int64 cur_batch = index / input_size_per_batch;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-545v-42p7-98fq",
    "API Signature": "tf.raw_ops.MaxPoolGradWithArgmax(\n    input,\n    grad,\n    argmax,\n    ksize,\n    strides,\n    padding,\n    include_batch_in_index=False,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "input = tf.constant([10.0, 10.0, 10.0], shape=[1, 1, 3, 1], dtype=tf.float32)\nargmax = tf.constant([1], shape=[1], dtype=tf.int64)"
  },
  {
    "Title": "\n        Lack of validation in `SparseDenseCwiseMul`\n      ",
    "Bug description": "Due to lack of validation in  tf.raw_ops.SparseDenseCwiseMul , an attacker can trigger denial of service via  CHECK -fails or accesses to outside the bounds of heap allocated data:",
    "Sample Code": "indices = tf.constant([], shape=[10, 0], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\nshape = tf.constant([0, 0], shape=[2], dtype=tf.int64)\ndense = tf.constant([], shape=[0], dtype=tf.int64)\n  \ntf.raw_ops.SparseDenseCwiseMul(\n    (\n    sp_indices=indices, sp_values=values, sp_shape=shape, dense=dense)",
    "Code change": [
      "@@ -78,6 +78,11 @@ class SparseDenseBinaryOpShared : public OpKernel {\n                     \"but received shapes: \",\n                     values_t->shape().DebugString(), \" and \",\n                     shape_t->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n+        errors::InvalidArgument(\n+            \"The first dimension of values and indices should match. (\",\n+            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n \n     const auto indices_mat = indices_t->matrix<int64>();\n     const auto shape_vec = shape_t->vec<int64>();\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wp3c-xw9g-gpcg",
    "API Signature": "tf.raw_ops.SparseDenseCwiseMul(\n    sp_indices, sp_values, sp_shape, dense, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "indices = tf.constant([], shape=[10, 0], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)"
  },
  {
    "Title": "\n        Reference binding to null in `ParameterizedTruncatedNormal`\n      ",
    "Bug description": "An attacker can trigger undefined behavior by binding to null pointer in  tf.raw_ops.ParameterizedTruncatedNormal :",
    "Sample Code": "shape = tf.constant([], shape=[0], dtype=tf.int32)\nmeans = tf.constant((1), dtype=tf.float32)\nstdevs = tf.constant((1), dtype=tf.float32)\nminvals = tf.constant((1), dtype=tf.float32)\nmaxvals = tf.constant((1), dtype=tf.float32)\n  \ntf.raw_ops.ParameterizedTruncatedNormal(\n  (\n  shape=shape, means=means, stdevs=stdevs, minvals=minvals, maxvals=maxvals)",
    "Code change": [
      "@@ -627,6 +627,9 @@ class ParameterizedTruncatedNormalOp : public OpKernel {\n         ctx, TensorShapeUtils::IsVector(shape_tensor.shape()),\n         errors::InvalidArgument(\"Input shape should be a vector, got shape: \",\n                                 shape_tensor.shape().DebugString()));\n+    OP_REQUIRES(ctx, shape_tensor.NumElements() > 0,\n+                errors::InvalidArgument(\"Shape tensor must not be empty, got \",\n+                                        shape_tensor.DebugString()));\n     int32 num_batches = shape_tensor.flat<int32>()(0);\n \n     int32 samples_per_batch = 1;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4p4p-www8-8fv9",
    "API Signature": "tf.raw_ops.ParameterizedTruncatedNormal(\n    shape, means, stdevs, minvals, maxvals, seed=0, seed2=0, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "shape = tf.constant([], shape=[0], dtype=tf.int32)"
  },
  {
    "Title": "\n        Null pointer dereference in `SparseFillEmptyRows`\n      ",
    "Bug description": "An attacker can trigger a null pointer dereference in the implementation of  tf.raw_ops.SparseFillEmptyRows :",
    "Sample Code": "indices = tf.constant([], shape=[0, 0], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\ndense_shape = tf.constant([], shape=[0], dtype=tf.int64)\ndefault_value = 0\n    \ntf.raw_ops.SparseFillEmptyRows(\n    indices=indices, values=values, dense_shape=dense_shape,\n    ,\n    default_value=default_value)",
    "Code change": [
      "@@ -228,7 +228,10 @@ void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                               default_value_t.shape().DebugString()),\n       done);\n   // TODO(ebrevdo): add shape checks between values, indices,\n-  // dense_shape.  Also add check that dense rank > 0.\n+  // Also add check that dense rank > 0.\n+  OP_REQUIRES_ASYNC(context, dense_shape_t.NumElements() != 0,\n+                    errors::InvalidArgument(\"Dense shape cannot be empty.\"),\n+                    done);\n \n   using FunctorType = functor::SparseFillEmptyRows<Device, T, Tindex>;\n   OP_REQUIRES_OK_ASYNC(context,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-r6pg-pjwc-j585",
    "API Signature": "tf.raw_ops.SparseFillEmptyRows(\n    indices, values, dense_shape, default_value, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "dense_shape = tf.constant([], shape=[0], dtype=tf.int64),"
  },
  {
    "Title": "\n        Null pointer dereference in `EditDistance`\n      ",
    "Bug description": "An attacker can trigger a null pointer dereference in the implementation of  tf.raw_ops.EditDistance :",
    "Sample Code": "hypothesis_indices = tf.constant([247, 247, 247], shape=[1, 3], dtype=tf.int64)\nhypothesis_values = tf.constant([-9.9999], shape=[1], dtype=tf.float32)\nhypothesis_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\ntruth_indices = tf.constant([], shape=[0, 3], dtype=tf.int64)\ntruth_values = tf.constant([], shape=[0], dtype=tf.float32)\ntruth_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\n\ntf.raw_ops.EditDistance(\n    hypothesis_indices=hypothesis_indices, hypothesis_values=hypothesis_values,\n    hypothesis_shape=hypothesis_shape, truth_indices=truth_indices,\n    ,\n    truth_values=truth_values, truth_shape=truth_shape, normalize=True)",
    "Code change": [
      "@@ -64,6 +64,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\n     return errors::InvalidArgument(\n         \"truth_shape should be a vector, but got shape: \",\n         truth_shape.shape().DebugString());\n+  if (hypothesis_values.NumElements() != hypothesis_indices.dim_size(0))\n+    return errors::InvalidArgument(\n+        \"Expected hypothesis_values.NumElements == \"\n+        \"#rows(hypothesis_indices), their shapes are: \",\n+        hypothesis_values.shape().DebugString(), \" and \",\n+        hypothesis_indices.shape().DebugString());\n   if (hypothesis_shape.NumElements() != hypothesis_indices.dim_size(1))\n     return errors::InvalidArgument(\n         \"Expected hypothesis_shape.NumElements == \"\n@@ -75,6 +81,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\n         \"Input SparseTensors must have rank at least 2, but truth_shape \"\n         \"rank is: \",\n         truth_shape.NumElements());\n+  if (truth_values.NumElements() != truth_indices.dim_size(0))\n+    return errors::InvalidArgument(\n+        \"Expected truth_values.NumElements == \"\n+        \"#rows(truth_indices), their shapes are: \",\n+        truth_values.shape().DebugString(), \" and \",\n+        truth_indices.shape().DebugString());\n   if (truth_shape.NumElements() != truth_indices.dim_size(1))\n     return errors::InvalidArgument(\n         \"Expected truth_shape.NumElements == \"\n@@ -153,6 +165,11 @@ class EditDistanceOp : public OpKernel {\n       output_shape.AddDim(std::max(hypothesis_st_shape.dim_size(d),\n                                    truth_st_shape.dim_size(d)));\n     }\n+    const auto output_elements = output_shape.num_elements();\n+    OP_REQUIRES(\n+        ctx, output_elements > 0,\n+        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),\n+                                \" which has 0 elements\"));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\n@@ -185,6 +202,12 @@ class EditDistanceOp : public OpKernel {\n       if (g_truth == g_hypothesis) {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) =\n             gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);\n         if (normalize_) output_t(loc) /= truth_seq.size();\n@@ -194,6 +217,12 @@ class EditDistanceOp : public OpKernel {\n       } else if (g_truth > g_hypothesis) {  // zero-length truth\n         auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) = hypothesis_seq.size();\n         if (normalize_ && output_t(loc) != 0.0f) {\n           output_t(loc) = std::numeric_limits<float>::infinity();\n@@ -202,6 +231,12 @@ class EditDistanceOp : public OpKernel {\n       } else {  // zero-length hypothesis\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n         ++truth_iter;\n       }\n@@ -212,6 +247,12 @@ class EditDistanceOp : public OpKernel {\n       auto hypothesis_seq = hypothesis_j.values<T>();\n       auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                     output_strides.begin(), int64{0});\n+      OP_REQUIRES(\n+          ctx, loc < output_elements,\n+          errors::Internal(\"Got an inner product \", loc,\n+                           \" which would require in writing to outside of the \"\n+                           \"buffer for the output tensor (max elements \",\n+                           output_elements, \")\"));\n       output_t(loc) = hypothesis_seq.size();\n       if (normalize_ && output_t(loc) != 0.0f) {\n         output_t(loc) = std::numeric_limits<float>::infinity();\n@@ -224,6 +265,12 @@ class EditDistanceOp : public OpKernel {\n       auto truth_seq = truth_i.values<T>();\n       auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                     output_strides.begin(), int64{0});\n+      OP_REQUIRES(\n+          ctx, loc < output_elements,\n+          errors::Internal(\"Got an inner product \", loc,\n+                           \" which would require in writing to outside of the \"\n+                           \"buffer for the output tensor (max elements \",\n+                           output_elements, \")\"));\n       output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n       ++truth_iter;\n     }\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-75f6-78jr-4656",
    "API Signature": "tf.raw_ops.EditDistance(\n    hypothesis_indices,\n    hypothesis_values,\n    hypothesis_shape,\n    truth_indices,\n    truth_values,\n    truth_shape,\n    normalize=True,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "hypothesis_indices = tf.constant([247, 247, 247], shape=[1, 3], dtype=tf.int64)\nhypothesis_values = tf.constant([-9.9999], shape=[1], dtype=tf.float32)"
  },
  {
    "Title": "\n        Null pointer dereference in `EditDistance`\n      ",
    "Bug description": "An attacker can trigger a null pointer dereference in the implementation of  tf.raw_ops.EditDistance :",
    "Sample Code": "hypothesis_indices = tf.constant([247, 247, 247], shape=[1, 3], dtype=tf.int64)\nhypothesis_values = tf.constant([-9.9999], shape=[1], dtype=tf.float32)\nhypothesis_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\ntruth_indices = tf.constant([], shape=[0, 3], dtype=tf.int64)\ntruth_values = tf.constant([], shape=[0], dtype=tf.float32)\ntruth_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\n\ntf.raw_ops.EditDistance(\n    hypothesis_indices=hypothesis_indices, hypothesis_values=hypothesis_values,\n    hypothesis_shape=hypothesis_shape, truth_indices=truth_indices,\n    ,\n    truth_values=truth_values, truth_shape=truth_shape, normalize=True)",
    "Code change": [
      "@@ -64,6 +64,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\n     return errors::InvalidArgument(\n         \"truth_shape should be a vector, but got shape: \",\n         truth_shape.shape().DebugString());\n+  if (hypothesis_values.NumElements() != hypothesis_indices.dim_size(0))\n+    return errors::InvalidArgument(\n+        \"Expected hypothesis_values.NumElements == \"\n+        \"#rows(hypothesis_indices), their shapes are: \",\n+        hypothesis_values.shape().DebugString(), \" and \",\n+        hypothesis_indices.shape().DebugString());\n   if (hypothesis_shape.NumElements() != hypothesis_indices.dim_size(1))\n     return errors::InvalidArgument(\n         \"Expected hypothesis_shape.NumElements == \"\n@@ -75,6 +81,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\n         \"Input SparseTensors must have rank at least 2, but truth_shape \"\n         \"rank is: \",\n         truth_shape.NumElements());\n+  if (truth_values.NumElements() != truth_indices.dim_size(0))\n+    return errors::InvalidArgument(\n+        \"Expected truth_values.NumElements == \"\n+        \"#rows(truth_indices), their shapes are: \",\n+        truth_values.shape().DebugString(), \" and \",\n+        truth_indices.shape().DebugString());\n   if (truth_shape.NumElements() != truth_indices.dim_size(1))\n     return errors::InvalidArgument(\n         \"Expected truth_shape.NumElements == \"\n@@ -153,6 +165,11 @@ class EditDistanceOp : public OpKernel {\n       output_shape.AddDim(std::max(hypothesis_st_shape.dim_size(d),\n                                    truth_st_shape.dim_size(d)));\n     }\n+    const auto output_elements = output_shape.num_elements();\n+    OP_REQUIRES(\n+        ctx, output_elements > 0,\n+        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),\n+                                \" which has 0 elements\"));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\n@@ -185,6 +202,12 @@ class EditDistanceOp : public OpKernel {\n       if (g_truth == g_hypothesis) {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) =\n             gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);\n         if (normalize_) output_t(loc) /= truth_seq.size();\n@@ -194,6 +217,12 @@ class EditDistanceOp : public OpKernel {\n       } else if (g_truth > g_hypothesis) {  // zero-length truth\n         auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) = hypothesis_seq.size();\n         if (normalize_ && output_t(loc) != 0.0f) {\n           output_t(loc) = std::numeric_limits<float>::infinity();\n@@ -202,6 +231,12 @@ class EditDistanceOp : public OpKernel {\n       } else {  // zero-length hypothesis\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n         ++truth_iter;\n       }\n@@ -212,6 +247,12 @@ class EditDistanceOp : public OpKernel {\n       auto hypothesis_seq = hypothesis_j.values<T>();\n       auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                     output_strides.begin(), int64{0});\n+      OP_REQUIRES(\n+          ctx, loc < output_elements,\n+          errors::Internal(\"Got an inner product \", loc,\n+                           \" which would require in writing to outside of the \"\n+                           \"buffer for the output tensor (max elements \",\n+                           output_elements, \")\"));\n       output_t(loc) = hypothesis_seq.size();\n       if (normalize_ && output_t(loc) != 0.0f) {\n         output_t(loc) = std::numeric_limits<float>::infinity();\n@@ -224,6 +265,12 @@ class EditDistanceOp : public OpKernel {\n       auto truth_seq = truth_i.values<T>();\n       auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                     output_strides.begin(), int64{0});\n+      OP_REQUIRES(\n+          ctx, loc < output_elements,\n+          errors::Internal(\"Got an inner product \", loc,\n+                           \" which would require in writing to outside of the \"\n+                           \"buffer for the output tensor (max elements \",\n+                           output_elements, \")\"));\n       output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n       ++truth_iter;\n     }\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-75f6-78jr-4656",
    "API Signature": "tf.raw_ops.EditDistance(\n    hypothesis_indices,\n    hypothesis_values,\n    hypothesis_shape,\n    truth_indices,\n    truth_values,\n    truth_shape,\n    normalize=True,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "truth_indices = tf.constant([], shape=[0, 3], dtype=tf.int64)\ntruth_values = tf.constant([], shape=[0], dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK`-fail in `tf.raw_ops.RFFT`\n      ",
    "Bug description": "An attacker can cause a denial of service by exploiting a  CHECK -failure coming from the implementation of  tf.raw_ops.RFFT :",
    "Sample Code": "inputs = tf.constant([1], shape=[1], dtype=tf.float32)\nfft_length = tf.constant([0], shape=[1], dtype=tf.int32)\n\n)\n\ntf.raw_ops.RFFT(input=inputs, fft_length=fft_length)",
    "Code change": [
      "@@ -222,6 +222,9 @@ class FFTCPU : public FFTBase {\n       input_slice_sizes[i] = fft_shape[i - 1];\n       temp_shape.AddDim(fft_shape[i - 1]);\n     }\n+    OP_REQUIRES(ctx, temp_shape.num_elements() > 0,\n+                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\n+                                        temp_shape.DebugString()));\n \n     auto output = out->flat_inner_dims<ComplexT, FFTRank + 1>();\n     const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> zero_start_indices;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-ph87-fvjr-v33w",
    "API Signature": "tf.raw_ops.RFFT(\n    input,\n    fft_length,\n    Tcomplex=tf.dtypes.complex64,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "fft_length = tf.constant([0], shape=[1], dtype=tf.int32)"
  },
  {
    "Title": "\n        `CHECK`-fail in `tf.raw_ops.IRFFT`\n      ",
    "Bug description": "An attacker can cause a denial of service by exploiting a  CHECK -failure coming from the implementation of  tf.raw_ops.IRFFT :",
    "Sample Code": "values = [-10.0] * 130\nvalues[0] = -9.999999999999995\ninputs = tf.constant(values, shape=[10, 13], dtype=tf.float32)\ninputs = tf.cast(inputs, dtype=tf.complex64)\nfft_length = tf.constant([0], shape=[1], dtype=tf.int32)\n\n)\n\ntf.raw_ops.IRFFT(input=inputs, fft_length=fft_length)",
    "Code change": [
      "@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include \"tensorflow/core/platform/errors.h\"\n #define EIGEN_USE_THREADS\n \n // See docs in ../ops/fft_ops.cc.\n@@ -261,6 +262,9 @@ class FFTCPU : public FFTBase {\n           i == FFTRank ? fft_shape[i - 1] / 2 + 1 : fft_shape[i - 1];\n       full_fft_shape.AddDim(fft_shape[i - 1]);\n     }\n+    OP_REQUIRES(ctx, full_fft_shape.num_elements() > 0,\n+                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\n+                                        full_fft_shape.DebugString()));\n \n     Tensor temp;\n     OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-36vm-xw34-x4pj",
    "API Signature": "tf.raw_ops.IRFFT(\n    input,\n    fft_length,\n    Treal=tf.dtypes.float32,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "fft_length = tf.constant([0], shape=[1], dtype=tf.int32)"
  },
  {
    "Title": "\n        `CHECK`-fail in `LoadAndRemapMatrix` \n      ",
    "Bug description": "An attacker can cause a denial of service by exploiting a  CHECK -failure coming from  tf.raw_ops.LoadAndRemapMatrix :",
    "Sample Code": "ckpt_path = tf.constant([], shape=[0], dtype=tf.string)\nold_tensor_name = tf.constant(\"\")\nrow_remapping = tf.constant([], shape=[0], dtype=tf.int64)\ncol_remapping = tf.constant([1], shape=[1], dtype=tf.int64)\ninitializing_values = tf.constant(1.0)\n\ntf.raw_ops.LoadAndRemapMatrix(\n    ckpt_path=ckpt_path, old_tensor_name=old_tensor_name,\n    row_remapping=row_remapping, col_remapping=col_remapping,\n    ,\n    initializing_values=initializing_values, num_rows=0, num_cols=1)",
    "Code change": [
      "@@ -123,6 +123,11 @@ class LoadAndRemapMatrixOp : public OpKernel {\n     // Processes the checkpoint source and the provided Tensor name.\n     const Tensor* ckpt_path_t;\n     OP_REQUIRES_OK(context, context->input(\"ckpt_path\", &ckpt_path_t));\n+    OP_REQUIRES(\n+        context, ckpt_path_t->NumElements() == 1,\n+        errors::InvalidArgument(\"The `ckpt_path` tensor must have exactly one \"\n+                                \"element, got tensor of shape \",\n+                                ckpt_path_t->shape().DebugString()));\n     const string& ckpt_path = ckpt_path_t->scalar<tstring>()();\n     const Tensor* old_tensor_name_t;\n     OP_REQUIRES_OK(context,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gvm4-h8j3-rjrq",
    "API Signature": "tf.raw_ops.LoadAndRemapMatrix(\n    ckpt_path,\n    old_tensor_name,\n    row_remapping,\n    col_remapping,\n    initializing_values,\n    num_rows,\n    num_cols,\n    max_rows_in_memory=-1,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "ckpt_path = tf.constant([], shape=[0], dtype=tf.string)"
  },
  {
    "Title": "\n        Heap OOB access in unicode ops\n      ",
    "Bug description": "An attacker can access data outside of bounds of heap allocated array in  tf.raw_ops.UnicodeEncode :",
    "Sample Code": "input_values = tf.constant([58], shape=[1], dtype=tf.int32)\ninput_splits = tf.constant([[81, 101, 0]], shape=[3], dtype=tf.int32)\noutput_encoding = \"UTF-8\"\n\ntf.raw_ops.UnicodeEncode(\n    input_values=input_values, input_splits=input_splits,\n    ,\n    output_encoding=output_encoding)",
    "Code change": [
      "@@ -533,6 +533,17 @@ class UnicodeEncodeOp : public OpKernel {\n     const Tensor& input_splits = context->input(1);\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n \n+    // Operation will treat first argument in input_splits as if it were zero\n+    // regardless of its actual value since splits should begin with zero and\n+    // end with the length of the input values vector.\n+    OP_REQUIRES(\n+        context, input_splits_flat(0) == 0,\n+        errors::InvalidArgument(\"First value in input_splits must be zero.\"));\n+    OP_REQUIRES(context,\n+                input_splits_flat(input_splits_flat.size() - 1) ==\n+                    input_tensor_flat.size(),\n+                errors::InvalidArgument(\"Last value in input_splits must be \"\n+                                        \"equal to length of input_tensor.\"));\n     // Since we limit to a 2-D input (flat_values of rank 1 and a single splits\n     // tensor), our output dimension will be 1 with it's size equal to the\n     // number of splits (outer dimension or ragged tensor).\n@@ -548,6 +559,14 @@ class UnicodeEncodeOp : public OpKernel {\n     for (int i = 1; i < input_splits_flat.size(); ++i) {\n       icu::UnicodeString unicode_string;\n       icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);\n+      OP_REQUIRES(\n+          context, input_splits_flat(i - 1) <= input_splits_flat(i),\n+          errors::InvalidArgument(\n+              \"Values in input_splits must be equal or in ascending order.\"));\n+      OP_REQUIRES(\n+          context, input_splits_flat(i) <= input_tensor_flat.size(),\n+          errors::InvalidArgument(\"Values in input_splits must be less than or \"\n+                                  \"equal to input_tensor length.\"));\n       for (; idx < input_splits_flat(i); ++idx) {\n         int32 code_point = input_tensor_flat(idx);\n         // Check for invalid code point\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-59q2-x2qc-4c97",
    "API Signature": "tf.raw_ops.UnicodeEncode(\n    input_values,\n    input_splits,\n    output_encoding,\n    errors='replace',\n    replacement_char=65533,\n    name=None\n)\n",
    "Score": 0.010638297872340425,
    "Anomaly": "Non sparse input tensor",
    "Category": "Tensor",
    "Argument": "input_splits = tf.constant([[81, 101, 0]], shape=[3], dtype=tf.int32)"
  },
  {
    "Title": "\n        Heap OOB access in unicode ops\n      ",
    "Bug description": "An attacker can access data outside of bounds of heap allocated array in  tf.raw_ops.UnicodeEncode :",
    "Sample Code": "input_values = tf.constant([58], shape=[1], dtype=tf.int32)\ninput_splits = tf.constant([[81, 101, 0]], shape=[3], dtype=tf.int32)\noutput_encoding = \"UTF-8\"\n\ntf.raw_ops.UnicodeEncode(\n    input_values=input_values, input_splits=input_splits,\n    ,\n    output_encoding=output_encoding)",
    "Code change": [
      "@@ -533,6 +533,17 @@ class UnicodeEncodeOp : public OpKernel {\n     const Tensor& input_splits = context->input(1);\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n \n+    // Operation will treat first argument in input_splits as if it were zero\n+    // regardless of its actual value since splits should begin with zero and\n+    // end with the length of the input values vector.\n+    OP_REQUIRES(\n+        context, input_splits_flat(0) == 0,\n+        errors::InvalidArgument(\"First value in input_splits must be zero.\"));\n+    OP_REQUIRES(context,\n+                input_splits_flat(input_splits_flat.size() - 1) ==\n+                    input_tensor_flat.size(),\n+                errors::InvalidArgument(\"Last value in input_splits must be \"\n+                                        \"equal to length of input_tensor.\"));\n     // Since we limit to a 2-D input (flat_values of rank 1 and a single splits\n     // tensor), our output dimension will be 1 with it's size equal to the\n     // number of splits (outer dimension or ragged tensor).\n@@ -548,6 +559,14 @@ class UnicodeEncodeOp : public OpKernel {\n     for (int i = 1; i < input_splits_flat.size(); ++i) {\n       icu::UnicodeString unicode_string;\n       icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);\n+      OP_REQUIRES(\n+          context, input_splits_flat(i - 1) <= input_splits_flat(i),\n+          errors::InvalidArgument(\n+              \"Values in input_splits must be equal or in ascending order.\"));\n+      OP_REQUIRES(\n+          context, input_splits_flat(i) <= input_tensor_flat.size(),\n+          errors::InvalidArgument(\"Values in input_splits must be less than or \"\n+                                  \"equal to input_tensor length.\"));\n       for (; idx < input_splits_flat(i); ++idx) {\n         int32 code_point = input_tensor_flat(idx);\n         // Check for invalid code point\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-59q2-x2qc-4c97",
    "API Signature": "tf.raw_ops.UnicodeEncode(\n    input_values,\n    input_splits,\n    output_encoding,\n    errors='replace',\n    replacement_char=65533,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "input_values = tf.constant([58], shape=[1], dtype=tf.int32)\ninput_splits = tf.constant([[81, 101, 0]], shape=[3], dtype=tf.int32)"
  },
  {
    "Title": "\n        Heap buffer overflow in `SparseSplit`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow in  tf.raw_ops.SparseSplit :",
    "Sample Code": "shape_dims = tf.constant(0, dtype=tf.int64)\nindices = tf.ones([1, 1], dtype=tf.int64)\nvalues = tf.ones([1], dtype=tf.int64)\nshape = tf.ones([1], dtype=tf.int64)\n\ntf.raw_ops.SparseSplit(\n    split_dim=shape_dims, indices=indices, values=values,\n    ,\n    shape=shape, num_split=1)",
    "Code change": [
      "@@ -527,6 +527,10 @@ inline Status SparseTensor::Split(const SparseTensor& input_tensor,\n   for (int i = 0; i < input_tensor.indices().dim_size(0); ++i) {\n     const int dim = input_tensor.indices().matrix<int64>()(i, split_dim);\n     int slice_index = GetSliceIndex(dim, split_size, residual);\n+    if (slice_index >= num_values.size()) {\n+      return errors::InvalidArgument(\"Slice index \", slice_index,\n+                                     \" is larger than num_split.\");\n+    }\n     num_values[slice_index]++;\n   }\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mqh2-9wrp-vx84",
    "API Signature": "tf.raw_ops.SparseSplit(\n    split_dim, indices, values, shape, num_split, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "indices = tf.ones([1, 1], dtype=tf.int64\nnum_split=1"
  },
  {
    "Title": "\n        Division by 0 in `Reverse`\n      ",
    "Bug description": "An attacker can cause a denial of service via a FPE runtime error in  tf.raw_ops.Reverse :",
    "Sample Code": "tensor_input = tf.constant([], shape=[0, 1, 1], dtype=tf.int32)\ndims = tf.constant([False, True, False], shape=[3], dtype=tf.bool)\n\n)\n\ntf.raw_ops.Reverse(tensor=tensor_input, dims=dims)",
    "Code change": [
      "@@ -155,6 +155,12 @@ class ReverseOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n+    // If input is provided, check to make sure the first dimension is valid.\n+    if (input.dims() > 0) {\n+      OP_REQUIRES(\n+          context, input.dim_size(0) != 0,\n+          errors::InvalidArgument(\"Invalid input first dimension. Found 0.\"));\n+    }\n     const Tensor& dims = context->input(1);\n \n     if (TensorShapeUtils::IsScalar(input.shape())) {\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fxqh-cfjm-fp93",
    "API Signature": "tf.raw_ops.Reverse(\n    tensor, dims, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "tensor_input = tf.constant([], shape=[0, 1, 1], dtype=tf.int32)"
  },
  {
    "Title": "\n        Division by 0 in `SparseMatMul`\n      ",
    "Bug description": "An attacker can cause a denial of service via a FPE runtime error in  tf.raw_ops.SparseMatMul :",
    "Sample Code": "a = tf.constant([100.0, 100.0, 100.0, 100.0], shape=[2, 2], dtype=tf.float32)\nb = tf.constant([], shape=[0, 2], dtype=tf.float32)\n\ntf.raw_ops.SparseMatMul(\n    a=a, b=b, transpose_a=True, transpose_b=True,\n    ,\n    a_is_sparse=True, b_is_sparse=True)",
    "Code change": [
      "@@ -1039,6 +1039,10 @@ class SparseMatMulOp : public OpKernel {\n     if (transpose_b) {\n       // TODO(agarwal): avoid transposing the matrix here and directly handle\n       // transpose in CreateDenseSlices.\n+      OP_REQUIRES(ctx, right->dim_size(0) != 0,\n+                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n+      OP_REQUIRES(ctx, right->dim_size(1) != 0,\n+                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n       right_tr.reset(\n           new Tensor(right->dtype(),\n                      TensorShape({right->dim_size(1), right->dim_size(0)})));\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xw93-v57j-fcgh",
    "API Signature": "tf.raw_ops.SparseMatMul(\n    a,\n    b,\n    transpose_a=False,\n    transpose_b=False,\n    a_is_sparse=False,\n    b_is_sparse=False,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "b = tf.constant([], shape=[0, 2], dtype=tf.float32)"
  },
  {
    "Title": "\n        Division by 0 in `FusedBatchNorm`\n      ",
    "Bug description": "An attacker can cause a denial of service via a FPE runtime error in  tf.raw_ops.FusedBatchNorm :",
    "Sample Code": "x = tf.constant([], shape=[1, 1, 1, 0], dtype=tf.float32)\nscale = tf.constant([], shape=[0], dtype=tf.float32)\noffset = tf.constant([], shape=[0], dtype=tf.float32)\nmean = tf.constant([], shape=[0], dtype=tf.float32)\nvariance = tf.constant([], shape=[0], dtype=tf.float32)\nepsilon = 0.0\nexponential_avg_factor = 0.0\ndata_format = \"NHWC\"\nis_training = False\n\ntf.raw_ops.FusedBatchNorm(\n    x=x, scale=scale, offset=offset, mean=mean,\n    variance=variance, epsilon=epsilon,\n    exponential_avg_factor=exponential_avg_factor,\n    ,\n    data_format=data_format, is_training=is_training)",
    "Code change": [
      "@@ -293,6 +293,9 @@ struct FusedBatchNorm<CPUDevice, T, U, /* is_training= */ false> {\n     const CPUDevice& d = context->eigen_device<CPUDevice>();\n \n     const int depth = x.dimension(3);\n+    OP_REQUIRES(\n+        context, depth != 0,\n+        errors::Internal(\"The 4th element in the input shape cannot be 0.\"));\n     const int size = x.size();\n     const int rest_size = size / depth;\n     Eigen::DSizes<Eigen::Index, 2> rest_by_depth(rest_size, depth);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-r35g-4525-29fq",
    "API Signature": "tf.raw_ops.FusedBatchNorm(\n    x,\n    scale,\n    offset,\n    mean,\n    variance,\n    epsilon=0.0001,\n    exponential_avg_factor=1,\n    data_format='NHWC',\n    is_training=True,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "x = tf.constant([], shape=[1, 1, 1, 0], dtype=tf.float32)"
  },
  {
    "Title": "\n        Division by 0 in `DenseCountSparseOutput`\n      ",
    "Bug description": "An attacker can cause a denial of service via a FPE runtime error in  tf.raw_ops.DenseCountSparseOutput :",
    "Sample Code": "values = tf.constant([], shape=[0, 0], dtype=tf.int64)\nweights = tf.constant([])\n\ntf.raw_ops.DenseCountSparseOutput(\n  values=values, weights=weights,\n  ,\n  minlength=-1, maxlength=58, binary_output=True)",
    "Code change": [
      "@@ -122,6 +122,9 @@ class DenseCount : public OpKernel {\n \n     int num_batch_elements = 1;\n     for (int i = 0; i < num_batch_dimensions; ++i) {\n+      OP_REQUIRES(context, data.shape().dim_size(i) != 0,\n+                  errors::InvalidArgument(\n+                      \"Invalid input: Shapes dimension cannot be 0.\"));\n       num_batch_elements *= data.shape().dim_size(i);\n     }\n     int num_value_elements = data.shape().num_elements() / num_batch_elements;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qg48-85hg-mqc5",
    "API Signature": "tf.raw_ops.DenseCountSparseOutput(\n    values, weights, binary_output, minlength=-1, maxlength=-1, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "values = tf.constant([], shape=[0, 0], dtype=tf.int64)"
  },
  {
    "Title": "\n        `CHECK`-failure in `UnsortedSegmentJoin`\n      ",
    "Bug description": "An attacker can cause a denial of service by controlling the values of  num_segments  tensor argument for  UnsortedSegmentJoin :",
    "Sample Code": "inputs = tf.constant([], dtype=tf.string)\nsegment_ids = tf.constant([], dtype=tf.int32)\nnum_segments = tf.constant([], dtype=tf.int32)\nseparator = ''\n\ntf.raw_ops.UnsortedSegmentJoin(\n  inputs=inputs, segment_ids=segment_ids,\n  ,\n  num_segments=num_segments, separator=separator)",
    "Code change": [
      "@@ -90,6 +90,8 @@ class UnsortedSegmentJoinOp : public OpKernel {\n     const int32 segment_dims = segment_id_shape.dims();\n \n     const Tensor& num_segments_tensor = context->input(2);\n+    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,\n+                errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n     OP_REQUIRES(context, segment_dims != 0,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jhq9-wm9m-cf89",
    "API Signature": "tf.raw_ops.UnsortedSegmentJoin(\n    inputs, segment_ids, num_segments, separator='', name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "num_segments = tf.constant([], dtype=tf.int32)"
  },
  {
    "Title": "\n        Heap OOB in `QuantizeAndDequantizeV3`\n      ",
    "Bug description": "An attacker can read data outside of bounds of heap allocated buffer in  tf.raw_ops.QuantizeAndDequantizeV3 :",
    "Sample Code": "tf.raw_ops.QuantizeAndDequantizeV3(\n  input=[2.5,2.5], input_min=[0,0], input_max=[1,1], num_bits=[30],\n  ],\n  signed_input=False, range_given=False, narrow_range=False, axis=3)",
    "Code change": [
      "@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include \"tensorflow/core/framework/op_requires.h\"\n #define EIGEN_USE_THREADS\n \n #if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\n@@ -234,6 +235,10 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(ctx, axis_ < input.dims(),\n+                errors::InvalidArgument(\n+                    \"Axis requested is larger than input dimensions. Axis: \",\n+                    axis_, \" Input Dimensions: \", input.dims()));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h9px-9vqg-222h",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV3(\n    input,\n    input_min,\n    input_max,\n    num_bits,\n    signed_input=True,\n    range_given=True,\n    narrow_range=False,\n    axis=-1,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "input=[2.5,2.5] \naxis=3"
  },
  {
    "Title": "\n        OOB read in `MatrixTriangularSolve`\n      ",
    "Bug description": "The implementation of  MatrixTriangularSolve  fails to terminate kernel execution if one validation condition fails:",
    "Sample Code": "import numpy as np\n\nmatrix_array = np.array([])\nmatrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(1,0)),dtype=tf.float32)\nrhs_array = np.array([])\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(0,1)),dtype=tf.float32)\n\n)\n\ntf.raw_ops.MatrixTriangularSolve(matrix=matrix_tensor,rhs=rhs_tensor,lower=False,adjoint=False)",
    "Code change": [
      "@@ -162,6 +162,9 @@ class BaseMatrixTriangularSolveOp : public OpKernel {\n     const Tensor& in1 = ctx->input(1);\n \n     ValidateInputTensors(ctx, in0, in1);\n+    if (!ctx->status().ok()) {\n+      return;\n+    }\n \n     MatMulBCast bcast(in0.shape().dim_sizes(), in1.shape().dim_sizes());\n     OP_REQUIRES(\n@@ -230,13 +233,22 @@ class MatrixTriangularSolveOp\n  private:\n   void ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0,\n                             const Tensor& in1) override {\n+    const auto in0_num_dims = in0.dims();\n     OP_REQUIRES(\n-        ctx, in0.dims() >= 2,\n-        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\n+        ctx, in0_num_dims >= 2,\n+        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0_num_dims));\n \n+    const auto in1_num_dims = in1.dims();\n     OP_REQUIRES(\n-        ctx, in1.dims() >= 2,\n-        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in1.dims()));\n+        ctx, in1_num_dims >= 2,\n+        errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1_num_dims));\n+\n+    const auto in0_last_dim = in0.dim_size(in0_num_dims - 1);\n+    const auto in0_prev_dim = in0.dim_size(in0_num_dims - 2);\n+    OP_REQUIRES(ctx, in0_last_dim == in0_prev_dim,\n+                errors::InvalidArgument(\n+                    \"In[0] matrices in the last dimensions must be square (\",\n+                    in0_last_dim, \" =/= \", in0_prev_dim, \")\"));\n   }\n };\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vqw6-72r7-fgw7",
    "API Signature": "tf.raw_ops.MatrixTriangularSolve(\n    matrix, rhs, lower=True, adjoint=False, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Numpy array",
    "Argument": "matrix_array = np.array([])\nrhs_array = np.array([])"
  },
  {
    "Title": "\n        Division by 0 in `FractionalAvgPool`\n      ",
    "Bug description": "An attacker can cause a runtime division by zero error and denial of service in  tf.raw_ops.FractionalAvgPool :",
    "Sample Code": "value = tf.constant([60], shape=[1, 1, 1, 1], dtype=tf.int32)\npooling_ratio = [1.0, 1.0000014345305555, 1.0, 1.0]\npseudo_random = False\noverlapping = False\ndeterministic = False\nseed = 0\nseed2 = 0\n\ntf.raw_ops.FractionalAvgPool(\n  value=value, pooling_ratio=pooling_ratio, pseudo_random=pseudo_random,\n  ,\n  overlapping=overlapping, deterministic=deterministic, seed=seed, seed2=seed2)",
    "Code change": [
      "@@ -80,6 +80,10 @@ class FractionalAvgPoolOp : public OpKernel {\n     std::vector<int> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n       input_size[i] = tensor_in.dim_size(i);\n+      OP_REQUIRES(\n+          context, pooling_ratio_[i] <= input_size[i],\n+          errors::InvalidArgument(\n+              \"Pooling ratio cannot be bigger than input tensor dim size.\"));\n     }\n     // Output size.\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-f78g-q7r4-9wcv",
    "API Signature": "tf.raw_ops.FractionalAvgPool(\n    value,\n    pooling_ratio,\n    pseudo_random=False,\n    overlapping=False,\n    deterministic=False,\n    seed=0,\n    seed2=0,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "value = tf.constant([60], shape=[1, 1, 1, 1], dtype=tf.int32)\npooling_ratio = [1.0, 1.0000014345305555, 1.0, 1.0]"
  },
  {
    "Title": "\n        Division by 0 in `QuantizedAdd`\n      ",
    "Bug description": "An attacker can cause a runtime division by zero error and denial of service in  tf.raw_ops.QuantizedAdd :",
    "Sample Code": "x = tf.constant([68, 228], shape=[2, 1], dtype=tf.quint8)\ny = tf.constant([], shape=[2, 0], dtype=tf.quint8)\n\nmin_x = tf.constant(10.723421015884028)\nmax_x = tf.constant(15.19578006631113)\nmin_y = tf.constant(-5.539003866682977)\nmax_y = tf.constant(42.18819949559947)\n\n)\n\ntf.raw_ops.QuantizedAdd(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y)",
    "Code change": [
      "@@ -538,6 +538,8 @@ class QuantizedAddOp : public OpKernel {\n         tensor_min = min_x;\n         tensor_max = max_x;\n       }\n+      OP_REQUIRES(context, vector_num_elements > 0,\n+                  errors::InvalidArgument(\"Must have some elements to add\"));\n       VectorTensorAddition<T, Toutput>(\n           vector_data, vector_min, vector_max, vector_num_elements, tensor_data,\n           tensor_min, tensor_max, tensor_num_elements, min_z_value, max_z_value,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x83m-p7pv-ch8v",
    "API Signature": "tf.raw_ops.QuantizedAdd(\n    x,\n    y,\n    min_x,\n    max_x,\n    min_y,\n    max_y,\n    Toutput=tf.dtypes.qint32,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "y = tf.constant([], shape=[2, 0], dtype=tf.quint8)"
  },
  {
    "Title": "\n        Division by 0 in `QuantizedBatchNormWithGlobalNormalization`\n      ",
    "Bug description": "An attacker can cause a runtime division by zero error and denial of service in  tf.raw_ops.QuantizedBatchNormWithGlobalNormalization :",
    "Sample Code": "t = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.quint8)\nt_min = tf.constant(-10.0, dtype=tf.float32)\nt_max = tf.constant(-10.0, dtype=tf.float32)\nm = tf.constant([], shape=[0], dtype=tf.quint8)\nm_min = tf.constant(-10.0, dtype=tf.float32)\nm_max = tf.constant(-10.0, dtype=tf.float32)\nv = tf.constant([], shape=[0], dtype=tf.quint8)\nv_min = tf.constant(-10.0, dtype=tf.float32)\nv_max = tf.constant(-10.0, dtype=tf.float32)\nbeta = tf.constant([], shape=[0], dtype=tf.quint8)\nbeta_min = tf.constant(-10.0, dtype=tf.float32)\nbeta_max = tf.constant(-10.0, dtype=tf.float32)\ngamma = tf.constant([], shape=[0], dtype=tf.quint8)\ngamma_min = tf.constant(-10.0, dtype=tf.float32)\ngamma_max = tf.constant(-10.0, dtype=tf.float32)\n\ntf.raw_ops.QuantizedBatchNormWithGlobalNormalization(\n  t=t, t_min=t_min, t_max=t_max, m=m, m_min=m_min, m_max=m_max,\n  v=v, v_min=v_min, v_max=v_max, beta=beta, beta_min=beta_min,\n  beta_max=beta_max, gamma=gamma, gamma_min=gamma_min,\n  gamma_max=gamma_max, out_type=tf.qint32,\n  ,\n  variance_epsilon=0.1, scale_after_normalization=True)",
    "Code change": [
      "@@ -173,20 +173,50 @@ class QuantizedBatchNormOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float input_min = context->input(1).flat<float>()(0);\n-    const float input_max = context->input(2).flat<float>()(0);\n+    const auto& input_min_tensor = context->input(1);\n+    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_min must have 1 element\"));\n+    const float input_min = input_min_tensor.flat<float>()(0);\n+    const auto& input_max_tensor = context->input(2);\n+    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_max must have 1 element\"));\n+    const float input_max = input_max_tensor.flat<float>()(0);\n     const Tensor& mean = context->input(3);\n-    const float mean_min = context->input(4).flat<float>()(0);\n-    const float mean_max = context->input(5).flat<float>()(0);\n+    const auto& mean_min_tensor = context->input(4);\n+    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_min must have 1 element\"));\n+    const float mean_min = mean_min_tensor.flat<float>()(0);\n+    const auto& mean_max_tensor = context->input(5);\n+    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_max must have 1 element\"));\n+    const float mean_max = mean_max_tensor.flat<float>()(0);\n     const Tensor& var = context->input(6);\n-    const float var_min = context->input(7).flat<float>()(0);\n-    const float var_max = context->input(8).flat<float>()(0);\n+    const auto& var_min_tensor = context->input(7);\n+    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_min must have 1 element\"));\n+    const float var_min = var_min_tensor.flat<float>()(0);\n+    const auto& var_max_tensor = context->input(8);\n+    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_max must have 1 element\"));\n+    const float var_max = var_max_tensor.flat<float>()(0);\n     const Tensor& beta = context->input(9);\n-    const float beta_min = context->input(10).flat<float>()(0);\n-    const float beta_max = context->input(11).flat<float>()(0);\n+    const auto& beta_min_tensor = context->input(10);\n+    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_min must have 1 element\"));\n+    const float beta_min = beta_min_tensor.flat<float>()(0);\n+    const auto& beta_max_tensor = context->input(11);\n+    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_max must have 1 element\"));\n+    const float beta_max = beta_max_tensor.flat<float>()(0);\n     const Tensor& gamma = context->input(12);\n-    const float gamma_min = context->input(13).flat<float>()(0);\n-    const float gamma_max = context->input(14).flat<float>()(0);\n+    const auto& gamma_min_tensor = context->input(13);\n+    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_min must have 1 element\"));\n+    const float gamma_min = gamma_min_tensor.flat<float>()(0);\n+    const auto& gamma_max_tensor = context->input(14);\n+    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_max must have 1 element\"));\n+    const float gamma_max = gamma_max_tensor.flat<float>()(0);\n \n     OP_REQUIRES(context, input.dims() == 4,\n                 errors::InvalidArgument(\"input must be 4-dimensional\",\n@@ -203,6 +233,33 @@ class QuantizedBatchNormOp : public OpKernel {\n     OP_REQUIRES(context, gamma.dims() == 1,\n                 errors::InvalidArgument(\"gamma must be 1-dimensional\",\n                                         gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\",\n+                                        gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\"));\n+    const auto last_dim = input.shape().dims() - 1;\n+    OP_REQUIRES(context,\n+                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\n+                errors::InvalidArgument(\"Must provide as many means as the \"\n+                                        \"last dimension of the input tensor: \",\n+                                        mean.shape().DebugString(), \" vs. \",\n+                                        input.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and variance tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and beta tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and gamma tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-p45v-v4pw-77jr",
    "API Signature": "tf.raw_ops.QuantizedBatchNormWithGlobalNormalization(\n    t,\n    t_min,\n    t_max,\n    m,\n    m_min,\n    m_max,\n    v,\n    v_min,\n    v_max,\n    beta,\n    beta_min,\n    beta_max,\n    gamma,\n    gamma_min,\n    gamma_max,\n    out_type,\n    variance_epsilon,\n    scale_after_normalization,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "t = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.quint8)\nm = tf.constant([], shape=[0], dtype=tf.quint8)\nv = tf.constant([], shape=[0], dtype=tf.quint8)\nbeta = tf.constant([], shape=[0], dtype=tf.quint8)\ngamma = tf.constant([], shape=[0], dtype=tf.quint8)"
  },
  {
    "Title": "\n        Division by 0 in `QuantizedBatchNormWithGlobalNormalization`\n      ",
    "Bug description": "An attacker can cause a runtime division by zero error and denial of service in  tf.raw_ops.QuantizedBatchNormWithGlobalNormalization :",
    "Sample Code": "t = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.quint8)\nt_min = tf.constant(-10.0, dtype=tf.float32)\nt_max = tf.constant(-10.0, dtype=tf.float32)\nm = tf.constant([], shape=[0], dtype=tf.quint8)\nm_min = tf.constant(-10.0, dtype=tf.float32)\nm_max = tf.constant(-10.0, dtype=tf.float32)\nv = tf.constant([], shape=[0], dtype=tf.quint8)\nv_min = tf.constant(-10.0, dtype=tf.float32)\nv_max = tf.constant(-10.0, dtype=tf.float32)\nbeta = tf.constant([], shape=[0], dtype=tf.quint8)\nbeta_min = tf.constant(-10.0, dtype=tf.float32)\nbeta_max = tf.constant(-10.0, dtype=tf.float32)\ngamma = tf.constant([], shape=[0], dtype=tf.quint8)\ngamma_min = tf.constant(-10.0, dtype=tf.float32)\ngamma_max = tf.constant(-10.0, dtype=tf.float32)\n\ntf.raw_ops.QuantizedBatchNormWithGlobalNormalization(\n  t=t, t_min=t_min, t_max=t_max, m=m, m_min=m_min, m_max=m_max,\n  v=v, v_min=v_min, v_max=v_max, beta=beta, beta_min=beta_min,\n  beta_max=beta_max, gamma=gamma, gamma_min=gamma_min,\n  gamma_max=gamma_max, out_type=tf.qint32,\n  ,\n  variance_epsilon=0.1, scale_after_normalization=True)",
    "Code change": [
      "@@ -173,20 +173,50 @@ class QuantizedBatchNormOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float input_min = context->input(1).flat<float>()(0);\n-    const float input_max = context->input(2).flat<float>()(0);\n+    const auto& input_min_tensor = context->input(1);\n+    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_min must have 1 element\"));\n+    const float input_min = input_min_tensor.flat<float>()(0);\n+    const auto& input_max_tensor = context->input(2);\n+    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_max must have 1 element\"));\n+    const float input_max = input_max_tensor.flat<float>()(0);\n     const Tensor& mean = context->input(3);\n-    const float mean_min = context->input(4).flat<float>()(0);\n-    const float mean_max = context->input(5).flat<float>()(0);\n+    const auto& mean_min_tensor = context->input(4);\n+    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_min must have 1 element\"));\n+    const float mean_min = mean_min_tensor.flat<float>()(0);\n+    const auto& mean_max_tensor = context->input(5);\n+    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_max must have 1 element\"));\n+    const float mean_max = mean_max_tensor.flat<float>()(0);\n     const Tensor& var = context->input(6);\n-    const float var_min = context->input(7).flat<float>()(0);\n-    const float var_max = context->input(8).flat<float>()(0);\n+    const auto& var_min_tensor = context->input(7);\n+    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_min must have 1 element\"));\n+    const float var_min = var_min_tensor.flat<float>()(0);\n+    const auto& var_max_tensor = context->input(8);\n+    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_max must have 1 element\"));\n+    const float var_max = var_max_tensor.flat<float>()(0);\n     const Tensor& beta = context->input(9);\n-    const float beta_min = context->input(10).flat<float>()(0);\n-    const float beta_max = context->input(11).flat<float>()(0);\n+    const auto& beta_min_tensor = context->input(10);\n+    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_min must have 1 element\"));\n+    const float beta_min = beta_min_tensor.flat<float>()(0);\n+    const auto& beta_max_tensor = context->input(11);\n+    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_max must have 1 element\"));\n+    const float beta_max = beta_max_tensor.flat<float>()(0);\n     const Tensor& gamma = context->input(12);\n-    const float gamma_min = context->input(13).flat<float>()(0);\n-    const float gamma_max = context->input(14).flat<float>()(0);\n+    const auto& gamma_min_tensor = context->input(13);\n+    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_min must have 1 element\"));\n+    const float gamma_min = gamma_min_tensor.flat<float>()(0);\n+    const auto& gamma_max_tensor = context->input(14);\n+    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_max must have 1 element\"));\n+    const float gamma_max = gamma_max_tensor.flat<float>()(0);\n \n     OP_REQUIRES(context, input.dims() == 4,\n                 errors::InvalidArgument(\"input must be 4-dimensional\",\n@@ -203,6 +233,33 @@ class QuantizedBatchNormOp : public OpKernel {\n     OP_REQUIRES(context, gamma.dims() == 1,\n                 errors::InvalidArgument(\"gamma must be 1-dimensional\",\n                                         gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\",\n+                                        gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\"));\n+    const auto last_dim = input.shape().dims() - 1;\n+    OP_REQUIRES(context,\n+                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\n+                errors::InvalidArgument(\"Must provide as many means as the \"\n+                                        \"last dimension of the input tensor: \",\n+                                        mean.shape().DebugString(), \" vs. \",\n+                                        input.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and variance tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and beta tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and gamma tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-p45v-v4pw-77jr",
    "API Signature": "tf.raw_ops.QuantizedBatchNormWithGlobalNormalization(\n    t,\n    t_min,\n    t_max,\n    m,\n    m_min,\n    m_max,\n    v,\n    v_min,\n    v_max,\n    beta,\n    beta_min,\n    beta_max,\n    gamma,\n    gamma_min,\n    gamma_max,\n    out_type,\n    variance_epsilon,\n    scale_after_normalization,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "m = tf.constant([], shape=[0], dtype=tf.quint8)\nv = tf.constant([], shape=[0], dtype=tf.quint8)\nbeta = tf.constant([], shape=[0], dtype=tf.quint8)\ngamma = tf.constant([], shape=[0], dtype=tf.quint8)"
  },
  {
    "Title": "\n        Division by 0 in `QuantizedBiasAdd`\n      ",
    "Bug description": "An attacker can trigger an integer division by zero undefined behavior in  tf.raw_ops.QuantizedBiasAdd :",
    "Sample Code": "input_tensor = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.quint8)\nbias = tf.constant([], shape=[0], dtype=tf.quint8)\nmin_input = tf.constant(-10.0, dtype=tf.float32)\nmax_input = tf.constant(-10.0, dtype=tf.float32)\nmin_bias = tf.constant(-10.0, dtype=tf.float32)\nmax_bias = tf.constant(-10.0, dtype=tf.float32)\n\ntf.raw_ops.QuantizedBiasAdd(input=input_tensor, bias=bias, min_input=min_input,\n                            max_input=max_input, min_bias=min_bias,\n                            ,\n                            max_bias=max_bias, out_type=tf.qint32)",
    "Code change": [
      "@@ -56,6 +56,8 @@ class QuantizedBiasAddOp : public OpKernel {\n             \"Must provide as many biases as the last dimension \"\n             \"of the input tensor: \",\n             bias.shape().DebugString(), \" vs. \", input.shape().DebugString()));\n+    OP_REQUIRES(context, bias.NumElements() > 0,\n+                errors::InvalidArgument(\"Must provide at least 1 bias\"));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m34j-p8rj-wjxq",
    "API Signature": "tf.raw_ops.QuantizedBiasAdd(\n    input, bias, min_input, max_input, min_bias, max_bias, out_type, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "bias = tf.constant([], shape=[0], dtype=tf.quint8)"
  },
  {
    "Title": "\n        `CHECK`-fail in `CTCGreedyDecoder`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in  tf.raw_ops.CTCGreedyDecoder :",
    "Sample Code": "inputs = tf.constant([], shape=[18, 2, 0], dtype=tf.float32)\nsequence_length = tf.constant([-100, 17], shape=[2], dtype=tf.int32)\nmerge_repeated = False\n\n\n\ntf.raw_ops.CTCGreedyDecoder(inputs=inputs, sequence_length=sequence_length, merge_repeated=merge_repeated)",
    "Code change": [
      "@@ -232,6 +232,8 @@ class CTCGreedyDecoderOp : public OpKernel {\n         int prev_indices = -1;\n         for (int t = 0; t < seq_len_t(b); ++t) {\n           int max_class_indices;\n+          OP_REQUIRES(ctx, input_list_t[t].dimension(1) > 0,\n+                      errors::InvalidArgument(\"Invalid input dimensions.\"));\n           log_prob_t(b, 0) +=\n               -RowMax<T>(input_list_t[t], b, &max_class_indices);\n           if (max_class_indices != blank_index &&\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fphq-gw9m-ghrv",
    "API Signature": "tf.raw_ops.CTCGreedyDecoder(\n    inputs, sequence_length, merge_repeated=False, blank_index=-1, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "inputs = tf.constant([], shape=[18, 2, 0], dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK`-fail in `QuantizeAndDequantizeV4Grad`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in  tf.raw_ops.QuantizeAndDequantizeV4Grad :",
    "Sample Code": "gradient_tensor = tf.constant([0.0], shape=[1])\ninput_tensor = tf.constant([0.0], shape=[1])\ninput_min = tf.constant([[0.0]], shape=[1, 1])\ninput_max = tf.constant([[0.0]], shape=[1, 1])\n\ntf.raw_ops.QuantizeAndDequantizeV4Grad(\n  gradients=gradient_tensor, input=input_tensor,\n  ,\n  input_min=input_min, input_max=input_max, axis=0)",
    "Code change": [
      "@@ -160,7 +160,17 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n         errors::InvalidArgument(\"gradient and input must be the same size\"));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     const Tensor& input_min_tensor = ctx->input(2);\n+    OP_REQUIRES(ctx,\n+                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n+                errors::InvalidArgument(\n+                    \"Input min tensor must have dimension 1. Recieved \",\n+                    input_min_tensor.dims(), \".\"));\n     const Tensor& input_max_tensor = ctx->input(3);\n+    OP_REQUIRES(ctx,\n+                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n+                errors::InvalidArgument(\n+                    \"Input max tensor must have dimension 1. Recieved \",\n+                    input_max_tensor.dims(), \".\"));\n     if (axis_ != -1) {\n       OP_REQUIRES(\n           ctx, input_min_tensor.dim_size(0) == depth,\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6g85-3hm8-83f9",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n    gradients, input, input_min, input_max, axis=-1, name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "input_min = tf.constant([[0.0]], shape=[1, 1])\ninput_max = tf.constant([[0.0]], shape=[1, 1])"
  },
  {
    "Title": "\n        Heap buffer overflow in `Conv2DBackpropFilter`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow to occur in  Conv2DBackpropFilter :",
    "Sample Code": "input_tensor = tf.constant([], shape=[0, 1, 1, 5], dtype=tf.float32)\nfilter_sizes = tf.constant([3, 8, 1, 1], shape=[4], dtype=tf.int32)\nout_backprop = tf.constant([], shape=[0, 1, 1, 1], dtype=tf.float32)\n\ntf.raw_ops.Conv2DBackpropFilter(\n  input=input_tensor,\n  filter_sizes=filter_sizes, \n  out_backprop=out_backprop,\n  strides=[1, 66, 49, 1], \n  use_cudnn_on_gpu=True,\n  padding='VALID',\n  explicit_paddings=[],\n  data_format='NHWC',\n  dilations=[1, 1, 1, 1]\n)]\n)",
    "Code change": [
      "@@ -495,6 +495,14 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n     const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                   dims.spatial_dims[1].filter_size *\n                                   dims.in_depth;\n+    OP_REQUIRES(\n+        context,\n+        filter_total_size * dims.out_depth == filter_backprop->NumElements(),\n+        errors::InvalidArgument(\n+            \"filter_size does not have enough elements, requested \",\n+            filter_total_size * dims.out_depth, \", got \",\n+            filter_backprop->NumElements()));\n+\n     // The output image size is the spatial size of the output.\n     const int output_image_size =\n         dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n@@ -518,6 +526,11 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n \n     const size_t work_unit_size = size_A + size_B + size_C;\n \n+    OP_REQUIRES(\n+        context, work_unit_size != 0,\n+        errors::InvalidArgument(\n+            \"Work size for convolution would be 0, which is not acceptable\"));\n+\n     const size_t shard_size =\n         (target_working_set_size + work_unit_size - 1) / work_unit_size;\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xgc3-m89p-vr3x",
    "API Signature": "tf.raw_ops.Conv2DBackpropFilter(\n    input,\n    filter_sizes,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "input_tensor = tf.constant([386.078431372549, 386.07843139643234], shape=[1, 1, 1, 2], dtype=tf.float32)\nfilter_sizes = tf.constant([1, 1, 1, 1], shape=[4], dtype=tf.int32)"
  },
  {
    "Title": "\n        Heap buffer overflow in `Conv2DBackpropFilter`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow to occur in  Conv2DBackpropFilter :",
    "Sample Code": "input_tensor = tf.constant([], shape=[0, 1, 1, 5], dtype=tf.float32)\nfilter_sizes = tf.constant([3, 8, 1, 1], shape=[4], dtype=tf.int32)\nout_backprop = tf.constant([], shape=[0, 1, 1, 1], dtype=tf.float32)\n\ntf.raw_ops.Conv2DBackpropFilter(\n  input=input_tensor,\n  filter_sizes=filter_sizes, \n  out_backprop=out_backprop,\n  strides=[1, 66, 49, 1], \n  use_cudnn_on_gpu=True,\n  padding='VALID',\n  explicit_paddings=[],\n  data_format='NHWC',\n  dilations=[1, 1, 1, 1]\n)]\n)",
    "Code change": [
      "@@ -495,6 +495,14 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n     const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                   dims.spatial_dims[1].filter_size *\n                                   dims.in_depth;\n+    OP_REQUIRES(\n+        context,\n+        filter_total_size * dims.out_depth == filter_backprop->NumElements(),\n+        errors::InvalidArgument(\n+            \"filter_size does not have enough elements, requested \",\n+            filter_total_size * dims.out_depth, \", got \",\n+            filter_backprop->NumElements()));\n+\n     // The output image size is the spatial size of the output.\n     const int output_image_size =\n         dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n@@ -518,6 +526,11 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n \n     const size_t work_unit_size = size_A + size_B + size_C;\n \n+    OP_REQUIRES(\n+        context, work_unit_size != 0,\n+        errors::InvalidArgument(\n+            \"Work size for convolution would be 0, which is not acceptable\"));\n+\n     const size_t shard_size =\n         (target_working_set_size + work_unit_size - 1) / work_unit_size;\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xgc3-m89p-vr3x",
    "API Signature": "tf.raw_ops.Conv2DBackpropFilter(\n    input,\n    filter_sizes,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "input_tensor = tf.constant([], shape=[0, 1, 1, 5], dtype=tf.float32)"
  },
  {
    "Title": "\n        Heap buffer overflow in `QuantizedReshape`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow in  QuantizedReshape  by passing in invalid thresholds for the quantization:",
    "Sample Code": "tensor = tf.constant([], dtype=tf.qint32)\nshape = tf.constant([], dtype=tf.int32)\ninput_min = tf.constant([], dtype=tf.float32)\ninput_max = tf.constant([], dtype=tf.float32)\n\n)\n\ntf.raw_ops.QuantizedReshape(tensor=tensor, shape=shape, input_min=input_min, input_max=input_max)",
    "Code change": [
      "@@ -17,6 +17,7 @@ limitations under the License.\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/tensor_types.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/reshape_op.h\"\n@@ -30,9 +31,29 @@ class QuantizedReshapeOp : public ReshapeOp {\n   void Compute(OpKernelContext* ctx) override {\n     // This call processes inputs 1 and 2 to write output 0.\n     ReshapeOp::Compute(ctx);\n+    if (!ctx->status().ok()) {\n+      return;\n+    }\n+\n+    const auto& input_min_float_tensor = ctx->input(2);\n+    const auto& input_min_float_shape = input_min_float_tensor.shape();\n+    OP_REQUIRES(ctx,\n+                TensorShapeUtils::IsScalar(input_min_float_shape) ||\n+                    (TensorShapeUtils::IsVector(input_min_float_shape) &&\n+                     (input_min_float_shape.dim_size(0) == 1)),\n+                errors::InvalidArgument(\n+                    \"input_min must be a scalar or a vector of 1 element\"));\n+    const float input_min_float = input_min_float_tensor.flat<float>()(0);\n+    const auto& input_max_float_tensor = ctx->input(3);\n+    const auto& input_max_float_shape = input_max_float_tensor.shape();\n+    OP_REQUIRES(ctx,\n+                TensorShapeUtils::IsScalar(input_max_float_shape) ||\n+                    (TensorShapeUtils::IsVector(input_max_float_shape) &&\n+                     (input_max_float_shape.dim_size(0) == 1)),\n+                errors::InvalidArgument(\n+                    \"input_max must be a scalar or a vector of 1 element\"));\n+    const float input_max_float = input_max_float_tensor.flat<float>()(0);\n \n-    const float input_min_float = ctx->input(2).flat<float>()(0);\n-    const float input_max_float = ctx->input(3).flat<float>()(0);\n     Tensor* output_min = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));\n     output_min->flat<float>()(0) = input_min_float;\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2gfx-95x2-5v3x",
    "API Signature": "tf.raw_ops.QuantizedReshape(\n    tensor, shape, input_min, input_max, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "tensor = tf.constant([], dtype=tf.qint32)\nshape = tf.constant([], dtype=tf.int32)\ninput_min = tf.constant([], dtype=tf.float32)\ninput_max = tf.constant([], dtype=tf.float32)"
  },
  {
    "Title": "\n        Heap buffer overflow in `QuantizedResizeBilinear`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow in  QuantizedResizeBilinear  by passing in invalid thresholds for the quantization:",
    "Sample Code": "images = tf.constant([], shape=[0], dtype=tf.qint32)\nsize = tf.constant([], shape=[0], dtype=tf.int32) \nmin = tf.constant([], dtype=tf.float32)\nmax = tf.constant([], dtype=tf.float32)\n\n)\n\ntf.raw_ops.QuantizedResizeBilinear(images=images, size=size, min=min, max=max, align_corners=False, half_pixel_centers=False)",
    "Code change": [
      "@@ -702,8 +702,14 @@ class QuantizedResizeBilinearOp : public OpKernel {\n   }\n \n   void Compute(OpKernelContext* context) override {\n-    const float in_min = context->input(2).flat<float>()(0);\n-    const float in_max = context->input(3).flat<float>()(0);\n+    const auto& in_min_tensor = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(in_min_tensor.shape()),\n+                errors::InvalidArgument(\"min must be a scalar\"));\n+    const float in_min = in_min_tensor.flat<float>()(0);\n+    const auto& in_max_tensor = context->input(3);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(in_max_tensor.shape()),\n+                errors::InvalidArgument(\"max must be a scalar\"));\n+    const float in_max = in_max_tensor.flat<float>()(0);\n \n     ImageResizerState st(align_corners_, false);\n     st.ValidateAndCreateOutput(context);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-8c89-2vwr-chcq",
    "API Signature": "tf.raw_ops.QuantizedResizeBilinear(\n    images,\n    size,\n    min,\n    max,\n    align_corners=False,\n    half_pixel_centers=False,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "images = tf.constant([], shape=[0], dtype=tf.qint32)\nsize = tf.constant([], shape=[0], dtype=tf.int32) \nmin = tf.constant([], dtype=tf.float32)\nmax = tf.constant([], dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK`-fail in `SparseConcat`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in  tf.raw_ops.SparseConcat :",
    "Sample Code": "import numpy as np\n\nindices_1 = tf.constant([[514, 514], [514, 514]], dtype=tf.int64)\nindices_2 = tf.constant([[514, 530], [599, 877]], dtype=tf.int64)\nindices = [indices_1, indices_2]\n\nvalues_1 = tf.zeros([0], dtype=tf.int64)\nvalues_2 = tf.zeros([0], dtype=tf.int64)\nvalues = [values_1, values_2]\n\nshape_1 = tf.constant([442, 514, 514, 515, 606, 347, 943, 61, 2], dtype=tf.int64)\nshape_2 = tf.zeros([9], dtype=tf.int64)\nshapes = [shape_1, shape_2]\n\n]\n\ntf.raw_ops.SparseConcat(indices=indices, values=values, shapes=shapes, concat_dim=2)",
    "Code change": [
      "@@ -21,9 +21,6 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n-#include \"tensorflow/core/framework/op_kernel.h\"\n-#include \"tensorflow/core/framework/register_types.h\"\n-\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/resource_mgr.h\"\n@@ -31,6 +28,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n #include \"tensorflow/core/util/sparse/sparse_tensor.h\"\n \n namespace tensorflow {\n@@ -254,7 +252,22 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n         errors::InvalidArgument(\n             \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n \n-    TensorShape tensor_input_shape(input_shape->vec<int64>());\n+    auto input_shape_vec = input_shape->vec<int64>();\n+    int new_num_elements = 1;\n+    bool overflow_ocurred = false;\n+    for (int i = 0; i < input_shape_vec.size(); i++) {\n+      new_num_elements =\n+          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n+      if (new_num_elements < 0) {\n+        overflow_ocurred = true;\n+      }\n+    }\n+\n+    OP_REQUIRES(\n+        context, !overflow_ocurred,\n+        errors::Internal(\"Encountered overflow from large input shape.\"));\n+\n+    TensorShape tensor_input_shape(input_shape_vec);\n     gtl::InlinedVector<int64, 8> std_order(rank);\n     std::iota(std_order.begin(), std_order.end(), 0);\n     SparseTensor input_st;\n@@ -262,8 +275,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n                                                  tensor_input_shape, std_order,\n                                                  &input_st));\n \n-    auto input_shape_t = input_shape->vec<int64>();\n-    const int64 N = input_shape_t(0);\n+    const int64 N = input_shape_vec(0);\n \n     Tensor sparse_handles(DT_INT64, TensorShape({N}));\n     auto sparse_handles_t = sparse_handles.vec<int64>();\n@@ -274,7 +286,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n     // minibatch entries.\n     TensorShape output_shape;\n     OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n-                                input_shape_t.data() + 1,\n+                                input_shape_vec.data() + 1,\n                                 input_shape->NumElements() - 1, &output_shape));\n \n     // Get groups by minibatch dimension\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6j9c-grc6-5m6g",
    "API Signature": "tf.raw_ops.SparseConcat(\n    indices, values, shapes, concat_dim, name=None\n)\n",
    "Score": 0.014184397163120567,
    "Anomaly": "Large input tensor",
    "Category": "Tensor",
    "Argument": "shape_1 = tf.constant([442, 514, 514, 515, 606, 347, 943, 61, 2], dtype=tf.int64)"
  },
  {
    "Title": "\n        Heap buffer overflow in `QuantizedMul`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow in  QuantizedMul  by passing in invalid thresholds for the quantization:",
    "Sample Code": "x = tf.constant([256, 328], shape=[1, 2], dtype=tf.quint8)\ny = tf.constant([256, 328], shape=[1, 2], dtype=tf.quint8)\nmin_x = tf.constant([], dtype=tf.float32)\nmax_x = tf.constant([], dtype=tf.float32)\nmin_y = tf.constant([], dtype=tf.float32)\nmax_y = tf.constant([], dtype=tf.float32)\n\n)\n\ntf.raw_ops.QuantizedMul(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y)",
    "Code change": [
      "@@ -284,10 +284,22 @@ class QuantizedMulOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& x = context->input(0);\n     const Tensor& y = context->input(1);\n-    const float min_x = context->input(2).flat<float>()(0);\n-    const float max_x = context->input(3).flat<float>()(0);\n-    const float min_y = context->input(4).flat<float>()(0);\n-    const float max_y = context->input(5).flat<float>()(0);\n+    auto& min_x_tensor = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),\n+                errors::InvalidArgument(\"min_x must be a scalar\"));\n+    const float min_x = min_x_tensor.flat<float>()(0);\n+    auto& max_x_tensor = context->input(3);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),\n+                errors::InvalidArgument(\"max_x must be a scalar\"));\n+    const float max_x = max_x_tensor.flat<float>()(0);\n+    auto& min_y_tensor = context->input(4);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),\n+                errors::InvalidArgument(\"min_y must be a scalar\"));\n+    const float min_y = min_y_tensor.flat<float>()(0);\n+    auto& max_y_tensor = context->input(5);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),\n+                errors::InvalidArgument(\"max_y must be a scalar\"));\n+    const float max_y = max_y_tensor.flat<float>()(0);\n \n     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n     if (!bcast.IsValid()) {\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m3f9-w3p3-p669",
    "API Signature": "tf.raw_ops.QuantizedMul(\n    x,\n    y,\n    min_x,\n    max_x,\n    min_y,\n    max_y,\n    Toutput=tf.dtypes.qint32,\n    name=None\n)\n",
    "Score": 0.07446808510638298,
    "Anomaly": "Non scalar input tensor",
    "Category": "Tensor",
    "Argument": "min_x = tf.constant([], dtype=tf.float32)\nmax_x = tf.constant([], dtype=tf.float32)\nmin_y = tf.constant([], dtype=tf.float32)\nmax_y = tf.constant([], dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK`-fail in `DrawBoundingBoxes`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK  failure by passing an empty image to  tf.raw_ops.DrawBoundingBoxes :",
    "Sample Code": "images = tf.fill([53, 0, 48, 1], 0.)\nboxes = tf.fill([53, 31, 4], 0.)\nboxes = tf.Variable(boxes)\nboxes[0, 0, 0].assign(3.90621)\n)\ntf.raw_ops.DrawBoundingBoxes(images=images, boxes=boxes)",
    "Code change": [
      "@@ -147,22 +147,46 @@ class DrawBoundingBoxesOp : public OpKernel {\n \n         // At this point, {min,max}_box_{row,col}_clamp are inside the\n         // image.\n-        CHECK_GE(min_box_row_clamp, 0);\n-        CHECK_GE(max_box_row_clamp, 0);\n-        CHECK_LT(min_box_row_clamp, height);\n-        CHECK_LT(max_box_row_clamp, height);\n-        CHECK_GE(min_box_col_clamp, 0);\n-        CHECK_GE(max_box_col_clamp, 0);\n-        CHECK_LT(min_box_col_clamp, width);\n-        CHECK_LT(max_box_col_clamp, width);\n+        OP_REQUIRES(\n+            context, min_box_row_clamp >= 0,\n+            errors::InvalidArgument(\"Min box row clamp is less than 0.\"));\n+        OP_REQUIRES(\n+            context, max_box_row_clamp >= 0,\n+            errors::InvalidArgument(\"Max box row clamp is less than 0.\"));\n+        OP_REQUIRES(context, min_box_row_clamp <= height,\n+                    errors::InvalidArgument(\n+                        \"Min box row clamp is greater than height.\"));\n+        OP_REQUIRES(context, max_box_row_clamp <= height,\n+                    errors::InvalidArgument(\n+                        \"Max box row clamp is greater than height.\"));\n+\n+        OP_REQUIRES(\n+            context, min_box_col_clamp >= 0,\n+            errors::InvalidArgument(\"Min box col clamp is less than 0.\"));\n+        OP_REQUIRES(\n+            context, max_box_col_clamp >= 0,\n+            errors::InvalidArgument(\"Max box col clamp is less than 0.\"));\n+        OP_REQUIRES(context, min_box_col_clamp <= width,\n+                    errors::InvalidArgument(\n+                        \"Min box col clamp is greater than width.\"));\n+        OP_REQUIRES(context, max_box_col_clamp <= width,\n+                    errors::InvalidArgument(\n+                        \"Max box col clamp is greater than width.\"));\n \n         // At this point, the min_box_row and min_box_col are either\n         // in the image or above/left of it, and max_box_row and\n         // max_box_col are either in the image or below/right or it.\n-        CHECK_LT(min_box_row, height);\n-        CHECK_GE(max_box_row, 0);\n-        CHECK_LT(min_box_col, width);\n-        CHECK_GE(max_box_col, 0);\n+\n+        OP_REQUIRES(\n+            context, min_box_row <= height,\n+            errors::InvalidArgument(\"Min box row is greater than height.\"));\n+        OP_REQUIRES(context, max_box_row >= 0,\n+                    errors::InvalidArgument(\"Max box row is less than 0.\"));\n+        OP_REQUIRES(\n+            context, min_box_col <= width,\n+            errors::InvalidArgument(\"Min box col is greater than width.\"));\n+        OP_REQUIRES(context, max_box_col >= 0,\n+                    errors::InvalidArgument(\"Max box col is less than 0.\"));\n \n         // Draw top line.\n         if (min_box_row >= 0) {\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-393f-2jr3-cp69",
    "API Signature": "tf.raw_ops.DrawBoundingBoxes(\n    images, boxes, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "images = tf.fill([], 0.)"
  },
  {
    "Title": "\n        Heap out of bounds read in `RaggedCross`\n      ",
    "Bug description": "An attacker can force accesses outside the bounds of heap allocated arrays by passing in invalid tensor values to  tf.raw_ops.RaggedCross :",
    "Sample Code": "ragged_values = []\nragged_row_splits = [] \nsparse_indices = []\nsparse_values = []\nsparse_shape = []\n\ndense_inputs_elem = tf.constant([], shape=[92, 0], dtype=tf.int64)\ndense_inputs = [dense_inputs_elem]\n\ninput_order = \"R\"\nhashed_output = False\nnum_buckets = 0\nhash_key = 0 \n\ntf.raw_ops.RaggedCross(ragged_values=ragged_values,\n    ragged_row_splits=ragged_row_splits,\n    sparse_indices=sparse_indices,\n    sparse_values=sparse_values,\n    sparse_shape=sparse_shape,\n    dense_inputs=dense_inputs,\n    input_order=input_order,\n    hashed_output=hashed_output,\n    num_buckets=num_buckets,\n    hash_key=hash_key,\n    out_values_type=tf.int64,\n    ,\n    out_row_splits_type=tf.int64)",
    "Code change": [
      "@@ -21,6 +21,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/fingerprint.h\"\n #include \"tensorflow/core/util/util.h\"\n #include \"tensorflow/core/util/work_sharder.h\"\n@@ -466,16 +467,45 @@ class RaggedCrossOp : public OpKernel {\n     int next_dense = 0;\n     for (char c : input_order_) {\n       if (c == 'R') {\n+        if (next_ragged >= ragged_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor value at index \",\n+              next_ragged, \" from a list of \", ragged_values_list.size(),\n+              \" values.\");\n+        if (next_ragged >= ragged_splits_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor split at index \",\n+              next_ragged, \" from a list of \", ragged_splits_list.size(),\n+              \" splits.\");\n         TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\n             ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\n             features));\n         next_ragged++;\n       } else if (c == 'S') {\n+        if (next_sparse >= sparse_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor value at index \",\n+              next_sparse, \" from a list of \", sparse_values_list.size(),\n+              \" values.\");\n+        if (next_sparse >= sparse_indices_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor index at index \",\n+              next_sparse, \" from a list of \", sparse_indices_list.size(),\n+              \" indices.\");\n         TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\n             sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\n             batch_size, features));\n         next_sparse++;\n       } else if (c == 'D') {\n+        if (next_dense >= dense_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a dense tensor at index \", next_dense,\n+              \" from a list of \", dense_list.size(), \" tensors.\");\n         TF_RETURN_IF_ERROR(\n             BuildDenseFeatureReader(dense_list[next_dense++], features));\n       } else {\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-j47f-4232-hvv8",
    "API Signature": "tf.raw_ops.RaggedCross(\n    ragged_values,\n    ragged_row_splits,\n    sparse_indices,\n    sparse_values,\n    sparse_shape,\n    dense_inputs,\n    input_order,\n    hashed_output,\n    num_buckets,\n    hash_key,\n    out_values_type,\n    out_row_splits_type,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "ragged_values = []\nragged_row_splits = [] \nsparse_indices = []\nsparse_values = []\nsparse_shape = []\n\ndense_inputs_elem = tf.constant([], shape=[92, 0], dtype=tf.int64)"
  },
  {
    "Title": "\n        `CHECK`-fail in `tf.raw_ops.EncodePng`\n      ",
    "Bug description": "An attacker can trigger a  CHECK  fail in PNG encoding by providing an empty input tensor as the pixel data:",
    "Sample Code": "image = tf.zeros([0, 0, 3])\nimage = tf.cast(image, dtype=tf.uint8) \n) \ntf.raw_ops.EncodePng(image=image) ",
    "Code change": [
      "@@ -54,6 +54,8 @@ class EncodePngOp : public OpKernel {\n     OP_REQUIRES(context, image.dims() == 3,\n                 errors::InvalidArgument(\"image must be 3-dimensional\",\n                                         image.shape().DebugString()));\n+    OP_REQUIRES(context, image.NumElements() > 0,\n+                errors::Internal(\"Invalid image provided.\"));\n     OP_REQUIRES(\n         context,\n         FastBoundsCheck(image.NumElements(), std::numeric_limits<int32>::max()),\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-3qxp-qjq7-w4hf",
    "API Signature": "tf.raw_ops.EncodePng(\n    image, compression=-1, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "image = tf.zeros([0, 0, 3])"
  },
  {
    "Title": "\n        Invalid validation in `SparseMatrixSparseCholesky`\n      ",
    "Bug description": "An attacker can trigger a null pointer dereference by providing an invalid  permutation  to  tf.raw_ops.SparseMatrixSparseCholesky :",
    "Sample Code": "import numpy as np\nfrom tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops\n\nindices_array = np.array([[0, 0]])\nvalue_array = np.array([-10.0], dtype=np.float32)\ndense_shape = [1, 1]\nst = tf.SparseTensor(indices_array, value_array, dense_shape)\n\ninput = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n       st.indices, st.values, st.dense_shape)\n\npermutation = tf.constant([], shape=[1, 0], dtype=tf.int32)\n \n)\n \ntf.raw_ops.SparseMatrixSparseCholesky(input=input, permutation=permutation, type=tf.float32)",
    "Code change": [
      "@@ -17,6 +17,8 @@ limitations under the License.\n #include <numeric>\n #include <vector>\n \n+#include \"tensorflow/core/framework/op_requires.h\"\n+\n #define EIGEN_USE_THREADS\n \n #include \"third_party/eigen3/Eigen/Core\"\n@@ -82,8 +84,8 @@ class CSRSparseCholeskyCPUOp : public OpKernel {\n \n     int64 num_rows;\n     int batch_size;\n-    ValidateInputs(ctx, *input_matrix, input_permutation_indices, &batch_size,\n-                   &num_rows);\n+    OP_REQUIRES_OK(ctx, ValidateInputs(*input_matrix, input_permutation_indices,\n+                                       &batch_size, &num_rows));\n \n     // Allocate batch pointers.\n     Tensor batch_ptr(cpu_allocator(), DT_INT32, TensorShape({batch_size + 1}));\n@@ -226,49 +228,48 @@ class CSRSparseCholeskyCPUOp : public OpKernel {\n   }\n \n  private:\n-  void ValidateInputs(OpKernelContext* ctx,\n-                      const CSRSparseMatrix& sparse_matrix,\n-                      const Tensor& permutation_indices, int* batch_size,\n-                      int64* num_rows) {\n-    OP_REQUIRES(ctx, sparse_matrix.dtype() == DataTypeToEnum<T>::value,\n-                errors::InvalidArgument(\n-                    \"Asked for a CSRSparseMatrix of type \",\n-                    DataTypeString(DataTypeToEnum<T>::value),\n-                    \" but saw dtype: \", DataTypeString(sparse_matrix.dtype())));\n+  Status ValidateInputs(const CSRSparseMatrix& sparse_matrix,\n+                        const Tensor& permutation_indices, int* batch_size,\n+                        int64* num_rows) {\n+    if (sparse_matrix.dtype() != DataTypeToEnum<T>::value)\n+      return errors::InvalidArgument(\n+          \"Asked for a CSRSparseMatrix of type \",\n+          DataTypeString(DataTypeToEnum<T>::value),\n+          \" but saw dtype: \", DataTypeString(sparse_matrix.dtype()));\n \n     const Tensor& dense_shape = sparse_matrix.dense_shape();\n     const int rank = dense_shape.dim_size(0);\n-    OP_REQUIRES(ctx, rank == 2 || rank == 3,\n-                errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\n-                                        \"but dense_shape has size \", rank));\n+    if (rank < 2 || rank > 3)\n+      return errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\n+                                     \"but dense_shape has size \", rank);\n     const int row_dim = (rank == 2) ? 0 : 1;\n     auto dense_shape_vec = dense_shape.vec<int64>();\n     *num_rows = dense_shape_vec(row_dim);\n     const int64 num_cols = dense_shape_vec(row_dim + 1);\n-    OP_REQUIRES(ctx, *num_rows == num_cols,\n-                errors::InvalidArgument(\"sparse matrix must be square; got: \",\n-                                        *num_rows, \" != \", num_cols));\n+    if (*num_rows != num_cols)\n+      return errors::InvalidArgument(\n+          \"sparse matrix must be square; got: \", *num_rows, \" != \", num_cols);\n     const TensorShape& perm_shape = permutation_indices.shape();\n-    OP_REQUIRES(\n-        ctx, perm_shape.dims() + 1 == rank,\n-        errors::InvalidArgument(\n-            \"sparse matrix must have the same rank as permutation; got: \", rank,\n-            \" != \", perm_shape.dims(), \" + 1.\"));\n-    OP_REQUIRES(\n-        ctx, perm_shape.dim_size(rank - 2) == *num_rows,\n-        errors::InvalidArgument(\n-            \"permutation must have the same number of elements in each batch \"\n-            \"as the number of rows in sparse matrix; got: \",\n-            perm_shape.dim_size(rank - 2), \" != \", *num_rows));\n+    if (perm_shape.dims() + 1 != rank)\n+      return errors::InvalidArgument(\n+          \"sparse matrix must have the same rank as permutation; got: \", rank,\n+          \" != \", perm_shape.dims(), \" + 1.\");\n+    if (perm_shape.dim_size(rank - 2) != *num_rows)\n+      return errors::InvalidArgument(\n+          \"permutation must have the same number of elements in each batch \"\n+          \"as the number of rows in sparse matrix; got: \",\n+          perm_shape.dim_size(rank - 2), \" != \", *num_rows);\n \n     *batch_size = sparse_matrix.batch_size();\n     if (*batch_size > 1) {\n-      OP_REQUIRES(\n-          ctx, perm_shape.dim_size(0) == *batch_size,\n-          errors::InvalidArgument(\"permutation must have the same batch size \"\n-                                  \"as sparse matrix; got: \",\n-                                  perm_shape.dim_size(0), \" != \", *batch_size));\n+      if (perm_shape.dim_size(0) != *batch_size)\n+        return errors::InvalidArgument(\n+            \"permutation must have the same batch size \"\n+            \"as sparse matrix; got: \",\n+            perm_shape.dim_size(0), \" != \", *batch_size);\n     }\n+\n+    return Status::OK();\n   }\n };\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xcwj-wfcm-m23c",
    "API Signature": "tf.raw_ops.SparseMatrixSparseCholesky(\n    input, permutation, type, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "permutation = tf.constant([], shape=[1, 0], dtype=tf.int32)"
  },
  {
    "Title": "\n        Division by 0 in `QuantizedMul`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.QuantizedMul :",
    "Sample Code": "x = tf.zeros([4, 1], dtype=tf.quint8)\ny = tf.constant([], dtype=tf.quint8)\nmin_x = tf.constant(0.0)\nmax_x = tf.constant(0.0010000000474974513)\nmin_y = tf.constant(0.0)\nmax_y = tf.constant(0.0010000000474974513)\n\n)\n\ntf.raw_ops.QuantizedMul(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y)",
    "Code change": [
      "@@ -347,6 +347,11 @@ class QuantizedMulOp : public OpKernel {\n         tensor_num_elements = x.NumElements();\n         tensor_offset = offset_x;\n       }\n+      if (vector_num_elements == 0) {\n+        context->SetStatus(\n+            errors::InvalidArgument(\"vector must have at least 1 element\"));\n+        return;\n+      }\n       VectorTensorMultiply<T, Toutput>(\n           vector_data, vector_offset, vector_num_elements, tensor_data,\n           tensor_offset, tensor_num_elements, z_data);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6f84-42vf-ppwp",
    "API Signature": "tf.raw_ops.QuantizedMul(\n    x,\n    y,\n    min_x,\n    max_x,\n    min_y,\n    max_y,\n    Toutput=tf.dtypes.qint32,\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "y = tf.constant([], dtype=tf.quint8)"
  },
  {
    "Title": "\n        Division by 0 in `QuantizedConv2D`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.QuantizedConv2D :",
    "Sample Code": "input = tf.zeros([1, 1, 1, 1], dtype=tf.quint8)\nfilter = tf.constant([], shape=[1, 0, 1, 1], dtype=tf.quint8)\nmin_input = tf.constant(0.0)\nmax_input = tf.constant(0.0001)\nmin_filter = tf.constant(0.0)\nmax_filter = tf.constant(0.0001)\nstrides = [1, 1, 1, 1]\npadding = \"SAME\"               \n                               \n\n               \n                               \n\ntf.raw_ops.QuantizedConv2D(input=input, filter=filter, min_input=min_input, max_input=max_input, min_filter=min_filter, max_filter=max_filter, strides=strides, padding=padding)",
    "Code change": [
      "@@ -18,6 +18,8 @@ limitations under the License.\n #include <algorithm>\n #include <vector>\n \n+#include \"tensorflow/core/platform/errors.h\"\n+\n #define EIGEN_USE_THREADS\n \n #define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\n@@ -227,8 +229,12 @@ class Im2ColConvFunctor {\n       return;\n     }\n \n-    CHECK_GT(output_width, 0);\n-    CHECK_GT(output_height, 0);\n+    OP_REQUIRES(\n+        context, output_width > 0,\n+        errors::InvalidArgument(\"output_width must be strictly positive\"));\n+    OP_REQUIRES(\n+        context, output_height > 0,\n+        errors::InvalidArgument(\"output_height must be strictly positive\"));\n     int filter_left_offset;\n     int filter_top_offset;\n     if (padding == VALID) {\n@@ -255,6 +261,9 @@ class Im2ColConvFunctor {\n     // by the width, then the height. This is the standard memory order in the\n     // image world if it helps to visualize it.\n     const int filter_value_count = filter_width * filter_height * input_depth;\n+    OP_REQUIRES(context, filter_value_count > 0,\n+                errors::InvalidArgument(\n+                    \"filter patch must contain at least one element\"));\n     const int64 patches_per_chunk =\n         kMaxChunkSize / (filter_value_count * sizeof(T1));\n     const int64 chunk_value_count =\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x4g7-fvjj-prg8",
    "API Signature": "tf.raw_ops.QuantizedConv2D(\n    input,\n    filter,\n    min_input,\n    max_input,\n    min_filter,\n    max_filter,\n    strides,\n    padding,\n    out_type=tf.dtypes.qint32,\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "min_input = tf.constant(0.0)\nmin_filter = tf.constant(0.0)"
  },
  {
    "Title": "\n        Division by 0 in `QuantizedConv2D`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.QuantizedConv2D :",
    "Sample Code": "input = tf.zeros([1, 1, 1, 1], dtype=tf.quint8)\nfilter = tf.constant([], shape=[1, 0, 1, 1], dtype=tf.quint8)\nmin_input = tf.constant(0.0)\nmax_input = tf.constant(0.0001)\nmin_filter = tf.constant(0.0)\nmax_filter = tf.constant(0.0001)\nstrides = [1, 1, 1, 1]\npadding = \"SAME\"               \n                               \n\n               \n                               \n\ntf.raw_ops.QuantizedConv2D(input=input, filter=filter, min_input=min_input, max_input=max_input, min_filter=min_filter, max_filter=max_filter, strides=strides, padding=padding)",
    "Code change": [
      "@@ -18,6 +18,8 @@ limitations under the License.\n #include <algorithm>\n #include <vector>\n \n+#include \"tensorflow/core/platform/errors.h\"\n+\n #define EIGEN_USE_THREADS\n \n #define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\n@@ -227,8 +229,12 @@ class Im2ColConvFunctor {\n       return;\n     }\n \n-    CHECK_GT(output_width, 0);\n-    CHECK_GT(output_height, 0);\n+    OP_REQUIRES(\n+        context, output_width > 0,\n+        errors::InvalidArgument(\"output_width must be strictly positive\"));\n+    OP_REQUIRES(\n+        context, output_height > 0,\n+        errors::InvalidArgument(\"output_height must be strictly positive\"));\n     int filter_left_offset;\n     int filter_top_offset;\n     if (padding == VALID) {\n@@ -255,6 +261,9 @@ class Im2ColConvFunctor {\n     // by the width, then the height. This is the standard memory order in the\n     // image world if it helps to visualize it.\n     const int filter_value_count = filter_width * filter_height * input_depth;\n+    OP_REQUIRES(context, filter_value_count > 0,\n+                errors::InvalidArgument(\n+                    \"filter patch must contain at least one element\"));\n     const int64 patches_per_chunk =\n         kMaxChunkSize / (filter_value_count * sizeof(T1));\n     const int64 chunk_value_count =\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x4g7-fvjj-prg8",
    "API Signature": "tf.raw_ops.QuantizedConv2D(\n    input,\n    filter,\n    min_input,\n    max_input,\n    min_filter,\n    max_filter,\n    strides,\n    padding,\n    out_type=tf.dtypes.qint32,\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "filter = tf.constant([], shape=[1, 0, 1, 1], dtype=tf.quint8)"
  },
  {
    "Title": "\n        Division by 0 in `Conv2D`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.Conv2D :",
    "Sample Code": "input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\nfilter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\n\nstrides = [1, 1, 1, 1]\npadding = \"SAME\"\n                               \n\n                               \ntf.raw_ops.Conv2D(input=input, filter=filter, strides=strides, padding=padding)",
    "Code change": [
      "@@ -260,6 +260,11 @@ struct LaunchConv2DOp<CPUDevice, T> {\n     const int64 out_depth = output->dim_size(3);\n     const int64 patch_depth = filter.dim_size(2);\n \n+    if (patch_depth <= 0) {\n+      ctx->SetStatus(errors::InvalidArgument(\n+          \"filter depth must be stricly positive, got \", patch_depth));\n+      return;\n+    }\n     if (in_depth % patch_depth != 0) {\n       ctx->SetStatus(errors::InvalidArgument(\n           \"input depth must be evenly divisible by filter depth: \", in_depth,\n@@ -268,6 +273,11 @@ struct LaunchConv2DOp<CPUDevice, T> {\n     }\n \n     const int64 num_groups = in_depth / patch_depth;\n+    if (num_groups <= 0) {\n+      ctx->SetStatus(errors::InvalidArgument(\n+          \"number of groups must be stricly positive, got \", num_groups));\n+      return;\n+    }\n     if (out_depth % num_groups != 0 || out_depth < num_groups) {\n       ctx->SetStatus(errors::InvalidArgument(\n           \"output depth must be evenly divisible by number of groups: \",\n@@ -536,6 +546,9 @@ Status ComputeConv2DDimension(const Conv2DParameters& params,\n               errors::InvalidArgument(\"Patch depth too large\"));\n   const int in_depth = static_cast<int>(in_depth_raw);\n   const int patch_depth = static_cast<int>(patch_depth_raw);\n+  TF_REQUIRES(patch_depth > 0,\n+              errors::InvalidArgument(\n+                  \"filter depth must be stricly positive, got \", patch_depth));\n   TF_REQUIRES(in_depth % patch_depth == 0,\n               errors::InvalidArgument(\n                   \"input depth must be evenly divisible by filter depth: \",\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4vf2-4xcg-65cx",
    "API Signature": "tf.raw_ops.Conv2D(\n    input,\n    filter,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\nfilter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)"
  },
  {
    "Title": "\n        Division by 0 in `Conv2DBackpropInput`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.Conv2DBackpropInput :",
    "Sample Code": "input_tensor = tf.constant([52, 1, 1, 5], shape=[4], dtype=tf.int32)\nfilter_tensor = tf.constant([], shape=[0, 1, 5, 0], dtype=tf.float32)\nout_backprop = tf.constant([], shape=[52, 1, 1, 0], dtype=tf.float32)\n\ntf.raw_ops.Conv2DBackpropInput(input_sizes=input_tensor, filter=filter_tensor,\n                               out_backprop=out_backprop, strides=[1, 1, 1, 1],\n                               use_cudnn_on_gpu=True, padding='SAME',\n                               explicit_paddings=[], data_format='NHWC',\n                               ,\n                               dilations=[1, 1, 1, 1])",
    "Code change": [
      "@@ -649,6 +649,11 @@ class Conv2DCustomBackpropInputOp : public OpKernel {\n         dims.batch_size == 1 ||\n         thread_work_unit_size >= min_thread_work_unit_size;\n \n+    OP_REQUIRES(\n+        context, work_unit_size > 0,\n+        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n+                                \"must all have at least 1 element\"));\n+\n     const size_t shard_size =\n         use_parallel_contraction\n             ? 1\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xm2v-8rrw-w9pm",
    "API Signature": "tf.raw_ops.Conv2DBackpropInput(\n    input_sizes,\n    filter,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "filter_tensor = tf.constant([], shape=[0, 1, 5, 0], dtype=tf.float32)\nout_backprop = tf.constant([], shape=[52, 1, 1, 0], dtype=tf.float32)"
  },
  {
    "Title": "\n        Division by 0 in `Conv2DBackpropFilter`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.Conv2DBackpropFilter :",
    "Sample Code": "input_tensor = tf.constant([], shape=[0, 0, 1, 0], dtype=tf.float32)\nfilter_sizes = tf.constant([1, 1, 1, 1], shape=[4], dtype=tf.int32)\nout_backprop = tf.constant([], shape=[0, 0, 1, 1], dtype=tf.float32)\n\ntf.raw_ops.Conv2DBackpropFilter(input=input_tensor, filter_sizes=filter_sizes,\n                                out_backprop=out_backprop,\n                                strides=[1, 66, 18, 1], use_cudnn_on_gpu=True,\n                                padding='SAME', explicit_paddings=[],\n                                [],\n                                data_format='NHWC', dilations=[1, 1, 1, 1])",
    "Code change": [
      "@@ -127,6 +127,10 @@ Status ConvBackpropComputeDimensionsV2(\n   // dimensions of the filter Tensor.\n   VLOG(2) << \"input vs filter_in depth \" << dims->in_depth << \" \"\n           << filter_shape.dim_size(num_dims - 2);\n+  if (filter_shape.dim_size(num_dims - 2) <= 0) {\n+    return errors ::InvalidArgument(\n+        label, \": filter depth must be strictly greated than zero\");\n+  }\n   if (dims->in_depth % filter_shape.dim_size(num_dims - 2)) {\n     return errors::InvalidArgument(\n         label, \": input depth must be evenly divisible by filter depth\");\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-r4pj-74mg-8868",
    "API Signature": "tf.raw_ops.Conv2DBackpropFilter(\n    input,\n    filter_sizes,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "input_tensor = tf.constant([], shape=[0, 0, 1, 0], dtype=tf.float32)\nout_backprop = tf.constant([], shape=[0, 0, 1, 1], dtype=tf.float32)"
  },
  {
    "Title": "\n        `CHECK`-fail in `AddManySparseToTensorsMap`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in   tf.raw_ops.AddManySparseToTensorsMap :",
    "Sample Code": "import numpy as np\n\nsparse_indices = tf.constant(530, shape=[1, 1], dtype=tf.int64)\nsparse_values = tf.ones([1], dtype=tf.int64)\n\nshape = tf.Variable(tf.ones([55], dtype=tf.int64))\nshape[:8].assign(np.array([855, 901, 429, 892, 892, 852, 93, 96], dtype=np.int64))\n\ntf.raw_ops.AddManySparseToTensorsMap(sparse_indices=sparse_indices,\n                    sparse_values=sparse_values,\n                    ,\n                    sparse_shape=shape)",
    "Code change": [
      "@@ -21,9 +21,6 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n-#include \"tensorflow/core/framework/op_kernel.h\"\n-#include \"tensorflow/core/framework/register_types.h\"\n-\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/resource_mgr.h\"\n@@ -31,6 +28,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n #include \"tensorflow/core/util/sparse/sparse_tensor.h\"\n \n namespace tensorflow {\n@@ -254,7 +252,22 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n         errors::InvalidArgument(\n             \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n \n-    TensorShape tensor_input_shape(input_shape->vec<int64>());\n+    auto input_shape_vec = input_shape->vec<int64>();\n+    int new_num_elements = 1;\n+    bool overflow_ocurred = false;\n+    for (int i = 0; i < input_shape_vec.size(); i++) {\n+      new_num_elements =\n+          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n+      if (new_num_elements < 0) {\n+        overflow_ocurred = true;\n+      }\n+    }\n+\n+    OP_REQUIRES(\n+        context, !overflow_ocurred,\n+        errors::Internal(\"Encountered overflow from large input shape.\"));\n+\n+    TensorShape tensor_input_shape(input_shape_vec);\n     gtl::InlinedVector<int64, 8> std_order(rank);\n     std::iota(std_order.begin(), std_order.end(), 0);\n     SparseTensor input_st;\n@@ -262,8 +275,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n                                                  tensor_input_shape, std_order,\n                                                  &input_st));\n \n-    auto input_shape_t = input_shape->vec<int64>();\n-    const int64 N = input_shape_t(0);\n+    const int64 N = input_shape_vec(0);\n \n     Tensor sparse_handles(DT_INT64, TensorShape({N}));\n     auto sparse_handles_t = sparse_handles.vec<int64>();\n@@ -274,7 +286,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n     // minibatch entries.\n     TensorShape output_shape;\n     OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n-                                input_shape_t.data() + 1,\n+                                input_shape_vec.data() + 1,\n                                 input_shape->NumElements() - 1, &output_shape));\n \n     // Get groups by minibatch dimension\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2cpx-427x-q2c6",
    "API Signature": "tf.raw_ops.AddManySparseToTensorsMap(\n    sparse_indices,\n    sparse_values,\n    sparse_shape,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.014184397163120567,
    "Anomaly": "Large input tensor",
    "Category": "Tensor",
    "Argument": "shape = tf.Variable(tf.ones([55], dtype=tf.int64))\nshape[:8].assign(np.array([855, 901, 429, 892, 892, 852, 93, 96], dtype=np.int64))"
  },
  {
    "Title": "\n        Division by 0 in `Conv3DBackprop*`\n      ",
    "Bug description": "The  tf.raw_ops.Conv3DBackprop*  operations fail to validate that the input tensors are not empty. In turn, this would result in a division by 0:",
    "Sample Code": "input_sizes = tf.constant([1], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\nfilter_tensor = tf.constant([0, 0, 0, 1, 0], shape=[5], dtype=tf.int32)\nout_backprop = tf.constant([], shape=[1, 1, 1, 1, 0], dtype=tf.float32)\n\n)\n\ntf.raw_ops.Conv3DBackpropFilterV2(input=input_sizes, filter_sizes=filter_tensor, out_backprop=out_backprop, strides=[1, 1, 1, 1, 1], padding='SAME', data_format='NDHWC', dilations=[1, 1, 1, 1, 1])",
    "Code change": [
      "@@ -239,6 +239,14 @@ class Conv3DBackpropInputOp : public OpKernel {\n       input_shape = context->input(0).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -360,6 +368,14 @@ class Conv3DCustomBackpropInputOp : public OpKernel {\n       input_shape = context->input(0).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -444,6 +460,11 @@ class Conv3DCustomBackpropInputOp : public OpKernel {\n     // contraction compared to sharding and matmuls.\n     const bool use_parallel_contraction = dims.batch_size == 1;\n \n+    OP_REQUIRES(\n+        context, work_unit_size > 0,\n+        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n+                                \"must all have at least 1 element\"));\n+\n     const size_t shard_size =\n         use_parallel_contraction\n             ? 1\n@@ -724,6 +745,14 @@ class Conv3DBackpropFilterOp : public OpKernel {\n       filter_shape = context->input(1).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -850,6 +879,14 @@ class Conv3DCustomBackpropFilterOp : public OpKernel {\n       filter_shape = context->input(1).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -936,6 +973,11 @@ class Conv3DCustomBackpropFilterOp : public OpKernel {\n \n     const int64 work_unit_size = size_A + size_B + size_C;\n \n+    OP_REQUIRES(\n+        context, work_unit_size > 0,\n+        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n+                                \"must all have at least 1 element\"));\n+\n     const size_t shard_size =\n         (target_working_set_size + work_unit_size - 1) / work_unit_size;\n \n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c968-pq7h-7fxv",
    "API Signature": "tf.raw_ops.Conv3DBackpropFilterV2(\n    input,\n    filter_sizes,\n    out_backprop,\n    strides,\n    padding,\n    data_format='NDHWC',\n    dilations=[1, 1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "filter_tensor = tf.constant([], shape=[0, 0, 0, 1, 0], dtype=tf.float32)\nout_backprop = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)"
  },
  {
    "Title": "\n        Heap buffer overflow in `Conv3DBackprop*`\n      ",
    "Bug description": "Missing validation between arguments to  tf.raw_ops.Conv3DBackprop*  operations can result in heap buffer overflows:",
    "Sample Code": "input_values = [-10.0] * (7 * 7 * 7 * 7 * 7)\ninput_values[0] = 429.6491056791816\ninput_sizes = tf.constant(input_values, shape=[7, 7, 7, 7, 7], dtype=tf.float32)\nfilter_tensor = tf.constant([7, 7, 7, 1, 1], shape=[5], dtype=tf.int32)\nout_backprop = tf.constant([-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], shape=[7, 1, 1, 1, 1], dtype=tf.float32)\n  \n)\n  \ntf.raw_ops.Conv3DBackpropFilterV2(input=input_sizes, filter_sizes=filter_tensor, out_backprop=out_backprop, strides=[1, 37, 65, 93, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 1, 1])",
    "Code change": [
      "@@ -239,6 +239,20 @@ class Conv3DBackpropInputOp : public OpKernel {\n       input_shape = context->input(0).shape();\n     }\n \n+    OP_REQUIRES(\n+        context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n+        errors::InvalidArgument(\"input and filter_sizes must have the same \"\n+                                \"number of channels. Got \",\n+                                input_shape.dim_size(4), \" for input and \",\n+                                filter_shape.dim_size(3), \" for filter_sizes\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),\n+        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"\n+                                \"same number of channels. Got \",\n+                                out_backprop_shape.dim_size(4),\n+                                \" for out_backprop and \",\n+                                filter_shape.dim_size(4), \" for filter_sizes\"));\n+\n     ConvBackpropDimensions dims;\n     OP_REQUIRES_OK(context, ConvBackpropComputeDimensions(\n                                 \"Conv3DBackpropInputOp\", /*num_spatial_dims=*/3,\n@@ -346,6 +360,20 @@ class Conv3DCustomBackpropInputOp : public OpKernel {\n       input_shape = context->input(0).shape();\n     }\n \n+    OP_REQUIRES(\n+        context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n+        errors::InvalidArgument(\"input and filter_sizes must have the same \"\n+                                \"number of channels. Got \",\n+                                input_shape.dim_size(4), \" for input and \",\n+                                filter_shape.dim_size(3), \" for filter_sizes\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),\n+        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"\n+                                \"same number of channels. Got \",\n+                                out_backprop_shape.dim_size(4),\n+                                \" for out_backprop and \",\n+                                filter_shape.dim_size(4), \" for filter_sizes\"));\n+\n     ConvBackpropDimensions dims;\n     OP_REQUIRES_OK(context, ConvBackpropComputeDimensions(\n                                 \"Conv3DBackpropInputOp\", /*num_spatial_dims=*/3,\n@@ -696,6 +724,20 @@ class Conv3DBackpropFilterOp : public OpKernel {\n       filter_shape = context->input(1).shape();\n     }\n \n+    OP_REQUIRES(\n+        context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n+        errors::InvalidArgument(\"input and filter_sizes must have the same \"\n+                                \"number of channels. Got \",\n+                                input_shape.dim_size(4), \" for input and \",\n+                                filter_shape.dim_size(3), \" for filter_sizes\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),\n+        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"\n+                                \"same number of channels. Got \",\n+                                out_backprop_shape.dim_size(4),\n+                                \" for out_backprop and \",\n+                                filter_shape.dim_size(4), \" for filter_sizes\"));\n+\n     ConvBackpropDimensions dims;\n     OP_REQUIRES_OK(context,\n                    ConvBackpropComputeDimensions(\n@@ -808,6 +850,20 @@ class Conv3DCustomBackpropFilterOp : public OpKernel {\n       filter_shape = context->input(1).shape();\n     }\n \n+    OP_REQUIRES(\n+        context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n+        errors::InvalidArgument(\"input and filter_sizes must have the same \"\n+                                \"number of channels. Got \",\n+                                input_shape.dim_size(4), \" for input and \",\n+                                filter_shape.dim_size(3), \" for filter_sizes\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),\n+        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"\n+                                \"same number of channels. Got \",\n+                                out_backprop_shape.dim_size(4),\n+                                \" for out_backprop and \",\n+                                filter_shape.dim_size(4), \" for filter_sizes\"));\n+\n     ConvBackpropDimensions dims;\n     OP_REQUIRES_OK(context,\n                    ConvBackpropComputeDimensions(\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wcv5-qrj6-9pfm",
    "API Signature": "tf.raw_ops.Conv3DBackpropInputV2(\n    input_sizes,\n    filter,\n    out_backprop,\n    strides,\n    padding,\n    data_format='NDHWC',\n    dilations=[1, 1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "input_sizes = tf.constant([1, 1, 1, 1, 2], shape=[5], dtype=tf.int32)\nfilter_tensor = tf.constant([734.6274508233133, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0,\n                            -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0,\n                            -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], shape=[4, 1, 6, 1, 1], dtype=tf.float32)\nout_backprop = tf.constant([-10.0], shape=[1, 1, 1, 1, 1], dtype=tf.float32)"
  },
  {
    "Title": "\n        Segfault in `SparseCountSparseOutput`\n      ",
    "Bug description": "Specifying a negative dense shape in  tf.raw_ops.SparseCountSparseOutput  results in a segmentation fault being thrown out from the standard library as  std::vector  invariants are broken.",
    "Sample Code": "indices = tf.constant([], shape=[0, 0], dtype=tf.int64)\nvalues = tf.constant([], shape=[0, 0], dtype=tf.int64)\ndense_shape = tf.constant([-100, -100, -100], shape=[3], dtype=tf.int64)\nweights = tf.constant([], shape=[0, 0], dtype=tf.int64)\n\n)\n\ntf.raw_ops.SparseCountSparseOutput(indices=indices, values=values, dense_shape=dense_shape, weights=weights, minlength=79, maxlength=96, binary_output=False)",
    "Code change": [
      "@@ -197,9 +197,17 @@ class SparseCount : public OpKernel {\n                     \"The shape argument requires at least one element.\"));\n \n     bool is_1d = shape.NumElements() == 1;\n-    int num_batches = is_1d ? 1 : shape.flat<int64>()(0);\n+    auto shape_vector = shape.flat<int64>();\n+    int num_batches = is_1d ? 1 : shape_vector(0);\n     int num_values = values.NumElements();\n \n+    for (int b = 0; b < shape_vector.size(); b++) {\n+      OP_REQUIRES(context, shape_vector(b) >= 0,\n+                  errors::InvalidArgument(\n+                      \"Elements in dense_shape must be >= 0. Instead got:\",\n+                      shape.DebugString()));\n+    }\n+\n     OP_REQUIRES(context, num_values == indices.shape().dim_size(0),\n                 errors::InvalidArgument(\n                     \"Number of values must match first dimension of indices.\",\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hr84-fqvp-48mm",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.024822695035460994,
    "Anomaly": "Negative input tensor",
    "Category": "Tensor",
    "Argument": "dense_shape = tf.constant([-100, -100, -100], shape=[3], dtype=tf.int64)"
  },
  {
    "Title": "\n        Session operations in eager mode lead to null pointer dereferences\n      ",
    "Bug description": "In eager mode (default in TF 2.0 and later), session operations are invalid. However, users could still call the raw ops associated with them and trigger a null pointer dereference:",
    "Sample Code": " tensorflow as tf\ntf.raw_ops.DeleteSessionTensor(handle=['])",
    "Code change": [
      "@@ -91,7 +91,6 @@ TF_CALL_NUMBER_TYPES(REGISTER_GPU_KERNEL);\n REGISTER_GPU_KERNEL(bool);\n #undef REGISTER_GPU_KERNEL\n \n-\n class GetSessionTensorOp : public OpKernel {\n  public:\n   explicit GetSessionTensorOp(OpKernelConstruction* context)\n@@ -101,7 +100,11 @@ class GetSessionTensorOp : public OpKernel {\n     const Tensor& handle = ctx->input(0);\n     const string& name = handle.scalar<tstring>()();\n     Tensor val;\n-    OP_REQUIRES_OK(ctx, ctx->session_state()->GetTensor(name, &val));\n+    auto session_state = ctx->session_state();\n+    OP_REQUIRES(ctx, session_state != nullptr,\n+                errors::FailedPrecondition(\n+                    \"GetSessionTensor called on null session state\"));\n+    OP_REQUIRES_OK(ctx, session_state->GetTensor(name, &val));\n     ctx->set_output(0, val);\n   }\n \n@@ -122,7 +125,6 @@ TF_CALL_NUMBER_TYPES(REGISTER_GPU_KERNEL);\n REGISTER_GPU_KERNEL(bool);\n #undef REGISTER_GPU_KERNEL\n \n-\n class DeleteSessionTensorOp : public OpKernel {\n  public:\n   explicit DeleteSessionTensorOp(OpKernelConstruction* context)\n@@ -131,7 +133,11 @@ class DeleteSessionTensorOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& handle = ctx->input(0);\n     const string& name = handle.scalar<tstring>()();\n-    OP_REQUIRES_OK(ctx, ctx->session_state()->DeleteTensor(name));\n+    auto session_state = ctx->session_state();\n+    OP_REQUIRES(ctx, session_state != nullptr,\n+                errors::FailedPrecondition(\n+                    \"DeleteSessionTensor called on null session state\"));\n+    OP_REQUIRES_OK(ctx, session_state->DeleteTensor(name));\n   }\n \n   TF_DISALLOW_COPY_AND_ASSIGN(DeleteSessionTensorOp);\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-62gx-355r-9fhg",
    "API Signature": "tf.raw_ops.GetSessionTensor(\n    handle, dtype, name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Invalid string list element",
    "Category": "List",
    "Argument": "handle=['\\x12\\x1a\\x07']"
  },
  {
    "Title": "\n        Division by zero in `Conv3D`\n      ",
    "Bug description": "A malicious user could trigger a division by 0 in  Conv3D  implementation:",
    "Sample Code": "input_tensor = tf.constant([], shape=[2, 2, 2, 2, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 2, 6, 2], dtype=tf.float32)\n\n)\n\ntf.raw_ops.Conv3D(input=input_tensor, filter=filter_tensor, strides=[1, 56, 39, 34, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 1, 1])",
    "Code change": [
      "@@ -69,6 +69,11 @@ struct LaunchConvOp<CPUDevice, T> {\n                 errors::InvalidArgument(\"CPU implementation of Conv3D \"\n                                         \"currently only supports dilated rates \"\n                                         \"of 1.\"));\n+    OP_REQUIRES(context, filter.dim_size(3) == input.dim_size(input.dims() - 1),\n+                errors::InvalidArgument(\n+                    \"Number of channels in filter (\", filter.dim_size(3),\n+                    \") must match last dimension of input (\",\n+                    input.dim_size(input.dims() - 1), \")\"));\n     functor::CuboidConvolution<CPUDevice, T>()(\n         context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),\n         input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],\n@@ -142,6 +147,8 @@ class Conv3DOp : public BinaryOp<T> {\n     const int64 filter_depth = filter.dim_size(3);\n     const int64 out_depth = filter.dim_size(4);\n \n+    OP_REQUIRES(context, filter_depth != 0,\n+                errors::InvalidArgument(\"filter_depth must be non-zero\"));\n     OP_REQUIRES(context, in_depth % filter_depth == 0,\n                 errors::InvalidArgument(\n                     \"Input depth must be evenly divisible by filter depth: \",\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-772p-x54p-hjrv",
    "API Signature": "tf.raw_ops.Conv3D(\n    input,\n    filter,\n    strides,\n    padding,\n    data_format='NDHWC',\n    dilations=[1, 1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "input_tensor = tf.constant([], shape=[2, 2, 2, 2, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 2, 6, 2], dtype=tf.float32)"
  },
  {
    "Title": "\n        Division by zero in `Conv3D`\n      ",
    "Bug description": "A malicious user could trigger a division by 0 in  Conv3D  implementation:",
    "Sample Code": "input_tensor = tf.constant([], shape=[2, 2, 2, 2, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 2, 6, 2], dtype=tf.float32)\n\n)\n\ntf.raw_ops.Conv3D(input=input_tensor, filter=filter_tensor, strides=[1, 56, 39, 34, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 1, 1])",
    "Code change": [
      "@@ -69,6 +69,11 @@ struct LaunchConvOp<CPUDevice, T> {\n                 errors::InvalidArgument(\"CPU implementation of Conv3D \"\n                                         \"currently only supports dilated rates \"\n                                         \"of 1.\"));\n+    OP_REQUIRES(context, filter.dim_size(3) == input.dim_size(input.dims() - 1),\n+                errors::InvalidArgument(\n+                    \"Number of channels in filter (\", filter.dim_size(3),\n+                    \") must match last dimension of input (\",\n+                    input.dim_size(input.dims() - 1), \")\"));\n     functor::CuboidConvolution<CPUDevice, T>()(\n         context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),\n         input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],\n@@ -142,6 +147,8 @@ class Conv3DOp : public BinaryOp<T> {\n     const int64 filter_depth = filter.dim_size(3);\n     const int64 out_depth = filter.dim_size(4);\n \n+    OP_REQUIRES(context, filter_depth != 0,\n+                errors::InvalidArgument(\"filter_depth must be non-zero\"));\n     OP_REQUIRES(context, in_depth % filter_depth == 0,\n                 errors::InvalidArgument(\n                     \"Input depth must be evenly divisible by filter depth: \",\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-772p-x54p-hjrv",
    "API Signature": "tf.raw_ops.Conv3D(\n    input,\n    filter,\n    strides,\n    padding,\n    data_format='NDHWC',\n    dilations=[1, 1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": NaN,
    "Argument": "input_tensor = tf.constant([], shape=[2, 2, 2, 2, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 2, 6, 2], dtype=tf.float32)"
  },
  {
    "Title": "\n        Reference binding to null pointer in `MatrixDiag*` ops\n      ",
    "Bug description": "The implementation of  MatrixDiag*  does not validate that the tensor arguments are non-empty:",
    "Sample Code": "d = tf.convert_to_tensor([],dtype=tf.float32)\np = tf.convert_to_tensor([],dtype=tf.float32)\n)\ntf.raw_ops.MatrixDiagV2(diagonal=d, k=0, num_rows=0, num_cols=0, padding_value=p)",
    "Code change": [
      "@@ -192,9 +192,22 @@ class MatrixDiagOp : public OpKernel {\n           upper_diag_index = diag_index.flat<int32>()(1);\n         }\n       }\n-      num_rows = context->input(2).flat<int32>()(0);\n-      num_cols = context->input(3).flat<int32>()(0);\n-      padding_value = context->input(4).flat<T>()(0);\n+\n+      auto& num_rows_tensor = context->input(2);\n+      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_rows_tensor.shape()),\n+                  errors::InvalidArgument(\"num_rows must be a scalar\"));\n+      num_rows = num_rows_tensor.flat<int32>()(0);\n+\n+      auto& num_cols_tensor = context->input(3);\n+      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_cols_tensor.shape()),\n+                  errors::InvalidArgument(\"num_cols must be a scalar\"));\n+      num_cols = num_cols_tensor.flat<int32>()(0);\n+\n+      auto& padding_value_tensor = context->input(4);\n+      OP_REQUIRES(context,\n+                  TensorShapeUtils::IsScalar(padding_value_tensor.shape()),\n+                  errors::InvalidArgument(\"padding_value must be a scalar\"));\n+      padding_value = padding_value_tensor.flat<T>()(0);\n     }\n \n     // Size validations.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hc6c-75p4-hmq4",
    "API Signature": "tf.raw_ops.MatrixDiagV2(\n    diagonal, k, num_rows, num_cols, padding_value, name=None\n)\n",
    "Score": 0.2127659574468085,
    "Anomaly": "Empty input tensor",
    "Category": "Tensor",
    "Argument": "d = tf.convert_to_tensor([],dtype=tf.float32)\np = tf.convert_to_tensor([],dtype=tf.float32)"
  },
  {
    "Title": "\n        Heap out of bounds write in `RaggedBinCount`\n      ",
    "Bug description": "If the  splits  argument of  RaggedBincount  does not specify a valid  SparseTensor , then an attacker can trigger a heap buffer overflow:",
    "Sample Code": "tf.raw_ops.RaggedBincount(splits=[7,8], values= [5, 16, 51, 76, 29, 27, 54, 95],\\\n                          size= 59, weights= [0, 0, 0, 0, 0, 0, 0, 0],\\\n                          ],\\\n                          binary_output=False)",
    "Code change": [
      "@@ -420,6 +420,15 @@ class RaggedBincountOp : public OpKernel {\n     int num_values = values.size();\n     int batch_idx = 0;\n \n+    OP_REQUIRES(ctx, splits(0) == 0,\n+                errors::InvalidArgument(\"Splits must start with 0, not with \",\n+                                        splits(0)));\n+\n+    OP_REQUIRES(ctx, splits(num_rows) == num_values,\n+                errors::InvalidArgument(\n+                    \"Splits must end with the number of values, got \",\n+                    splits(num_rows), \" instead of \", num_values));\n+\n     Tensor* out_t;\n     OP_REQUIRES_OK(\n         ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-8h46-5m9h-7553",
    "API Signature": "tf.raw_ops.RaggedBincount(\n    splits, values, size, weights, binary_output=False, name=None\n)\n",
    "Score": 0.010638297872340425,
    "Anomaly": "Non sparse input tensor",
    "Category": "Tensor",
    "Argument": "splits=[7,8]"
  },
  {
    "Title": "\n        Segfault in tf.raw_ops.ImmutableConst\n      ",
    "Bug description": "Calling  tf.raw_ops.ImmutableConst  with a  dtype  of  tf.resource  or  tf.variant  results in a segfault in the implementation as code assumes that the tensor contents are pure scalars.",
    "Sample Code": ">>> tf.raw_ops.ImmutableConst(dtype=tf.resource, shape=[], memory_region_name=\"/tmp/test.txt\")\n...\n)\n...\nSegmentation fault",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-g4h2-gqm3-c9wq",
    "API Signature": "tf.raw_ops.ImmutableConst(\n    dtype, shape, memory_region_name, name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Invalid data type",
    "Category": "tf.resource",
    "Argument": "dtype=tf.resource"
  },
  {
    "Title": "\n        Lack of validation in data format attributes\n      ",
    "Bug description": "The  tf.raw_ops.DataFormatVecPermute  API does not validate the  src_format  and  dst_format  attributes.  The code  assumes that these two arguments define a permutation of  NHWC .",
    "Sample Code": ">>> dst_format='8765')\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[1954047348, 1954047348],\n       [1852793646, 1852793646],\n       [1954047348, 1954047348],\n       [],\n       [1852793632, 1852793632]], dtype=int32)>",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c9f3-9wfr-wgh7",
    "API Signature": "tf.raw_ops.DataFormatVecPermute(\n    x, src_format='NHWC', dst_format='NCHW', name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Invalid string argument",
    "Category": "String",
    "Argument": "src_format='1234',\ndst_format='1234'"
  },
  {
    "Title": "\n        Lack of validation in data format attributes\n      ",
    "Bug description": "The  tf.raw_ops.DataFormatVecPermute  API does not validate the  src_format  and  dst_format  attributes.  The code  assumes that these two arguments define a permutation of  NHWC .",
    "Sample Code": ">>> dst_format='8765')\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[1954047348, 1954047348],\n       [1852793646, 1852793646],\n       [1954047348, 1954047348],\n       [],\n       [1852793632, 1852793632]], dtype=int32)>",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c9f3-9wfr-wgh7",
    "API Signature": "tf.raw_ops.DataFormatVecPermute(\n    x, src_format='NHWC', dst_format='NCHW', name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Invalid string argument",
    "Category": "String",
    "Argument": "src_format='HHHH',\ndst_format='WWWW'"
  },
  {
    "Title": "\n        Lack of validation in data format attributes\n      ",
    "Bug description": "The  tf.raw_ops.DataFormatVecPermute  API does not validate the  src_format  and  dst_format  attributes.  The code  assumes that these two arguments define a permutation of  NHWC .",
    "Sample Code": ">>> dst_format='8765')\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[1954047348, 1954047348],\n       [1852793646, 1852793646],\n       [1954047348, 1954047348],\n       [],\n       [1852793632, 1852793632]], dtype=int32)>",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c9f3-9wfr-wgh7",
    "API Signature": "tf.raw_ops.DataFormatVecPermute(\n    x, src_format='NHWC', dst_format='NCHW', name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Invalid string argument",
    "Category": "String",
    "Argument": "src_format='H',\ndst_format='W'"
  },
  {
    "Title": "\n        Lack of validation in data format attributes\n      ",
    "Bug description": "The  tf.raw_ops.DataFormatVecPermute  API does not validate the  src_format  and  dst_format  attributes.  The code  assumes that these two arguments define a permutation of  NHWC .",
    "Sample Code": ">>> dst_format='8765')\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[1954047348, 1954047348],\n       [1852793646, 1852793646],\n       [1954047348, 1954047348],\n       [],\n       [1852793632, 1852793632]], dtype=int32)>",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c9f3-9wfr-wgh7",
    "API Signature": "tf.raw_ops.DataFormatVecPermute(\n    x, src_format='NHWC', dst_format='NCHW', name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Invalid string argument",
    "Category": "String",
    "Argument": "src_format='1234',\ndst_format='1253'"
  },
  {
    "Title": "\n        Lack of validation in data format attributes\n      ",
    "Bug description": "The  tf.raw_ops.DataFormatVecPermute  API does not validate the  src_format  and  dst_format  attributes.  The code  assumes that these two arguments define a permutation of  NHWC .",
    "Sample Code": ">>> dst_format='8765')\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[1954047348, 1954047348],\n       [1852793646, 1852793646],\n       [1954047348, 1954047348],\n       [],\n       [1852793632, 1852793632]], dtype=int32)>",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c9f3-9wfr-wgh7",
    "API Signature": "tf.raw_ops.DataFormatVecPermute(\n    x, src_format='NHWC', dst_format='NCHW', name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Invalid string argument",
    "Category": "String",
    "Argument": "src_format='1234',\ndst_format='1223'"
  },
  {
    "Title": "\n        Lack of validation in data format attributes\n      ",
    "Bug description": "The  tf.raw_ops.DataFormatVecPermute  API does not validate the  src_format  and  dst_format  attributes.  The code  assumes that these two arguments define a permutation of  NHWC .",
    "Sample Code": ">>> dst_format='8765')\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[1954047348, 1954047348],\n       [1852793646, 1852793646],\n       [1954047348, 1954047348],\n       [],\n       [1852793632, 1852793632]], dtype=int32)>",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c9f3-9wfr-wgh7",
    "API Signature": "tf.raw_ops.DataFormatVecPermute(\n    x, src_format='NHWC', dst_format='NCHW', name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Invalid string argument",
    "Category": "String",
    "Argument": "src_format='1224',\ndst_format='1423'"
  },
  {
    "Title": "\n        Lack of validation in data format attributes\n      ",
    "Bug description": "The  tf.raw_ops.DataFormatVecPermute  API does not validate the  src_format  and  dst_format  attributes.  The code  assumes that these two arguments define a permutation of  NHWC .",
    "Sample Code": ">>> dst_format='8765')\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[1954047348, 1954047348],\n       [1852793646, 1852793646],\n       [1954047348, 1954047348],\n       [],\n       [1852793632, 1852793632]], dtype=int32)>",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c9f3-9wfr-wgh7",
    "API Signature": "tf.raw_ops.DataFormatVecPermute(\n    x, src_format='NHWC', dst_format='NCHW', name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Invalid string argument",
    "Category": "String",
    "Argument": "src_format='1224',\ndst_format='432'"
  },
  {
    "Title": "\n        Lack of validation in data format attributes\n      ",
    "Bug description": "The  tf.raw_ops.DataFormatVecPermute  API does not validate the  src_format  and  dst_format  attributes.  The code  assumes that these two arguments define a permutation of  NHWC .",
    "Sample Code": ">>> dst_format='8765')\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[1954047348, 1954047348],\n       [1852793646, 1852793646],\n       [1954047348, 1954047348],\n       [],\n       [1852793632, 1852793632]], dtype=int32)>",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c9f3-9wfr-wgh7",
    "API Signature": "tf.raw_ops.DataFormatVecPermute(\n    x, src_format='NHWC', dst_format='NCHW', name=None\n)\n",
    "Score": 0.028368794326241134,
    "Anomaly": "Invalid string argument",
    "Category": "String",
    "Argument": "src_format='12345678',\ndst_format='87654321'"
  },
  {
    "Title": "\n        Float cast overflow undefined behavior\n      ",
    "Bug description": "When the  boxes  argument of  tf.image.crop_and_resize  has a very large value, the CPU kernel implementation receives it as a C++  nan  floating point value. Attempting to operate on this is undefined behavior which later produces a segmentation fault.",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xwhf-g6j5-j5gc",
    "API Signature": "tf.image.crop_and_resize(\n    image,\n    boxes,\n    box_indices,\n    crop_size,\n    method='bilinear',\n    extrapolation_value=0.0,\n    name=None\n)\n",
    "Score": 0.014184397163120567,
    "Anomaly": "Large input tensor",
    "Category": "Tensor",
    "Argument": "boxes"
  },
  {
    "Title": "\n        Type confusion during tensor casts lead to dereferencing null pointers\n      ",
    "Bug description": "Calling TF operations with tensors of non-numeric types when the operations expect numeric tensors result in null pointer dereferences.",
    "Sample Code": "import numpy as np\n\nwriter_array = np.array([1,2],dtype=np.int32)\n)\nwriter_tensor = tf.convert_to_tensor(writer_array,dtype=tf.resource)",
    "Code change": [
      "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"tensorflow/python/lib/core/ndarray_tensor.h\"\n \n #include <cstring>\n+#include <optional>\n \n #include \"tensorflow/c/eager/tfe_context_internal.h\"\n #include \"tensorflow/c/tf_tensor_internal.h\"\n@@ -74,6 +75,13 @@ Status PyArrayDescr_to_TF_DataType(PyArray_Descr* descr,\n   PyObject* key;\n   PyObject* value;\n   Py_ssize_t pos = 0;\n+\n+  // Return an error if the fields attribute is null.\n+  // Occurs with an improper conversion attempt to resource.\n+  if (descr->fields == nullptr) {\n+    return errors::Internal(\"Unexpected numpy data type\");\n+  }\n+\n   if (PyDict_Next(descr->fields, &pos, &key, &value)) {\n     // In Python 3, the keys of numpy custom struct types are unicode, unlike\n     // Python 2, where the keys are bytes.\n"
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-452g-f7fp-9jf7",
    "API Signature": "tf.random.truncated_normal(\n    shape,\n    mean=0.0,\n    stddev=1.0,\n    dtype=tf.dtypes.float32,\n    seed=None,\n    name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Invalid data type",
    "Category": "Float",
    "Argument": "dtype=20"
  },
  {
    "Title": "\n        Segfault in `tf.quantization.quantize_and_dequantize`\n      ",
    "Bug description": "An attacker can pass an invalid  axis  value to  tf.quantization.quantize_and_dequantize :",
    "Sample Code": ".quantization.quantize_and_dequantize(\n    input=[2.5, 2.5], input_min=[0,0], input_max=[1,1], axis=10)",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rrfp-j2mp-hq9c",
    "API Signature": "tf.quantization.quantize_and_dequantize(\n    input,\n    input_min,\n    input_max,\n    signed_input=True,\n    num_bits=8,\n    range_given=False,\n    round_mode='HALF_TO_EVEN',\n    name=None,\n    narrow_range=False,\n    axis=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Integer",
    "Argument": "axis=10"
  },
  {
    "Title": "\n        Crash due to invalid shape of grad_values in SparseFillEmptyRowsGrad\n      ",
    "Bug description": "The  SparseFillEmptyRowsGrad  implementation has incomplete validation of the shapes of its arguments: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9mqp-7v2h-2382",
    "API Signature": "tf.raw_ops.SparseFillEmptyRowsGrad(\n    reverse_index_map, grad_values, name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Non vector input",
    "Category": "Tensor",
    "Argument": "grad_values"
  },
  {
    "Title": "\n        Crash due to invalid splits in SparseCountSparseOutput\n      ",
    "Bug description": "The  SparseCountSparseOutput  implementation does not validate that the input arguments form a valid sparse tensor. In particular, there is no validation that the  indices  tensor has rank 2. This tensor must be a matrix because code assumes its elements are accessed as elements of a matrix: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qc53-44cj-vfvx",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "indices = [[[0], [0]], [[0], [1]], [[1], [0]], [[1], [2]]]"
  },
  {
    "Title": "\n        Crash due to invalid splits in SparseCountSparseOutput\n      ",
    "Bug description": "The  SparseCountSparseOutput  implementation does not validate that the input arguments form a valid sparse tensor. In particular, there is no validation that the  indices  tensor has rank 2. This tensor must be a matrix because code assumes its elements are accessed as elements of a matrix: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qc53-44cj-vfvx",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "N.A",
    "Argument": "N.A"
  },
  {
    "Title": "\n        Abort due to invalid splits in RaggedCountSparseOutput\n      ",
    "Bug description": "The  RaggedCountSparseOutput  does not validate that the input arguments form a valid ragged tensor. In particular, there is no validation that the  splits  tensor has the minimum required number of elements. Code uses this quantity to initialize a different data structure: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x5cp-9pcf-pp3h",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "indices = [[[0], [0]], [[0], [1]], [[1], [0]], [[1], [2]]]"
  },
  {
    "Title": "\n        Abort due to invalid splits in RaggedCountSparseOutput\n      ",
    "Bug description": "The  RaggedCountSparseOutput  does not validate that the input arguments form a valid ragged tensor. In particular, there is no validation that the  splits  tensor has the minimum required number of elements. Code uses this quantity to initialize a different data structure: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x5cp-9pcf-pp3h",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "splits = [0, 5]\nvalues = [1, 1, 2, 1, 2, 10, 5]"
  },
  {
    "Title": "\n        Abort due to invalid splits in RaggedCountSparseOutput\n      ",
    "Bug description": "The  RaggedCountSparseOutput  does not validate that the input arguments form a valid ragged tensor. In particular, there is no validation that the  splits  tensor has the minimum required number of elements. Code uses this quantity to initialize a different data structure: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x5cp-9pcf-pp3h",
    "API Signature": "tf.raw_ops.RaggedCountSparseOutput(\n    splits,\n    values,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "indices = [[[0], [0]], [[0], [1]], [[1], [0]], [[1], [2]]]"
  },
  {
    "Title": "\n        Heap buffer overflow due to invalid indices in SparseCountSparseOutput\n      ",
    "Bug description": "The  SparseCountSparseOutput  implementation does not validate that the input arguments form a valid sparse tensor. In particular, there is no validation that the  indices  tensor has the same shape as the  values  one. The values in these tensors are always accessed in parallel: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jc87-6vpp-7ff3",
    "API Signature": "tf.raw_ops.RaggedCountSparseOutput(\n    splits,\n    values,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "values = [1, 1, 1, 10]\nweights = [1, 2, 4]"
  },
  {
    "Title": "\n        Heap buffer overflow due to invalid indices in SparseCountSparseOutput\n      ",
    "Bug description": "The  SparseCountSparseOutput  implementation does not validate that the input arguments form a valid sparse tensor. In particular, there is no validation that the  indices  tensor has the same shape as the  values  one. The values in these tensors are always accessed in parallel: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jc87-6vpp-7ff3",
    "API Signature": "tf.raw_ops.RaggedCountSparseOutput(\n    splits,\n    values,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "indices = [[0, 0], [0, 1], [1, 0]]\nvalues = [1, 1, 1, 10]"
  },
  {
    "Title": "\n        Heap buffer overflow due to invalid indices in SparseCountSparseOutput\n      ",
    "Bug description": "The  SparseCountSparseOutput  implementation does not validate that the input arguments form a valid sparse tensor. In particular, there is no validation that the  indices  tensor has the same shape as the  values  one. The values in these tensors are always accessed in parallel: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jc87-6vpp-7ff3",
    "API Signature": "tf.raw_ops.RaggedCountSparseOutput(\n    splits,\n    values,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "List",
    "Argument": "splits = []"
  },
  {
    "Title": "\n        Heap buffer overflow due to invalid indices in SparseCountSparseOutput\n      ",
    "Bug description": "The  SparseCountSparseOutput  implementation does not validate that the input arguments form a valid sparse tensor. In particular, there is no validation that the  indices  tensor has the same shape as the  values  one. The values in these tensors are always accessed in parallel: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jc87-6vpp-7ff3",
    "API Signature": "tf.raw_ops.RaggedCountSparseOutput(\n    splits,\n    values,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.0035460992907801418,
    "Anomaly": "First element other than zero",
    "Category": NaN,
    "Argument": "splits = [1, 7]"
  },
  {
    "Title": "\n        Heap buffer overflow due to invalid indices in SparseCountSparseOutput\n      ",
    "Bug description": "The  SparseCountSparseOutput  implementation does not validate that the input arguments form a valid sparse tensor. In particular, there is no validation that the  indices  tensor has the same shape as the  values  one. The values in these tensors are always accessed in parallel: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jc87-6vpp-7ff3",
    "API Signature": "tf.raw_ops.RaggedCountSparseOutput(\n    splits,\n    values,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.13829787234042554,
    "Anomaly": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "indices = [[[0], [0]], [[0], [1]], [[1], [0]], [[1], [2]]]"
  },
  {
    "Title": "\n        Heap buffer overflow due to invalid indices in SparseCountSparseOutput\n      ",
    "Bug description": "The  SparseCountSparseOutput  implementation does not validate that the input arguments form a valid sparse tensor. In particular, there is no validation that the  indices  tensor has the same shape as the  values  one. The values in these tensors are always accessed in parallel: \n",
    "Sample Code": "",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jc87-6vpp-7ff3",
    "API Signature": "tf.raw_ops.RaggedCountSparseOutput(\n    splits,\n    values,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.19858156028368795,
    "Anomaly": "Dimension mismatch",
    "Category": "Tensor",
    "Argument": "splits = [0, 5]\nvalues = [1, 1, 2, 1, 2, 10, 5]"
  },
  {
    "Title": "\n        Data leak in `tf.raw_ops.StringNGrams`\n      ",
    "Bug description": "The  data_splits  argument of  tf.raw_ops.StringNGrams  lacks validation. This allows a user to pass values that can cause heap overflow errors and even leak contents of memory",
    "Sample Code": "StringNGrams(ngrams=<tf.Tensor: shape=(6,), dtype=string, numpy=\narray([b'aa bb cc', b'bb cc dd', b'cc dd ee', b'dd ee ff',\n       b'ee ff ,\n       ,\n       b'ff ],...",
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-g7p5-5759-qv46",
    "API Signature": "tf.raw_ops.StringNGrams(\n    data,\n    data_splits,\n    separator,\n    ngram_widths,\n    left_pad,\n    right_pad,\n    pad_width,\n    preserve_short_sequences,\n    name=None\n)\n",
    "Score": 0.0070921985815602835,
    "Anomaly": "Invalid string list element",
    "Category": "List",
    "Argument": "data=[\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\"]"
  }
]
