[
    {
    "Title": "\n        `CHECK` fail in `QuantizeAndDequantizeV3`\n      ",
    "Bug description": "If  QuantizeAndDequantizeV3  is given a nonscalar  num_bits  input tensor, it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "signed_input = True\nrange_given = False\nnarrow_range = False\naxis = -1\ninput = tf.constant(-3.5, shape=[1], dtype=tf.float32)\ninput_min = tf.constant(-3.5, shape=[1], dtype=tf.float32)\ninput_max = tf.constant(-3.5, shape=[1], dtype=tf.float32)\nnum_bits = tf.constant([], shape=[0], dtype=tf.int32)\n)\ntf.raw_ops.QuantizeAndDequantizeV3(input=input, input_min=input_min, input_max=input_max, num_bits=num_bits, signed_input=signed_input, range_given=range_given, narrow_range=narrow_range, axis=axis)",
    "Code change": [
        "@@ -21,19 +21,23 @@ limitations under the License.\n #define EIGEN_USE_GPU\n #endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n \n-#include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"\n-\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/type_traits.h\"\n #include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n \n namespace tensorflow {\n+namespace {\n \n-typedef Eigen::ThreadPoolDevice CPUDevice;\n-typedef Eigen::GpuDevice GPUDevice;\n+using CpuDevice = ::Eigen::ThreadPoolDevice;\n+using GpuDevice = ::Eigen::GpuDevice;\n+using ::tensorflow::errors::InvalidArgument;\n+\n+}  // namespace\n \n // Simulate quantization precision loss in a float tensor by:\n // 1. Quantize the tensor to fixed point numbers, which should match the target\n@@ -49,8 +53,8 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n-                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n-                                        \" with signed_input_ \", signed_input_));\n+                InvalidArgument(\"num_bits is out of range: \", num_bits_,\n+                                \" with signed_input_ \", signed_input_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n \n     string round_mode_string;\n@@ -58,10 +62,10 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n     OP_REQUIRES(\n         ctx,\n         (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),\n-        errors::InvalidArgument(\"Round mode string must be \"\n-                                \"'HALF_UP' or \"\n-                                \"'HALF_TO_EVEN', is '\" +\n-                                round_mode_string + \"'\"));\n+        InvalidArgument(\"Round mode string must be \"\n+                        \"'HALF_UP' or \"\n+                        \"'HALF_TO_EVEN', is '\" +\n+                        round_mode_string + \"'\"));\n     if (round_mode_string == \"HALF_UP\") {\n       round_mode_ = ROUND_HALF_UP;\n     } else if (round_mode_string == \"HALF_TO_EVEN\") {\n@@ -72,12 +76,10 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n-    OP_REQUIRES(\n-        ctx, axis_ >= -1,\n-        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n-    OP_REQUIRES(\n-        ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n-        errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,\n+    OP_REQUIRES(ctx, axis_ >= -1,\n+                InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n+    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n+                InvalidArgument(\"Shape must be at least rank \", axis_ + 1,\n                                 \" but is rank \", input.shape().dims()));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     Tensor input_min_tensor;\n@@ -91,21 +93,21 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n         auto min_val = input_min_tensor.scalar<T>()();\n         auto max_val = input_max_tensor.scalar<T>()();\n         OP_REQUIRES(ctx, min_val <= max_val,\n-                    errors::InvalidArgument(\"Invalid range: input_min \",\n-                                            min_val, \" > input_max \", max_val));\n+                    InvalidArgument(\"Invalid range: input_min \", min_val,\n+                                    \" > input_max \", max_val));\n       } else {\n-        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_min_tensor has incorrect size, was \",\n-                        input_min_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_min_tensor.shape()));\n-        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_max_tensor has incorrect size, was \",\n-                        input_max_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_max_tensor.shape()));\n+        OP_REQUIRES(\n+            ctx, input_min_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_min_tensor has incorrect size, was \",\n+                            input_min_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_min_tensor.shape()));\n+        OP_REQUIRES(\n+            ctx, input_max_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_max_tensor has incorrect size, was \",\n+                            input_max_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_max_tensor.shape()));\n       }\n     } else {\n       auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n@@ -158,38 +160,34 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n     Tensor* input_backprop = nullptr;\n     OP_REQUIRES_OK(ctx,\n                    ctx->allocate_output(0, input.shape(), &input_backprop));\n-    OP_REQUIRES(\n-        ctx, axis_ >= -1,\n-        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n+    OP_REQUIRES(ctx, axis_ >= -1,\n+                InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n     OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n-                errors::InvalidArgument(\n+                InvalidArgument(\n                     \"Axis should be -1 or 0 or a positive value less than \",\n                     input.shape().dims(), \"but given axis value was \", axis_));\n \n-    OP_REQUIRES(\n-        ctx, input.IsSameSize(gradient),\n-        errors::InvalidArgument(\"gradient and input must be the same size\"));\n+    OP_REQUIRES(ctx, input.IsSameSize(gradient),\n+                InvalidArgument(\"gradient and input must be the same size\"));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     const Tensor& input_min_tensor = ctx->input(2);\n     OP_REQUIRES(ctx,\n                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n-                errors::InvalidArgument(\n+                InvalidArgument(\n                     \"Input min tensor must have dimension 0 or 1. Received \",\n                     input_min_tensor.dims(), \".\"));\n     const Tensor& input_max_tensor = ctx->input(3);\n     OP_REQUIRES(ctx,\n                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n-                errors::InvalidArgument(\n+                InvalidArgument(\n                     \"Input max tensor must have dimension 0 or 1. Received \",\n                     input_max_tensor.dims(), \".\"));\n     if (axis_ != -1) {\n-      OP_REQUIRES(\n-          ctx, input_min_tensor.dim_size(0) == depth,\n-          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n+      OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n+                  InvalidArgument(\"min has incorrect size, expected \", depth,\n                                   \" was \", input_min_tensor.dim_size(0)));\n-      OP_REQUIRES(\n-          ctx, input_max_tensor.dim_size(0) == depth,\n-          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n+      OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n+                  InvalidArgument(\"max has incorrect size, expected \", depth,\n                                   \" was \", input_max_tensor.dim_size(0)));\n     }\n \n@@ -203,12 +201,12 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n \n     if (axis_ == -1) {\n-      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n-                  errors::InvalidArgument(\n-                      \"input_min must be a scalar if axis is unspecified\"));\n-      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n-                  errors::InvalidArgument(\n-                      \"input_max must be a scalar if axis is unspecified\"));\n+      OP_REQUIRES(\n+          ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n+          InvalidArgument(\"input_min must be a scalar if axis is unspecified\"));\n+      OP_REQUIRES(\n+          ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n+          InvalidArgument(\"input_max must be a scalar if axis is unspecified\"));\n       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n         input.template flat<T>(), input_min_tensor.scalar<T>(),\n@@ -252,21 +250,25 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n     OP_REQUIRES(ctx, axis_ < input.dims(),\n-                errors::InvalidArgument(\n+                InvalidArgument(\n                     \"Axis requested is larger than input dimensions. Axis: \",\n                     axis_, \" Input Dimensions: \", input.dims()));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n \n-    Tensor num_bits_tensor;\n-    num_bits_tensor = ctx->input(3);\n-    int num_bits_val = num_bits_tensor.scalar<int32>()();\n+    // Get num_bits and validate.\n+    const Tensor num_bits_tensor = ctx->input(3);\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(num_bits_tensor.shape()),\n+                InvalidArgument(\"Invalid shape. The `num_bits` tensor should \"\n+                                \"be a scalar. Got dimensions: \",\n+                                num_bits_tensor.dims()));\n \n-    OP_REQUIRES(\n-        ctx, num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),\n-        errors::InvalidArgument(\"num_bits is out of range: \", num_bits_val,\n-                                \" with signed_input_ \", signed_input_));\n+    const int num_bits_val = num_bits_tensor.scalar<int32>()();\n+    OP_REQUIRES(ctx,\n+                num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),\n+                InvalidArgument(\"num_bits is out of range: \", num_bits_val,\n+                                \" with `signed_input_` \", signed_input_));\n \n     Tensor input_min_tensor;\n     Tensor input_max_tensor;\n@@ -274,24 +276,24 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\n       input_min_tensor = ctx->input(1);\n       input_max_tensor = ctx->input(2);\n       if (axis_ == -1) {\n-        auto min_val = input_min_tensor.scalar<T>()();\n-        auto max_val = input_max_tensor.scalar<T>()();\n+        const auto min_val = input_min_tensor.scalar<T>()();\n+        const auto max_val = input_max_tensor.scalar<T>()();\n         OP_REQUIRES(ctx, min_val <= max_val,\n-                    errors::InvalidArgument(\"Invalid range: input_min \",\n-                                            min_val, \" > input_max \", max_val));\n+                    InvalidArgument(\"Invalid range: input_min \", min_val,\n+                                    \" > input_max \", max_val));\n       } else {\n-        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_min_tensor has incorrect size, was \",\n-                        input_min_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_min_tensor.shape()));\n-        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_max_tensor has incorrect size, was \",\n-                        input_max_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_max_tensor.shape()));\n+        OP_REQUIRES(\n+            ctx, input_min_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_min_tensor has incorrect size, was \",\n+                            input_min_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_min_tensor.shape()));\n+        OP_REQUIRES(\n+            ctx, input_max_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_max_tensor has incorrect size, was \",\n+                            input_max_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_max_tensor.shape()));\n       }\n     } else {\n       auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n@@ -331,15 +333,14 @@ class QuantizeAndDequantizeOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n-                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n-                                        \" with signed_input_ \", signed_input_));\n+                InvalidArgument(\"num_bits is out of range: \", num_bits_,\n+                                \" with signed_input_ \", signed_input_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));\n     if (range_given_) {\n-      OP_REQUIRES(\n-          ctx, input_min_ <= input_max_,\n-          errors::InvalidArgument(\"Invalid range: input_min \", input_min_,\n+      OP_REQUIRES(ctx, input_min_ <= input_max_,\n+                  InvalidArgument(\"Invalid range: input_min \", input_min_,\n                                   \" > input_max \", input_max_));\n     }\n   }\n@@ -371,53 +372,53 @@ class QuantizeAndDequantizeOp : public OpKernel {\n   float input_max_;\n };\n \n-// Specializations for CPUDevice.\n+// Specializations for CpuDevice.\n \n namespace functor {\n template <typename T>\n-struct QuantizeAndDequantizeOneScaleFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d, typename TTypes<T>::ConstVec input,\n+struct QuantizeAndDequantizeOneScaleFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d, typename TTypes<T>::ConstVec input,\n                   const bool signed_input, const int num_bits,\n                   const bool range_given, Tensor* input_min_tensor,\n                   Tensor* input_max_tensor, QuantizerRoundMode round_mode,\n                   bool narrow_range, typename TTypes<T>::Vec out) {\n-    QuantizeAndDequantizeOneScaleImpl<CPUDevice, T>::Compute(\n+    QuantizeAndDequantizeOneScaleImpl<CpuDevice, T>::Compute(\n         d, input, signed_input, num_bits, range_given, input_min_tensor,\n         input_max_tensor, round_mode, narrow_range, out);\n   }\n };\n \n template <typename T>\n-struct QuantizeAndDequantizePerChannelFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d, typename TTypes<T, 3>::ConstTensor input,\n+struct QuantizeAndDequantizePerChannelFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d, typename TTypes<T, 3>::ConstTensor input,\n                   bool signed_input, int num_bits, bool range_given,\n                   Tensor* input_min_tensor, Tensor* input_max_tensor,\n                   QuantizerRoundMode round_mode, bool narrow_range,\n                   typename TTypes<T, 3>::Tensor out) {\n-    QuantizeAndDequantizePerChannelImpl<CPUDevice, T>::Compute(\n+    QuantizeAndDequantizePerChannelImpl<CpuDevice, T>::Compute(\n         d, input, signed_input, num_bits, range_given, input_min_tensor,\n         input_max_tensor, round_mode, narrow_range, out);\n   }\n };\n \n template <typename T>\n-struct QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d, typename TTypes<T>::ConstFlat gradient,\n+struct QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d, typename TTypes<T>::ConstFlat gradient,\n                   typename TTypes<T>::ConstFlat input,\n                   typename TTypes<T>::ConstScalar input_min_tensor,\n                   typename TTypes<T>::ConstScalar input_max_tensor,\n                   typename TTypes<T>::Flat input_backprop,\n                   typename TTypes<T>::Scalar input_min_backprop,\n                   typename TTypes<T>::Scalar input_max_backprop) {\n-    QuantizeAndDequantizeOneScaleGradientImpl<CPUDevice, T>::Compute(\n+    QuantizeAndDequantizeOneScaleGradientImpl<CpuDevice, T>::Compute(\n         d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,\n         input_min_backprop, input_max_backprop);\n   }\n };\n \n template <typename T>\n-struct QuantizeAndDequantizePerChannelGradientFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d,\n+struct QuantizeAndDequantizePerChannelGradientFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d,\n                   typename TTypes<T, 3>::ConstTensor gradient,\n                   typename TTypes<T, 3>::ConstTensor input,\n                   const Tensor* input_min_tensor,\n@@ -425,16 +426,16 @@ struct QuantizeAndDequantizePerChannelGradientFunctor<CPUDevice, T> {\n                   typename TTypes<T, 3>::Tensor input_backprop,\n                   typename TTypes<T>::Flat input_min_backprop,\n                   typename TTypes<T>::Flat input_max_backprop) {\n-    QuantizeAndDequantizePerChannelGradientImpl<CPUDevice, T>::Compute(\n+    QuantizeAndDequantizePerChannelGradientImpl<CpuDevice, T>::Compute(\n         d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,\n         input_min_backprop, input_max_backprop);\n   }\n };\n \n-template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice,\n+template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice,\n                                                                       float>;\n template struct functor::QuantizeAndDequantizePerChannelGradientFunctor<\n-    CPUDevice, double>;\n+    CpuDevice, double>;\n \n }  // namespace functor\n \n@@ -442,22 +443,22 @@ template struct functor::QuantizeAndDequantizePerChannelGradientFunctor<\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV2\")                      \\\n                               .Device(DEVICE_CPU)                              \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\\n                               .Device(DEVICE_CPU)                              \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV3Op<CPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV3Op<CpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\\n                               .Device(DEVICE_CPU)                              \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\\n                               .Device(DEVICE_CPU)                              \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV4GradientOp<CPUDevice, T>);    \\\n+                          QuantizeAndDequantizeV4GradientOp<CpuDevice, T>);    \\\n   REGISTER_KERNEL_BUILDER(                                                     \\\n       Name(\"QuantizeAndDequantize\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n-      QuantizeAndDequantizeOp<CPUDevice, T>);\n+      QuantizeAndDequantizeOp<CpuDevice, T>);\n TF_CALL_float(REGISTER_CPU_KERNEL);\n TF_CALL_double(REGISTER_CPU_KERNEL);\n #undef REGISTER_CPU_KERNEL\n@@ -470,29 +471,29 @@ TF_CALL_double(REGISTER_CPU_KERNEL);\n                               .HostMemory(\"input_min\")                         \\\n                               .HostMemory(\"input_max\")                         \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\\n                               .Device(DEVICE_GPU)                              \\\n                               .HostMemory(\"input_min\")                         \\\n                               .HostMemory(\"input_max\")                         \\\n                               .HostMemory(\"num_bits\")                          \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV3Op<GPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV3Op<GpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\\n                               .Device(DEVICE_GPU)                              \\\n                               .HostMemory(\"input_min\")                         \\\n                               .HostMemory(\"input_max\")                         \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\\n+                          QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\\n   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\\n                               .Device(DEVICE_GPU)                              \\\n                               .HostMemory(\"input_min\")                         \\\n                               .HostMemory(\"input_max\")                         \\\n                               .TypeConstraint<T>(\"T\"),                         \\\n-                          QuantizeAndDequantizeV4GradientOp<GPUDevice, T>);    \\\n+                          QuantizeAndDequantizeV4GradientOp<GpuDevice, T>);    \\\n   REGISTER_KERNEL_BUILDER(                                                     \\\n       Name(\"QuantizeAndDequantize\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\\n-      QuantizeAndDequantizeOp<GPUDevice, T>);\n+      QuantizeAndDequantizeOp<GpuDevice, T>);\n TF_CALL_float(REGISTER_GPU_KERNEL);\n TF_CALL_double(REGISTER_GPU_KERNEL);\n #undef REGISTER_GPU_KERNEL\n",
        "@@ -15,9 +15,11 @@\n \"\"\"Tests for tf.quantize ops.\"\"\"\n import numpy as np\n \n+from tensorflow.python.eager import context\n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors\n+from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import math_ops\n@@ -407,5 +409,59 @@ class QuantizeDownAndShrinkRangeOpTest(test_util.TensorFlowTestCase):\n               out_type=dtypes.quint8))\n \n \n+class QuantizeAndDequantizeV3OpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_valid(self):\n+    with ops.Graph().as_default(), context.eager_mode():\n+      input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],\n+                                         shape=(6,),\n+                                         dtype=dtypes.float32),\n+      input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)\n+      input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)\n+      num_bits = constant_op.constant(8, shape=(), dtype=dtypes.int32)\n+\n+      quantized = array_ops.quantize_and_dequantize_v3(\n+          input_value,\n+          input_min,\n+          input_max,\n+          num_bits,\n+          signed_input=True,\n+          range_given=False)\n+      self.assertSequenceAlmostEqual(\n+          input_value[0].numpy(), quantized.numpy()[0], delta=0.05)\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],\n+                                       shape=(6,),\n+                                       dtype=dtypes.float32),\n+    input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)\n+    input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)\n+    # Tensor with invalid shape and invalid number of elements.\n+    num_bits = constant_op.constant([], shape=(0,), dtype=dtypes.int32)\n+\n+    # Test that running the op raises error. It raises different errors\n+    # depending on whether the shape inference is run first or the op's\n+    # Compute() is run first.\n+    try:\n+      array_ops.quantize_and_dequantize_v3(\n+          input_value, input_min, input_max, num_bits, signed_input=True)\n+    except Exception as ex:  # pylint: disable=broad-except\n+      if isinstance(ex, errors.InvalidArgumentError):\n+        self.assertRegex(str(ex), \"The `num_bits` tensor should be a scalar.\")\n+      elif isinstance(ex, ValueError):\n+        self.assertRegex(str(ex), \"Shape must be rank 0\")\n+      else:\n+        self.fail(\n+            \"Raised exception other than expected: %s. \"\n+            \"Expected exceptions are errors.InvalidArgumentError or ValueError\",\n+            ex.__name__)\n+    else:\n+      self.fail(\n+          \"Did not raise an exception where it is expected to raise either \"\n+          \"a ValueError or errors.InvalidArgumentError.\")\n+\n+\n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Buggy Code": [
        [
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "",
            "#include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"",
            "",
            "#include \"tensorflow/core/framework/op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/type_traits.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "",
            "namespace tensorflow {",
            "",
            "typedef Eigen::ThreadPoolDevice CPUDevice;",
            "typedef Eigen::GpuDevice GPUDevice;",
            "",
            "// Simulate quantization precision loss in a float tensor by:",
            "// 1. Quantize the tensor to fixed point numbers, which should match the target",
            "//    quantization method when it is used in inference.",
            "// 2. Dequantize it back to floating point numbers for the following ops, most",
            "//    likely matmul.",
            "template <typename Device, typename T>",
            "class QuantizeAndDequantizeV2Op : public OpKernel {"
        ],
        [
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));",
            "",
            "    string round_mode_string;",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"round_mode\", &round_mode_string));",
            "    OP_REQUIRES(",
            "        ctx,",
            "        (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),",
            "        errors::InvalidArgument(\"Round mode string must be \""
        ],
        [
            "                                \"'HALF_TO_EVEN', is '\" +",
            "                                round_mode_string + \"'\"));",
            "    if (round_mode_string == \"HALF_UP\") {",
            "      round_mode_ = ROUND_HALF_UP;",
            "    } else if (round_mode_string == \"HALF_TO_EVEN\") {",
            "      round_mode_ = ROUND_HALF_TO_EVEN;",
            "    }",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"narrow_range\", &narrow_range_));",
            "  }",
            ""
        ],
        [
            "        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
            "    OP_REQUIRES(",
            "        ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
            "        errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,",
            "                                \" but is rank \", input.shape().dims()));",
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    Tensor input_min_tensor;",
            "    Tensor input_max_tensor;",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));"
        ],
        [
            "                    errors::InvalidArgument(\"Invalid range: input_min \",",
            "                                            min_val, \" > input_max \", max_val));",
            "      } else {",
            "        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
            "                    errors::InvalidArgument(",
            "                        \"input_min_tensor has incorrect size, was \",",
            "                        input_min_tensor.dim_size(0), \" expected \", depth,",
            "                        \" to match dim \", axis_, \" of the input \",",
            "                        input_min_tensor.shape()));",
            "        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
            "                    errors::InvalidArgument(",
            "                        \"input_max_tensor has incorrect size, was \",",
            "                        input_max_tensor.dim_size(0), \" expected \", depth,",
            "                        \" to match dim \", axis_, \" of the input \",",
            "                        input_max_tensor.shape()));",
            "      }",
            "    } else {",
            "      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});",
            "      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,",
            "                                             range_shape, &input_min_tensor));",
            "      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,"
        ],
        [
            "    OP_REQUIRES(",
            "        ctx, axis_ >= -1,",
            "        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
            "    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
            "                errors::InvalidArgument(",
            "                    \"Axis should be -1 or 0 or a positive value less than \",",
            "                    input.shape().dims(), \"but given axis value was \", axis_));",
            "",
            "    OP_REQUIRES(",
            "        ctx, input.IsSameSize(gradient),",
            "        errors::InvalidArgument(\"gradient and input must be the same size\"));",
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    const Tensor& input_min_tensor = ctx->input(2);",
            "    OP_REQUIRES(ctx,",
            "                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,",
            "                errors::InvalidArgument(",
            "                    \"Input min tensor must have dimension 0 or 1. Received \",",
            "                    input_min_tensor.dims(), \".\"));",
            "    const Tensor& input_max_tensor = ctx->input(3);",
            "    OP_REQUIRES(ctx,",
            "                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,",
            "                errors::InvalidArgument(",
            "                    \"Input max tensor must have dimension 0 or 1. Received \",",
            "                    input_max_tensor.dims(), \".\"));",
            "    if (axis_ != -1) {",
            "      OP_REQUIRES(",
            "          ctx, input_min_tensor.dim_size(0) == depth,",
            "          errors::InvalidArgument(\"min has incorrect size, expected \", depth,",
            "                                  \" was \", input_min_tensor.dim_size(0)));",
            "      OP_REQUIRES(",
            "          ctx, input_max_tensor.dim_size(0) == depth,",
            "          errors::InvalidArgument(\"max has incorrect size, expected \", depth,",
            "                                  \" was \", input_max_tensor.dim_size(0)));",
            "    }"
        ],
        [
            "    OP_REQUIRES_OK(ctx,",
            "                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));",
            "",
            "    if (axis_ == -1) {",
            "      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),",
            "                  errors::InvalidArgument(",
            "                      \"input_min must be a scalar if axis is unspecified\"));",
            "      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),",
            "                  errors::InvalidArgument(",
            "                      \"input_max must be a scalar if axis is unspecified\"));",
            "      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;",
            "      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),"
        ],
        [
            "",
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& input = ctx->input(0);",
            "    OP_REQUIRES(ctx, axis_ < input.dims(),",
            "                errors::InvalidArgument(",
            "                    \"Axis requested is larger than input dimensions. Axis: \",",
            "                    axis_, \" Input Dimensions: \", input.dims()));",
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
            "",
            "    Tensor num_bits_tensor;",
            "    num_bits_tensor = ctx->input(3);",
            "    int num_bits_val = num_bits_tensor.scalar<int32>()();",
            "",
            "    OP_REQUIRES(",
            "        ctx, num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),",
            "        errors::InvalidArgument(\"num_bits is out of range: \", num_bits_val,",
            "                                \" with signed_input_ \", signed_input_));",
            "",
            "    Tensor input_min_tensor;",
            "    Tensor input_max_tensor;",
            "    if (range_given_) {",
            "      input_min_tensor = ctx->input(1);",
            "      input_max_tensor = ctx->input(2);"
        ],
        [
            "        auto min_val = input_min_tensor.scalar<T>()();",
            "        auto max_val = input_max_tensor.scalar<T>()();",
            "        OP_REQUIRES(ctx, min_val <= max_val,",
            "                    errors::InvalidArgument(\"Invalid range: input_min \",",
            "                                            min_val, \" > input_max \", max_val));",
            "      } else {",
            "        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
            "                    errors::InvalidArgument(",
            "                        \"input_min_tensor has incorrect size, was \",",
            "                        input_min_tensor.dim_size(0), \" expected \", depth,",
            "                        \" to match dim \", axis_, \" of the input \",",
            "                        input_min_tensor.shape()));",
            "        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
            "                    errors::InvalidArgument(",
            "                        \"input_max_tensor has incorrect size, was \",",
            "                        input_max_tensor.dim_size(0), \" expected \", depth,",
            "                        \" to match dim \", axis_, \" of the input \",",
            "                        input_max_tensor.shape()));",
            "      }",
            "    } else {",
            "      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});",
            "      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,",
            "                                             range_shape, &input_min_tensor));",
            "      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,"
        ],
        [
            "                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,",
            "                                        \" with signed_input_ \", signed_input_));",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));",
            "    if (range_given_) {",
            "      OP_REQUIRES(",
            "          ctx, input_min_ <= input_max_,",
            "          errors::InvalidArgument(\"Invalid range: input_min \", input_min_,",
            "                                  \" > input_max \", input_max_));",
            "    }",
            "  }",
            "",
            "  void Compute(OpKernelContext* ctx) override {"
        ],
        [
            "",
            "// Specializations for CPUDevice.",
            "",
            "namespace functor {",
            "template <typename T>",
            "struct QuantizeAndDequantizeOneScaleFunctor<CPUDevice, T> {",
            "  void operator()(const CPUDevice& d, typename TTypes<T>::ConstVec input,",
            "                  const bool signed_input, const int num_bits,",
            "                  const bool range_given, Tensor* input_min_tensor,",
            "                  Tensor* input_max_tensor, QuantizerRoundMode round_mode,",
            "                  bool narrow_range, typename TTypes<T>::Vec out) {",
            "    QuantizeAndDequantizeOneScaleImpl<CPUDevice, T>::Compute(",
            "        d, input, signed_input, num_bits, range_given, input_min_tensor,",
            "        input_max_tensor, round_mode, narrow_range, out);",
            "  }",
            "};",
            "",
            "template <typename T>",
            "struct QuantizeAndDequantizePerChannelFunctor<CPUDevice, T> {",
            "  void operator()(const CPUDevice& d, typename TTypes<T, 3>::ConstTensor input,",
            "                  bool signed_input, int num_bits, bool range_given,",
            "                  Tensor* input_min_tensor, Tensor* input_max_tensor,",
            "                  QuantizerRoundMode round_mode, bool narrow_range,",
            "                  typename TTypes<T, 3>::Tensor out) {",
            "    QuantizeAndDequantizePerChannelImpl<CPUDevice, T>::Compute(",
            "        d, input, signed_input, num_bits, range_given, input_min_tensor,",
            "        input_max_tensor, round_mode, narrow_range, out);",
            "  }",
            "};",
            "",
            "template <typename T>",
            "struct QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice, T> {",
            "  void operator()(const CPUDevice& d, typename TTypes<T>::ConstFlat gradient,",
            "                  typename TTypes<T>::ConstFlat input,",
            "                  typename TTypes<T>::ConstScalar input_min_tensor,",
            "                  typename TTypes<T>::ConstScalar input_max_tensor,",
            "                  typename TTypes<T>::Flat input_backprop,",
            "                  typename TTypes<T>::Scalar input_min_backprop,",
            "                  typename TTypes<T>::Scalar input_max_backprop) {",
            "    QuantizeAndDequantizeOneScaleGradientImpl<CPUDevice, T>::Compute(",
            "        d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,",
            "        input_min_backprop, input_max_backprop);",
            "  }",
            "};",
            "",
            "template <typename T>",
            "struct QuantizeAndDequantizePerChannelGradientFunctor<CPUDevice, T> {",
            "  void operator()(const CPUDevice& d,",
            "                  typename TTypes<T, 3>::ConstTensor gradient,",
            "                  typename TTypes<T, 3>::ConstTensor input,",
            "                  const Tensor* input_min_tensor,",
            "                  const Tensor* input_max_tensor,",
            "                  typename TTypes<T, 3>::Tensor input_backprop,"
        ],
        [
            "                  typename TTypes<T>::Flat input_max_backprop) {",
            "    QuantizeAndDequantizePerChannelGradientImpl<CPUDevice, T>::Compute(",
            "        d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,",
            "        input_min_backprop, input_max_backprop);",
            "  }",
            "};",
            "",
            "template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice,",
            "                                                                      float>;",
            "template struct functor::QuantizeAndDequantizePerChannelGradientFunctor<",
            "    CPUDevice, double>;",
            "",
            "}  // namespace functor",
            "",
            "#define REGISTER_CPU_KERNEL(T)                                                 \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV2\")                      \\"
        ],
        [
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
            "                              .Device(DEVICE_CPU)                              \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV3Op<CPUDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
            "                              .Device(DEVICE_CPU)                              \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
            "                              .Device(DEVICE_CPU)                              \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV4GradientOp<CPUDevice, T>);    \\",
            "  REGISTER_KERNEL_BUILDER(                                                     \\",
            "      Name(\"QuantizeAndDequantize\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      QuantizeAndDequantizeOp<CPUDevice, T>);",
            "TF_CALL_float(REGISTER_CPU_KERNEL);",
            "TF_CALL_double(REGISTER_CPU_KERNEL);",
            "#undef REGISTER_CPU_KERNEL",
            "",
            "#if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\"
        ],
        [
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
            "                              .Device(DEVICE_GPU)                              \\",
            "                              .HostMemory(\"input_min\")                         \\",
            "                              .HostMemory(\"input_max\")                         \\",
            "                              .HostMemory(\"num_bits\")                          \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV3Op<GPUDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
            "                              .Device(DEVICE_GPU)                              \\",
            "                              .HostMemory(\"input_min\")                         \\",
            "                              .HostMemory(\"input_max\")                         \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
            "                              .Device(DEVICE_GPU)                              \\",
            "                              .HostMemory(\"input_min\")                         \\",
            "                              .HostMemory(\"input_max\")                         \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV4GradientOp<GPUDevice, T>);    \\",
            "  REGISTER_KERNEL_BUILDER(                                                     \\",
            "      Name(\"QuantizeAndDequantize\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
            "      QuantizeAndDequantizeOp<GPUDevice, T>);",
            "TF_CALL_float(REGISTER_GPU_KERNEL);",
            "TF_CALL_double(REGISTER_GPU_KERNEL);",
            "#undef REGISTER_GPU_KERNEL",
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "}  // namespace tensorflow"
        ]
    ],
    "Clean Code": [
        [
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "",
            "#include \"tensorflow/core/framework/op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/framework/type_traits.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "",
            "namespace tensorflow {",
            "namespace {",
            "",
            "using CpuDevice = ::Eigen::ThreadPoolDevice;",
            "using GpuDevice = ::Eigen::GpuDevice;",
            "using ::tensorflow::errors::InvalidArgument;",
            "",
            "}  // namespace",
            "",
            "// Simulate quantization precision loss in a float tensor by:",
            "// 1. Quantize the tensor to fixed point numbers, which should match the target",
            "//    quantization method when it is used in inference."
        ],
        [
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));",
            "    OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),",
            "                InvalidArgument(\"num_bits is out of range: \", num_bits_,",
            "                                \" with signed_input_ \", signed_input_));",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));",
            "",
            "    string round_mode_string;",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"round_mode\", &round_mode_string));"
        ],
        [
            "        ctx,",
            "        (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),",
            "        InvalidArgument(\"Round mode string must be \"",
            "                        \"'HALF_UP' or \"",
            "                        \"'HALF_TO_EVEN', is '\" +",
            "                        round_mode_string + \"'\"));",
            "    if (round_mode_string == \"HALF_UP\") {",
            "      round_mode_ = ROUND_HALF_UP;",
            "    } else if (round_mode_string == \"HALF_TO_EVEN\") {",
            "      round_mode_ = ROUND_HALF_TO_EVEN;"
        ],
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& input = ctx->input(0);",
            "    OP_REQUIRES(ctx, axis_ >= -1,",
            "                InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
            "    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
            "                InvalidArgument(\"Shape must be at least rank \", axis_ + 1,",
            "                                \" but is rank \", input.shape().dims()));",
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    Tensor input_min_tensor;",
            "    Tensor input_max_tensor;"
        ],
        [
            "        auto max_val = input_max_tensor.scalar<T>()();",
            "        OP_REQUIRES(ctx, min_val <= max_val,",
            "                    InvalidArgument(\"Invalid range: input_min \", min_val,",
            "                                    \" > input_max \", max_val));",
            "      } else {",
            "        OP_REQUIRES(",
            "            ctx, input_min_tensor.dim_size(0) == depth,",
            "            InvalidArgument(\"input_min_tensor has incorrect size, was \",",
            "                            input_min_tensor.dim_size(0), \" expected \", depth,",
            "                            \" to match dim \", axis_, \" of the input \",",
            "                            input_min_tensor.shape()));",
            "        OP_REQUIRES(",
            "            ctx, input_max_tensor.dim_size(0) == depth,",
            "            InvalidArgument(\"input_max_tensor has incorrect size, was \",",
            "                            input_max_tensor.dim_size(0), \" expected \", depth,",
            "                            \" to match dim \", axis_, \" of the input \",",
            "                            input_max_tensor.shape()));",
            "      }",
            "    } else {",
            "      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});",
            "      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,"
        ],
        [
            "    OP_REQUIRES_OK(ctx,",
            "                   ctx->allocate_output(0, input.shape(), &input_backprop));",
            "    OP_REQUIRES(ctx, axis_ >= -1,",
            "                InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
            "    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
            "                InvalidArgument(",
            "                    \"Axis should be -1 or 0 or a positive value less than \",",
            "                    input.shape().dims(), \"but given axis value was \", axis_));",
            "",
            "    OP_REQUIRES(ctx, input.IsSameSize(gradient),",
            "                InvalidArgument(\"gradient and input must be the same size\"));",
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    const Tensor& input_min_tensor = ctx->input(2);",
            "    OP_REQUIRES(ctx,",
            "                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,",
            "                InvalidArgument(",
            "                    \"Input min tensor must have dimension 0 or 1. Received \",",
            "                    input_min_tensor.dims(), \".\"));",
            "    const Tensor& input_max_tensor = ctx->input(3);",
            "    OP_REQUIRES(ctx,",
            "                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,",
            "                InvalidArgument(",
            "                    \"Input max tensor must have dimension 0 or 1. Received \",",
            "                    input_max_tensor.dims(), \".\"));",
            "    if (axis_ != -1) {",
            "      OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
            "                  InvalidArgument(\"min has incorrect size, expected \", depth,",
            "                                  \" was \", input_min_tensor.dim_size(0)));",
            "      OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
            "                  InvalidArgument(\"max has incorrect size, expected \", depth,",
            "                                  \" was \", input_max_tensor.dim_size(0)));",
            "    }",
            "",
            "    TensorShape min_max_shape(input_min_tensor.shape());"
        ],
        [
            "",
            "    if (axis_ == -1) {",
            "      OP_REQUIRES(",
            "          ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),",
            "          InvalidArgument(\"input_min must be a scalar if axis is unspecified\"));",
            "      OP_REQUIRES(",
            "          ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),",
            "          InvalidArgument(\"input_max must be a scalar if axis is unspecified\"));",
            "      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;",
            "      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),",
            "        input.template flat<T>(), input_min_tensor.scalar<T>(),",
            "        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),"
        ],
        [
            "    const Tensor& input = ctx->input(0);",
            "    OP_REQUIRES(ctx, axis_ < input.dims(),",
            "                InvalidArgument(",
            "                    \"Axis requested is larger than input dimensions. Axis: \",",
            "                    axis_, \" Input Dimensions: \", input.dims()));",
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
            "",
            "    // Get num_bits and validate.",
            "    const Tensor num_bits_tensor = ctx->input(3);",
            "    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(num_bits_tensor.shape()),",
            "                InvalidArgument(\"Invalid shape. The `num_bits` tensor should \"",
            "                                \"be a scalar. Got dimensions: \",",
            "                                num_bits_tensor.dims()));",
            "",
            "    const int num_bits_val = num_bits_tensor.scalar<int32>()();",
            "    OP_REQUIRES(ctx,",
            "                num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),",
            "                InvalidArgument(\"num_bits is out of range: \", num_bits_val,",
            "                                \" with `signed_input_` \", signed_input_));",
            "",
            "    Tensor input_min_tensor;",
            "    Tensor input_max_tensor;",
            "    if (range_given_) {"
        ],
        [
            "      input_max_tensor = ctx->input(2);",
            "      if (axis_ == -1) {",
            "        const auto min_val = input_min_tensor.scalar<T>()();",
            "        const auto max_val = input_max_tensor.scalar<T>()();",
            "        OP_REQUIRES(ctx, min_val <= max_val,",
            "                    InvalidArgument(\"Invalid range: input_min \", min_val,",
            "                                    \" > input_max \", max_val));",
            "      } else {",
            "        OP_REQUIRES(",
            "            ctx, input_min_tensor.dim_size(0) == depth,",
            "            InvalidArgument(\"input_min_tensor has incorrect size, was \",",
            "                            input_min_tensor.dim_size(0), \" expected \", depth,",
            "                            \" to match dim \", axis_, \" of the input \",",
            "                            input_min_tensor.shape()));",
            "        OP_REQUIRES(",
            "            ctx, input_max_tensor.dim_size(0) == depth,",
            "            InvalidArgument(\"input_max_tensor has incorrect size, was \",",
            "                            input_max_tensor.dim_size(0), \" expected \", depth,",
            "                            \" to match dim \", axis_, \" of the input \",",
            "                            input_max_tensor.shape()));",
            "      }",
            "    } else {",
            "      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});",
            "      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,"
        ],
        [
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));",
            "    OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),",
            "                InvalidArgument(\"num_bits is out of range: \", num_bits_,",
            "                                \" with signed_input_ \", signed_input_));",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));",
            "    if (range_given_) {",
            "      OP_REQUIRES(ctx, input_min_ <= input_max_,",
            "                  InvalidArgument(\"Invalid range: input_min \", input_min_,",
            "                                  \" > input_max \", input_max_));",
            "    }",
            "  }",
            ""
        ],
        [
            "};",
            "",
            "// Specializations for CpuDevice.",
            "",
            "namespace functor {",
            "template <typename T>",
            "struct QuantizeAndDequantizeOneScaleFunctor<CpuDevice, T> {",
            "  void operator()(const CpuDevice& d, typename TTypes<T>::ConstVec input,",
            "                  const bool signed_input, const int num_bits,",
            "                  const bool range_given, Tensor* input_min_tensor,",
            "                  Tensor* input_max_tensor, QuantizerRoundMode round_mode,",
            "                  bool narrow_range, typename TTypes<T>::Vec out) {",
            "    QuantizeAndDequantizeOneScaleImpl<CpuDevice, T>::Compute(",
            "        d, input, signed_input, num_bits, range_given, input_min_tensor,",
            "        input_max_tensor, round_mode, narrow_range, out);",
            "  }",
            "};",
            "",
            "template <typename T>",
            "struct QuantizeAndDequantizePerChannelFunctor<CpuDevice, T> {",
            "  void operator()(const CpuDevice& d, typename TTypes<T, 3>::ConstTensor input,",
            "                  bool signed_input, int num_bits, bool range_given,",
            "                  Tensor* input_min_tensor, Tensor* input_max_tensor,",
            "                  QuantizerRoundMode round_mode, bool narrow_range,",
            "                  typename TTypes<T, 3>::Tensor out) {",
            "    QuantizeAndDequantizePerChannelImpl<CpuDevice, T>::Compute(",
            "        d, input, signed_input, num_bits, range_given, input_min_tensor,",
            "        input_max_tensor, round_mode, narrow_range, out);",
            "  }",
            "};",
            "",
            "template <typename T>",
            "struct QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice, T> {",
            "  void operator()(const CpuDevice& d, typename TTypes<T>::ConstFlat gradient,",
            "                  typename TTypes<T>::ConstFlat input,",
            "                  typename TTypes<T>::ConstScalar input_min_tensor,",
            "                  typename TTypes<T>::ConstScalar input_max_tensor,",
            "                  typename TTypes<T>::Flat input_backprop,",
            "                  typename TTypes<T>::Scalar input_min_backprop,",
            "                  typename TTypes<T>::Scalar input_max_backprop) {",
            "    QuantizeAndDequantizeOneScaleGradientImpl<CpuDevice, T>::Compute(",
            "        d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,",
            "        input_min_backprop, input_max_backprop);",
            "  }",
            "};",
            "",
            "template <typename T>",
            "struct QuantizeAndDequantizePerChannelGradientFunctor<CpuDevice, T> {",
            "  void operator()(const CpuDevice& d,",
            "                  typename TTypes<T, 3>::ConstTensor gradient,",
            "                  typename TTypes<T, 3>::ConstTensor input,",
            "                  const Tensor* input_min_tensor,",
            "                  const Tensor* input_max_tensor,"
        ],
        [
            "                  typename TTypes<T>::Flat input_min_backprop,",
            "                  typename TTypes<T>::Flat input_max_backprop) {",
            "    QuantizeAndDequantizePerChannelGradientImpl<CpuDevice, T>::Compute(",
            "        d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,",
            "        input_min_backprop, input_max_backprop);",
            "  }",
            "};",
            "",
            "template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice,",
            "                                                                      float>;",
            "template struct functor::QuantizeAndDequantizePerChannelGradientFunctor<",
            "    CpuDevice, double>;",
            "",
            "}  // namespace functor",
            "",
            "#define REGISTER_CPU_KERNEL(T)                                                 \\"
        ],
        [
            "                              .Device(DEVICE_CPU)                              \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
            "                              .Device(DEVICE_CPU)                              \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV3Op<CpuDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
            "                              .Device(DEVICE_CPU)                              \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
            "                              .Device(DEVICE_CPU)                              \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV4GradientOp<CpuDevice, T>);    \\",
            "  REGISTER_KERNEL_BUILDER(                                                     \\",
            "      Name(\"QuantizeAndDequantize\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      QuantizeAndDequantizeOp<CpuDevice, T>);",
            "TF_CALL_float(REGISTER_CPU_KERNEL);",
            "TF_CALL_double(REGISTER_CPU_KERNEL);",
            "#undef REGISTER_CPU_KERNEL",
            ""
        ],
        [
            "                              .HostMemory(\"input_max\")                         \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
            "                              .Device(DEVICE_GPU)                              \\",
            "                              .HostMemory(\"input_min\")                         \\",
            "                              .HostMemory(\"input_max\")                         \\",
            "                              .HostMemory(\"num_bits\")                          \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV3Op<GpuDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
            "                              .Device(DEVICE_GPU)                              \\",
            "                              .HostMemory(\"input_min\")                         \\",
            "                              .HostMemory(\"input_max\")                         \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
            "                              .Device(DEVICE_GPU)                              \\",
            "                              .HostMemory(\"input_min\")                         \\",
            "                              .HostMemory(\"input_max\")                         \\",
            "                              .TypeConstraint<T>(\"T\"),                         \\",
            "                          QuantizeAndDequantizeV4GradientOp<GpuDevice, T>);    \\",
            "  REGISTER_KERNEL_BUILDER(                                                     \\",
            "      Name(\"QuantizeAndDequantize\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
            "      QuantizeAndDequantizeOp<GpuDevice, T>);",
            "TF_CALL_float(REGISTER_GPU_KERNEL);",
            "TF_CALL_double(REGISTER_GPU_KERNEL);",
            "#undef REGISTER_GPU_KERNEL",
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9cr2-8pwr-fhfq",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV3(\n    input,\n    input_min,\n    input_max,\n    num_bits,\n    signed_input=True,\n    range_given=True,\n    narrow_range=False,\n    axis=-1,\n    name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "num_bits = tf.constant([], shape=[0], dtype=tf.int32)"
},
{
    "Title": "\n        `CHECK` fail in `FakeQuantWithMinMaxVarsGradient`\n      ",
    "Bug description": "When  tf.quantization.fake_quant_with_min_max_vars_gradient  receives input  min  or  max  that is nonscalar, it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "import numpy as np \narg_0=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)\narg_1=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)\narg_2=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)\narg_3=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)\narg_4=8\narg_5=False\narg_6=''\ntf.quantization.fake_quant_with_min_max_vars_gradient(gradients=arg_0, inputs=arg_1,\n,\nmin=arg_2, max=arg_3, num_bits=arg_4, narrow_range=arg_5, name=arg_6)",
    "Code change": [
        "@@ -261,6 +261,12 @@ class FakeQuantWithMinMaxVarsGradientOp : public OpKernel {\n                 InvalidArgument(\"gradient and input must be the same size\"));\n     const Tensor& min = context->input(2);\n     const Tensor& max = context->input(3);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n \n     Tensor* grad_wrt_input;\n     OP_REQUIRES_OK(context,\n@@ -414,10 +420,16 @@ class FakeQuantWithMinMaxVarsPerChannelGradientOp : public OpKernel {\n                 InvalidArgument(\"gradient and input must be the same size\"));\n     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n     const Tensor& min = context->input(2);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n     OP_REQUIRES(context, min.dim_size(0) == depth,\n                 InvalidArgument(\"min has incorrect size, expected \", depth,\n                                 \" was \", min.dim_size(0)));\n     const Tensor& max = context->input(3);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n     OP_REQUIRES(context, max.dim_size(0) == depth,\n                 InvalidArgument(\"max has incorrect size, expected \", depth,\n                                 \" was \", max.dim_size(0)));\n",
        "@@ -77,6 +77,71 @@ class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n               inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n \n \n+class FakeQuantWithMinMaxVarsGradientOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    gradients = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be equal rank|must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_gradient(\n+              gradients=gradients,\n+              inputs=inputs,\n+              min=0.0,\n+              max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_gradient(\n+              gradients=gradients,\n+              inputs=inputs,\n+              min=[[1.0], [2.0], [4.0]],\n+              max=[[1.0], [2.0], [4.0]]))\n+\n+\n+class FakeQuantWithMinMaxVarsPerChannelGradientOpTest(\n+    test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    gradients = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Shapes must be equal rank|must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[[0.0]], max=[1.0]))\n+\n+    with self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError),\n+        \"Dimension 0 in both shapes must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Shapes must be equal rank|must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[1.0], max=[[1.0]]))\n+\n+    with self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError),\n+        \"Dimension 0 in both shapes must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n+\n+\n class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n \n   @test_util.run_in_graph_and_eager_modes\n@@ -337,10 +402,9 @@ class QuantizeDownAndShrinkRangeOpTest(test_util.TensorFlowTestCase):\n     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                 \"must be rank 0\"):\n       self.evaluate(\n-          math_ops.quantize_down_and_shrink_range(input=inputs,\n-                                                  input_min=[],\n-                                                  input_max=4.0,\n-                                                  out_type=dtypes.quint8))\n+          math_ops.quantize_down_and_shrink_range(\n+              input=inputs, input_min=[], input_max=4.0,\n+              out_type=dtypes.quint8))\n \n \n if __name__ == \"__main__\":\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor& min = context->input(2);",
            "    const Tensor& max = context->input(3);",
            "",
            "    Tensor* grad_wrt_input;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &grad_wrt_input));",
            "",
            "    TensorShape scalar_shape;",
            "    Tensor* grad_wrt_min;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(1, scalar_shape, &grad_wrt_min));",
            ""
        ],
        [
            "    OP_REQUIRES(context, max.dim_size(0) == depth,",
            "                InvalidArgument(\"max has incorrect size, expected \", depth,",
            "                                \" was \", max.dim_size(0)));",
            "",
            "    Tensor* grad_wrt_input;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &grad_wrt_input));",
            "",
            "    TensorShape min_max_shape({input.dim_size(input.dims() - 1)});",
            "    Tensor* grad_wrt_min;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(1, min_max_shape, &grad_wrt_min));",
            "",
            "    Tensor* grad_wrt_max;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(2, min_max_shape, &grad_wrt_max));"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor& min = context->input(2);",
            "    const Tensor& max = context->input(3);",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(min.shape()),",
            "        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(max.shape()),",
            "        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));",
            "",
            "    Tensor* grad_wrt_input;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &grad_wrt_input));"
        ],
        [
            "    const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
            "    const Tensor& min = context->input(2);",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsVector(min.shape()),",
            "        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
            "    OP_REQUIRES(context, min.dim_size(0) == depth,",
            "                InvalidArgument(\"min has incorrect size, expected \", depth,",
            "                                \" was \", min.dim_size(0)));",
            "    const Tensor& max = context->input(3);",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsVector(max.shape()),",
            "        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
            "    OP_REQUIRES(context, max.dim_size(0) == depth,",
            "                InvalidArgument(\"max has incorrect size, expected \", depth,",
            "                                \" was \", max.dim_size(0)));",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-r26c-679w-mrjm",
    "API Signature": "tf.quantization.fake_quant_with_min_max_vars_gradient(\n    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "arg_2=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)"
},
{
    "Title": "\n        `CHECK` fail in `tf.random.gamma`\n      ",
    "Bug description": "When  tf.random.gamma  receives large input shape and rates, it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(4,), dtype=tf.int32, maxval=65536)\narg_1=tf.random.uniform(shape=(4, 4), dtype=tf.float64, maxval=None)\narg_2=tf.random.uniform(shape=(4, 4, 4, 4, 4), dtype=tf.float64, maxval=None)\narg_3=tf.float64\narg_4=48\narg_5='None'\n\ntf.random.gamma(shape=arg_0, alpha=arg_1, beta=arg_2, dtype=arg_3, seed=arg_4, name=arg_5)",
    "Code change": [
        "@@ -166,7 +166,7 @@ class RandomGammaOp : public OpKernel {\n     }\n     const int64_t samples_per_alpha = samples_shape.num_elements();\n \n-    samples_shape.AppendShape(alpha_t.shape());\n+    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(alpha_t.shape()));\n     // Allocate output samples.\n     Tensor* samples_t = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));\n",
        "@@ -296,8 +296,8 @@ class RandomPoissonOp : public OpKernel {\n     TensorShape samples_shape;\n     OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_t, &samples_shape));\n     const int64_t num_samples = samples_shape.num_elements();\n+    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(rate_t.shape()));\n \n-    samples_shape.AppendShape(rate_t.shape());\n     // Allocate output samples.\n     Tensor* samples_t = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));\n",
        "@@ -16,7 +16,10 @@\n \n import numpy as np\n \n+from tensorflow.python.eager import context\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import random_seed\n from tensorflow.python.framework import test_util\n@@ -216,6 +219,16 @@ class RandomGammaTest(test.TestCase):\n         self.assertEqual(0, math_ops.reduce_sum(math_ops.cast(\n             math_ops.less_equal(x, 0.), dtype=dtypes.int64)).eval())\n \n+  def testSizeTooLarge(self):\n+    # Grappler asserts on size overflow, so this error is only caught when\n+    # running eagerly.\n+    if context.executing_eagerly():\n+      with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                  \"overflow\"):\n+        rate = constant_op.constant(1.0, shape=(4, 4, 4, 4, 4))\n+        self.evaluate(\n+            random_ops.random_gamma(\n+                shape=[46902, 51188, 34063, 59195], alpha=rate))\n \n if __name__ == \"__main__\":\n   test.main()\n",
        "@@ -17,6 +17,7 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.kernel_tests.random import util\n@@ -171,6 +172,14 @@ class RandomPoissonTest(test.TestCase):\n     sample = random_ops.random_poisson(shape=[2], lam=np.inf)\n     self.assertAllEqual([np.inf, np.inf], self.evaluate(sample))\n \n+  def testSizeTooLarge(self):\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"overflow\"):\n+      rate = constant_op.constant(1.0, shape=(4, 4, 4, 4, 4))\n+      self.evaluate(\n+          random_ops.random_poisson(\n+              shape=[46902, 51188, 34063, 59195], lam=rate))\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "    const int64_t samples_per_alpha = samples_shape.num_elements();",
            "",
            "    samples_shape.AppendShape(alpha_t.shape());",
            "    // Allocate output samples.",
            "    Tensor* samples_t = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));",
            ""
        ],
        [
            "    OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_t, &samples_shape));",
            "    const int64_t num_samples = samples_shape.num_elements();",
            "",
            "    samples_shape.AppendShape(rate_t.shape());",
            "    // Allocate output samples.",
            "    Tensor* samples_t = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));",
            "    if (num_samples == 0) return;"
        ]
    ],
    "Clean Code": [
        [
            "    const int64_t samples_per_alpha = samples_shape.num_elements();",
            "",
            "    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(alpha_t.shape()));",
            "    // Allocate output samples.",
            "    Tensor* samples_t = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));",
            ""
        ],
        [
            "    OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_t, &samples_shape));",
            "    const int64_t num_samples = samples_shape.num_elements();",
            "    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(rate_t.shape()));",
            "",
            "    // Allocate output samples.",
            "    Tensor* samples_t = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));",
            "    if (num_samples == 0) return;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mv8m-8x97-937q",
    "API Signature": "tf.random.gamma(\n    shape,\n    alpha,\n    beta=None,\n    dtype=tf.dtypes.float32,\n    seed=None,\n    name=None\n)\n",
    "Score": 0.02158273381294964,
    "Anomaly": "Large input tensor",
    "Anomaly Description": "A large tensor refers to a tensor that has a large number of elements or values or occupies a significant amount of memory.",
    "Category": "Tensor",
    "Argument": "arg_0=tf.random.uniform(shape=(4,), dtype=tf.int32, maxval=65536)"
},
{
    "Title": "\n        `CHECK` fail in `RandomPoissonV2`\n      ",
    "Bug description": "When  RandomPoissonV2  receives large input shape and rates, it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(4,), dtype=tf.int32, maxval=65536)\narg_1=tf.random.uniform(shape=(4, 4, 4, 4, 4), dtype=tf.float32, maxval=None)\narg_2=0\narg_3=0\narg_4=tf.int32\narg_5=None\ntf.raw_ops.RandomPoissonV2(shape=arg_0, rate=arg_1, seed=arg_2,\n                           ,\n                           seed2=arg_3, dtype=arg_4, name=arg_5)",
    "Code change": [
        "@@ -166,7 +166,7 @@ class RandomGammaOp : public OpKernel {\n     }\n     const int64_t samples_per_alpha = samples_shape.num_elements();\n \n-    samples_shape.AppendShape(alpha_t.shape());\n+    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(alpha_t.shape()));\n     // Allocate output samples.\n     Tensor* samples_t = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));\n",
        "@@ -296,8 +296,8 @@ class RandomPoissonOp : public OpKernel {\n     TensorShape samples_shape;\n     OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_t, &samples_shape));\n     const int64_t num_samples = samples_shape.num_elements();\n+    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(rate_t.shape()));\n \n-    samples_shape.AppendShape(rate_t.shape());\n     // Allocate output samples.\n     Tensor* samples_t = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));\n",
        "@@ -16,7 +16,10 @@\n \n import numpy as np\n \n+from tensorflow.python.eager import context\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import random_seed\n from tensorflow.python.framework import test_util\n@@ -216,6 +219,16 @@ class RandomGammaTest(test.TestCase):\n         self.assertEqual(0, math_ops.reduce_sum(math_ops.cast(\n             math_ops.less_equal(x, 0.), dtype=dtypes.int64)).eval())\n \n+  def testSizeTooLarge(self):\n+    # Grappler asserts on size overflow, so this error is only caught when\n+    # running eagerly.\n+    if context.executing_eagerly():\n+      with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                  \"overflow\"):\n+        rate = constant_op.constant(1.0, shape=(4, 4, 4, 4, 4))\n+        self.evaluate(\n+            random_ops.random_gamma(\n+                shape=[46902, 51188, 34063, 59195], alpha=rate))\n \n if __name__ == \"__main__\":\n   test.main()\n",
        "@@ -17,6 +17,7 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.kernel_tests.random import util\n@@ -171,6 +172,14 @@ class RandomPoissonTest(test.TestCase):\n     sample = random_ops.random_poisson(shape=[2], lam=np.inf)\n     self.assertAllEqual([np.inf, np.inf], self.evaluate(sample))\n \n+  def testSizeTooLarge(self):\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"overflow\"):\n+      rate = constant_op.constant(1.0, shape=(4, 4, 4, 4, 4))\n+      self.evaluate(\n+          random_ops.random_poisson(\n+              shape=[46902, 51188, 34063, 59195], lam=rate))\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "    const int64_t samples_per_alpha = samples_shape.num_elements();",
            "",
            "    samples_shape.AppendShape(alpha_t.shape());",
            "    // Allocate output samples.",
            "    Tensor* samples_t = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));",
            ""
        ],
        [
            "    OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_t, &samples_shape));",
            "    const int64_t num_samples = samples_shape.num_elements();",
            "",
            "    samples_shape.AppendShape(rate_t.shape());",
            "    // Allocate output samples.",
            "    Tensor* samples_t = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));",
            "    if (num_samples == 0) return;"
        ]
    ],
    "Clean Code": [
        [
            "    const int64_t samples_per_alpha = samples_shape.num_elements();",
            "",
            "    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(alpha_t.shape()));",
            "    // Allocate output samples.",
            "    Tensor* samples_t = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));",
            ""
        ],
        [
            "    OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_t, &samples_shape));",
            "    const int64_t num_samples = samples_shape.num_elements();",
            "    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(rate_t.shape()));",
            "",
            "    // Allocate output samples.",
            "    Tensor* samples_t = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));",
            "    if (num_samples == 0) return;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cv2p-32v3-vhwq",
    "API Signature": "tf.raw_ops.RandomPoissonV2(\n    shape,\n    rate,\n    seed=0,\n    seed2=0,\n    dtype=tf.dtypes.int64,\n    name=None\n)\n",
    "Score": 0.02158273381294964,
    "Anomaly": "Large input tensor",
    "Anomaly Description": "A large tensor refers to a tensor that has a large number of elements or values or occupies a significant amount of memory.",
    "Category": "Tensor",
    "Argument": "arg_0=tf.random.uniform(shape=(4,), dtype=tf.int32, maxval=65536)"
},
{
    "Title": "\n        `CHECK` fail in `Unbatch`\n      ",
    "Bug description": "When  Unbatch  receives a nonscalar input  id , it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "import numpy as np\narg_0=tf.constant(value=np.random.random(size=(3, 3, 1)), dtype=tf.float64)\narg_1=tf.constant(value=np.random.randint(0,100,size=(3, 3, 1)), dtype=tf.int64)\narg_2=tf.constant(value=np.random.randint(0,100,size=(3, 3,  1)), dtype=tf.int64)\narg_3=47\narg_4=''\narg_5=''\ntf.raw_ops.Unbatch(batched_tensor=arg_0, batch_index=arg_1, id=arg_2, \n                   , \n                   timeout_micros=arg_3, container=arg_4, shared_name=arg_5)",
    "Code change": [
        "@@ -23,6 +23,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/resource_mgr.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/batching_util/adaptive_shared_batch_scheduler.h\"\n@@ -654,6 +655,12 @@ class UnbatchResource : public ResourceBase {\n           batch_index_t.shape().dim_size(1), \".\");\n     }\n \n+    if (!TensorShapeUtils::IsScalar(context->input(2).shape())) {\n+      return errors::InvalidArgument(\n+          \"Input id should be scalar; \"\n+          \"Got: \",\n+          context->input(2).DebugString(), \".\");\n+    }\n     const int64_t batch_key = context->input(2).scalar<int64_t>()();\n     const bool nonempty_input = batch_index_t.dim_size(0) > 0;\n \n",
        "@@ -236,6 +236,26 @@ class BatchOpsTest(test.TestCase):\n       self.assertEqual(thread_results[0], [2])\n       self.assertEqual(main_results[0], [3])\n \n+  def testUnbatchInvalidIdArg(self):\n+    \"\"\"Tests that unbatch work together.\"\"\"\n+    if context.executing_eagerly():\n+      batched_tensor = constant_op.constant(\n+          value=np.random.random(size=(3, 3, 1)), dtype=dtypes.float64)\n+      batched_index = constant_op.constant(\n+          value=np.random.randint(0, 100, size=(3, 3, 1)), dtype=dtypes.int64)\n+      arg_id = constant_op.constant(\n+          value=np.random.randint(0, 100, size=(3, 3, 1)), dtype=dtypes.int64)\n+\n+      with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                  \"Input id should be scalar;\"):\n+        batch_ops.unbatch(\n+            batched_tensor=batched_tensor,\n+            batch_index=batched_index,\n+            id=arg_id,\n+            timeout_micros=50,\n+            container=\"\",\n+            shared_name=\"\")\n+\n   def testBatchDecoratedWithCapturedInput(self):\n     \"\"\"Tests that the batch_function decorator works.\"\"\"\n     if context.executing_eagerly():\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/resource_mgr.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/kernels/batching_util/adaptive_shared_batch_scheduler.h\"",
            "#include \"tensorflow/core/kernels/batching_util/batch_resource_base.h\"",
            "#include \"tensorflow/core/kernels/batching_util/bounded_executor.h\""
        ],
        [
            "",
            "    const int64_t batch_key = context->input(2).scalar<int64_t>()();",
            "    const bool nonempty_input = batch_index_t.dim_size(0) > 0;",
            "",
            "    // If we have a non-empty tensor, slice it up.",
            "    // (It is important to do this outside of the critical section below.)",
            "    // The following variables are populated iff 'nonempty_input==true'.",
            "    std::vector<int64_t> sizes;",
            "    std::vector<int64_t> batch_keys;",
            "    std::vector<Tensor> split_inputs;",
            "    if (nonempty_input) {",
            "      auto batch_indices ="
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/resource_mgr.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/kernels/batching_util/adaptive_shared_batch_scheduler.h\"",
            "#include \"tensorflow/core/kernels/batching_util/batch_resource_base.h\""
        ],
        [
            "    }",
            "",
            "    if (!TensorShapeUtils::IsScalar(context->input(2).shape())) {",
            "      return errors::InvalidArgument(",
            "          \"Input id should be scalar; \"",
            "          \"Got: \",",
            "          context->input(2).DebugString(), \".\");",
            "    }",
            "    const int64_t batch_key = context->input(2).scalar<int64_t>()();",
            "    const bool nonempty_input = batch_index_t.dim_size(0) > 0;",
            "",
            "    // If we have a non-empty tensor, slice it up."
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mh3m-62v7-68xg",
    "API Signature": "tf.raw_ops.Unbatch(\n    batched_tensor,\n    batch_index,\n    id,\n    timeout_micros,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "arg_2=tf.constant(value=np.random.randint(0,100,size=(3, 3, 1)), dtype=tf.int64)"
},
{
    "Title": "\n        `CHECK` fail in `DrawBoundingBoxes`\n      ",
    "Bug description": "When  DrawBoundingBoxes  receives an input  boxes  that is not of dtype  float , it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "import numpy as np\narg_0=tf.constant(value=np.random.random(size=(1, 3, 2, 3)), shape=(1, 3, 2, 3), dtype=tf.half)\narg_1=tf.constant(value=np.random.random(size=(1, 2, 4)), shape=(1, 2, 4), dtype=tf.float32)\narg_2=''\n\ntf.raw_ops.DrawBoundingBoxes(images=arg_0, boxes=arg_1, name=arg_2)",
    "Code change": [
        "@@ -119,7 +119,7 @@ class DrawBoundingBoxesOp : public OpKernel {\n \n     for (int64_t b = 0; b < batch_size; ++b) {\n       const int64_t num_boxes = boxes.dim_size(1);\n-      const auto tboxes = boxes.tensor<T, 3>();\n+      const auto tboxes = boxes.tensor<float, 3>();\n       for (int64_t bb = 0; bb < num_boxes; ++bb) {\n         int64_t color_index = bb % color_table.size();\n         const int64_t min_box_row =\n",
        "@@ -50,11 +50,16 @@ class DrawBoundingBoxOpTest(test.TestCase):\n     image[height - 1, 0:width, 0:depth] = color\n     return image\n \n-  def _testDrawBoundingBoxColorCycling(self, img, colors=None):\n+  def _testDrawBoundingBoxColorCycling(self,\n+                                       img,\n+                                       dtype=dtypes.float32,\n+                                       colors=None):\n     \"\"\"Tests if cycling works appropriately.\n \n     Args:\n       img: 3-D numpy image on which to draw.\n+      dtype: image dtype (float, half).\n+      colors: color table.\n     \"\"\"\n     color_table = colors\n     if colors is None:\n@@ -82,7 +87,7 @@ class DrawBoundingBoxOpTest(test.TestCase):\n       bboxes = math_ops.cast(bboxes, dtypes.float32)\n       bboxes = array_ops.expand_dims(bboxes, 0)\n       image = ops.convert_to_tensor(image)\n-      image = image_ops_impl.convert_image_dtype(image, dtypes.float32)\n+      image = image_ops_impl.convert_image_dtype(image, dtype)\n       image = array_ops.expand_dims(image, 0)\n       image = image_ops.draw_bounding_boxes(image, bboxes, colors=colors)\n       with self.cached_session(use_gpu=False) as sess:\n@@ -118,6 +123,14 @@ class DrawBoundingBoxOpTest(test.TestCase):\n                          [0, 0, 0.5, 1]])\n     self._testDrawBoundingBoxColorCycling(image, colors=colors)\n \n+  def testDrawBoundingBoxHalf(self):\n+    \"\"\"Test if RGBA color cycling works correctly with provided colors.\"\"\"\n+    image = np.zeros([10, 10, 4], \"float32\")\n+    colors = np.asarray([[0.5, 0, 0.5, 1], [0.5, 0.5, 0, 1], [0.5, 0, 0, 1],\n+                         [0, 0, 0.5, 1]])\n+    self._testDrawBoundingBoxColorCycling(\n+        image, dtype=dtypes.half, colors=colors)\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "    for (int64_t b = 0; b < batch_size; ++b) {",
            "      const int64_t num_boxes = boxes.dim_size(1);",
            "      const auto tboxes = boxes.tensor<T, 3>();",
            "      for (int64_t bb = 0; bb < num_boxes; ++bb) {",
            "        int64_t color_index = bb % color_table.size();",
            "        const int64_t min_box_row =",
            "            static_cast<float>(tboxes(b, bb, 0)) * (height - 1);"
        ]
    ],
    "Clean Code": [
        [
            "    for (int64_t b = 0; b < batch_size; ++b) {",
            "      const int64_t num_boxes = boxes.dim_size(1);",
            "      const auto tboxes = boxes.tensor<float, 3>();",
            "      for (int64_t bb = 0; bb < num_boxes; ++bb) {",
            "        int64_t color_index = bb % color_table.size();",
            "        const int64_t min_box_row =",
            "            static_cast<float>(tboxes(b, bb, 0)) * (height - 1);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jqm7-m5q7-3hm5",
    "API Signature": "tf.raw_ops.DrawBoundingBoxes(\n    images, boxes, name=None\n)\n",
    "Score": 0.0035971223021582736,
    "Anomaly": "Input tensor with half data type",
    "Anomaly Description": "An input tensor with a half data type refers to a tensor that uses the float16 data type. The float16 data type, also known as half-precision floating-point format, represents a floating-point number with reduced precision compared to the standard float32 data type.",
    "Category": "Tensor",
    "Argument": "arg_1=tf.constant(value=np.random.random(size=(1, 2, 4)), shape=(1, 2, 4), dtype=tf.float32)"
},
{
    "Title": "\n        `CHECK` fail in `Eig`\n      ",
    "Bug description": "Eig  can be fed an incorrect  Tout  input, resulting in a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "import numpy as np \narg_0=tf.constant(value=np.random.random(size=(2, 2)), shape=(2, 2), dtype=tf.float32)\narg_1=tf.complex128\narg_2=True\narg_3=''\n\ntf.raw_ops.Eig(input=arg_0, Tout=arg_1, compute_v=arg_2, name=arg_3)",
    "Code change": [
        "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include \"tensorflow/core/kernels/linalg/linalg_ops_common.h\"\n \n+#include <initializer_list>\n #include <utility>\n \n #include \"third_party/eigen3/Eigen/Core\"\n@@ -22,7 +23,9 @@ limitations under the License.\n #include \"tensorflow/core/framework/kernel_def_builder.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/types.h\"\n \n@@ -152,6 +155,10 @@ void LinearAlgebraOp<InputScalar, OutputScalar>::AnalyzeInputs(\n     input_matrix_shapes->emplace_back(\n         std::initializer_list<int64_t>({num_rows, num_cols}));\n     inputs->emplace_back(&in);\n+    OP_REQUIRES(\n+        context, in.dtype() == DataTypeToEnum<InputScalar>::v(),\n+        errors::InvalidArgument(\"Invalid input dtype \", in.dtype(), \" vs \",\n+                                DataTypeToEnum<InputScalar>::v()));\n   }\n   // Have the derived class validate that the inputs are as expected.\n   ValidateInputMatrixShapes(context, *input_matrix_shapes);\n@@ -212,6 +219,11 @@ void LinearAlgebraOp<InputScalar, OutputScalar>::PrepareOutputs(\n       OP_REQUIRES_OK(context, context->allocate_output(\n                                   output_idx, output_tensor_shape, &out));\n     }\n+    OP_REQUIRES(\n+        context, out->dtype() == DataTypeToEnum<OutputScalar>::v(),\n+        errors::InvalidArgument(\"Invalid output dtype \", out->dtype(), \" vs \",\n+                                DataTypeToEnum<OutputScalar>::v()));\n+\n     outputs->emplace_back(out);\n   }\n }\n",
        "@@ -18,8 +18,10 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes as dtypes_lib\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import gen_linalg_ops\n from tensorflow.python.ops import gradient_checker_v2\n from tensorflow.python.ops import linalg_ops\n from tensorflow.python.ops import math_ops\n@@ -88,6 +90,16 @@ class EigTest(test.TestCase):\n       self.assertAllClose(matrix,\n                           np.matmul(np.matmul(v, np.diag(e)), v.transpose()))\n \n+  def testMismatchedDtypes(self):\n+    tensor = constant_op.constant([[0, 1], [2, 3]], dtype=dtypes_lib.float32)\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Invalid output dtype\"):\n+      self.evaluate(\n+          gen_linalg_ops.eig(\n+              input=tensor,\n+              Tout=dtypes_lib.complex128,  # Expected dtype: complex64.\n+              compute_v=True))\n+\n \n def SortEigenValues(e):\n   perm = np.argsort(e.real + e.imag, -1)\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/kernels/linalg/linalg_ops_common.h\"",
            "",
            "#include <utility>",
            "",
            "#include \"third_party/eigen3/Eigen/Core\"",
            "#include \"tensorflow/core/framework/device_base.h\"",
            "#include \"tensorflow/core/framework/kernel_def_builder.h\""
        ],
        [
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/types.h\"",
            "",
            "namespace tensorflow {",
            "",
            "// static",
            "template <class InputScalar, class OutputScalar>"
        ],
        [
            "  // Have the derived class validate that the inputs are as expected.",
            "  ValidateInputMatrixShapes(context, *input_matrix_shapes);",
            "}",
            "",
            "template <class InputScalar, class OutputScalar>",
            "void LinearAlgebraOp<InputScalar, OutputScalar>::PrepareOutputs(",
            "    OpKernelContext* context, const TensorShapes& input_matrix_shapes,",
            "    const TensorShape& batch_shape, TensorOutputs* outputs,",
            "    TensorShapes* output_matrix_shapes) {",
            "  // Get shape for each of the matrix outputs produced by the derived class."
        ],
        [
            "void LinearAlgebraOp<InputScalar, OutputScalar>::ComputeTensorSlice(",
            "    OpKernelContext* context, int64_t matrix_index, const TensorInputs& inputs,",
            "    const TensorShapes& input_matrix_shapes, const TensorOutputs& outputs,",
            "    const TensorShapes& output_matrix_shapes) {",
            "  InputConstMatrixMaps matrix_inputs;",
            "  for (size_t i = 0; i < inputs.size(); ++i) {",
            "    // TODO(kalakris): Handle alignment if possible. Eigen::Map is",
            "    // unaligned by default.",
            "    matrix_inputs.emplace_back(",
            "        inputs[i]->flat<InputScalar>().data() +",
            "            matrix_index * input_matrix_shapes[i].num_elements(),"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/kernels/linalg/linalg_ops_common.h\"",
            "",
            "#include <initializer_list>",
            "#include <utility>",
            "",
            "#include \"third_party/eigen3/Eigen/Core\"",
            "#include \"tensorflow/core/framework/device_base.h\""
        ],
        [
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/types.h\"",
            "",
            "namespace tensorflow {"
        ],
        [
            "        std::initializer_list<int64_t>({num_rows, num_cols}));",
            "    inputs->emplace_back(&in);",
            "    OP_REQUIRES(",
            "        context, in.dtype() == DataTypeToEnum<InputScalar>::v(),",
            "        errors::InvalidArgument(\"Invalid input dtype \", in.dtype(), \" vs \",",
            "                                DataTypeToEnum<InputScalar>::v()));",
            "  }",
            "  // Have the derived class validate that the inputs are as expected.",
            "  ValidateInputMatrixShapes(context, *input_matrix_shapes);",
            "}"
        ],
        [
            "                                  output_idx, output_tensor_shape, &out));",
            "    }",
            "    OP_REQUIRES(",
            "        context, out->dtype() == DataTypeToEnum<OutputScalar>::v(),",
            "        errors::InvalidArgument(\"Invalid output dtype \", out->dtype(), \" vs \",",
            "                                DataTypeToEnum<OutputScalar>::v()));",
            "",
            "    outputs->emplace_back(out);",
            "  }",
            "}",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fqxc-pvf8-2w9v",
    "API Signature": "tf.raw_ops.Eig(\n    input, Tout, compute_v=True, name=None\n)\n",
    "Score": 0.0035971223021582736,
    "Anomaly": "Input argument with complex data type",
    "Anomaly Description": "An input argument with a complex data type refers to a tensor that represents complex numbers. Complex numbers consist of a real part and an imaginary part, and they can be represented using the complex64 or complex128 data types.",
    "Category": "tf.complex",
    "Argument": "arg_1=tf.complex128"
},
{
    "Title": "\n        `CHECK` fail in `Conv2DBackpropInput`\n      ",
    "Bug description": "When  Conv2DBackpropInput  receives empty  out_backprop  inputs (e.g.  [3, 1, 0, 1] ), the current CPU/GPU kernels  CHECK  fail (one with dnnl, the other with cudnn). This can be used to trigger a denial of service attack.",
    "Sample Code": "import numpy as np\ninput_sizes = [3, 1, 1, 2]\nfilter = np.ones([1, 3, 2, 3])\nout_backprop = np.ones([3, 1, 0, 3])\nstrides = [1, 1, 2, 1]\npadding = 'VALID'\n\ntf.raw_ops.Conv2DBackpropInput(\n   input_sizes = input_sizes,\n   filter = filter,\n   out_backprop = out_backprop,\n   strides = strides,\n   padding = padding\n)\n)",
    "Code change": [
        "@@ -37,6 +37,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/conv_2d.h\"\n #include \"tensorflow/core/kernels/conv_grad_ops.h\"\n #include \"tensorflow/core/kernels/conv_grad_shape_utils.h\"\n+#include \"tensorflow/core/kernels/fill_functor.h\"\n #ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS\n #include \"tensorflow/core/kernels/xsmm_conv2d.h\"\n #endif\n@@ -436,6 +437,15 @@ class Conv2DBackpropInputOp : public OpKernel {\n       return;\n     }\n \n+    // If shapes are valid but `out_backprop` is empty, in_backprop should be\n+    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.\n+    if (out_backprop.NumElements() == 0) {\n+      functor::SetZeroFunctor<Device, T> set_zero;\n+      set_zero(context->eigen_device<Device>(),\n+               in_backprop->template flat<T>());\n+      return;\n+    }\n+\n     // For now we take the stride from the second and third dimensions only (we\n     // do not support striding on the batch or depth dimension).\n     const int stride_rows = GetTensorDim(strides_, data_format_, 'H');\n@@ -554,6 +564,15 @@ class Conv2DCustomBackpropInputOp : public OpKernel {\n       return;\n     }\n \n+    // If shapes are valid but `out_backprop` is empty, in_backprop should be\n+    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.\n+    if (out_backprop.NumElements() == 0) {\n+      functor::SetZeroFunctor<Device, T> set_zero;\n+      set_zero(context->eigen_device<Device>(),\n+               in_backprop->template flat<T>());\n+      return;\n+    }\n+\n // TODO(ezhulenev): Remove custom kernel and move XSMM support to\n // LaunchConv2DBackpropInputOp functor.\n #if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\\n",
        "@@ -1103,6 +1103,23 @@ class Conv2DTest(test.TestCase):\n           use_gpu=use_gpu,\n           err=1e-5)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  @test_util.disable_xla(\"b/239598470\")\n+  def testConv2DBackpropInputDegenerateBackpropInput(self):\n+    input_sizes = [3, 1, 1, 2]\n+    expected_output = np.zeros(input_sizes).flatten()\n+    for (data_format, use_gpu) in GetTestConfigs():\n+      self._RunAndVerifyBackpropInput(\n+          input_sizes=input_sizes,\n+          filter_sizes=[1, 3, 2, 3],\n+          output_sizes=[3, 1, 0, 3],\n+          strides=[1, 2],\n+          padding=\"VALID\",\n+          expected=expected_output,\n+          data_format=data_format,\n+          use_gpu=use_gpu,\n+          err=1e-5)\n+\n   # Testing for backprops\n   def _RunAndVerifyBackpropFilter(self,\n                                   input_sizes,\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/kernels/conv_grad_ops.h\"",
            "#include \"tensorflow/core/kernels/conv_grad_shape_utils.h\"",
            "#ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS",
            "#include \"tensorflow/core/kernels/xsmm_conv2d.h\"",
            "#endif",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/lib/gtl/array_slice.h\""
        ],
        [
            "",
            "    // For now we take the stride from the second and third dimensions only (we",
            "    // do not support striding on the batch or depth dimension).",
            "    const int stride_rows = GetTensorDim(strides_, data_format_, 'H');",
            "    const int stride_cols = GetTensorDim(strides_, data_format_, 'W');",
            "    const int dilation_rows = GetTensorDim(dilations_, data_format_, 'H');",
            "    const int dilation_cols = GetTensorDim(dilations_, data_format_, 'W');",
            "",
            "    VLOG(2) << \"Conv2DBackpropInput:\"",
            "            << \" input: \" << input_shape.DebugString()",
            "            << \" filter:\" << filter.shape().DebugString()",
            "            << \" out_backprop: \" << out_backprop.shape().DebugString()",
            "            << \" strides: [\" << stride_rows << \", \" << stride_cols << \"]\"",
            "            << \" dilations: [\" << dilation_rows << \", \" << dilation_cols << \"]\";",
            ""
        ],
        [
            "        GetWindowedOutputSizeVerbose(",
            "            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,",
            "            dims.spatial_dims[0].stride, padding_,",
            "            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));",
            "    OP_REQUIRES_OK(",
            "        context,",
            "        GetWindowedOutputSizeVerbose(",
            "            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,",
            "            dims.spatial_dims[1].stride, padding_,",
            "            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));",
            "",
            "    if (pad_left == pad_right && pad_top == pad_bottom) {",
            "      if (LaunchXsmmBackwardInputConvolution<Device, T>()(",
            "              context, context->eigen_device<Device>(),",
            "              in_backprop->tensor<T, 4>(), filter.tensor<T, 4>(),"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/kernels/conv_grad_ops.h\"",
            "#include \"tensorflow/core/kernels/conv_grad_shape_utils.h\"",
            "#include \"tensorflow/core/kernels/fill_functor.h\"",
            "#ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS",
            "#include \"tensorflow/core/kernels/xsmm_conv2d.h\"",
            "#endif",
            "#include \"tensorflow/core/lib/core/errors.h\""
        ],
        [
            "    }",
            "",
            "    // If shapes are valid but `out_backprop` is empty, in_backprop should be",
            "    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.",
            "    if (out_backprop.NumElements() == 0) {",
            "      functor::SetZeroFunctor<Device, T> set_zero;",
            "      set_zero(context->eigen_device<Device>(),",
            "               in_backprop->template flat<T>());",
            "      return;",
            "    }",
            "",
            "    // For now we take the stride from the second and third dimensions only (we",
            "    // do not support striding on the batch or depth dimension).",
            "    const int stride_rows = GetTensorDim(strides_, data_format_, 'H');",
            "    const int stride_cols = GetTensorDim(strides_, data_format_, 'W');"
        ],
        [
            "    }",
            "",
            "    // If shapes are valid but `out_backprop` is empty, in_backprop should be",
            "    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.",
            "    if (out_backprop.NumElements() == 0) {",
            "      functor::SetZeroFunctor<Device, T> set_zero;",
            "      set_zero(context->eigen_device<Device>(),",
            "               in_backprop->template flat<T>());",
            "      return;",
            "    }",
            "",
            "// TODO(ezhulenev): Remove custom kernel and move XSMM support to",
            "// LaunchConv2DBackpropInputOp functor.",
            "#if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\",
            "    defined TENSORFLOW_USE_LIBXSMM_BACKWARD_CONVOLUTIONS"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-37jf-mjv6-xfqw",
    "API Signature": "tf.raw_ops.Conv2DBackpropInput(\n    input_sizes,\n    filter,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.03237410071942446,
    "Anomaly": "Zero integer list element",
    "Anomaly Description": "In Python, a zero integer list element refers to a list element that has the value of zero (0). It is simply a list element that holds the integer value of zero.",
    "Category": "List",
    "Argument": "arg = [3, 1, 0, 3]"
},
{
    "Title": "\n        `CHECK` fail in `EmptyTensorList`\n      ",
    "Bug description": "If  EmptyTensorList  receives an input  element_shape  with more than one dimension, it gives a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.EmptyTensorList(element_shape=tf.ones(dtype=tf.int32, shape=[1, 0]), max_num_elements=tf.constant(1),element_dtype=tf.int32)",
    "Code change": [
        "@@ -21,7 +21,11 @@ limitations under the License.\n \n #include \"tensorflow/core/kernels/list_kernels.h\"\n \n+#include <algorithm>\n+#include <iterator>\n #include <limits>\n+#include <memory>\n+#include <utility>\n \n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/allocator.h\"\n@@ -30,10 +34,6 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_types.h\"\n #include \"tensorflow/core/framework/variant.h\"\n #include \"tensorflow/core/framework/variant_op_registry.h\"\n-#include \"tensorflow/core/kernels/concat_lib.h\"\n-#include \"tensorflow/core/lib/core/coding.h\"\n-#include \"tensorflow/core/lib/core/errors.h\"\n-#include \"tensorflow/core/util/util.h\"\n \n namespace tensorflow {\n \n@@ -49,6 +49,9 @@ Status TensorShapeFromTensor(const Tensor& t, PartialTensorShape* out) {\n     return errors::InvalidArgument(\n         \"The only valid scalar shape tensor is the fully unknown shape \"\n         \"specified as -1.\");\n+  } else if (t.shape().dims() != 1) {\n+    return errors::InvalidArgument(\"Shape must be at most rank 1 but is rank \",\n+                                   t.shape().dims());\n   }\n   if (t.dtype() == DT_INT32) {\n     return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),\n",
        "@@ -1458,6 +1458,15 @@ class ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n       t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n       self.evaluate(t)\n \n+  def testEmptyTensorListInvalidShape(self):\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                r\"Shape must be at most rank 1 but is rank 2\"):\n+      t = gen_list_ops.EmptyTensorList(\n+          element_shape=array_ops.ones(dtype=dtypes.int32, shape=[1, 0]),\n+          max_num_elements=constant_op.constant(1),\n+          element_dtype=dtypes.int32)\n+      self.evaluate(t)\n+\n   def testEvenSplit(self):\n \n     def RunTest(input_tensor, lengths, expected_stacked_output):\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/kernels/list_kernels.h\"",
            "",
            "#include <limits>",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/allocator.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor_types.h\"",
            "#include \"tensorflow/core/framework/variant.h\"",
            "#include \"tensorflow/core/framework/variant_op_registry.h\""
        ],
        [
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/util/util.h\"",
            "",
            "namespace tensorflow {",
            "",
            "typedef Eigen::ThreadPoolDevice CPUDevice;"
        ],
        [
            "        \"The only valid scalar shape tensor is the fully unknown shape \"",
            "        \"specified as -1.\");",
            "  }",
            "  if (t.dtype() == DT_INT32) {",
            "    return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),",
            "                                                t.NumElements(), out);",
            "  } else if (t.dtype() == DT_INT64) {",
            "    return PartialTensorShape::MakePartialShape(t.vec<int64_t>().data(),",
            "                                                t.NumElements(), out);"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/kernels/list_kernels.h\"",
            "",
            "#include <algorithm>",
            "#include <iterator>",
            "#include <limits>",
            "#include <memory>",
            "#include <utility>",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/allocator.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\""
        ],
        [
            "#include \"tensorflow/core/framework/variant.h\"",
            "#include \"tensorflow/core/framework/variant_op_registry.h\"",
            "",
            "namespace tensorflow {",
            "",
            "typedef Eigen::ThreadPoolDevice CPUDevice;"
        ],
        [
            "        \"The only valid scalar shape tensor is the fully unknown shape \"",
            "        \"specified as -1.\");",
            "  } else if (t.shape().dims() != 1) {",
            "    return errors::InvalidArgument(\"Shape must be at most rank 1 but is rank \",",
            "                                   t.shape().dims());",
            "  }",
            "  if (t.dtype() == DT_INT32) {",
            "    return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),",
            "                                                t.NumElements(), out);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qhw4-wwr7-gjc5",
    "API Signature": "tf.raw_ops.EmptyTensorList(\n    element_shape, max_num_elements, element_dtype, name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "tf.ones(dtype=tf.int32, shape=[1, 0])"
},
{
    "Title": "\n        `CHECK` fail in `tf.sparse.cross`\n      ",
    "Bug description": "If  tf.sparse.cross  receives an input  separator  that is not a scalar, it gives a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": " tensorflow as tf\n\ntf.sparse.cross(inputs=[],name='a',separator=tf.constant(['a', 'b'],dtype=tf.string))",
    "Code change": [
        "@@ -24,12 +24,14 @@ limitations under the License.\n #include \"tensorflow/core/framework/kernel_def_builder.h\"\n #include \"tensorflow/core/framework/op_def_builder.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/framework/types.pb.h\"\n #include \"tensorflow/core/lib/core/stringpiece.h\"\n #include \"tensorflow/core/lib/strings/str_util.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/fingerprint.h\"\n #include \"tensorflow/core/platform/strong_hash.h\"\n #include \"tensorflow/core/util/work_sharder.h\"\n@@ -832,6 +834,10 @@ class SparseCrossV2Op : public OpKernel {\n \n     const Tensor* sep_t;\n     OP_REQUIRES_OK(context, context->input(\"sep\", &sep_t));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(sep_t->shape()),\n+                errors::InvalidArgument(\"Input separator should be a scalar. \"\n+                                        \"Received: \",\n+                                        sep_t->DebugString()));\n     const tstring separator = sep_t->scalar<tstring>()();\n \n     std::vector<std::unique_ptr<ColumnInterface<tstring>>> columns =\n",
        "@@ -873,6 +873,14 @@ class SparseCrossV2OpTest(BaseSparseCrossOpTest):\n     with self.cached_session():\n       self._assert_sparse_tensor_empty(self.evaluate(out))\n \n+  def testNonScalarInput(self):\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                'Input separator should be a scalar.'):\n+      self.evaluate(sparse_ops.sparse_cross(\n+          inputs=[],\n+          name='a',\n+          separator=constant_op.constant(['a', 'b'], dtype=dtypes.string)))\n+\n \n class SparseCrossHashedOpTest(BaseSparseCrossOpTest):\n \n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/op_def_builder.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/framework/types.pb.h\"",
            "#include \"tensorflow/core/lib/core/stringpiece.h\"",
            "#include \"tensorflow/core/lib/strings/str_util.h\"",
            "#include \"tensorflow/core/platform/fingerprint.h\"",
            "#include \"tensorflow/core/platform/strong_hash.h\"",
            "#include \"tensorflow/core/util/work_sharder.h\"",
            "",
            "namespace tensorflow {",
            ""
        ],
        [
            "    const tstring separator = sep_t->scalar<tstring>()();",
            "",
            "    std::vector<std::unique_ptr<ColumnInterface<tstring>>> columns =",
            "        GenerateColumnsFromInput<tstring>(indices_list_in, values_list_in,",
            "                                          shapes_list_in, dense_list_in);",
            "    Tensor* indices_out;",
            "    Tensor* values_out;",
            "    Tensor* shape_out;",
            "    const int64_t batch_size =",
            "        CalculateBatchSize(shapes_list_in, dense_list_in);"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/op_def_builder.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/framework/types.pb.h\"",
            "#include \"tensorflow/core/lib/core/stringpiece.h\"",
            "#include \"tensorflow/core/lib/strings/str_util.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#include \"tensorflow/core/platform/fingerprint.h\"",
            "#include \"tensorflow/core/platform/strong_hash.h\"",
            "#include \"tensorflow/core/util/work_sharder.h\"",
            ""
        ],
        [
            "    const Tensor* sep_t;",
            "    OP_REQUIRES_OK(context, context->input(\"sep\", &sep_t));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(sep_t->shape()),",
            "                errors::InvalidArgument(\"Input separator should be a scalar. \"",
            "                                        \"Received: \",",
            "                                        sep_t->DebugString()));",
            "    const tstring separator = sep_t->scalar<tstring>()();",
            "",
            "    std::vector<std::unique_ptr<ColumnInterface<tstring>>> columns =",
            "        GenerateColumnsFromInput<tstring>(indices_list_in, values_list_in,"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-p7hr-f446-x6qf",
    "API Signature": "tf.sparse.cross(\n    inputs, name=None, separator=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "separator=tf.constant(['a', 'b']"
},
{
    "Title": "\n        Floating point exception in `Conv2D`\n      ",
    "Bug description": "If  Conv2D  is given empty  input  and the  filter  and  padding  sizes are valid, the output is all-zeros. This causes division-by-zero floating point exceptions that can be used to trigger a denial of service attack.",
    "Sample Code": "import numpy as np\nwith tf.device(\"CPU\"): # also can be triggerred on GPU\n   input = np.ones([1, 0, 2, 1])\n   filter = np.ones([1, 1, 1, 1])\n   strides = ([1, 1, 1, 1])\n   padding = \"EXPLICIT\"\n   explicit_paddings = [0 , 0, 1, 1, 1, 1, 0, 0]\n   data_format = \"NHWC\"\n   res = tf.raw_ops.Conv2D(\n       input=input,\n       filter=filter,\n       strides=strides,\n       padding=padding,\n        explicit_paddings=explicit_paddings,\n       data_format=data_format,\n  ),\n  )",
    "Code change": [
        "@@ -44,6 +44,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/conv_2d.h\"\n #include \"tensorflow/core/kernels/deep_conv2d.h\"\n+#include \"tensorflow/core/kernels/fill_functor.h\"\n #include \"tensorflow/core/kernels/ops_util.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/lib/gtl/array_slice.h\"\n@@ -701,6 +702,15 @@ class Conv2DOp : public BinaryOp<T> {\n       return;\n     }\n \n+    // If the input is empty, result can only be due to padding.\n+    if (input.NumElements() == 0) {\n+      // Zero-out output and return.\n+      functor::SetZeroFunctor<Device, T>()(context->eigen_device<Device>(),\n+                                           output->template flat<T>());\n+\n+      return;\n+    }\n+\n #ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS\n     if (params_.padding != EXPLICIT &&\n         LaunchXsmmConvOp<Device, T>::Run(\n",
        "@@ -759,6 +759,15 @@ class Conv2DTest(test.TestCase):\n         padding=[[2, 1], [1, 2]],\n         dilations=[2, 3])\n \n+  @test_util.run_in_graph_and_eager_modes()\n+  def testConv2dOnlyPaddingReturnsZeros(self):\n+    self._VerifyValues(\n+        tensor_in_sizes=[1, 0, 2, 1],\n+        filter_in_sizes=[1, 1, 1, 1],\n+        strides=[1, 1],\n+        padding=[[1, 1], [1, 1]],\n+        expected=[0, 0, 0, 0, 0, 0, 0, 0])\n+\n   def testConv2DExplicitPaddingWithLayoutOptimizer(self):\n     # Test with Grappler's layout optimizer, to ensure the layout optimizer\n     # handles explicit padding correctly.\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/kernels/conv_2d.h\"",
            "#include \"tensorflow/core/kernels/deep_conv2d.h\"",
            "#include \"tensorflow/core/kernels/ops_util.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/lib/gtl/array_slice.h\"",
            "#include \"tensorflow/core/lib/strings/numbers.h\"",
            "#include \"tensorflow/core/lib/strings/str_util.h\""
        ],
        [
            "",
            "#ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS",
            "    if (params_.padding != EXPLICIT &&",
            "        LaunchXsmmConvOp<Device, T>::Run(",
            "            context, input, filter, dimensions.batch, dimensions.input_rows,",
            "            dimensions.input_cols, dimensions.in_depth, dimensions.filter_rows,",
            "            dimensions.filter_cols, dimensions.pad_rows_before,",
            "            dimensions.pad_cols_before, dimensions.out_rows,",
            "            dimensions.out_cols, dimensions.out_depth, dimensions.dilation_rows,",
            "            dimensions.dilation_cols, dimensions.stride_rows,",
            "            dimensions.stride_cols, output, params_.data_format)) {",
            "      return;",
            "    }",
            "#endif",
            ""
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/kernels/conv_2d.h\"",
            "#include \"tensorflow/core/kernels/deep_conv2d.h\"",
            "#include \"tensorflow/core/kernels/fill_functor.h\"",
            "#include \"tensorflow/core/kernels/ops_util.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/lib/gtl/array_slice.h\"",
            "#include \"tensorflow/core/lib/strings/numbers.h\""
        ],
        [
            "    }",
            "",
            "    // If the input is empty, result can only be due to padding.",
            "    if (input.NumElements() == 0) {",
            "      // Zero-out output and return.",
            "      functor::SetZeroFunctor<Device, T>()(context->eigen_device<Device>(),",
            "                                           output->template flat<T>());",
            "",
            "      return;",
            "    }",
            "",
            "#ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS",
            "    if (params_.padding != EXPLICIT &&",
            "        LaunchXsmmConvOp<Device, T>::Run(",
            "            context, input, filter, dimensions.batch, dimensions.input_rows,"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-q5jv-m6qw-5g37",
    "API Signature": "tf.raw_ops.Conv2D(\n    input,\n    filter,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.03237410071942446,
    "Anomaly": "Zero integer list element",
    "Anomaly Description": "In Python, a zero integer list element refers to a list element that has the value of zero (0). It is simply a list element that holds the integer value of zero.",
    "Category": "List",
    "Argument": "arg = [1, 0, 2, 1]"
},
{
    "Title": "\n        `CHECK` fail in `AudioSummaryV2`\n      ",
    "Bug description": "When  AudioSummaryV2  receives an input  sample_rate  with more than one element, it gives a  CHECK  fails that can be used to trigger a denial of service attack.",
    "Sample Code": "arg_0=''\narg_1=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)\narg_2=tf.random.uniform(shape=(2,1), dtype=tf.float32, maxval=None)\narg_3=3\narg_4=''\ntf.raw_ops.AudioSummaryV2(tag=arg_0, tensor=arg_1, sample_rate=arg_2,\n                          ,\n                          max_outputs=arg_3, name=arg_4)",
    "Code change": [
        "@@ -49,6 +49,11 @@ class SummaryAudioOp : public OpKernel {\n     float sample_rate = sample_rate_attr_;\n     if (!has_sample_rate_attr_) {\n       const Tensor& sample_rate_tensor = c->input(2);\n+      OP_REQUIRES(c,\n+                  sample_rate_tensor.IsAligned() &&\n+                      sample_rate_tensor.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"sample_rate must be rank-0 or contain a single value\"));\n       sample_rate = sample_rate_tensor.scalar<float>()();\n     }\n     OP_REQUIRES(c, sample_rate > 0.0f,\n",
        "@@ -23,6 +23,7 @@ tensorflow/python/kernel_tests/summary_v1_*.py.\n from tensorflow.core.framework import summary_pb2\n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import meta_graph\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n@@ -183,6 +184,11 @@ class SummaryTest(test.TestCase):\n         'family/outer/family/inner/audio/{}'.format(i) for i in range(3))\n     self.assertEqual(tags, expected)\n \n+  def testAudioSummaryWithInvalidSampleRate(self):\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      invalid_sample_rate = [22000.0, 22000.0]\n+      self.evaluate(summary_lib.audio('', [[1.0]], invalid_sample_rate))\n+\n   @test_util.run_deprecated_v1\n   def testTextSummary(self):\n     with self.cached_session():\n"
    ],
    "Buggy Code": [
        [
            "    if (!has_sample_rate_attr_) {",
            "      const Tensor& sample_rate_tensor = c->input(2);",
            "      sample_rate = sample_rate_tensor.scalar<float>()();",
            "    }",
            "    OP_REQUIRES(c, sample_rate > 0.0f,",
            "                errors::InvalidArgument(\"sample_rate must be > 0\"));",
            "",
            "    const int batch_size = tensor.dim_size(0);",
            "    const int64_t length_frames = tensor.dim_size(1);",
            "    const int64_t num_channels =",
            "        tensor.dims() == 2 ? 1 : tensor.dim_size(tensor.dims() - 1);"
        ]
    ],
    "Clean Code": [
        [
            "    if (!has_sample_rate_attr_) {",
            "      const Tensor& sample_rate_tensor = c->input(2);",
            "      OP_REQUIRES(c,",
            "                  sample_rate_tensor.IsAligned() &&",
            "                      sample_rate_tensor.NumElements() == 1,",
            "                  errors::InvalidArgument(",
            "                      \"sample_rate must be rank-0 or contain a single value\"));",
            "      sample_rate = sample_rate_tensor.scalar<float>()();",
            "    }",
            "    OP_REQUIRES(c, sample_rate > 0.0f,",
            "                errors::InvalidArgument(\"sample_rate must be > 0\"));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-g9h5-vr8m-x2h4",
    "API Signature": "tf.raw_ops.AudioSummaryV2(\n    tag, tensor, sample_rate, max_outputs=3, name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "arg_2=tf.random.uniform(shape=(2,1), dtype=tf.float32, maxval=None)"
},
{
    "Title": "\n        `CHECK` fail in `CollectiveGather`\n      ",
    "Bug description": "When  CollectiveGather  receives an scalar input  input , it gives a  CHECK  fails that can be used to trigger a denial of service attack.",
    "Sample Code": "arg_0=1\narg_1=1\narg_2=1\narg_3=1\narg_4=(3, 3,3)\narg_5='auto'\narg_6=0\narg_7=''\ntf.raw_ops.CollectiveGather(input=arg_0, group_size=arg_1, group_key=arg_2,\n                            instance_key=arg_3, shape=arg_4,\n                            ,\n                            communication_hint=arg_5, timeout_seconds=arg_6, name=arg_7)",
    "Code change": [
        "@@ -176,6 +176,10 @@ class CollectiveGatherOpKernel : public CollectiveOpV1Kernel {\n   void ComputeAsyncImpl(OpKernelContext* c, CollectiveExecutor* col_exec,\n                         DoneCallback done) override {\n     auto output_shape = c->input(0).shape();\n+    OP_REQUIRES_ASYNC(c, output_shape.dims() > 0,\n+                      errors::InvalidArgument(\"input should have rank > 0, \",\n+                                              \"recieved \", output_shape.dims()),\n+                      done);\n     output_shape.set_dim(\n         0, output_shape.dim_size(0) * col_params_->group.group_size);\n     col_params_->instance.shape = output_shape;\n",
        "@@ -451,6 +451,20 @@ class CollectiveOpTest(test.TestCase):\n     ])\n     context.ensure_initialized()\n \n+  @test_util.run_v2_only\n+  def testCollectiveGatherShapeCheckFailure(self):\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                'input should have rank > 0'):\n+      collective_ops.gen_collective_ops.CollectiveGather(\n+          input=1,\n+          group_size=1,\n+          group_key=1,\n+          instance_key=1,\n+          shape=(3, 3, 3),\n+          communication_hint='auto',\n+          timeout_seconds=0,\n+          name='')\n+\n     @def_function.function\n     def run_all_reduce():\n       group_key = 10\n"
    ],
    "Buggy Code": [
        [
            "                        DoneCallback done) override {",
            "    auto output_shape = c->input(0).shape();",
            "    output_shape.set_dim(",
            "        0, output_shape.dim_size(0) * col_params_->group.group_size);",
            "    col_params_->instance.shape = output_shape;",
            "",
            "    // Allocate output on the first pass through this function.  This must be",
            "    // done immediately, while we're still in the executor thread.  Otherwise",
            "    // the memory is not guaranteed to be unused by any concurrently executing",
            "    // GPU kernel."
        ]
    ],
    "Clean Code": [
        [
            "                        DoneCallback done) override {",
            "    auto output_shape = c->input(0).shape();",
            "    OP_REQUIRES_ASYNC(c, output_shape.dims() > 0,",
            "                      errors::InvalidArgument(\"input should have rank > 0, \",",
            "                                              \"recieved \", output_shape.dims()),",
            "                      done);",
            "    output_shape.set_dim(",
            "        0, output_shape.dim_size(0) * col_params_->group.group_size);",
            "    col_params_->instance.shape = output_shape;",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fhfc-2q7x-929f",
    "API Signature": "tf.raw_ops.CollectiveGather(\n    input,\n    group_size,\n    group_key,\n    instance_key,\n    shape,\n    communication_hint='auto',\n    timeout_seconds=0,\n    name=None\n)\n",
    "Score": 0.007194244604316547,
    "Anomaly": "Scalar input",
    "Anomaly Description": "In Python, a scalar input refers to a single value or variable that represents a basic data type. It is a fundamental unit of data and does not have any internal structure or additional dimensions. Scalars are used to represent individual values such as numbers or characters.",
    "Category": "Tensor",
    "Argument": "arg_0=1"
},
{
    "Title": "\n        `CHECK` fail in `SetSize`\n      ",
    "Bug description": "When  SetSize  receives an input  set_shape  that is not a 1D tensor, it gives a  CHECK  fails that can be used to trigger a denial of service attack.",
    "Sample Code": "arg_0=1\narg_1=[1,1]\narg_2=1\narg_3=True\narg_4=''\ntf.raw_ops.SetSize(set_indices=arg_0, set_values=arg_1, set_shape=arg_2,\n                   ,\n                   validate_indices=arg_3, name=arg_4)",
    "Code change": [
        "@@ -70,8 +70,12 @@ Status SparseTensorFromContext(OpKernelContext* ctx, const int32_t base_index,\n                                sparse::SparseTensor* tensor) {\n   // Assume row-major order.\n   TensorShape shape;\n-  TF_RETURN_IF_ERROR(TensorShape::BuildTensorShape(\n-      ctx->input(base_index + 2).vec<int64_t>(), &shape));\n+  const Tensor& shape_tensor = ctx->input(base_index + 2);\n+  if (shape_tensor.dims() != 1) {\n+    return errors::InvalidArgument(\"Shape must be a 1D tensor.\");\n+  }\n+  TF_RETURN_IF_ERROR(\n+      TensorShape::BuildTensorShape(shape_tensor.vec<int64_t>(), &shape));\n   CheckRankAtLeast2(ctx, shape);\n   std::vector<int64_t> order(shape.dims());\n   std::iota(order.begin(), order.end(), 0);\n",
        "@@ -23,6 +23,7 @@ from tensorflow.python.framework import errors_impl\n from tensorflow.python.framework import sparse_tensor as sparse_tensor_lib\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import gen_set_ops\n from tensorflow.python.ops import math_ops\n from tensorflow.python.ops import sets\n from tensorflow.python.ops import sparse_ops\n@@ -1303,6 +1304,18 @@ class SetOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n         result.values,\n         _constant([1, 3, 5, 7, 9, 0, 2, 4, 5, 6, 6, 8, 9], dtype))\n \n+  def test_raw_ops_setsize_invalid_shape(self):\n+    with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n+                                \"Shape must be a 1D tensor\"):\n+      invalid_shape = 1\n+      self.evaluate(\n+          gen_set_ops.set_size(\n+              set_indices=1,\n+              set_values=[1, 1],\n+              set_shape=invalid_shape,\n+              validate_indices=True,\n+              name=\"\"))\n+\n \n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Buggy Code": [
        [
            "  // Assume row-major order.",
            "  TensorShape shape;",
            "  TF_RETURN_IF_ERROR(TensorShape::BuildTensorShape(",
            "      ctx->input(base_index + 2).vec<int64_t>(), &shape));",
            "  CheckRankAtLeast2(ctx, shape);",
            "  std::vector<int64_t> order(shape.dims());",
            "  std::iota(order.begin(), order.end(), 0);",
            "",
            "  Status status = sparse::SparseTensor::Create(",
            "      ctx->input(base_index), ctx->input(base_index + 1), shape, order, tensor);",
            "",
            "  if (!validate_indices || !status.ok()) return status;"
        ]
    ],
    "Clean Code": [
        [
            "  // Assume row-major order.",
            "  TensorShape shape;",
            "  const Tensor& shape_tensor = ctx->input(base_index + 2);",
            "  if (shape_tensor.dims() != 1) {",
            "    return errors::InvalidArgument(\"Shape must be a 1D tensor.\");",
            "  }",
            "  TF_RETURN_IF_ERROR(",
            "      TensorShape::BuildTensorShape(shape_tensor.vec<int64_t>(), &shape));",
            "  CheckRankAtLeast2(ctx, shape);",
            "  std::vector<int64_t> order(shape.dims());",
            "  std::iota(order.begin(), order.end(), 0);",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wq6q-6m32-9rv9",
    "API Signature": "tf.raw_ops.SetSize(\n    set_indices, set_values, set_shape, validate_indices=True, name=None\n)\n",
    "Score": 0.007194244604316547,
    "Anomaly": "Scalar input",
    "Anomaly Description": "In Python, a scalar input refers to a single value or variable that represents a basic data type. It is a fundamental unit of data and does not have any internal structure or additional dimensions. Scalars are used to represent individual values such as numbers or characters.",
    "Category": "Tensor",
    "Argument": "arg_2=1"
},
{
    "Title": "\n        `CHECK` fail in `TensorListFromTensor`\n      ",
    "Bug description": "When  TensorListFromTensor  receives an  element_shape  of a rank greater than one, it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(6, 6, 2), dtype=tf.bfloat16, maxval=None)\narg_1=tf.random.uniform(shape=(6, 9, 1, 3), dtype=tf.int64, maxval=65536)\narg_2=''\n\ntf.raw_ops.TensorListFromTensor(tensor=arg_0, element_shape=arg_1, name=arg_2)",
    "Code change": [
        "@@ -769,6 +769,11 @@ class TensorListFromTensor : public OpKernel {\n     attr.set_on_host(true);\n     OP_REQUIRES_OK(c, c->allocate_output(0, {}, &output_tensor, attr));\n     PartialTensorShape element_shape;\n+    OP_REQUIRES(\n+        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(1).shape()),\n+        errors::InvalidArgument(\n+            \"TensorListFromTensor: element_shape must be at most rank 1 but \",\n+            \"has the shape of \", c->input(1).shape().DebugString()));\n     OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(1), &element_shape));\n     TensorList output_list;\n     const Tensor& t = c->input(0);\n",
        "@@ -584,6 +584,17 @@ class ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n     self.assertAllEqual(e, 1.0)\n     self.assertAllEqual(list_ops.tensor_list_length(l), 0)\n \n+  def testTensorListFromTensorFailsWhenElementShapeIsNotVector(self):\n+    t = constant_op.constant([1.0, 2.0])\n+    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n+    # In graph mode, ValueError is generated by the shape function.\n+    with self.assertRaisesRegex(\n+        (errors.InvalidArgumentError, ValueError),\n+        \"must be at most rank 1\"):\n+      # Wrong element_shape. Should be at most rank 1.\n+      l = list_ops.tensor_list_from_tensor(t, element_shape=[[1]])\n+      self.evaluate(l)\n+\n   @test_util.run_gpu_only\n   def testFromTensorGPU(self):\n     with context.device(\"gpu:0\"):\n"
    ],
    "Buggy Code": [
        [
            "    OP_REQUIRES_OK(c, c->allocate_output(0, {}, &output_tensor, attr));",
            "    PartialTensorShape element_shape;",
            "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(1), &element_shape));",
            "    TensorList output_list;",
            "    const Tensor& t = c->input(0);",
            "    output_list.element_dtype = t.dtype();",
            "    OP_REQUIRES(c, TensorShapeUtils::IsVectorOrHigher(t.shape()),",
            "                errors::InvalidArgument(",
            "                    \"Tensor must be at least a vector, but saw shape: \",",
            "                    t.shape().DebugString()));",
            "    TensorShape output_shape(t.shape());"
        ]
    ],
    "Clean Code": [
        [
            "    OP_REQUIRES_OK(c, c->allocate_output(0, {}, &output_tensor, attr));",
            "    PartialTensorShape element_shape;",
            "    OP_REQUIRES(",
            "        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(1).shape()),",
            "        errors::InvalidArgument(",
            "            \"TensorListFromTensor: element_shape must be at most rank 1 but \",",
            "            \"has the shape of \", c->input(1).shape().DebugString()));",
            "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(1), &element_shape));",
            "    TensorList output_list;",
            "    const Tensor& t = c->input(0);",
            "    output_list.element_dtype = t.dtype();"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9v8w-xmr4-wgxp",
    "API Signature": "tf.raw_ops.TensorListFromTensor(\n    tensor, element_shape, name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "arg_1=tf.random.uniform(shape=(6, 9, 1, 3), dtype=tf.int64, maxval=65536)"
},
{
    "Title": "\n        `CHECK` fail in `TensorListScatter` and `TensorListScatterV2`\n      ",
    "Bug description": "When  TensorListScatter  and  TensorListScatterV2  receive an  element_shape  of a rank greater than one, they give a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(2, 2, 2), dtype=tf.float16, maxval=None)\narg_1=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)\narg_2=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)\narg_3=''\ntf.raw_ops.TensorListScatter(tensor=arg_0, indices=arg_1, \n, \nelement_shape=arg_2, name=arg_3)",
    "Code change": [
        "@@ -895,6 +895,11 @@ class TensorListScatter : public OpKernel {\n     OP_REQUIRES_OK(c, c->allocate_output(0, {}, &output_tensor, attr));\n     Tensor indices = c->input(1);\n     PartialTensorShape element_shape;\n+    OP_REQUIRES(\n+        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(2).shape()),\n+        errors::InvalidArgument(\n+            \"TensorListScatter: element_shape must be at most rank 1 but has \",\n+            \"the shape of \", c->input(2).shape().DebugString()));\n     OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(2), &element_shape));\n     // TensorListScatterV2 passes the num_elements input, TensorListScatter does\n     // not.\n",
        "@@ -481,6 +481,30 @@ class ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n     # TensorListScatter should return a list with size num_elements.\n     self.assertAllEqual(list_ops.tensor_list_length(l), 5)\n \n+  def testScatterFailsWhenElementShapeIsNotVector(self):\n+    c0 = constant_op.constant([1.0, 2.0])\n+    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n+    # In graph mode, ValueError is generated by the shape function.\n+    with self.assertRaisesRegex(\n+        (errors.InvalidArgumentError, ValueError),\n+        \"must be at most rank 1\"):\n+      l = gen_list_ops.tensor_list_scatter(\n+          # Wrong element_shape. Should be at most rank 1.\n+          c0, [1, 3], element_shape=[[1]])\n+      self.evaluate(l)\n+\n+  def testScatterV2FailsWhenElementShapeIsNotVector(self):\n+    c0 = constant_op.constant([1.0, 2.0])\n+    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n+    # In graph mode, ValueError is generated by the shape function.\n+    with self.assertRaisesRegex(\n+        (errors.InvalidArgumentError, ValueError),\n+        \"must be at most rank 1\"):\n+      l = gen_list_ops.tensor_list_scatter_v2(\n+          # Wrong element_shape. Should be at most rank 1.\n+          c0, [1, 3], element_shape=[[1]], num_elements=2)\n+      self.evaluate(l)\n+\n   def testScatterFailsWhenIndexLargerThanNumElements(self):\n     c0 = constant_op.constant([1.0, 2.0])\n     with self.assertRaisesRegex(\n"
    ],
    "Buggy Code": [
        [
            "    Tensor indices = c->input(1);",
            "    PartialTensorShape element_shape;",
            "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(2), &element_shape));",
            "    // TensorListScatterV2 passes the num_elements input, TensorListScatter does",
            "    // not.",
            "    int num_elements = c->num_inputs() >= 4 ? c->input(3).scalar<int>()() : -1;",
            "    OP_REQUIRES(c, num_elements >= -1,",
            "                errors::InvalidArgument(",
            "                    \"TensorListScatter expects num_elements >= -1, found: \",",
            "                    num_elements));",
            "    TensorList output_list;"
        ]
    ],
    "Clean Code": [
        [
            "    Tensor indices = c->input(1);",
            "    PartialTensorShape element_shape;",
            "    OP_REQUIRES(",
            "        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(2).shape()),",
            "        errors::InvalidArgument(",
            "            \"TensorListScatter: element_shape must be at most rank 1 but has \",",
            "            \"the shape of \", c->input(2).shape().DebugString()));",
            "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(2), &element_shape));",
            "    // TensorListScatterV2 passes the num_elements input, TensorListScatter does",
            "    // not.",
            "    int num_elements = c->num_inputs() >= 4 ? c->input(3).scalar<int>()() : -1;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vm7x-4qhj-rrcq",
    "API Signature": "tf.raw_ops.TensorListScatter(\n    tensor, indices, element_shape, name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "arg_2=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)"
},
{
    "Title": "\n        `CHECK` fail in `TensorListScatter` and `TensorListScatterV2`\n      ",
    "Bug description": "When  TensorListScatter  and  TensorListScatterV2  receive an  element_shape  of a rank greater than one, they give a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(2, 2, 2), dtype=tf.float16, maxval=None)\narg_1=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)\narg_2=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)\narg_3=''\ntf.raw_ops.TensorListScatter(tensor=arg_0, indices=arg_1, \n, \nelement_shape=arg_2, name=arg_3)",
    "Code change": [
        "@@ -895,6 +895,11 @@ class TensorListScatter : public OpKernel {\n     OP_REQUIRES_OK(c, c->allocate_output(0, {}, &output_tensor, attr));\n     Tensor indices = c->input(1);\n     PartialTensorShape element_shape;\n+    OP_REQUIRES(\n+        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(2).shape()),\n+        errors::InvalidArgument(\n+            \"TensorListScatter: element_shape must be at most rank 1 but has \",\n+            \"the shape of \", c->input(2).shape().DebugString()));\n     OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(2), &element_shape));\n     // TensorListScatterV2 passes the num_elements input, TensorListScatter does\n     // not.\n",
        "@@ -481,6 +481,30 @@ class ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n     # TensorListScatter should return a list with size num_elements.\n     self.assertAllEqual(list_ops.tensor_list_length(l), 5)\n \n+  def testScatterFailsWhenElementShapeIsNotVector(self):\n+    c0 = constant_op.constant([1.0, 2.0])\n+    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n+    # In graph mode, ValueError is generated by the shape function.\n+    with self.assertRaisesRegex(\n+        (errors.InvalidArgumentError, ValueError),\n+        \"must be at most rank 1\"):\n+      l = gen_list_ops.tensor_list_scatter(\n+          # Wrong element_shape. Should be at most rank 1.\n+          c0, [1, 3], element_shape=[[1]])\n+      self.evaluate(l)\n+\n+  def testScatterV2FailsWhenElementShapeIsNotVector(self):\n+    c0 = constant_op.constant([1.0, 2.0])\n+    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n+    # In graph mode, ValueError is generated by the shape function.\n+    with self.assertRaisesRegex(\n+        (errors.InvalidArgumentError, ValueError),\n+        \"must be at most rank 1\"):\n+      l = gen_list_ops.tensor_list_scatter_v2(\n+          # Wrong element_shape. Should be at most rank 1.\n+          c0, [1, 3], element_shape=[[1]], num_elements=2)\n+      self.evaluate(l)\n+\n   def testScatterFailsWhenIndexLargerThanNumElements(self):\n     c0 = constant_op.constant([1.0, 2.0])\n     with self.assertRaisesRegex(\n"
    ],
    "Buggy Code": [
        [
            "    Tensor indices = c->input(1);",
            "    PartialTensorShape element_shape;",
            "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(2), &element_shape));",
            "    // TensorListScatterV2 passes the num_elements input, TensorListScatter does",
            "    // not.",
            "    int num_elements = c->num_inputs() >= 4 ? c->input(3).scalar<int>()() : -1;",
            "    OP_REQUIRES(c, num_elements >= -1,",
            "                errors::InvalidArgument(",
            "                    \"TensorListScatter expects num_elements >= -1, found: \",",
            "                    num_elements));",
            "    TensorList output_list;"
        ]
    ],
    "Clean Code": [
        [
            "    Tensor indices = c->input(1);",
            "    PartialTensorShape element_shape;",
            "    OP_REQUIRES(",
            "        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(2).shape()),",
            "        errors::InvalidArgument(",
            "            \"TensorListScatter: element_shape must be at most rank 1 but has \",",
            "            \"the shape of \", c->input(2).shape().DebugString()));",
            "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(2), &element_shape));",
            "    // TensorListScatterV2 passes the num_elements input, TensorListScatter does",
            "    // not.",
            "    int num_elements = c->num_inputs() >= 4 ? c->input(3).scalar<int>()() : -1;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vm7x-4qhj-rrcq",
    "API Signature": "tf.raw_ops.TensorListScatterV2(\n    tensor, indices, element_shape, num_elements, name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "arg_2=tf.random.uniform(shape=(2, 2, 2), dtype=tf.int32, maxval=65536)"
},
{
    "Title": "\n        `CHECK` fail in `FakeQuantWithMinMaxVarsPerChannelGradient`\n      ",
    "Bug description": "When  tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient  receives input  min  or  max  of rank other than 1, it gives a  CHECK  fail that can trigger a denial of service attack.",
    "Sample Code": "arg_0=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)\narg_1=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)\narg_2=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)\narg_3=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)\narg_4=8\narg_5=False\narg_6=None\ntf.quantization.fake_quant_with_min_max_vars_per_channel_gradient(gradients=arg_0, \n            inputs=arg_1, min=arg_2,  max=arg_3, num_bits=arg_4, \n            , \n            narrow_range=arg_5, name=arg_6)",
    "Code change": [
        "@@ -261,6 +261,12 @@ class FakeQuantWithMinMaxVarsGradientOp : public OpKernel {\n                 InvalidArgument(\"gradient and input must be the same size\"));\n     const Tensor& min = context->input(2);\n     const Tensor& max = context->input(3);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n \n     Tensor* grad_wrt_input;\n     OP_REQUIRES_OK(context,\n@@ -414,10 +420,16 @@ class FakeQuantWithMinMaxVarsPerChannelGradientOp : public OpKernel {\n                 InvalidArgument(\"gradient and input must be the same size\"));\n     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n     const Tensor& min = context->input(2);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n     OP_REQUIRES(context, min.dim_size(0) == depth,\n                 InvalidArgument(\"min has incorrect size, expected \", depth,\n                                 \" was \", min.dim_size(0)));\n     const Tensor& max = context->input(3);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n     OP_REQUIRES(context, max.dim_size(0) == depth,\n                 InvalidArgument(\"max has incorrect size, expected \", depth,\n                                 \" was \", max.dim_size(0)));\n",
        "@@ -77,6 +77,71 @@ class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n               inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n \n \n+class FakeQuantWithMinMaxVarsGradientOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    gradients = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be equal rank|must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_gradient(\n+              gradients=gradients,\n+              inputs=inputs,\n+              min=0.0,\n+              max=[[1.0], [2.0], [4.0]]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_gradient(\n+              gradients=gradients,\n+              inputs=inputs,\n+              min=[[1.0], [2.0], [4.0]],\n+              max=[[1.0], [2.0], [4.0]]))\n+\n+\n+class FakeQuantWithMinMaxVarsPerChannelGradientOpTest(\n+    test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    gradients = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+    inputs = constant_op.constant(\n+        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Shapes must be equal rank|must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[[0.0]], max=[1.0]))\n+\n+    with self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError),\n+        \"Dimension 0 in both shapes must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Shapes must be equal rank|must be rank 1\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[1.0], max=[[1.0]]))\n+\n+    with self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError),\n+        \"Dimension 0 in both shapes must be equal|incorrect size\"):\n+      self.evaluate(\n+          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n+              gradients=gradients, inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n+\n+\n class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n \n   @test_util.run_in_graph_and_eager_modes\n@@ -337,10 +402,9 @@ class QuantizeDownAndShrinkRangeOpTest(test_util.TensorFlowTestCase):\n     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                 \"must be rank 0\"):\n       self.evaluate(\n-          math_ops.quantize_down_and_shrink_range(input=inputs,\n-                                                  input_min=[],\n-                                                  input_max=4.0,\n-                                                  out_type=dtypes.quint8))\n+          math_ops.quantize_down_and_shrink_range(\n+              input=inputs, input_min=[], input_max=4.0,\n+              out_type=dtypes.quint8))\n \n \n if __name__ == \"__main__\":\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor& min = context->input(2);",
            "    const Tensor& max = context->input(3);",
            "",
            "    Tensor* grad_wrt_input;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &grad_wrt_input));",
            "",
            "    TensorShape scalar_shape;",
            "    Tensor* grad_wrt_min;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(1, scalar_shape, &grad_wrt_min));",
            ""
        ],
        [
            "    OP_REQUIRES(context, max.dim_size(0) == depth,",
            "                InvalidArgument(\"max has incorrect size, expected \", depth,",
            "                                \" was \", max.dim_size(0)));",
            "",
            "    Tensor* grad_wrt_input;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &grad_wrt_input));",
            "",
            "    TensorShape min_max_shape({input.dim_size(input.dims() - 1)});",
            "    Tensor* grad_wrt_min;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(1, min_max_shape, &grad_wrt_min));",
            "",
            "    Tensor* grad_wrt_max;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(2, min_max_shape, &grad_wrt_max));"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor& min = context->input(2);",
            "    const Tensor& max = context->input(3);",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(min.shape()),",
            "        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(max.shape()),",
            "        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));",
            "",
            "    Tensor* grad_wrt_input;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &grad_wrt_input));"
        ],
        [
            "    const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
            "    const Tensor& min = context->input(2);",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsVector(min.shape()),",
            "        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
            "    OP_REQUIRES(context, min.dim_size(0) == depth,",
            "                InvalidArgument(\"min has incorrect size, expected \", depth,",
            "                                \" was \", min.dim_size(0)));",
            "    const Tensor& max = context->input(3);",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsVector(max.shape()),",
            "        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
            "    OP_REQUIRES(context, max.dim_size(0) == depth,",
            "                InvalidArgument(\"max has incorrect size, expected \", depth,",
            "                                \" was \", max.dim_size(0)));",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h7ff-cfc9-wmmh",
    "API Signature": "tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient(\n    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "arg_1=tf.random.uniform(shape=(1,1), dtype=tf.float32, maxval=None)"
},
{
    "Title": "\n        `CHECK` fail in `MaxPool`\n      ",
    "Bug description": "When  MaxPool  receives a window size input array  ksize  with dimensions greater than its input tensor  input , the GPU kernel gives a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "import numpy as np\n\ninput = np.ones([1, 1, 1, 1])\nksize = [1, 1, 2, 2]\nstrides = [1, 1, 1, 1]\npadding = 'VALID'\ndata_format = 'NCHW'\n\n\n\ntf.raw_ops.MaxPool(input=input, ksize=ksize, strides=strides, padding=padding, data_format=data_format)",
    "Code change": [
        "@@ -1268,6 +1268,13 @@ class MaxPoolingNoMaskOp<GPUDevice, T> : public OpKernel {\n         ShapeFromFormat(data_format_, params.tensor_in_batch, params.out_height,\n                         params.out_width, params.depth);\n \n+    // Degenerate pooling output should return an empty tensor.\n+    if (out_shape.num_elements() == 0) {\n+      Tensor* output = nullptr;\n+      OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));\n+      return;\n+    }\n+\n     // Assuming qint8 <--> NCHW_VECT_C (int8x4) here.\n     constexpr bool is_int8x4 = std::is_same<T, qint8>::value;\n     OP_REQUIRES(context, (is_int8x4 == (data_format_ == FORMAT_NCHW_VECT_C)),\n",
        "@@ -772,6 +772,18 @@ class PoolingTest(test.TestCase, parameterized.TestCase):\n         expected=[],\n         **kwargs)\n \n+  @parameterized.parameters(\n+      GetTestConfigsDicts(nn_ops.max_pool, gen_nn_ops.max_pool_v2))\n+  @test_util.run_deprecated_v1\n+  def testMaxPoolInvalidFilterSize(self, **kwargs):\n+    with self.cached_session(use_gpu=test.is_gpu_available()):\n+      t = constant_op.constant(1.0, shape=[1, 1, 1, 1])\n+      with self.assertRaisesRegex(\n+          (errors_impl.InvalidArgumentError, ValueError),\n+          \"Negative dimension size\"):\n+        t = self.evaluate(\n+            nn_ops.max_pool(t, ksize=[1, 1, 2, 1], strides=1, padding=\"VALID\"))\n+\n   # Tests for DepthwiseMaxPooling on CPU only.\n   @parameterized.parameters(\n       GetTestConfigsDicts(\n"
    ],
    "Buggy Code": [
        [
            "                        params.out_width, params.depth);",
            "",
            "    // Assuming qint8 <--> NCHW_VECT_C (int8x4) here.",
            "    constexpr bool is_int8x4 = std::is_same<T, qint8>::value;",
            "    OP_REQUIRES(context, (is_int8x4 == (data_format_ == FORMAT_NCHW_VECT_C)),",
            "                errors::InvalidArgument(",
            "                    \"qint8 should be used with data_format NCHW_VECT_C.\"));",
            "",
            "#if CUDNN_VERSION >= 7300",
            "    DnnPoolingOp<T>::Compute(context, se::dnn::PoolingMode::kMaximum, ksize_,",
            "                             stride_, padding_, explicit_paddings_,",
            "                             data_format_, tensor_in, out_shape,",
            "                             propagate_nans_);"
        ]
    ],
    "Clean Code": [
        [
            "                        params.out_width, params.depth);",
            "",
            "    // Degenerate pooling output should return an empty tensor.",
            "    if (out_shape.num_elements() == 0) {",
            "      Tensor* output = nullptr;",
            "      OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));",
            "      return;",
            "    }",
            "",
            "    // Assuming qint8 <--> NCHW_VECT_C (int8x4) here.",
            "    constexpr bool is_int8x4 = std::is_same<T, qint8>::value;",
            "    OP_REQUIRES(context, (is_int8x4 == (data_format_ == FORMAT_NCHW_VECT_C)),",
            "                errors::InvalidArgument("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-j43h-pgmg-5hjq",
    "API Signature": "tf.raw_ops.MaxPool(\n    input,\n    ksize,\n    strides,\n    padding,\n    explicit_paddings=[],\n    data_format='NHWC',\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "ksize = [1, 1, 2, 2]"
},
{
    "Title": "\n        `CHECK` fail in `tf.linalg.matrix_rank`\n      ",
    "Bug description": "When  tf.linalg.matrix_rank  receives an empty input  a , the GPU kernel gives a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "a = tf.constant([], shape=[0, 1, 1], dtype=tf.float32)\n)\ntf.linalg.matrix_rank(a=a)",
    "Code change": [
        "@@ -395,6 +395,12 @@ class SvdOpGpu : public AsyncOpKernel {\n     OP_REQUIRES_OK_ASYNC(context, context->allocate_output(2, shapeV, &outputV),\n                          done);\n \n+    // If there are zero batches, we are done.\n+    if (shapeRaw.num_elements() == 0) {\n+      done();\n+      return;\n+    }\n+\n     if (n == 0 || m == 0) {\n       if (n == m || !compute_uv_ || !full_matrices_) {\n         // S, U, and V are all empty. Nothing to do.\n",
        "@@ -108,6 +108,14 @@ class SvdOpTest(test.TestCase):\n     for i in range(0, len(val), 2):\n       self.assertAllEqual(val[i], val[i + 1])\n \n+  @test_util.run_in_graph_and_eager_modes(use_gpu=True)\n+  def testEmptyBatches(self):\n+    matrices = constant_op.constant(1.0, shape=[0, 2, 2])\n+    s, u, v = self.evaluate(linalg_ops.svd(matrices))\n+    self.assertAllEqual(s, np.zeros([0, 2]))\n+    self.assertAllEqual(u, np.zeros([0, 2, 2]))\n+    self.assertAllEqual(v, np.zeros([0, 2, 2]))\n+\n \n def _GetSvdOpTest(dtype_, shape_, use_static_shape_, compute_uv_,\n                   full_matrices_):\n"
    ],
    "Buggy Code": [
        [
            "                         done);",
            "",
            "    if (n == 0 || m == 0) {",
            "      if (n == m || !compute_uv_ || !full_matrices_) {",
            "        // S, U, and V are all empty. Nothing to do.",
            "        done();",
            "        return;",
            "      }",
            "      auto device = context->eigen_device<GPUDevice>();",
            "      functor::EyeFunctor<GPUDevice, Scalar> eye;",
            "      if (m > 0) {",
            "        // Return a full canonical basis for the column space."
        ]
    ],
    "Clean Code": [
        [
            "                         done);",
            "",
            "    // If there are zero batches, we are done.",
            "    if (shapeRaw.num_elements() == 0) {",
            "      done();",
            "      return;",
            "    }",
            "",
            "    if (n == 0 || m == 0) {",
            "      if (n == m || !compute_uv_ || !full_matrices_) {",
            "        // S, U, and V are all empty. Nothing to do.",
            "        done();"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9vqj-64pv-w55c",
    "API Signature": "tf.linalg.matrix_rank(\n    a, tol=None, validate_args=False, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "a = tf.constant([], shape=[0, 1, 1], dtype=tf.float32)"
},
{
    "Title": "\n        `CHECK` fail in `DenseBincount`\n      ",
    "Bug description": "DenseBincount  assumes its input tensor  weights  to either have the same shape as its input tensor  input  or to be length-0. A different  weights  shape will trigger a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "binary_output = True\ninput = tf.random.uniform(shape=[0, 0], minval=-10000, maxval=10000, dtype=tf.int32, seed=-2460)\nsize = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-10000)\nweights = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.float32, seed=-10000)\n)\ntf.raw_ops.DenseBincount(input=input, size=size, weights=weights, binary_output=binary_output)",
    "Code change": [
        "@@ -80,6 +80,17 @@ class DenseBincountOp : public XlaOpKernel {\n     OP_REQUIRES_OK(ctx, weights_shape_or.status());\n \n     auto weights_shape = weights_shape_or.ValueOrDie();\n+    OP_REQUIRES(ctx,\n+                xla::ShapeUtil::CompatibleIgnoringElementType(weights_shape,\n+                                                              input_shape) ||\n+                    (weights_shape.dimensions_size() > 0 &&\n+                     weights_shape.dimensions(0) == 0),\n+                errors::InvalidArgument(\n+                    \"`weights` must be the same shape as `arr` or a length-0 \"\n+                    \"`Tensor`, in which case it acts as all weights equal to \"\n+                    \"1. Received \",\n+                    weights_shape.DebugString()));\n+\n     auto weights_size = weights_shape.dimensions(0);\n     bool has_weights = false;\n     if (weights_size) {\n",
        "@@ -280,6 +280,14 @@ class DenseBincountOp : public OpKernel {\n     OP_REQUIRES(ctx, size_t.dims() == 0,\n                 errors::InvalidArgument(\"Shape must be rank 0 but is rank \",\n                                         size_t.dims()));\n+    OP_REQUIRES(ctx,\n+                weights.shape() == data.shape() || weights.NumElements() == 0,\n+                errors::InvalidArgument(\n+                    \"`weights` must be the same shape as `arr` or a length-0 \"\n+                    \"`Tensor`, in which case it acts as all weights equal to \"\n+                    \"1. Received \",\n+                    weights.shape().DebugString()));\n+\n     Tidx size = size_t.scalar<Tidx>()();\n     OP_REQUIRES(\n         ctx, size >= 0,\n",
        "@@ -24,6 +24,7 @@ from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import bincount_ops\n from tensorflow.python.ops import gen_math_ops\n+from tensorflow.python.ops import random_ops\n from tensorflow.python.ops import sparse_ops\n from tensorflow.python.ops.ragged import ragged_factory_ops\n from tensorflow.python.ops.ragged import ragged_tensor\n@@ -152,6 +153,31 @@ class BincountTest(test_util.TensorFlowTestCase):\n       v2 = gen_math_ops.bincount([1, 2, 3, 1, 6, 8], s, [])\n       self.assertAllEqual(v2.get_shape().as_list(), [None])\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    binary_output = True\n+    inp = random_ops.random_uniform(\n+        shape=[10, 10],\n+        minval=-10000,\n+        maxval=10000,\n+        dtype=dtypes.int32,\n+        seed=-2460)\n+    size = random_ops.random_uniform(\n+        shape=[], minval=-10000, maxval=10000, dtype=dtypes.int32, seed=-10000)\n+    weights = random_ops.random_uniform(\n+        shape=[],\n+        minval=-10000,\n+        maxval=10000,\n+        dtype=dtypes.float32,\n+        seed=-10000)\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      self.evaluate(\n+          gen_math_ops.dense_bincount(\n+              input=inp,\n+              size=size,\n+              weights=weights,\n+              binary_output=binary_output))\n+\n \n class BincountOpTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n \n"
    ],
    "Buggy Code": [
        [
            "",
            "    auto weights_shape = weights_shape_or.ValueOrDie();",
            "    auto weights_size = weights_shape.dimensions(0);",
            "    bool has_weights = false;",
            "    if (weights_size) {",
            "      has_weights = true;",
            "    }",
            "    xla::Shape output_shape = xla::ShapeUtil::MakeShape(dtype, {output_size});",
            "    xla::ScatterDimensionNumbers scatter_dnums;",
            "    scatter_dnums.set_index_vector_dim(1);",
            "    scatter_dnums.add_inserted_window_dims(0);",
            "    scatter_dnums.add_scatter_dims_to_operand_dims(0);",
            "",
            "    if (rank == 2) {",
            "      output_shape = xla::ShapeUtil::MakeShape(dtype, {size, output_size});",
            "      scatter_dnums.add_inserted_window_dims(1);",
            "      scatter_dnums.add_scatter_dims_to_operand_dims(1);"
        ],
        [
            "                errors::InvalidArgument(\"Shape must be rank 0 but is rank \",",
            "                                        size_t.dims()));",
            "    Tidx size = size_t.scalar<Tidx>()();",
            "    OP_REQUIRES(",
            "        ctx, size >= 0,",
            "        errors::InvalidArgument(\"size (\", size, \") must be non-negative\"));",
            "",
            "    Tensor* out_t;",
            "    functor::SetZeroFunctor<Device, T> fill;",
            "    if (data.dims() == 1) {",
            "      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({size}), &out_t));",
            "      auto out = out_t->flat<T>();",
            "      fill(ctx->eigen_device<Device>(), out);",
            "      if (binary_output_) {"
        ]
    ],
    "Clean Code": [
        [
            "",
            "    auto weights_shape = weights_shape_or.ValueOrDie();",
            "    OP_REQUIRES(ctx,",
            "                xla::ShapeUtil::CompatibleIgnoringElementType(weights_shape,",
            "                                                              input_shape) ||",
            "                    (weights_shape.dimensions_size() > 0 &&",
            "                     weights_shape.dimensions(0) == 0),",
            "                errors::InvalidArgument(",
            "                    \"`weights` must be the same shape as `arr` or a length-0 \"",
            "                    \"`Tensor`, in which case it acts as all weights equal to \"",
            "                    \"1. Received \",",
            "                    weights_shape.DebugString()));",
            "",
            "    auto weights_size = weights_shape.dimensions(0);",
            "    bool has_weights = false;",
            "    if (weights_size) {",
            "      has_weights = true;"
        ],
        [
            "                errors::InvalidArgument(\"Shape must be rank 0 but is rank \",",
            "                                        size_t.dims()));",
            "    OP_REQUIRES(ctx,",
            "                weights.shape() == data.shape() || weights.NumElements() == 0,",
            "                errors::InvalidArgument(",
            "                    \"`weights` must be the same shape as `arr` or a length-0 \"",
            "                    \"`Tensor`, in which case it acts as all weights equal to \"",
            "                    \"1. Received \",",
            "                    weights.shape().DebugString()));",
            "",
            "    Tidx size = size_t.scalar<Tidx>()();",
            "    OP_REQUIRES(",
            "        ctx, size >= 0,",
            "        errors::InvalidArgument(\"size (\", size, \") must be non-negative\"));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-w62h-8xjm-fv49",
    "API Signature": "tf.raw_ops.DenseBincount(\n    input, size, weights, binary_output=False, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "input = tf.random.uniform(shape=[0, 0], minval=-10000, maxval=10000, dtype=tf.int32, seed=-2460)\nweights = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.float32, seed=-10000)"
},
{
    "Title": "\n        Segfault in `RaggedBincount`\n      ",
    "Bug description": "If  RaggedBincount  is given an empty input tensor  splits , it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "binary_output = True\nsplits = tf.random.uniform(shape=[0], minval=-10000, maxval=10000, dtype=tf.int64, seed=-7430)\nvalues = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-10000)\nsize = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-10000)\nweights = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.float32, seed=-10000)\n)\ntf.raw_ops.RaggedBincount(splits=splits, values=values, size=size, weights=weights, binary_output=binary_output)",
    "Code change": [
        "@@ -493,6 +493,9 @@ class RaggedBincountOp : public OpKernel {\n     int num_values = values.size();\n     int batch_idx = 0;\n \n+    OP_REQUIRES(ctx, splits.size() > 0,\n+                errors::InvalidArgument(\"Splits must be non-empty\"));\n+\n     OP_REQUIRES(ctx, splits(0) == 0,\n                 errors::InvalidArgument(\"Splits must start with 0, not with \",\n                                         splits(0)));\n",
        "@@ -734,6 +734,18 @@ class RaggedBincountOpTest(test_util.TensorFlowTestCase,\n               binary_output=False,\n               name=None))\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def test_splits_empty(self):  # b/238450914\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Splits must be non-empty\"):\n+      self.evaluate(\n+          gen_math_ops.ragged_bincount(\n+              splits=[],  # Invalid splits\n+              values=[1],\n+              size=1,\n+              weights=[1],\n+              binary_output=False,\n+              name=None))\n \n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Buggy Code": [
        [
            "    int batch_idx = 0;",
            "",
            "    OP_REQUIRES(ctx, splits(0) == 0,",
            "                errors::InvalidArgument(\"Splits must start with 0, not with \",",
            "                                        splits(0)));",
            "",
            "    OP_REQUIRES(ctx, splits(num_rows) == num_values,",
            "                errors::InvalidArgument(",
            "                    \"Splits must end with the number of values, got \","
        ]
    ],
    "Clean Code": [
        [
            "    int batch_idx = 0;",
            "",
            "    OP_REQUIRES(ctx, splits.size() > 0,",
            "                errors::InvalidArgument(\"Splits must be non-empty\"));",
            "",
            "    OP_REQUIRES(ctx, splits(0) == 0,",
            "                errors::InvalidArgument(\"Splits must start with 0, not with \",",
            "                                        splits(0)));",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wr9v-g9vf-c74v",
    "API Signature": "tf.raw_ops.RaggedBincount(\n    splits, values, size, weights, binary_output=False, name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "splits = tf.random.uniform(shape=[0], minval=-10000, maxval=10000, dtype=tf.int64, seed=-7430)"
},
{
    "Title": "\n        `CHECK` fail in `LRNGrad`\n      ",
    "Bug description": "If  LRNGrad  is given an  output_image  input tensor that is not 4-D, it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "depth_radius = 1\nbias = 1.59018219\nalpha = 0.117728651\nbeta = 0.404427052\ninput_grads = tf.random.uniform(shape=[4, 4, 4, 4], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2033)\ninput_image = tf.random.uniform(shape=[4, 4, 4, 4], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2033)\noutput_image = tf.random.uniform(shape=[4, 4, 4, 4, 4, 4], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2033)\n)\ntf.raw_ops.LRNGrad(input_grads=input_grads, input_image=input_image, output_image=output_image, depth_radius=depth_radius, bias=bias, alpha=alpha, beta=beta)",
    "Code change": [
        "@@ -668,7 +668,8 @@ class LRNGradOp : public OpKernel {\n         in_image.dim_size(0) == batch && in_image.dim_size(1) == rows &&\n             in_image.dim_size(2) == cols && in_image.dim_size(3) == depth &&\n             out_image.dim_size(0) == batch && out_image.dim_size(1) == rows &&\n-            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth,\n+            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth &&\n+            out_image.dims() == 4,\n         errors::InvalidArgument(\n             \"input_grads, input_image, and out_image should have the same \"\n             \"shape\"));\n",
        "@@ -20,11 +20,13 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors_impl\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gradient_checker\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import nn\n+from tensorflow.python.ops import random_ops\n import tensorflow.python.ops.nn_grad  # pylint: disable=unused-import\n from tensorflow.python.platform import test\n \n@@ -111,6 +113,41 @@ class LRNOpTest(test.TestCase):\n     self.assertAllClose(r, expected)\n     self.assertShapeEqual(expected, grad)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testIncompatibleInputAndOutputImageShapes(self):\n+    depth_radius = 1\n+    bias = 1.59018219\n+    alpha = 0.117728651\n+    beta = 0.404427052\n+    input_grads = random_ops.random_uniform(\n+        shape=[4, 4, 4, 4],\n+        minval=-10000,\n+        maxval=10000,\n+        dtype=dtypes.float32,\n+        seed=-2033)\n+    input_image = random_ops.random_uniform(\n+        shape=[4, 4, 4, 4],\n+        minval=-10000,\n+        maxval=10000,\n+        dtype=dtypes.float32,\n+        seed=-2033)\n+    invalid_output_image = random_ops.random_uniform(\n+        shape=[4, 4, 4, 4, 4, 4],\n+        minval=-10000,\n+        maxval=10000,\n+        dtype=dtypes.float32,\n+        seed=-2033)\n+    with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n+      self.evaluate(\n+          nn.lrn_grad(\n+              input_grads=input_grads,\n+              input_image=input_image,\n+              output_image=invalid_output_image,\n+              depth_radius=depth_radius,\n+              bias=bias,\n+              alpha=alpha,\n+              beta=beta))\n+\n   def _RunAndVerifyGradients(self, dtype):\n     with self.cached_session():\n       # random shape\n"
    ],
    "Buggy Code": [
        [
            "            in_image.dim_size(2) == cols && in_image.dim_size(3) == depth &&",
            "            out_image.dim_size(0) == batch && out_image.dim_size(1) == rows &&",
            "            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth,",
            "        errors::InvalidArgument(",
            "            \"input_grads, input_image, and out_image should have the same \"",
            "            \"shape\"));",
            "",
            "    Tensor* output = nullptr;"
        ]
    ],
    "Clean Code": [
        [
            "            in_image.dim_size(2) == cols && in_image.dim_size(3) == depth &&",
            "            out_image.dim_size(0) == batch && out_image.dim_size(1) == rows &&",
            "            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth &&",
            "            out_image.dims() == 4,",
            "        errors::InvalidArgument(",
            "            \"input_grads, input_image, and out_image should have the same \"",
            "            \"shape\"));",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9942-r22v-78cp",
    "API Signature": "tf.raw_ops.LRNGrad(\n    input_grads,\n    input_image,\n    output_image,\n    depth_radius=5,\n    bias=1,\n    alpha=1,\n    beta=0.5,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "utput_image = tf.random.uniform(shape=[4, 4, 4, 4, 4, 4], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2033)"
},
{
    "Title": "\n        `CHECK` fail in `ParameterizedTruncatedNormal`\n      ",
    "Bug description": "ParameterizedTruncatedNormal  assumes  shape  is of type  int32 . A valid  shape  of type  int64  results in a mismatched type  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "seed = 1618\nseed2 = 0\nshape = tf.random.uniform(shape=[3], minval=-10000, maxval=10000, dtype=tf.int64, seed=4894)\nmeans = tf.random.uniform(shape=[3, 3, 3], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2971)\nstdevs = tf.random.uniform(shape=[3, 3, 3], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2971)\nminvals = tf.random.uniform(shape=[3, 3, 3], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2971)\nmaxvals = tf.random.uniform(shape=[3, 3, 3], minval=-10000, maxval=10000, dtype=tf.float32, seed=-2971)\n)\ntf.raw_ops.ParameterizedTruncatedNormal(shape=shape, means=means, stdevs=stdevs, minvals=minvals, maxvals=maxvals, seed=seed, seed2=seed2)",
    "Code change": [
        "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/kernels/stateless_random_ops.h\"\n #include \"tensorflow/core/lib/random/random_distributions.h\"\n #include \"tensorflow/core/platform/logging.h\"\n@@ -630,20 +631,18 @@ class ParameterizedTruncatedNormalOp : public OpKernel {\n     OP_REQUIRES(ctx, shape_tensor.NumElements() > 0,\n                 errors::InvalidArgument(\"Shape tensor must not be empty, got \",\n                                         shape_tensor.DebugString()));\n-    int32_t num_batches = shape_tensor.flat<int32>()(0);\n+    TensorShape tensor_shape;\n+    OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_tensor, &tensor_shape));\n \n+    int32_t num_batches = tensor_shape.dim_size(0);\n     int32_t samples_per_batch = 1;\n-    const int32_t num_dims = shape_tensor.dim_size(0);\n+    const int32_t num_dims = tensor_shape.dims();\n     for (int32_t i = 1; i < num_dims; i++) {\n-      samples_per_batch *= shape_tensor.flat<int32>()(i);\n+      samples_per_batch *= tensor_shape.dim_size(i);\n     }\n     const int32_t num_elements = num_batches * samples_per_batch;\n \n     // Allocate the output before fudging num_batches and samples_per_batch.\n-    auto shape_vec = shape_tensor.flat<int32>();\n-    TensorShape tensor_shape;\n-    OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(\n-                            shape_vec.data(), shape_vec.size(), &tensor_shape));\n     Tensor* samples_tensor;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, tensor_shape, &samples_tensor));\n \n",
        "@@ -303,6 +303,29 @@ class ParameterizedTruncatedNormalTest(test.TestCase):\n       self.assertAllGreater(samples, 0.)\n       self.assertAllGreater(samples_stateless, 0.)\n \n+  def testShapeTypes(self):\n+    for shape_dtype in [np.int32, np.int64]:\n+      shape = np.array([1000], dtype=shape_dtype)\n+      sample_op = random_ops.parameterized_truncated_normal(\n+          shape=shape, means=0.0, stddevs=0.1, minvals=-1., maxvals=1.)\n+      new_seed = random_ops.random_uniform([2],\n+                                           seed=1234,\n+                                           minval=0,\n+                                           maxval=(2**31 - 1),\n+                                           dtype=np.int32)\n+      sample_op_stateless = stateless.stateless_parameterized_truncated_normal(\n+          shape=shape,\n+          seed=new_seed,\n+          means=0.0,\n+          stddevs=0.1,\n+          minvals=-1.,\n+          maxvals=1.)\n+\n+      samples = self.evaluate(sample_op)\n+      stateless_samples = self.evaluate(sample_op_stateless)\n+      self.assertAllEqual(samples.shape, shape)\n+      self.assertAllEqual(stateless_samples.shape, shape)\n+\n   def testStatelessParameterizedTruncatedNormalHasGrads(self):\n     mean = variables.Variable(0.01)\n     stddev = variables.Variable(1.)\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/kernels/stateless_random_ops.h\"",
            "#include \"tensorflow/core/lib/random/random_distributions.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/util/guarded_philox_random.h\"",
            "#include \"tensorflow/core/util/work_sharder.h\""
        ],
        [
            "                                        shape_tensor.DebugString()));",
            "    int32_t num_batches = shape_tensor.flat<int32>()(0);",
            "",
            "    int32_t samples_per_batch = 1;",
            "    const int32_t num_dims = shape_tensor.dim_size(0);",
            "    for (int32_t i = 1; i < num_dims; i++) {",
            "      samples_per_batch *= shape_tensor.flat<int32>()(i);",
            "    }",
            "    const int32_t num_elements = num_batches * samples_per_batch;",
            "",
            "    // Allocate the output before fudging num_batches and samples_per_batch.",
            "    auto shape_vec = shape_tensor.flat<int32>();",
            "    TensorShape tensor_shape;",
            "    OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(",
            "                            shape_vec.data(), shape_vec.size(), &tensor_shape));",
            "    Tensor* samples_tensor;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, tensor_shape, &samples_tensor));",
            ""
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/kernels/stateless_random_ops.h\"",
            "#include \"tensorflow/core/lib/random/random_distributions.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/util/guarded_philox_random.h\""
        ],
        [
            "                errors::InvalidArgument(\"Shape tensor must not be empty, got \",",
            "                                        shape_tensor.DebugString()));",
            "    TensorShape tensor_shape;",
            "    OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_tensor, &tensor_shape));",
            "",
            "    int32_t num_batches = tensor_shape.dim_size(0);",
            "    int32_t samples_per_batch = 1;",
            "    const int32_t num_dims = tensor_shape.dims();",
            "    for (int32_t i = 1; i < num_dims; i++) {",
            "      samples_per_batch *= tensor_shape.dim_size(i);",
            "    }",
            "    const int32_t num_elements = num_batches * samples_per_batch;",
            "",
            "    // Allocate the output before fudging num_batches and samples_per_batch.",
            "    Tensor* samples_tensor;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, tensor_shape, &samples_tensor));",
            "",
            "    // Parameters must be 0-d or 1-d."
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-p2xf-8hgm-hpw5",
    "API Signature": "tf.raw_ops.ParameterizedTruncatedNormal(\n    shape, means, stdevs, minvals, maxvals, seed=0, seed2=0, name=None\n)\n",
    "Score": 0.01079136690647482,
    "Anomaly": "Tensor with specific dtype",
    "Anomaly Description": "A tensor with random data type",
    "Category": "Tensor",
    "Argument": "shape = tf.random.uniform(shape=[3], minval=-10000, maxval=10000, dtype=tf.int64, seed=4894)"
},
{
    "Title": "\n        `CHECK` fail in `Save` and `SaveSlices`\n      ",
    "Bug description": "If  Save  or  SaveSlices  is run over tensors of an unsupported  dtype , it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "filename = tf.constant(\"\")\ntensor_names = tf.constant(\"\")\n# Save\ndata = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=-2021), tf.uint64)\ntf.raw_ops.Save(filename=filename, tensor_names=tensor_names, data=data, )\n# SaveSlices\nshapes_and_slices = tf.constant(\"\")\ndata = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=9712), tf.uint32)\n)\ntf.raw_ops.SaveSlices(filename=filename, tensor_names=tensor_names, shapes_and_slices=shapes_and_slices, data=data, )",
    "Code change": [
        "@@ -131,6 +131,16 @@ Status TensorSliceWriter::Finish() {\n \n /* static */\n size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n+  size_t max_bytes_per_element =\n+      TensorSliceWriter::MaxBytesPerElementOrZero(dt);\n+  if (max_bytes_per_element == 0) {\n+    LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n+  }\n+  return max_bytes_per_element;\n+}\n+\n+/* static */\n+size_t TensorSliceWriter::MaxBytesPerElementOrZero(DataType dt) {\n   switch (dt) {\n     case DT_FLOAT:\n       return 4;\n@@ -170,9 +180,8 @@ size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n     case DT_STRING:\n     case DT_BFLOAT16:\n     default:\n-      LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n+      return 0;\n   }\n-  return 0;\n }\n \n template <>\n",
        "@@ -68,6 +68,8 @@ class TensorSliceWriter {\n   static size_t MaxBytesPerElement(DataType dt);\n \n  private:\n+  static size_t MaxBytesPerElementOrZero(DataType dt);\n+\n   static constexpr size_t kMaxMessageBytes = 1LL << 31;\n   // Filling in the TensorProto in a SavedSlice will add the following\n   // header bytes, in addition to the data:\n@@ -162,9 +164,15 @@ Status TensorSliceWriter::Add(const string& name, const TensorShape& shape,\n template <typename T>\n Status TensorSliceWriter::SaveData(const T* data, int64_t num_elements,\n                                    SavedSlice* ss) {\n-  size_t size_bound =\n-      ss->ByteSize() + kTensorProtoHeaderBytes +\n-      (MaxBytesPerElement(DataTypeToEnum<T>::value) * num_elements);\n+  size_t max_bytes_per_element =\n+      MaxBytesPerElementOrZero(DataTypeToEnum<T>::value);\n+  if (max_bytes_per_element == 0) {\n+    return errors::InvalidArgument(\n+        \"Tensor slice serialization not implemented for dtype \",\n+        DataTypeToEnum<T>::value);\n+  }\n+  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +\n+                      (max_bytes_per_element * num_elements);\n   if (size_bound > kMaxMessageBytes) {\n     return errors::InvalidArgument(\n         \"Tensor slice is too large to serialize (conservative estimate: \",\n",
        "@@ -15,17 +15,19 @@ limitations under the License.\n \n #include \"tensorflow/core/util/tensor_slice_writer.h\"\n \n+#include <algorithm>\n #include <array>\n+#include <memory>\n+#include <vector>\n \n #include \"tensorflow/core/framework/tensor_shape.pb.h\"\n #include \"tensorflow/core/framework/versions.pb.h\"\n #include \"tensorflow/core/lib/core/status_test_util.h\"\n-#include \"tensorflow/core/lib/core/stringpiece.h\"\n-#include \"tensorflow/core/lib/io/path.h\"\n-#include \"tensorflow/core/lib/strings/str_util.h\"\n #include \"tensorflow/core/platform/logging.h\"\n+#include \"tensorflow/core/platform/path.h\"\n #include \"tensorflow/core/platform/protobuf.h\"\n #include \"tensorflow/core/platform/test.h\"\n+#include \"tensorflow/core/protobuf/error_codes.pb.h\"\n #include \"tensorflow/core/public/version.h\"\n #include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n #include \"tensorflow/core/util/tensor_slice_reader.h\"\n@@ -362,6 +364,17 @@ TEST(TensorSliceWriteTest, SizeErrors) {\n   }\n }\n \n+TEST(TensorSliceWriterTest, InvalidInput) {\n+  SavedSlice ss;\n+  std::array<uint32_t, 1> data;\n+  std::fill(data.begin(), data.end(), 1234);\n+  Status s = TensorSliceWriter::SaveData(data.data(), data.size(), &ss);\n+  EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n+  EXPECT_TRUE(absl::StrContains(\n+      s.error_message(),\n+      \"Tensor slice serialization not implemented for dtype\"));\n+}\n+\n }  // namespace checkpoint\n \n }  // namespace tensorflow\n"
    ],
    "Buggy Code": [
        [
            "/* static */",
            "size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {",
            "  switch (dt) {",
            "    case DT_FLOAT:",
            "      return 4;",
            "    case DT_DOUBLE:",
            "      return 8;",
            "    case DT_INT32:",
            "      return 10;",
            "    case DT_UINT8:",
            "      return 2;",
            "    case DT_INT16:",
            "      return 10;",
            "    case DT_INT8:",
            "      return 10;",
            "    case DT_COMPLEX64:"
        ],
        [
            "  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +",
            "                      (num_elements * MaxBytesPerElement(DT_INT32));",
            "  for (int64_t i = 0; i < num_elements; ++i) {",
            "    size_bound += data[i].size();",
            "  }",
            "  if (size_bound > kMaxMessageBytes) {",
            "    return errors::InvalidArgument(",
            "        \"Tensor slice is too large to serialize (conservative estimate: \","
        ],
        [
            "",
            " private:",
            "  static constexpr size_t kMaxMessageBytes = 1LL << 31;",
            "  // Filling in the TensorProto in a SavedSlice will add the following",
            "  // header bytes, in addition to the data:",
            "  // - 1 byte: TensorProto tag and wire format",
            "  // - <= 5 bytes: TensorProto length",
            "  // - 1 byte: Repeated *_val tag and wire format"
        ],
        [
            "  size_t size_bound =",
            "      ss->ByteSize() + kTensorProtoHeaderBytes +",
            "      (MaxBytesPerElement(DataTypeToEnum<T>::value) * num_elements);",
            "  if (size_bound > kMaxMessageBytes) {",
            "    return errors::InvalidArgument(",
            "        \"Tensor slice is too large to serialize (conservative estimate: \",",
            "        size_bound, \" bytes)\");",
            "  }",
            "  Fill(data, num_elements, ss->mutable_data());",
            "  DCHECK_GE(ss->ByteSize(), 0);",
            "  DCHECK_LE(ss->ByteSize(), size_bound);",
            "  return OkStatus();",
            "}",
            "",
            "template <>"
        ]
    ],
    "Clean Code": [
        [
            "/* static */",
            "size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {",
            "  size_t max_bytes_per_element =",
            "      TensorSliceWriter::MaxBytesPerElementOrZero(dt);",
            "  if (max_bytes_per_element == 0) {",
            "    LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;",
            "  }",
            "  return max_bytes_per_element;",
            "}",
            "",
            "/* static */",
            "size_t TensorSliceWriter::MaxBytesPerElementOrZero(DataType dt) {",
            "  switch (dt) {",
            "    case DT_FLOAT:",
            "      return 4;",
            "    case DT_DOUBLE:"
        ],
        [
            "    case DT_BFLOAT16:",
            "    default:",
            "      return 0;",
            "  }",
            "}",
            "",
            "template <>",
            "Status TensorSliceWriter::SaveData(const tstring* data, int64_t num_elements,"
        ],
        [
            "",
            " private:",
            "  static size_t MaxBytesPerElementOrZero(DataType dt);",
            "",
            "  static constexpr size_t kMaxMessageBytes = 1LL << 31;",
            "  // Filling in the TensorProto in a SavedSlice will add the following",
            "  // header bytes, in addition to the data:",
            "  // - 1 byte: TensorProto tag and wire format"
        ],
        [
            "Status TensorSliceWriter::SaveData(const T* data, int64_t num_elements,",
            "                                   SavedSlice* ss) {",
            "  size_t max_bytes_per_element =",
            "      MaxBytesPerElementOrZero(DataTypeToEnum<T>::value);",
            "  if (max_bytes_per_element == 0) {",
            "    return errors::InvalidArgument(",
            "        \"Tensor slice serialization not implemented for dtype \",",
            "        DataTypeToEnum<T>::value);",
            "  }",
            "  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +",
            "                      (max_bytes_per_element * num_elements);",
            "  if (size_bound > kMaxMessageBytes) {",
            "    return errors::InvalidArgument(",
            "        \"Tensor slice is too large to serialize (conservative estimate: \",",
            "        size_bound, \" bytes)\");"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m6vp-8q9j-whx4",
    "API Signature": "tf.raw_ops.Save(\n    filename, tensor_names, data, name=None\n)\n",
    "Score": 0.01079136690647482,
    "Anomaly": "Tensor with specific dtype",
    "Anomaly Description": "A tensor with random data type",
    "Category": "Tensor",
    "Argument": "data = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=-2021), tf.uint64)"
},
{
    "Title": "\n        `CHECK` fail in `Save` and `SaveSlices`\n      ",
    "Bug description": "If  Save  or  SaveSlices  is run over tensors of an unsupported  dtype , it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "filename = tf.constant(\"\")\ntensor_names = tf.constant(\"\")\n# Save\ndata = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=-2021), tf.uint64)\ntf.raw_ops.Save(filename=filename, tensor_names=tensor_names, data=data, )\n# SaveSlices\nshapes_and_slices = tf.constant(\"\")\ndata = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=9712), tf.uint32)\n)\ntf.raw_ops.SaveSlices(filename=filename, tensor_names=tensor_names, shapes_and_slices=shapes_and_slices, data=data, )",
    "Code change": [
        "@@ -131,6 +131,16 @@ Status TensorSliceWriter::Finish() {\n \n /* static */\n size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n+  size_t max_bytes_per_element =\n+      TensorSliceWriter::MaxBytesPerElementOrZero(dt);\n+  if (max_bytes_per_element == 0) {\n+    LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n+  }\n+  return max_bytes_per_element;\n+}\n+\n+/* static */\n+size_t TensorSliceWriter::MaxBytesPerElementOrZero(DataType dt) {\n   switch (dt) {\n     case DT_FLOAT:\n       return 4;\n@@ -170,9 +180,8 @@ size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n     case DT_STRING:\n     case DT_BFLOAT16:\n     default:\n-      LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n+      return 0;\n   }\n-  return 0;\n }\n \n template <>\n",
        "@@ -68,6 +68,8 @@ class TensorSliceWriter {\n   static size_t MaxBytesPerElement(DataType dt);\n \n  private:\n+  static size_t MaxBytesPerElementOrZero(DataType dt);\n+\n   static constexpr size_t kMaxMessageBytes = 1LL << 31;\n   // Filling in the TensorProto in a SavedSlice will add the following\n   // header bytes, in addition to the data:\n@@ -162,9 +164,15 @@ Status TensorSliceWriter::Add(const string& name, const TensorShape& shape,\n template <typename T>\n Status TensorSliceWriter::SaveData(const T* data, int64_t num_elements,\n                                    SavedSlice* ss) {\n-  size_t size_bound =\n-      ss->ByteSize() + kTensorProtoHeaderBytes +\n-      (MaxBytesPerElement(DataTypeToEnum<T>::value) * num_elements);\n+  size_t max_bytes_per_element =\n+      MaxBytesPerElementOrZero(DataTypeToEnum<T>::value);\n+  if (max_bytes_per_element == 0) {\n+    return errors::InvalidArgument(\n+        \"Tensor slice serialization not implemented for dtype \",\n+        DataTypeToEnum<T>::value);\n+  }\n+  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +\n+                      (max_bytes_per_element * num_elements);\n   if (size_bound > kMaxMessageBytes) {\n     return errors::InvalidArgument(\n         \"Tensor slice is too large to serialize (conservative estimate: \",\n",
        "@@ -15,17 +15,19 @@ limitations under the License.\n \n #include \"tensorflow/core/util/tensor_slice_writer.h\"\n \n+#include <algorithm>\n #include <array>\n+#include <memory>\n+#include <vector>\n \n #include \"tensorflow/core/framework/tensor_shape.pb.h\"\n #include \"tensorflow/core/framework/versions.pb.h\"\n #include \"tensorflow/core/lib/core/status_test_util.h\"\n-#include \"tensorflow/core/lib/core/stringpiece.h\"\n-#include \"tensorflow/core/lib/io/path.h\"\n-#include \"tensorflow/core/lib/strings/str_util.h\"\n #include \"tensorflow/core/platform/logging.h\"\n+#include \"tensorflow/core/platform/path.h\"\n #include \"tensorflow/core/platform/protobuf.h\"\n #include \"tensorflow/core/platform/test.h\"\n+#include \"tensorflow/core/protobuf/error_codes.pb.h\"\n #include \"tensorflow/core/public/version.h\"\n #include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n #include \"tensorflow/core/util/tensor_slice_reader.h\"\n@@ -362,6 +364,17 @@ TEST(TensorSliceWriteTest, SizeErrors) {\n   }\n }\n \n+TEST(TensorSliceWriterTest, InvalidInput) {\n+  SavedSlice ss;\n+  std::array<uint32_t, 1> data;\n+  std::fill(data.begin(), data.end(), 1234);\n+  Status s = TensorSliceWriter::SaveData(data.data(), data.size(), &ss);\n+  EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n+  EXPECT_TRUE(absl::StrContains(\n+      s.error_message(),\n+      \"Tensor slice serialization not implemented for dtype\"));\n+}\n+\n }  // namespace checkpoint\n \n }  // namespace tensorflow\n"
    ],
    "Buggy Code": [
        [
            "/* static */",
            "size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {",
            "  switch (dt) {",
            "    case DT_FLOAT:",
            "      return 4;",
            "    case DT_DOUBLE:",
            "      return 8;",
            "    case DT_INT32:",
            "      return 10;",
            "    case DT_UINT8:",
            "      return 2;",
            "    case DT_INT16:",
            "      return 10;",
            "    case DT_INT8:",
            "      return 10;",
            "    case DT_COMPLEX64:"
        ],
        [
            "  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +",
            "                      (num_elements * MaxBytesPerElement(DT_INT32));",
            "  for (int64_t i = 0; i < num_elements; ++i) {",
            "    size_bound += data[i].size();",
            "  }",
            "  if (size_bound > kMaxMessageBytes) {",
            "    return errors::InvalidArgument(",
            "        \"Tensor slice is too large to serialize (conservative estimate: \","
        ],
        [
            "",
            " private:",
            "  static constexpr size_t kMaxMessageBytes = 1LL << 31;",
            "  // Filling in the TensorProto in a SavedSlice will add the following",
            "  // header bytes, in addition to the data:",
            "  // - 1 byte: TensorProto tag and wire format",
            "  // - <= 5 bytes: TensorProto length",
            "  // - 1 byte: Repeated *_val tag and wire format"
        ],
        [
            "  size_t size_bound =",
            "      ss->ByteSize() + kTensorProtoHeaderBytes +",
            "      (MaxBytesPerElement(DataTypeToEnum<T>::value) * num_elements);",
            "  if (size_bound > kMaxMessageBytes) {",
            "    return errors::InvalidArgument(",
            "        \"Tensor slice is too large to serialize (conservative estimate: \",",
            "        size_bound, \" bytes)\");",
            "  }",
            "  Fill(data, num_elements, ss->mutable_data());",
            "  DCHECK_GE(ss->ByteSize(), 0);",
            "  DCHECK_LE(ss->ByteSize(), size_bound);",
            "  return OkStatus();",
            "}",
            "",
            "template <>"
        ]
    ],
    "Clean Code": [
        [
            "/* static */",
            "size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {",
            "  size_t max_bytes_per_element =",
            "      TensorSliceWriter::MaxBytesPerElementOrZero(dt);",
            "  if (max_bytes_per_element == 0) {",
            "    LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;",
            "  }",
            "  return max_bytes_per_element;",
            "}",
            "",
            "/* static */",
            "size_t TensorSliceWriter::MaxBytesPerElementOrZero(DataType dt) {",
            "  switch (dt) {",
            "    case DT_FLOAT:",
            "      return 4;",
            "    case DT_DOUBLE:"
        ],
        [
            "    case DT_BFLOAT16:",
            "    default:",
            "      return 0;",
            "  }",
            "}",
            "",
            "template <>",
            "Status TensorSliceWriter::SaveData(const tstring* data, int64_t num_elements,"
        ],
        [
            "",
            " private:",
            "  static size_t MaxBytesPerElementOrZero(DataType dt);",
            "",
            "  static constexpr size_t kMaxMessageBytes = 1LL << 31;",
            "  // Filling in the TensorProto in a SavedSlice will add the following",
            "  // header bytes, in addition to the data:",
            "  // - 1 byte: TensorProto tag and wire format"
        ],
        [
            "Status TensorSliceWriter::SaveData(const T* data, int64_t num_elements,",
            "                                   SavedSlice* ss) {",
            "  size_t max_bytes_per_element =",
            "      MaxBytesPerElementOrZero(DataTypeToEnum<T>::value);",
            "  if (max_bytes_per_element == 0) {",
            "    return errors::InvalidArgument(",
            "        \"Tensor slice serialization not implemented for dtype \",",
            "        DataTypeToEnum<T>::value);",
            "  }",
            "  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +",
            "                      (max_bytes_per_element * num_elements);",
            "  if (size_bound > kMaxMessageBytes) {",
            "    return errors::InvalidArgument(",
            "        \"Tensor slice is too large to serialize (conservative estimate: \",",
            "        size_bound, \" bytes)\");"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m6vp-8q9j-whx4",
    "API Signature": null,
    "Score": 0.01079136690647482,
    "Anomaly": "Tensor with specific dtype",
    "Anomaly Description": "A tensor with random data type",
    "Category": "Tensor",
    "Argument": "data = tf.cast(tf.random.uniform(shape=[1], minval=-10000, maxval=10000, dtype=tf.int64, seed=9712), tf.uint32)"
},
{
    "Title": "\n        Segfault in `SparseBincount`\n      ",
    "Bug description": "If  SparseBincount  is given inputs for  indices ,  values , and  dense_shape  that do not make a valid sparse tensor, it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "binary_output = True\nindices = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int64, seed=-1288)\nvalues = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-9366)\ndense_shape = tf.random.uniform(shape=[0], minval=-10000, maxval=10000, dtype=tf.int64, seed=-9878)\nsize = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-10000)\nweights = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.float32, seed=-10000)\n)\ntf.raw_ops.SparseBincount(indices=indices, values=values, dense_shape=dense_shape, size=size, weights=weights, binary_output=binary_output)",
    "Code change": [
        "@@ -4421,6 +4421,7 @@ tf_kernel_library(\n     deps = [\n         \":fill_functor\",\n         \":gpu_prim_hdrs\",\n+        \":sparse_utils\",\n         \"//tensorflow/core:framework\",\n         \"//tensorflow/core:lib\",\n         \"//tensorflow/core:lib_internal\",\n@@ -5007,6 +5008,7 @@ cc_library(\n SPARSE_DEPS = [\n     \"//tensorflow/core:framework\",\n     \"//tensorflow/core:lib\",\n+    \":sparse_utils\",\n ]\n \n tf_kernel_library(\n@@ -6480,6 +6482,7 @@ filegroup(\n         \"sparse_reorder_op.h\",\n         \"sparse_slice_op.h\",\n         \"sparse_tensor_dense_matmul_op.h\",\n+        \"sparse_utils.h\",\n         \"string_util.h\",\n         \"string_to_hash_bucket_op.h\",\n         \"string_to_hash_bucket_fast_op.h\",\n@@ -6718,6 +6721,7 @@ filegroup(\n         \"random_ops_util.h\",\n         \"random_poisson_op.cc\",\n         \"shuffle_common.h\",\n+        \"sparse_utils.cc\",\n         \"random_shuffle_op.cc\",\n         \"reduce_join_op.cc\",\n         \"reduction_ops_all.cc\",\n",
        "@@ -23,6 +23,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/bincount_op.h\"\n #include \"tensorflow/core/kernels/fill_functor.h\"\n+#include \"tensorflow/core/kernels/sparse_utils.h\"\n #include \"tensorflow/core/lib/core/threadpool.h\"\n #include \"tensorflow/core/platform/types.h\"\n #include \"tensorflow/core/util/determinism.h\"\n@@ -369,7 +370,8 @@ class SparseBincountOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& indices = ctx->input(0);\n-    const auto values = ctx->input(1).flat<Tidx>();\n+    const Tensor& values = ctx->input(1);\n+    const auto values_flat = values.flat<Tidx>();\n     const Tensor& dense_shape = ctx->input(2);\n     const Tensor& size_t = ctx->input(3);\n     const auto weights = ctx->input(4).flat<T>();\n@@ -382,6 +384,9 @@ class SparseBincountOp : public OpKernel {\n     OP_REQUIRES(\n         ctx, size >= 0,\n         errors::InvalidArgument(\"size (\", size, \") must be non-negative\"));\n+    OP_REQUIRES_OK(\n+        ctx, sparse_utils::ValidateSparseTensor<int64_t>(\n+                 indices, values, dense_shape, /*validate_indices=*/true));\n \n     bool is_1d = dense_shape.NumElements() == 1;\n \n@@ -394,11 +399,11 @@ class SparseBincountOp : public OpKernel {\n       if (binary_output_) {\n         OP_REQUIRES_OK(ctx,\n                        functor::BincountFunctor<Device, Tidx, T, true>::Compute(\n-                           ctx, values, weights, out, size));\n+                           ctx, values_flat, weights, out, size));\n       } else {\n         OP_REQUIRES_OK(\n             ctx, functor::BincountFunctor<Device, Tidx, T, false>::Compute(\n-                     ctx, values, weights, out, size));\n+                     ctx, values_flat, weights, out, size));\n       }\n     } else {\n       const auto shape = dense_shape.flat<int64_t>();\n@@ -410,7 +415,7 @@ class SparseBincountOp : public OpKernel {\n       const auto indices_mat = indices.matrix<int64_t>();\n       for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\n         const int64_t batch = indices_mat(i, 0);\n-        const Tidx bin = values(i);\n+        const Tidx bin = values_flat(i);\n         OP_REQUIRES(\n             ctx, batch < out.dimension(0),\n             errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,\n",
        "@@ -366,7 +366,7 @@ class SparseBincountOpTest(test_util.TensorFlowTestCase,\n     num_rows = 128\n     size = 1000\n     n_elems = 4096\n-    inp_indices = np.random.randint(0, num_rows, (n_elems,))\n+    inp_indices = np.random.randint(0, num_rows, (n_elems, 1))\n     inp_vals = np.random.randint(0, size, (n_elems,), dtype=dtype)\n \n     np_out = np.bincount(inp_vals, minlength=size)\n@@ -390,7 +390,7 @@ class SparseBincountOpTest(test_util.TensorFlowTestCase,\n     num_rows = 128\n     size = 1000\n     n_elems = 4096\n-    inp_indices = np.random.randint(0, num_rows, (n_elems,))\n+    inp_indices = np.random.randint(0, num_rows, (n_elems, 1))\n     inp_vals = np.random.randint(0, size, (n_elems,), dtype=dtype)\n     inp_weight = np.random.random((n_elems,))\n \n@@ -415,7 +415,7 @@ class SparseBincountOpTest(test_util.TensorFlowTestCase,\n     num_rows = 128\n     size = 10\n     n_elems = 4096\n-    inp_indices = np.random.randint(0, num_rows, (n_elems,))\n+    inp_indices = np.random.randint(0, num_rows, (n_elems, 1))\n     inp_vals = np.random.randint(0, size, (n_elems,), dtype=dtype)\n \n     np_out = np.ones((size,))\n@@ -440,7 +440,7 @@ class SparseBincountOpTest(test_util.TensorFlowTestCase,\n     num_rows = 128\n     size = 10\n     n_elems = 4096\n-    inp_indices = np.random.randint(0, num_rows, (n_elems,))\n+    inp_indices = np.random.randint(0, num_rows, (n_elems, 1))\n     inp_vals = np.random.randint(0, size, (n_elems,), dtype=dtype)\n     inp_weight = np.random.random((n_elems,))\n \n@@ -532,6 +532,27 @@ class SparseBincountOpTest(test_util.TensorFlowTestCase,\n               weights=[0, 0],\n               binary_output=False))\n \n+  def test_sparse_bincount_input_validation(self):\n+    np.random.seed(42)\n+    num_rows = 128\n+    size = 1000\n+    n_elems = 4096\n+    inp_indices = np.random.randint(0, num_rows, (n_elems, 1))\n+    inp_vals = np.random.randint(0, size, (n_elems,))\n+\n+    # Insert negative index.\n+    inp_indices[10, 0] = -2\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"out of bounds\"):\n+      self.evaluate(\n+          gen_math_ops.sparse_bincount(\n+              indices=inp_indices,\n+              values=inp_vals,\n+              dense_shape=[num_rows],\n+              size=size,\n+              weights=[]))\n+\n \n class RaggedBincountOpTest(test_util.TensorFlowTestCase,\n                            parameterized.TestCase):\n"
    ],
    "Buggy Code": [
        [
            "        \":fill_functor\",",
            "        \":gpu_prim_hdrs\",",
            "        \"//tensorflow/core:framework\",",
            "        \"//tensorflow/core:lib\",",
            "        \"//tensorflow/core:lib_internal\",",
            "        \"//third_party/eigen3\",",
            "    ],"
        ],
        [
            "    \"//tensorflow/core:lib\",",
            "]",
            "",
            "tf_kernel_library(",
            "    name = \"sparse_add_grad_op\",",
            "    prefix = \"sparse_add_grad_op\",",
            "    deps = SPARSE_DEPS,"
        ],
        [
            "        \"string_util.h\",",
            "        \"string_to_hash_bucket_op.h\",",
            "        \"string_to_hash_bucket_fast_op.h\",",
            "        \"tensor_array.h\",",
            "        \"tensor_list.h\",",
            "        \"tensor_map.h\",",
            "        \"tile_functor.h\","
        ],
        [
            "        \"reduce_join_op.cc\",",
            "        \"reduction_ops_all.cc\",",
            "        \"reduction_ops_any.cc\",",
            "        \"reduction_ops_common.cc\",",
            "        \"reduction_ops_max.cc\",",
            "        \"reduction_ops_mean.cc\",",
            "        \"reduction_ops_min.cc\","
        ],
        [
            "#include \"tensorflow/core/kernels/bincount_op.h\"",
            "#include \"tensorflow/core/kernels/fill_functor.h\"",
            "#include \"tensorflow/core/lib/core/threadpool.h\"",
            "#include \"tensorflow/core/platform/types.h\"",
            "#include \"tensorflow/core/util/determinism.h\"",
            "",
            "namespace tensorflow {"
        ],
        [
            "    const Tensor& indices = ctx->input(0);",
            "    const auto values = ctx->input(1).flat<Tidx>();",
            "    const Tensor& dense_shape = ctx->input(2);",
            "    const Tensor& size_t = ctx->input(3);",
            "    const auto weights = ctx->input(4).flat<T>();",
            "    const int64_t weights_size = weights.size();",
            "",
            "    OP_REQUIRES(ctx, size_t.dims() == 0,"
        ],
        [
            "",
            "    bool is_1d = dense_shape.NumElements() == 1;",
            "",
            "    Tensor* out_t;",
            "    functor::SetZeroFunctor<Device, T> fill;",
            "    if (is_1d) {",
            "      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({size}), &out_t));",
            "      auto out = out_t->flat<T>();",
            "      fill(ctx->eigen_device<Device>(), out);"
        ],
        [
            "            ctx, functor::BincountFunctor<Device, Tidx, T, false>::Compute(",
            "                     ctx, values, weights, out, size));",
            "      }",
            "    } else {",
            "      const auto shape = dense_shape.flat<int64_t>();",
            "      const int64_t num_rows = shape(0);",
            "      OP_REQUIRES_OK(",
            "          ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));",
            "      const auto out = out_t->matrix<T>();",
            "      fill(ctx->eigen_device<Device>(), out_t->flat<T>());",
            "      const auto indices_mat = indices.matrix<int64_t>();"
        ],
        [
            "            errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,",
            "                                    \") must be less than the dimension size (\",",
            "                                    out.dimension(0), \").\"));",
            "        OP_REQUIRES(",
            "            ctx, bin < out.dimension(1),",
            "            errors::InvalidArgument(\"Index out ouf bound. `bin` (\", bin,",
            "                                    \") must be less then the dimension size (\","
        ]
    ],
    "Clean Code": [
        [
            "        \":fill_functor\",",
            "        \":gpu_prim_hdrs\",",
            "        \":sparse_utils\",",
            "        \"//tensorflow/core:framework\",",
            "        \"//tensorflow/core:lib\",",
            "        \"//tensorflow/core:lib_internal\",",
            "        \"//third_party/eigen3\","
        ],
        [
            "    \"//tensorflow/core:framework\",",
            "    \"//tensorflow/core:lib\",",
            "    \":sparse_utils\",",
            "]",
            "",
            "tf_kernel_library(",
            "    name = \"sparse_add_grad_op\","
        ],
        [
            "        \"sparse_slice_op.h\",",
            "        \"sparse_tensor_dense_matmul_op.h\",",
            "        \"sparse_utils.h\",",
            "        \"string_util.h\",",
            "        \"string_to_hash_bucket_op.h\",",
            "        \"string_to_hash_bucket_fast_op.h\",",
            "        \"tensor_array.h\","
        ],
        [
            "        \"random_poisson_op.cc\",",
            "        \"shuffle_common.h\",",
            "        \"sparse_utils.cc\",",
            "        \"random_shuffle_op.cc\",",
            "        \"reduce_join_op.cc\",",
            "        \"reduction_ops_all.cc\",",
            "        \"reduction_ops_any.cc\","
        ],
        [
            "#include \"tensorflow/core/kernels/bincount_op.h\"",
            "#include \"tensorflow/core/kernels/fill_functor.h\"",
            "#include \"tensorflow/core/kernels/sparse_utils.h\"",
            "#include \"tensorflow/core/lib/core/threadpool.h\"",
            "#include \"tensorflow/core/platform/types.h\"",
            "#include \"tensorflow/core/util/determinism.h\"",
            ""
        ],
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& indices = ctx->input(0);",
            "    const Tensor& values = ctx->input(1);",
            "    const auto values_flat = values.flat<Tidx>();",
            "    const Tensor& dense_shape = ctx->input(2);",
            "    const Tensor& size_t = ctx->input(3);",
            "    const auto weights = ctx->input(4).flat<T>();",
            "    const int64_t weights_size = weights.size();"
        ],
        [
            "        ctx, size >= 0,",
            "        errors::InvalidArgument(\"size (\", size, \") must be non-negative\"));",
            "    OP_REQUIRES_OK(",
            "        ctx, sparse_utils::ValidateSparseTensor<int64_t>(",
            "                 indices, values, dense_shape, /*validate_indices=*/true));",
            "",
            "    bool is_1d = dense_shape.NumElements() == 1;",
            "",
            "    Tensor* out_t;"
        ],
        [
            "        OP_REQUIRES_OK(ctx,",
            "                       functor::BincountFunctor<Device, Tidx, T, true>::Compute(",
            "                           ctx, values_flat, weights, out, size));",
            "      } else {",
            "        OP_REQUIRES_OK(",
            "            ctx, functor::BincountFunctor<Device, Tidx, T, false>::Compute(",
            "                     ctx, values_flat, weights, out, size));",
            "      }",
            "    } else {",
            "      const auto shape = dense_shape.flat<int64_t>();",
            "      const int64_t num_rows = shape(0);"
        ],
        [
            "      for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {",
            "        const int64_t batch = indices_mat(i, 0);",
            "        const Tidx bin = values_flat(i);",
            "        OP_REQUIRES(",
            "            ctx, batch < out.dimension(0),",
            "            errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,",
            "                                    \") must be less than the dimension size (\","
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-397c-5g2j-qxpv",
    "API Signature": "tf.raw_ops.SparseBincount(\n    indices, values, dense_shape, size, weights, binary_output=False, name=None\n)\n",
    "Score": 0.01079136690647482,
    "Anomaly": "Non sparse input tensor",
    "Anomaly Description": "A non-sparse input tensor refers to a tensor in which most of the elements are non-zero or have significant values, meaning it has a dense representation. In a non-sparse tensor, the majority of its elements contain meaningful data or contribute to computations.",
    "Category": "Tensor",
    "Argument": "indices = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int64, seed=-1288)\nvalues = tf.random.uniform(shape=[], minval=-10000, maxval=10000, dtype=tf.int32, seed=-9366)\ndense_shape = tf.random.uniform(shape=[0], minval=-10000, maxval=10000, dtype=tf.int64, seed=-9878)"
},
{
    "Title": "\n        `CHECK` fail in `RaggedTensorToVariant`\n      ",
    "Bug description": "If  RaggedTensorToVariant  is given a  rt_nested_splits  list that contains tensors of ranks other than one, it results in a  CHECK  fail that can be used to trigger a denial of service attack.",
    "Sample Code": "batched_input = True\nrt_nested_splits = tf.constant([0,32,64], shape=[3], dtype=tf.int64)\nrt_dense_values = tf.constant([0,32,64], shape=[3], dtype=tf.int64)\n)\ntf.raw_ops.RaggedTensorToVariant(rt_nested_splits=rt_nested_splits, rt_dense_values=rt_dense_values, batched_input=batched_input)",
    "Code change": [
        "@@ -188,6 +188,10 @@ class RaggedTensorToVariantOp : public OpKernel {\n     batched_ragged_input.mutable_nested_splits()->reserve(\n         ragged_nested_splits_len);\n     for (int i = 0; i < ragged_nested_splits_len; i++) {\n+      OP_REQUIRES(context, ragged_nested_splits_in[i].dims() == 1,\n+                  errors::InvalidArgument(\"Requires nested_row_splits[\", i, \"]\",\n+                                          \" to be rank 1 but is rank \",\n+                                          ragged_nested_splits_in[i].dims()));\n       batched_ragged_input.append_splits(ragged_nested_splits_in[i]);\n     }\n \n",
        "@@ -1468,6 +1468,21 @@ class RaggedTensorTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n         for i in range(3):\n           self.assertAllEqual(sess.run(rt[i]), out)\n \n+  def testToVariantInvalidParams(self):\n+    self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                           r'be rank 1 but is rank 0',\n+                           gen_ragged_conversion_ops.ragged_tensor_to_variant,\n+                           rt_nested_splits=[0, 1, 2],\n+                           rt_dense_values=[0, 1, 2],\n+                           batched_input=True)\n+\n+    self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                           r'be rank 1 but is rank 2',\n+                           gen_ragged_conversion_ops.ragged_tensor_to_variant,\n+                           rt_nested_splits=[[[0]], [[1]], [[2]]],\n+                           rt_dense_values=[0, 1, 2],\n+                           batched_input=True)\n+\n   def testFromVariantInvalidParams(self):\n     rt = ragged_factory_ops.constant([[0], [1], [2], [3]])\n     batched_variant = rt._to_variant(batched_input=True)\n"
    ],
    "Buggy Code": [
        [
            "        ragged_nested_splits_len);",
            "    for (int i = 0; i < ragged_nested_splits_len; i++) {",
            "      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);",
            "    }",
            "",
            "    if (!batched_input_) {",
            "      // Encode as a Scalar Variant Tensor.",
            "      Tensor* encoded_scalar;",
            "      OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({}),",
            "                                                       &encoded_scalar));"
        ]
    ],
    "Clean Code": [
        [
            "        ragged_nested_splits_len);",
            "    for (int i = 0; i < ragged_nested_splits_len; i++) {",
            "      OP_REQUIRES(context, ragged_nested_splits_in[i].dims() == 1,",
            "                  errors::InvalidArgument(\"Requires nested_row_splits[\", i, \"]\",",
            "                                          \" to be rank 1 but is rank \",",
            "                                          ragged_nested_splits_in[i].dims()));",
            "      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);",
            "    }",
            "",
            "    if (!batched_input_) {"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m6cv-4fmf-66xf",
    "API Signature": "tf.raw_ops.RaggedTensorToVariant(\n    rt_nested_splits, rt_dense_values, batched_input, name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "rt_nested_splits = tf.constant([0,32,64], shape=[3], dtype=tf.int64)"
},
{
    "Title": "\n        `CHECK` fail in `FractionalMaxPoolGrad`\n      ",
    "Bug description": "FractionalMaxPoolGrad  validates its inputs with  CHECK  failures instead of with returning errors. If it gets incorrectly sized inputs, the  CHECK  failure can be used to trigger a denial of service attack:",
    "Sample Code": "overlapping = True\norig_input = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)\norig_output = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)\nout_backprop = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)\nrow_pooling_sequence = tf.constant(0, shape=[5], dtype=tf.int64)\ncol_pooling_sequence = tf.constant(0, shape=[5], dtype=tf.int64)\n)\ntf.raw_ops.FractionalMaxPoolGrad(orig_input=orig_input, orig_output=orig_output, out_backprop=out_backprop, row_pooling_sequence=row_pooling_sequence, col_pooling_sequence=col_pooling_sequence, overlapping=overlapping)",
    "Code change": [
        "@@ -19,12 +19,13 @@ limitations under the License.\n #include <random>\n #include <vector>\n \n-#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n-\n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n+#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n #include \"tensorflow/core/lib/random/random.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n #include \"tensorflow/core/util/guarded_philox_random.h\"\n@@ -352,7 +353,9 @@ class FractionalMaxPoolGradOp : public OpKernel {\n         output_size[2] * output_size[1] * output_size[0];\n     for (int64_t i = 0; i < num_reshaped_cols; ++i) {\n       for (int64_t j = 0; j < output_size[3]; ++j) {\n-        DCHECK_EQ(tensor_out_dup_mat(j, i), tensor_out_mat(j, i));\n+        OP_REQUIRES(context, tensor_out_dup_mat(j, i) == tensor_out_mat(j, i),\n+                    errors::InvalidArgument(\n+                        \"tensor_out_dup is not the same as tensor_out\"));\n       }\n     }\n \n@@ -369,11 +372,12 @@ class FractionalMaxPoolGradOp : public OpKernel {\n \n     for (int index = 0; index < num_total_outputs; ++index) {\n       int input_backprop_index = out_arg_max_flat(index);\n-      // According to maxpooling_op.cc, the performance impact below is small.\n-      CHECK(input_backprop_index >= 0 &&\n-            input_backprop_index < num_total_inputs)\n-          << \"Invalid input backprop index: \" << input_backprop_index << \", \"\n-          << num_total_inputs;\n+      OP_REQUIRES(\n+          context,\n+          input_backprop_index >= 0 && input_backprop_index < num_total_inputs,\n+          errors::InvalidArgument(\n+              \"Invalid input backprop index: \", input_backprop_index, \", \",\n+              num_total_inputs));\n       input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n     }\n   }\n",
        "@@ -124,7 +124,7 @@ class FractionalMaxPoolTest(test.TestCase):\n     Returns:\n       None\n     \"\"\"\n-    with self.cached_session() as sess:\n+    with self.cached_session():\n       p, r, c = nn_ops.fractional_max_pool_v2(\n           input_tensor,\n           pooling_ratio,\n@@ -155,7 +155,7 @@ class FractionalMaxPoolTest(test.TestCase):\n           overlapping))\n       rand_mat = self._PRNG.randint(10, size=tensor_shape)\n       pooling_ratio = [1, math.sqrt(2), math.sqrt(2), 1]\n-      with self.cached_session() as sess:\n+      with self.cached_session():\n         p, r, c = nn_ops.fractional_max_pool_v2(\n             rand_mat,\n             pooling_ratio,\n@@ -630,6 +630,29 @@ class FractionalMaxPoolGradTest(test.TestCase):\n       self.assertAllClose(expected_input_backprop_overlapping,\n                           input_backprop_overlapping)\n \n+  def testInvalidSeqRaiseErrorForFractionalMaxPoolGrad(self):\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      with self.cached_session() as _:\n+        overlapping = True\n+        orig_input = constant_op.constant(\n+            .453409232, shape=[1, 7, 13, 1], dtype=dtypes.float32)\n+        orig_output = constant_op.constant(\n+            .453409232, shape=[1, 7, 13, 1], dtype=dtypes.float32)\n+        out_backprop = constant_op.constant(\n+            .453409232, shape=[1, 7, 13, 1], dtype=dtypes.float32)\n+        row_pooling_sequence = constant_op.constant(\n+            0, shape=[5], dtype=dtypes.int64)\n+        col_pooling_sequence = constant_op.constant(\n+            0, shape=[5], dtype=dtypes.int64)\n+        t = gen_nn_ops.FractionalMaxPoolGrad(\n+            orig_input=orig_input,\n+            orig_output=orig_output,\n+            out_backprop=out_backprop,\n+            row_pooling_sequence=row_pooling_sequence,\n+            col_pooling_sequence=col_pooling_sequence,\n+            overlapping=overlapping)\n+        self.evaluate(t)\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "#include <vector>",
            "",
            "#include \"tensorflow/core/kernels/fractional_pool_common.h\"",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/numeric_op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/lib/random/random.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/mutex.h\"",
            "#include \"tensorflow/core/util/guarded_philox_random.h\"",
            "",
            "namespace tensorflow {"
        ],
        [
            "      for (int64_t j = 0; j < output_size[3]; ++j) {",
            "        DCHECK_EQ(tensor_out_dup_mat(j, i), tensor_out_mat(j, i));",
            "      }",
            "    }",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(",
            "                                {0}, 0, tensor_in.shape(), &output));",
            "    output->flat<T>().setZero();"
        ],
        [
            "      CHECK(input_backprop_index >= 0 &&",
            "            input_backprop_index < num_total_inputs)",
            "          << \"Invalid input backprop index: \" << input_backprop_index << \", \"",
            "          << num_total_inputs;",
            "      input_backprop_flat(input_backprop_index) += out_backprop_flat(index);",
            "    }",
            "  }",
            "",
            " private:",
            "  bool overlapping_;",
            "};",
            ""
        ]
    ],
    "Clean Code": [
        [
            "#include <vector>",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/numeric_op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/kernels/fractional_pool_common.h\"",
            "#include \"tensorflow/core/lib/random/random.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/mutex.h\"",
            "#include \"tensorflow/core/util/guarded_philox_random.h\"",
            ""
        ],
        [
            "    for (int64_t i = 0; i < num_reshaped_cols; ++i) {",
            "      for (int64_t j = 0; j < output_size[3]; ++j) {",
            "        OP_REQUIRES(context, tensor_out_dup_mat(j, i) == tensor_out_mat(j, i),",
            "                    errors::InvalidArgument(",
            "                        \"tensor_out_dup is not the same as tensor_out\"));",
            "      }",
            "    }",
            "",
            "    Tensor* output = nullptr;"
        ],
        [
            "    for (int index = 0; index < num_total_outputs; ++index) {",
            "      int input_backprop_index = out_arg_max_flat(index);",
            "      OP_REQUIRES(",
            "          context,",
            "          input_backprop_index >= 0 && input_backprop_index < num_total_inputs,",
            "          errors::InvalidArgument(",
            "              \"Invalid input backprop index: \", input_backprop_index, \", \",",
            "              num_total_inputs));",
            "      input_backprop_flat(input_backprop_index) += out_backprop_flat(index);",
            "    }",
            "  }",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vxv8-r8q2-63xw",
    "API Signature": "tf.raw_ops.FractionalMaxPoolGrad(\n    orig_input,\n    orig_output,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "orig_output = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)\nout_backprop = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)"
},
{
    "Title": "\n        Segfault in `QuantizedRelu` and `QuantizedRelu6`\n      ",
    "Bug description": "If  QuantizedRelu  or  QuantizedRelu6  are given nonscalar inputs for  min_features  or  max_features , it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.quint8\nfeatures = tf.constant(28, shape=[4,2], dtype=tf.quint8)\nmin_features = tf.constant([], shape=[0], dtype=tf.float32)\nmax_features = tf.constant(-128, shape=[1], dtype=tf.float32)\ntf.raw_ops.QuantizedRelu(features=features, min_features=min_features, max_features=max_features, out_type=out_type)\n)\ntf.raw_ops.QuantizedRelu6(features=features, min_features=min_features, max_features=max_features, out_type=out_type)",
    "Code change": [
        "@@ -32,8 +32,21 @@ class QuantizedReluOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -65,8 +78,21 @@ class QuantizedRelu6Op : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n",
        "@@ -55,8 +55,8 @@ TEST_F(QuantizedActivationsTest, TestRelu) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -86,8 +86,8 @@ TEST_F(QuantizedActivationsTest, TestRelu6) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
        "@@ -25,6 +25,7 @@ limitations under the License.\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n@@ -457,10 +458,28 @@ class QuantizedAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& x = context->input(0);\n     const Tensor& y = context->input(1);\n-    const float min_x = context->input(2).flat<float>()(0);\n-    const float max_x = context->input(3).flat<float>()(0);\n-    const float min_y = context->input(4).flat<float>()(0);\n-    const float max_y = context->input(5).flat<float>()(0);\n+    const Tensor& min_x_tensor = context->input(2);\n+    const Tensor& max_x_tensor = context->input(3);\n+    const Tensor& min_y_tensor = context->input(4);\n+    const Tensor& max_y_tensor = context->input(5);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),\n+                errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",\n+                                        min_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),\n+                errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",\n+                                        max_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),\n+                errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",\n+                                        min_y_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),\n+                errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",\n+                                        max_y_tensor.dims()));\n+\n+    const float min_x = min_x_tensor.scalar<float>()();\n+    const float max_x = max_x_tensor.scalar<float>()();\n+    const float min_y = min_y_tensor.scalar<float>()();\n+    const float max_y = max_y_tensor.scalar<float>()();\n \n     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n     if (!bcast.IsValid()) {\n",
        "@@ -206,5 +206,60 @@ class RequantizeOpTest(test_util.TensorFlowTestCase):\n               out_type=dtypes.qint8))\n \n \n+class QuantizedAddOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    x = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.quantized_add(\n+              x=x,\n+              y=y,\n+              min_x=[],\n+              max_x=1.0,\n+              min_y=0.0,\n+              max_y=1.0,\n+              Toutput=dtypes.qint32))\n+\n+\n+class QuantizedReluOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n+class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu6(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const float min_input = context->input(1).flat<float>()(0);",
            "    const float max_input = context->input(2).flat<float>()(0);",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "    const T min_as_quantized = FloatToQuantized<T>(0.0f, min_input, max_input);",
            "",
            "    if (meta::IsSupportedAndEnabled() && std::is_same<T, quint8>()) {",
            "      auto input_ui8_array = input.flat<quint8>();",
            "      meta::Clamp(context, input_ui8_array.data(), input_ui8_array.size(),",
            "                  min_as_quantized, 255, output->flat<quint8>().data());",
            "    } else {",
            "      output->flat<T>().device(context->eigen_cpu_device()) =",
            "          input.flat<T>().cwiseMax(min_as_quantized).template cast<T>();",
            "    }",
            "",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));",
            "    output_min->flat<float>()(0) = min_input;"
        ],
        [
            "                  min_as_quantized, max_as_quantized,",
            "                  output->flat<quint8>().data());",
            "    } else {",
            "      output->flat<T>().device(context->eigen_cpu_device()) =",
            "          input.flat<T>()",
            "              .cwiseMax(min_as_quantized)",
            "              .cwiseMin(max_as_quantized)",
            "              .template cast<T>();",
            "    }",
            "",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));",
            "    output_min->flat<float>()(0) = min_input;",
            "    Tensor* output_max = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));",
            "    output_max->flat<float>()(0) = max_input;",
            "  }",
            "};",
            "",
            "REGISTER_KERNEL_BUILDER(Name(\"QuantizedRelu\")",
            "                            .Device(DEVICE_CPU)"
        ],
        [
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/kernels/meta_support.h\"",
            "#include \"tensorflow/core/kernels/quantization_utils.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/util/bcast.h\"",
            ""
        ],
        [
            "    const Tensor& y = context->input(1);",
            "    const float min_x = context->input(2).flat<float>()(0);",
            "    const float max_x = context->input(3).flat<float>()(0);",
            "    const float min_y = context->input(4).flat<float>()(0);",
            "    const float max_y = context->input(5).flat<float>()(0);",
            "",
            "    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
            "    if (!bcast.IsValid()) {",
            "      context->SetStatus(errors::InvalidArgument(",
            "          \"Incompatible shapes: \", x.shape().DebugString(), \" vs. \",",
            "          y.shape().DebugString()));",
            "      return;",
            "    }",
            "    Tensor* z;",
            "    OP_REQUIRES_OK(context, context->allocate_output(",
            "                                0, BCast::ToShape(bcast.output_shape()), &z));",
            "",
            "    // Make sure that we have valid quantization ranges for the input buffers.",
            "    // If the difference between the min and max is negative or zero, it makes",
            "    // it hard to do meaningful intermediate operations on the values.",
            "    OP_REQUIRES(context, (max_x > min_x),",
            "                errors::InvalidArgument(\"max_x must be larger than min_x.\"));",
            "    OP_REQUIRES(context, (max_y > min_y),",
            "                errors::InvalidArgument(\"max_y must be larger than min_y.\"));",
            "    const T* x_data = x.flat<T>().data();",
            "    const T* y_data = y.flat<T>().data();",
            "    Toutput* z_data = z->flat<Toutput>().data();",
            ""
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const Tensor& min_input_tensor = context->input(1);",
            "    const Tensor& max_input_tensor = context->input(2);",
            "",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
            "                                min_input_tensor.dims()));",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
            "                                max_input_tensor.dims()));",
            "",
            "    const float min_input = min_input_tensor.scalar<float>()();",
            "    const float max_input = max_input_tensor.scalar<float>()();",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "    const T min_as_quantized = FloatToQuantized<T>(0.0f, min_input, max_input);"
        ],
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const Tensor& min_input_tensor = context->input(1);",
            "    const Tensor& max_input_tensor = context->input(2);",
            "",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
            "                                min_input_tensor.dims()));",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
            "                                max_input_tensor.dims()));",
            "",
            "    const float min_input = min_input_tensor.scalar<float>()();",
            "    const float max_input = max_input_tensor.scalar<float>()();",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "    const T min_as_quantized = FloatToQuantized<T>(0.0f, min_input, max_input);"
        ],
        [
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/kernels/meta_support.h\"",
            "#include \"tensorflow/core/kernels/quantization_utils.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/util/bcast.h\""
        ],
        [
            "    const Tensor& x = context->input(0);",
            "    const Tensor& y = context->input(1);",
            "    const Tensor& min_x_tensor = context->input(2);",
            "    const Tensor& max_x_tensor = context->input(3);",
            "    const Tensor& min_y_tensor = context->input(4);",
            "    const Tensor& max_y_tensor = context->input(5);",
            "",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),",
            "                errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",",
            "                                        min_x_tensor.dims()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),",
            "                errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",",
            "                                        max_x_tensor.dims()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),",
            "                errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",",
            "                                        min_y_tensor.dims()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),",
            "                errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",",
            "                                        max_y_tensor.dims()));",
            "",
            "    const float min_x = min_x_tensor.scalar<float>()();",
            "    const float max_x = max_x_tensor.scalar<float>()();",
            "    const float min_y = min_y_tensor.scalar<float>()();",
            "    const float max_y = max_y_tensor.scalar<float>()();",
            "",
            "    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
            "    if (!bcast.IsValid()) {",
            "      context->SetStatus(errors::InvalidArgument("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v7vw-577f-vp8x",
    "API Signature": "tf.raw_ops.QuantizedRelu(\n    features,\n    min_features,\n    max_features,\n    out_type=tf.dtypes.quint8,\n    name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "min_features = tf.constant([], shape=[0], dtype=tf.float32)\nmax_features = tf.constant(-128, shape=[1], dtype=tf.float32)"
},
{
    "Title": "\n        Segfault in `QuantizedRelu` and `QuantizedRelu6`\n      ",
    "Bug description": "If  QuantizedRelu  or  QuantizedRelu6  are given nonscalar inputs for  min_features  or  max_features , it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.quint8\nfeatures = tf.constant(28, shape=[4,2], dtype=tf.quint8)\nmin_features = tf.constant([], shape=[0], dtype=tf.float32)\nmax_features = tf.constant(-128, shape=[1], dtype=tf.float32)\ntf.raw_ops.QuantizedRelu(features=features, min_features=min_features, max_features=max_features, out_type=out_type)\n)\ntf.raw_ops.QuantizedRelu6(features=features, min_features=min_features, max_features=max_features, out_type=out_type)",
    "Code change": [
        "@@ -32,8 +32,21 @@ class QuantizedReluOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -65,8 +78,21 @@ class QuantizedRelu6Op : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n",
        "@@ -55,8 +55,8 @@ TEST_F(QuantizedActivationsTest, TestRelu) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -86,8 +86,8 @@ TEST_F(QuantizedActivationsTest, TestRelu6) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
        "@@ -25,6 +25,7 @@ limitations under the License.\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n@@ -457,10 +458,28 @@ class QuantizedAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& x = context->input(0);\n     const Tensor& y = context->input(1);\n-    const float min_x = context->input(2).flat<float>()(0);\n-    const float max_x = context->input(3).flat<float>()(0);\n-    const float min_y = context->input(4).flat<float>()(0);\n-    const float max_y = context->input(5).flat<float>()(0);\n+    const Tensor& min_x_tensor = context->input(2);\n+    const Tensor& max_x_tensor = context->input(3);\n+    const Tensor& min_y_tensor = context->input(4);\n+    const Tensor& max_y_tensor = context->input(5);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),\n+                errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",\n+                                        min_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),\n+                errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",\n+                                        max_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),\n+                errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",\n+                                        min_y_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),\n+                errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",\n+                                        max_y_tensor.dims()));\n+\n+    const float min_x = min_x_tensor.scalar<float>()();\n+    const float max_x = max_x_tensor.scalar<float>()();\n+    const float min_y = min_y_tensor.scalar<float>()();\n+    const float max_y = max_y_tensor.scalar<float>()();\n \n     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n     if (!bcast.IsValid()) {\n",
        "@@ -206,5 +206,60 @@ class RequantizeOpTest(test_util.TensorFlowTestCase):\n               out_type=dtypes.qint8))\n \n \n+class QuantizedAddOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    x = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.quantized_add(\n+              x=x,\n+              y=y,\n+              min_x=[],\n+              max_x=1.0,\n+              min_y=0.0,\n+              max_y=1.0,\n+              Toutput=dtypes.qint32))\n+\n+\n+class QuantizedReluOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n+class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu6(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const float min_input = context->input(1).flat<float>()(0);",
            "    const float max_input = context->input(2).flat<float>()(0);",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "    const T min_as_quantized = FloatToQuantized<T>(0.0f, min_input, max_input);",
            "",
            "    if (meta::IsSupportedAndEnabled() && std::is_same<T, quint8>()) {",
            "      auto input_ui8_array = input.flat<quint8>();",
            "      meta::Clamp(context, input_ui8_array.data(), input_ui8_array.size(),",
            "                  min_as_quantized, 255, output->flat<quint8>().data());",
            "    } else {",
            "      output->flat<T>().device(context->eigen_cpu_device()) =",
            "          input.flat<T>().cwiseMax(min_as_quantized).template cast<T>();",
            "    }",
            "",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));",
            "    output_min->flat<float>()(0) = min_input;"
        ],
        [
            "                  min_as_quantized, max_as_quantized,",
            "                  output->flat<quint8>().data());",
            "    } else {",
            "      output->flat<T>().device(context->eigen_cpu_device()) =",
            "          input.flat<T>()",
            "              .cwiseMax(min_as_quantized)",
            "              .cwiseMin(max_as_quantized)",
            "              .template cast<T>();",
            "    }",
            "",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));",
            "    output_min->flat<float>()(0) = min_input;",
            "    Tensor* output_max = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));",
            "    output_max->flat<float>()(0) = max_input;",
            "  }",
            "};",
            "",
            "REGISTER_KERNEL_BUILDER(Name(\"QuantizedRelu\")",
            "                            .Device(DEVICE_CPU)"
        ],
        [
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/kernels/meta_support.h\"",
            "#include \"tensorflow/core/kernels/quantization_utils.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/util/bcast.h\"",
            ""
        ],
        [
            "    const Tensor& y = context->input(1);",
            "    const float min_x = context->input(2).flat<float>()(0);",
            "    const float max_x = context->input(3).flat<float>()(0);",
            "    const float min_y = context->input(4).flat<float>()(0);",
            "    const float max_y = context->input(5).flat<float>()(0);",
            "",
            "    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
            "    if (!bcast.IsValid()) {",
            "      context->SetStatus(errors::InvalidArgument(",
            "          \"Incompatible shapes: \", x.shape().DebugString(), \" vs. \",",
            "          y.shape().DebugString()));",
            "      return;",
            "    }",
            "    Tensor* z;",
            "    OP_REQUIRES_OK(context, context->allocate_output(",
            "                                0, BCast::ToShape(bcast.output_shape()), &z));",
            "",
            "    // Make sure that we have valid quantization ranges for the input buffers.",
            "    // If the difference between the min and max is negative or zero, it makes",
            "    // it hard to do meaningful intermediate operations on the values.",
            "    OP_REQUIRES(context, (max_x > min_x),",
            "                errors::InvalidArgument(\"max_x must be larger than min_x.\"));",
            "    OP_REQUIRES(context, (max_y > min_y),",
            "                errors::InvalidArgument(\"max_y must be larger than min_y.\"));",
            "    const T* x_data = x.flat<T>().data();",
            "    const T* y_data = y.flat<T>().data();",
            "    Toutput* z_data = z->flat<Toutput>().data();",
            ""
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const Tensor& min_input_tensor = context->input(1);",
            "    const Tensor& max_input_tensor = context->input(2);",
            "",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
            "                                min_input_tensor.dims()));",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
            "                                max_input_tensor.dims()));",
            "",
            "    const float min_input = min_input_tensor.scalar<float>()();",
            "    const float max_input = max_input_tensor.scalar<float>()();",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "    const T min_as_quantized = FloatToQuantized<T>(0.0f, min_input, max_input);"
        ],
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const Tensor& min_input_tensor = context->input(1);",
            "    const Tensor& max_input_tensor = context->input(2);",
            "",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
            "                                min_input_tensor.dims()));",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
            "                                max_input_tensor.dims()));",
            "",
            "    const float min_input = min_input_tensor.scalar<float>()();",
            "    const float max_input = max_input_tensor.scalar<float>()();",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "    const T min_as_quantized = FloatToQuantized<T>(0.0f, min_input, max_input);"
        ],
        [
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/kernels/meta_support.h\"",
            "#include \"tensorflow/core/kernels/quantization_utils.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/util/bcast.h\""
        ],
        [
            "    const Tensor& x = context->input(0);",
            "    const Tensor& y = context->input(1);",
            "    const Tensor& min_x_tensor = context->input(2);",
            "    const Tensor& max_x_tensor = context->input(3);",
            "    const Tensor& min_y_tensor = context->input(4);",
            "    const Tensor& max_y_tensor = context->input(5);",
            "",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),",
            "                errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",",
            "                                        min_x_tensor.dims()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),",
            "                errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",",
            "                                        max_x_tensor.dims()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),",
            "                errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",",
            "                                        min_y_tensor.dims()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),",
            "                errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",",
            "                                        max_y_tensor.dims()));",
            "",
            "    const float min_x = min_x_tensor.scalar<float>()();",
            "    const float max_x = max_x_tensor.scalar<float>()();",
            "    const float min_y = min_y_tensor.scalar<float>()();",
            "    const float max_y = max_y_tensor.scalar<float>()();",
            "",
            "    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
            "    if (!bcast.IsValid()) {",
            "      context->SetStatus(errors::InvalidArgument("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v7vw-577f-vp8x",
    "API Signature": "tf.raw_ops.QuantizedRelu6(\n    features,\n    min_features,\n    max_features,\n    out_type=tf.dtypes.quint8,\n    name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "min_features = tf.constant([], shape=[0], dtype=tf.float32)\nmax_features = tf.constant(-128, shape=[1], dtype=tf.float32)"
},
{
    "Title": "\n        Segfault in `QuantizeDownAndShrinkRange`\n      ",
    "Bug description": "If  QuantizeDownAndShrinkRange  is given nonscalar inputs for  input_min  or  input_max , it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.quint8\ninput = tf.constant([1], shape=[3], dtype=tf.qint32)\ninput_min = tf.constant([], shape=[0], dtype=tf.float32)\ninput_max = tf.constant(-256, shape=[1], dtype=tf.float32)\n)\ntf.raw_ops.QuantizeDownAndShrinkRange(input=input, input_min=input_min, input_max=input_max, out_type=out_type)",
    "Code change": [
        "@@ -40,8 +40,20 @@ class QuantizeDownAndShrinkRangeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n-    const float input_min_float = ctx->input(1).flat<float>()(0);\n-    const float input_max_float = ctx->input(2).flat<float>()(0);\n+    const Tensor& input_min = ctx->input(1);\n+    const Tensor& input_max = ctx->input(2);\n+\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n+        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n+                                input_min.dims()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n+        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n+                                input_max.dims()));\n+\n+    const float input_min_float = input_min.scalar<float>()();\n+    const float input_max_float = input_max.scalar<float>()();\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n     Tensor* output_min = nullptr;\n",
        "@@ -53,8 +53,8 @@ TEST_F(QuantizeDownAndShrinkRangeTest, HandCrafted) {\n   const int value_count = 3;\n   AddInputFromArray<qint32>(TensorShape({value_count}),\n                             {-(1 << 23), 0, (1 << 23)});\n-  AddInputFromArray<float>(TensorShape({1}), {-256.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));\n   test::FillValues<quint8>(&expected, {0, 128, 255});\n",
        "@@ -261,5 +261,21 @@ class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n               out_type=dtypes.quint8))\n \n \n+class QuantizeDownAndShrinkRangeOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.quantize_down_and_shrink_range(input=inputs,\n+                                                  input_min=[],\n+                                                  input_max=4.0,\n+                                                  out_type=dtypes.quint8))\n+\n+\n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& input = ctx->input(0);",
            "    const float input_min_float = ctx->input(1).flat<float>()(0);",
            "    const float input_max_float = ctx->input(2).flat<float>()(0);",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));",
            "    Tensor* output_max = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(2, TensorShape({}), &output_max));",
            "",
            "    // See QuantizationRangeOp as well, which has a copy of this logic.",
            "    auto input_array = input.flat<T1>();",
            "    const int32_t input_lowest_quantized =",
            "        static_cast<int32>(Eigen::NumTraits<T1>::lowest());",
            "    const int32_t input_highest_quantized =",
            "        static_cast<int32>(Eigen::NumTraits<T1>::highest());",
            "    T1 actual_min_quantized = input_highest_quantized;",
            "    T1 actual_max_quantized = input_lowest_quantized;",
            "    for (int i = 0; i < input_array.size(); ++i) {"
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& input = ctx->input(0);",
            "    const Tensor& input_min = ctx->input(1);",
            "    const Tensor& input_max = ctx->input(2);",
            "",
            "    OP_REQUIRES(",
            "        ctx, TensorShapeUtils::IsScalar(input_min.shape()),",
            "        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",",
            "                                input_min.dims()));",
            "    OP_REQUIRES(",
            "        ctx, TensorShapeUtils::IsScalar(input_max.shape()),",
            "        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",",
            "                                input_max.dims()));",
            "",
            "    const float input_min_float = input_min.scalar<float>()();",
            "    const float input_max_float = input_max.scalar<float>()();",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vgvh-2pf4-jr2x",
    "API Signature": "tf.raw_ops.QuantizeDownAndShrinkRange(\n    input, input_min, input_max, out_type, name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "input_min = tf.constant([], shape=[0], dtype=tf.float32)\ninput_max = tf.constant(-256, shape=[1], dtype=tf.float32)"
},
{
    "Title": "\n        Segfault in `QuantizedMatMul`\n      ",
    "Bug description": "If  QuantizedMatMul  is given nonscalar input for:",
    "Sample Code": "Toutput = tf.qint32\ntranspose_a = False\ntranspose_b = False\nTactivation = tf.quint8\na = tf.constant(7, shape=[3,4], dtype=tf.quint8)\nb = tf.constant(1, shape=[2,3], dtype=tf.quint8)\nmin_a = tf.constant([], shape=[0], dtype=tf.float32)\nmax_a = tf.constant(0, shape=[1], dtype=tf.float32)\nmin_b = tf.constant(0, shape=[1], dtype=tf.float32)\nmax_b = tf.constant(0, shape=[1], dtype=tf.float32)\n)\ntf.raw_ops.QuantizedMatMul(a=a, b=b, min_a=min_a, max_a=max_a, min_b=min_b, max_b=max_b, Toutput=Toutput, transpose_a=transpose_a, transpose_b=transpose_b, Tactivation=Tactivation)",
    "Code change": [
        "@@ -20,11 +20,14 @@ limitations under the License.\n #define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\n #include \"public/gemmlowp.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/kernels/reference_gemm.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -75,9 +78,21 @@ class QuantizedMatMulOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& a = context->input(0);\n     const Tensor& b = context->input(1);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(2).shape()),\n+                errors::InvalidArgument(\"min_a must be a scalar, but got shape\",\n+                                        context->input(2).shape()));\n     const float min_a = context->input(2).flat<float>()(0);\n+    OP_REQUIRES(context, context->input(3).NumElements() == 1,\n+                errors::InvalidArgument(\"max_a must be a scalar, but got shape\",\n+                                        context->input(3).shape()));\n     const float max_a = context->input(3).flat<float>()(0);\n+    OP_REQUIRES(context, context->input(4).NumElements() == 1,\n+                errors::InvalidArgument(\"min_b must be a scalar, but got shape\",\n+                                        context->input(4).shape()));\n     const float min_b = context->input(4).flat<float>()(0);\n+    OP_REQUIRES(context, context->input(5).NumElements() == 1,\n+                errors::InvalidArgument(\"max_b must be a scalar, but got shape\",\n+                                        context->input(5).shape()));\n     const float max_b = context->input(5).flat<float>()(0);\n \n     // Make sure that we have valid quantization ranges for the input buffers.\n",
        "@@ -62,10 +62,10 @@ TEST_F(QuantizedMatMulTest, Small_NoParams) {\n   // | 15 | 16 | 17 | 18 |\n   AddInputFromArray<quint8>(TensorShape({3, 4}),\n                             {7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n \n   TF_ASSERT_OK(RunOpKernel());\n   // Here are the results we expect, from hand calculations:\n@@ -118,10 +118,10 @@ TEST_F(QuantizedMatMulTest, VerySmall_WithParams) {\n   // The B matrix is:\n   // |   1 |\n   AddInputFromArray<quint8>(TensorShape({b_rows, b_cols}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {-12.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {243.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-12.0f});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   // We're requesting C = A.transposed() * B,\n   // so we expect to get these results:\n@@ -162,12 +162,50 @@ TEST_F(QuantizedMatMulTest, VerySmall_BadRange) {\n   // The B matrix is:\n   // |   1 |\n   AddInputFromArray<quint8>(TensorShape({b_rows, b_cols}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {-12.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-12.0f});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n   // Here we set the range so that the min and max are equal, so we expect to\n   // see an error when we run.\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  EXPECT_EQ(::tensorflow::error::INVALID_ARGUMENT, RunOpKernel().code());\n+}\n+\n+// This test multiplies two 1x1 8bit matrices, but sets invalid quantized min\n+// and max values, so we expect to get an error\n+TEST_F(QuantizedMatMulTest, VerySmall_BadMinMax) {\n+  // These parameters reflect a typical production usage of eight-bit matmuls\n+  // in an Inception-style network.\n+  const bool transpose_a = true;\n+  const int a_rows = 1;\n+  const int a_cols = 1;\n+  const int b_rows = 1;\n+  const int b_cols = 1;\n+  const bool transpose_b = false;\n+  TF_ASSERT_OK(NodeDefBuilder(\"quantized_mat_mul_op\", \"QuantizedMatMul\")\n+                   .Input(FakeInput(DT_QUINT8))\n+                   .Input(FakeInput(DT_QUINT8))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Attr(\"Toutput\", DataTypeToEnum<qint32>::v())\n+                   .Attr(\"transpose_a\", transpose_a)\n+                   .Attr(\"transpose_b\", transpose_b)\n+                   .Finalize(node_def()));\n+  TF_ASSERT_OK(InitOp());\n+  // The A matrix is:\n+  // |  -1 |\n+  AddInputFromArray<quint8>(TensorShape({a_rows, a_cols}), {11});\n+  // The B matrix is:\n+  // |   1 |\n+  AddInputFromArray<quint8>(TensorShape({b_rows, b_cols}), {0});\n+  // Here we set the error of a non scalar min_a value, so we expect to see an\n+  // error when we run.\n+  AddInputFromArray<float>(TensorShape({1}), {2});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n   EXPECT_EQ(::tensorflow::error::INVALID_ARGUMENT, RunOpKernel().code());\n }\n \n@@ -233,10 +271,10 @@ TEST_F(QuantizedMatMulTest, Small_WithParams) {\n                                                                3,\n                                                                6,\n                                                            });\n-  AddInputFromArray<float>(TensorShape({1}), {-12.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {243.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-12.0f});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   // We're requesting C = A.transposed() * B,\n   // so we expect to get these results:\n@@ -326,10 +364,10 @@ TEST_F(QuantizedMatMulTest, Medium_WithParams) {\n \n   AddInputFromArray<quint8>(a_quantized.shape(), a_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(b_quantized.shape(), b_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {a_min});\n-  AddInputFromArray<float>(TensorShape({1}), {a_max});\n-  AddInputFromArray<float>(TensorShape({1}), {b_min});\n-  AddInputFromArray<float>(TensorShape({1}), {b_max});\n+  AddInputFromArray<float>(TensorShape({}), {a_min});\n+  AddInputFromArray<float>(TensorShape({}), {a_max});\n+  AddInputFromArray<float>(TensorShape({}), {b_min});\n+  AddInputFromArray<float>(TensorShape({}), {b_max});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected_float(DT_FLOAT, {a_cols, b_cols});\n"
    ],
    "Buggy Code": [
        [
            "#include \"public/gemmlowp.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/kernels/meta_support.h\"",
            "#include \"tensorflow/core/kernels/quantization_utils.h\"",
            "#include \"tensorflow/core/kernels/reference_gemm.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "",
            "namespace tensorflow {",
            "",
            "// We have to break this out as a separate function because there are multiple",
            "// combinations of transpose attributes we need to support, and they have to be",
            "// compile-time constants to work with the templates used internally.",
            "template <bool TransposeA, bool TransposeB, bool TransposeC>"
        ],
        [
            "    const float max_a = context->input(3).flat<float>()(0);",
            "    const float min_b = context->input(4).flat<float>()(0);",
            "    const float max_b = context->input(5).flat<float>()(0);",
            "",
            "    // Make sure that we have valid quantization ranges for the input buffers.",
            "    // If the difference between the min and max is negative or zero, it makes",
            "    // it hard to do meaningful intermediate operations on the values.",
            "    OP_REQUIRES(context, (max_a > min_a),",
            "                errors::InvalidArgument(\"max_a must be larger than min_a.\"));",
            "    OP_REQUIRES(context, (max_b > min_b),",
            "                errors::InvalidArgument(\"max_b must be larger than min_b.\"));",
            "    const int32_t offset_a = FloatToQuantizedUnclamped<T1>(0.0f, min_a, max_a);",
            "    const int32_t offset_b = FloatToQuantizedUnclamped<T2>(0.0f, min_b, max_b);",
            "    const int32_t offset_c = 0;",
            "    const int32_t mult_c = 1;",
            "    const int32_t shift_c = 0;",
            "",
            "    // Check that the dimensions of the two matrices are valid.",
            "    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(a.shape()),",
            "                errors::InvalidArgument(\"In[0] is not a matrix\"));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(b.shape()),"
        ]
    ],
    "Clean Code": [
        [
            "#include \"public/gemmlowp.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/kernels/meta_support.h\"",
            "#include \"tensorflow/core/kernels/quantization_utils.h\"",
            "#include \"tensorflow/core/kernels/reference_gemm.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "namespace tensorflow {",
            "",
            "// We have to break this out as a separate function because there are multiple"
        ],
        [
            "    const Tensor& a = context->input(0);",
            "    const Tensor& b = context->input(1);",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(2).shape()),",
            "                errors::InvalidArgument(\"min_a must be a scalar, but got shape\",",
            "                                        context->input(2).shape()));",
            "    const float min_a = context->input(2).flat<float>()(0);",
            "    OP_REQUIRES(context, context->input(3).NumElements() == 1,",
            "                errors::InvalidArgument(\"max_a must be a scalar, but got shape\",",
            "                                        context->input(3).shape()));",
            "    const float max_a = context->input(3).flat<float>()(0);",
            "    OP_REQUIRES(context, context->input(4).NumElements() == 1,",
            "                errors::InvalidArgument(\"min_b must be a scalar, but got shape\",",
            "                                        context->input(4).shape()));",
            "    const float min_b = context->input(4).flat<float>()(0);",
            "    OP_REQUIRES(context, context->input(5).NumElements() == 1,",
            "                errors::InvalidArgument(\"max_b must be a scalar, but got shape\",",
            "                                        context->input(5).shape()));",
            "    const float max_b = context->input(5).flat<float>()(0);",
            "",
            "    // Make sure that we have valid quantization ranges for the input buffers.",
            "    // If the difference between the min and max is negative or zero, it makes"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-689c-r7h2-fv9v",
    "API Signature": "tf.raw_ops.QuantizedMatMul(\n    a,\n    b,\n    min_a,\n    max_a,\n    min_b,\n    max_b,\n    Toutput=tf.dtypes.qint32,\n    transpose_a=False,\n    transpose_b=False,\n    Tactivation=tf.dtypes.quint8,\n    name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "min_a = tf.constant([], shape=[0], dtype=tf.float32)\nmax_a = tf.constant(0, shape=[1], dtype=tf.float32)\nmin_b = tf.constant(0, shape=[1], dtype=tf.float32)\nmax_b = tf.constant(0, shape=[1], dtype=tf.float32)"
},
{
    "Title": "\n        `CHECK` fail in `Conv2DBackpropInput`\n      ",
    "Bug description": "The implementation of  Conv2DBackpropInput  requires  input_sizes  to be 4-dimensional. Otherwise, it gives a  CHECK  failure which can be used to trigger a denial of service attack:",
    "Sample Code": "strides = [1, 1, 1, 1]\npadding = \"SAME\"\nuse_cudnn_on_gpu = True\nexplicit_paddings = []\ndata_format = \"NHWC\"\ndilations = [1, 1, 1, 1]\ninput_sizes = tf.constant([65534,65534], shape=[2], dtype=tf.int32)\nfilter = tf.constant(0.159749106, shape=[3,3,2,2], dtype=tf.float32)\nout_backprop = tf.constant(0, shape=[], dtype=tf.float32)\n)\ntf.raw_ops.Conv2DBackpropInput(input_sizes=input_sizes, filter=filter, out_backprop=out_backprop, strides=strides, padding=padding, use_cudnn_on_gpu=use_cudnn_on_gpu, explicit_paddings=explicit_paddings, data_format=data_format, dilations=dilations)",
    "Code change": [
        "@@ -422,6 +422,11 @@ class Conv2DBackpropInputOp : public OpKernel {\n     const Tensor& filter = context->input(1);\n     const Tensor& out_backprop = context->input(2);\n \n+    OP_REQUIRES(\n+        context, out_backprop.dims() == 4,\n+        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",\n+                                out_backprop.dims()));\n+\n     TensorShape input_shape;\n     OP_REQUIRES_OK(context,\n                    Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),\n@@ -527,6 +532,10 @@ class Conv2DCustomBackpropInputOp : public OpKernel {\n     const Tensor& input_sizes = context->input(0);\n     const Tensor& filter = context->input(1);\n     const Tensor& out_backprop = context->input(2);\n+    OP_REQUIRES(\n+        context, out_backprop.dims() == 4,\n+        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",\n+                                out_backprop.dims()));\n \n     TensorShape input_shape;\n     OP_REQUIRES_OK(context,\n",
        "@@ -32,6 +32,7 @@ from tensorflow.python.framework import test_util\n from tensorflow.python.layers import convolutional\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_nn_ops\n from tensorflow.python.ops import gradient_checker\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import math_ops\n@@ -1319,7 +1320,7 @@ class Conv2DTest(test.TestCase):\n     x2 = self._CreateNumpyTensor(filter_sizes)\n     default_dilations = (dilations[0] == 1 and dilations[1] == 1)\n     if default_dilations or use_gpu:\n-      with self.cached_session(use_gpu=use_gpu) as sess:\n+      with self.cached_session(use_gpu=use_gpu):\n         if data_format == \"NCHW\":\n           input_sizes = test_util.NHWCToNCHW(input_sizes)\n         t1 = constant_op.constant(x1, shape=input_sizes)\n@@ -1365,7 +1366,7 @@ class Conv2DTest(test.TestCase):\n     x2 = self._CreateNumpyTensor(filter_sizes)\n     default_dilations = (dilations[0] == 1 and dilations[1] == 1)\n     if default_dilations or use_gpu:\n-      with self.cached_session(use_gpu=use_gpu) as sess:\n+      with self.cached_session(use_gpu=use_gpu):\n         if data_format == \"NCHW\":\n           input_sizes = test_util.NHWCToNCHW(input_sizes)\n         t1 = constant_op.constant(x1, shape=input_sizes)\n@@ -2628,6 +2629,27 @@ class Conv2DTest(test.TestCase):\n               strides=[1, 1, 1, 1],\n               padding=[[0, 0], [-1, 0], [0, 0], [0, 0]]))\n \n+  def testConv2DBackpropInputInvalidOutBackpropRaiseError(self):\n+    with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n+      with self.cached_session():\n+        input_sizes = constant_op.constant([65534, 65534],\n+                                           shape=[2],\n+                                           dtype=dtypes.int32)\n+        filters = constant_op.constant(\n+            0.159749106, shape=[3, 3, 2, 2], dtype=dtypes.float32)\n+        out_backprop = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+        t = gen_nn_ops.conv2d_backprop_input(\n+            input_sizes=input_sizes,\n+            filter=filters,\n+            out_backprop=out_backprop,\n+            strides=[1, 1, 1, 1],\n+            padding=\"SAME\",\n+            use_cudnn_on_gpu=True,\n+            explicit_paddings=[],\n+            data_format=\"NHWC\",\n+            dilations=[1, 1, 1, 1])\n+        self.evaluate(t)\n+\n \n @test_util.run_all_without_tensor_float_32(\"Avoid TF32 conv on GPU\")\n class DepthwiseConv2DTest(test.TestCase):\n@@ -2655,7 +2677,7 @@ class DepthwiseConv2DTest(test.TestCase):\n     # numbers from 1.\n     x1 = [f * 1.0 for f in range(1, total_size_1 + 1)]\n     x2 = [f * 1.0 for f in range(1, total_size_2 + 1)]\n-    with self.cached_session() as sess:\n+    with self.cached_session():\n       t1 = constant_op.constant(x1, shape=tensor_in_sizes)\n       t1.set_shape(tensor_in_sizes)\n       t2 = constant_op.constant(x2, shape=filter_in_sizes)\n@@ -2926,7 +2948,7 @@ class DeepConv2DTest(test.TestCase):\n     x1 = np.random.rand(*tensor_in_sizes).astype(np.float32)\n     x2 = np.random.rand(*filter_in_sizes).astype(np.float32)\n \n-    with self.cached_session(use_gpu=False) as sess:\n+    with self.cached_session(use_gpu=False):\n       t1 = constant_op.constant(x1, shape=tensor_in_sizes)\n       t2 = constant_op.constant(x2, shape=filter_in_sizes)\n       strides = [1] + conv_strides + [1]\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor& out_backprop = context->input(2);",
            "",
            "    TensorShape input_shape;",
            "    OP_REQUIRES_OK(context,",
            "                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),",
            "                                                   out_backprop.shape(),",
            "                                                   data_format_, &input_shape));",
            "",
            "    Tensor* in_backprop = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input_shape, &in_backprop));"
        ],
        [
            "                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),",
            "                                                   out_backprop.shape(),",
            "                                                   data_format_, &input_shape));",
            "",
            "    ConvBackpropDimensions dims;",
            "    OP_REQUIRES_OK(context,",
            "                   ConvBackpropComputeDimensionsV2(",
            "                       \"Conv2DCustomBackpropInput\", /*num_spatial_dims=*/2,",
            "                       input_shape, filter.shape(), out_backprop.shape(),",
            "                       /*dilations=*/{1, 1, 1, 1}, strides_, padding_,"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor& out_backprop = context->input(2);",
            "",
            "    OP_REQUIRES(",
            "        context, out_backprop.dims() == 4,",
            "        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",",
            "                                out_backprop.dims()));",
            "",
            "    TensorShape input_shape;",
            "    OP_REQUIRES_OK(context,",
            "                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),",
            "                                                   out_backprop.shape(),"
        ],
        [
            "    const Tensor& filter = context->input(1);",
            "    const Tensor& out_backprop = context->input(2);",
            "    OP_REQUIRES(",
            "        context, out_backprop.dims() == 4,",
            "        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",",
            "                                out_backprop.dims()));",
            "",
            "    TensorShape input_shape;",
            "    OP_REQUIRES_OK(context,",
            "                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-q2c3-jpmc-gfjx",
    "API Signature": "tf.raw_ops.Conv2DBackpropInput(\n    input_sizes,\n    filter,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "input_sizes = tf.constant([65534,65534], shape=[2], dtype=tf.int32)"
},
{
    "Title": "\n        `CHECK` fail in `AvgPoolGrad`\n      ",
    "Bug description": "The implementation of  AvgPoolGrad  does not fully validate the input  orig_input_shape . This results in a  CHECK  failure which can be used to trigger a denial of service attack:",
    "Sample Code": "ksize = [1, 2, 2, 1]\nstrides = [1, 2, 2, 1]\npadding = \"VALID\"\ndata_format = \"NHWC\"\norig_input_shape = tf.constant(-536870912, shape=[4], dtype=tf.int32)\ngrad = tf.constant(.0890338004362538, shape=[1,5,7,1], dtype=tf.float64)\n)\ntf.raw_ops.AvgPoolGrad(orig_input_shape=orig_input_shape, grad=grad, ksize=ksize, strides=strides, padding=padding, data_format=data_format)",
    "Code change": [
        "@@ -298,7 +298,7 @@ class AvgPoolingGradOp : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n     const int64_t in_rows = output_shape.dim_size(1);\n     const int64_t in_cols = output_shape.dim_size(2);\n@@ -457,7 +457,7 @@ class AvgPoolingGradOp<GPUDevice, T> : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n \n     if (output_shape.num_elements() == 0) {\n@@ -543,7 +543,7 @@ class AvgPoolingGradOpCustomGPUKernel : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n     if (output_shape.num_elements() == 0) {\n       Tensor* output = nullptr;\n",
        "@@ -2470,6 +2470,22 @@ class PoolingTest(test.TestCase, parameterized.TestCase):\n               inp, grad, argmax, ksize=[1, 1, 1, 1], strides=[1, 1, 1, 1],\n               padding=\"VALID\")\n \n+  def testAvgPoolGradInvalidInputShapeRaiseError(self):\n+    with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n+      with self.cached_session():\n+        orig_input_shape = constant_op.constant(\n+            -536870912, shape=[4], dtype=dtypes.int32)\n+        grad = constant_op.constant(\n+            .0890338004362538, shape=[1, 5, 7, 1], dtype=dtypes.float64)\n+        t = gen_nn_ops.AvgPoolGrad(\n+            orig_input_shape=orig_input_shape,\n+            grad=grad,\n+            ksize=[1, 2, 2, 1],\n+            strides=[1, 2, 2, 1],\n+            padding=\"VALID\",\n+            data_format=\"NHWC\")\n+        self.evaluate(t)\n+\n \n def GetMaxPoolFwdTest(input_size, filter_size, strides, padding):\n \n"
    ],
    "Buggy Code": [
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      output_shape.AddDim(shape_vec(i));",
            "    }",
            "    const int64_t in_rows = output_shape.dim_size(1);",
            "    const int64_t in_cols = output_shape.dim_size(2);",
            ""
        ],
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      output_shape.AddDim(shape_vec(i));",
            "    }",
            "",
            "    if (output_shape.num_elements() == 0) {",
            "      Tensor* output = nullptr;"
        ],
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      output_shape.AddDim(shape_vec(i));",
            "    }",
            "    if (output_shape.num_elements() == 0) {",
            "      Tensor* output = nullptr;",
            "      OP_REQUIRES_OK(context,"
        ]
    ],
    "Clean Code": [
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));",
            "    }",
            "    const int64_t in_rows = output_shape.dim_size(1);",
            "    const int64_t in_cols = output_shape.dim_size(2);",
            ""
        ],
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));",
            "    }",
            "",
            "    if (output_shape.num_elements() == 0) {",
            "      Tensor* output = nullptr;"
        ],
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));",
            "    }",
            "    if (output_shape.num_elements() == 0) {",
            "      Tensor* output = nullptr;",
            "      OP_REQUIRES_OK(context,"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2475-53vw-vp25",
    "API Signature": "tf.raw_ops.AvgPoolGrad(\n    orig_input_shape,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NHWC',\n    name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Negative input tensor",
    "Anomaly Description": "A negative input tensor refers to a tensor that contains negative values. In other words, the elements of the tensor have a value less than zero.",
    "Category": "Tensor",
    "Argument": "orig_input_shape = tf.constant(-536870912, shape=[4], dtype=tf.int32)"
},
{
    "Title": "\n        Segfault in `QuantizedAdd`\n      ",
    "Bug description": "If  QuantizedAdd  is given  min_input  or  max_input  tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "Toutput = tf.qint32\nx = tf.constant(140, shape=[1], dtype=tf.quint8)\ny = tf.constant(26, shape=[10], dtype=tf.quint8)\nmin_x = tf.constant([], shape=[0], dtype=tf.float32)\nmax_x = tf.constant(0, shape=[], dtype=tf.float32)\nmin_y = tf.constant(0, shape=[], dtype=tf.float32)\nmax_y = tf.constant(0, shape=[], dtype=tf.float32)\n)\ntf.raw_ops.QuantizedAdd(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y, Toutput=Toutput)",
    "Code change": [
        "@@ -32,8 +32,21 @@ class QuantizedReluOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -65,8 +78,21 @@ class QuantizedRelu6Op : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n",
        "@@ -55,8 +55,8 @@ TEST_F(QuantizedActivationsTest, TestRelu) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -86,8 +86,8 @@ TEST_F(QuantizedActivationsTest, TestRelu6) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
        "@@ -25,6 +25,7 @@ limitations under the License.\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n@@ -457,10 +458,28 @@ class QuantizedAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& x = context->input(0);\n     const Tensor& y = context->input(1);\n-    const float min_x = context->input(2).flat<float>()(0);\n-    const float max_x = context->input(3).flat<float>()(0);\n-    const float min_y = context->input(4).flat<float>()(0);\n-    const float max_y = context->input(5).flat<float>()(0);\n+    const Tensor& min_x_tensor = context->input(2);\n+    const Tensor& max_x_tensor = context->input(3);\n+    const Tensor& min_y_tensor = context->input(4);\n+    const Tensor& max_y_tensor = context->input(5);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),\n+                errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",\n+                                        min_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),\n+                errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",\n+                                        max_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),\n+                errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",\n+                                        min_y_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),\n+                errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",\n+                                        max_y_tensor.dims()));\n+\n+    const float min_x = min_x_tensor.scalar<float>()();\n+    const float max_x = max_x_tensor.scalar<float>()();\n+    const float min_y = min_y_tensor.scalar<float>()();\n+    const float max_y = max_y_tensor.scalar<float>()();\n \n     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n     if (!bcast.IsValid()) {\n",
        "@@ -206,5 +206,60 @@ class RequantizeOpTest(test_util.TensorFlowTestCase):\n               out_type=dtypes.qint8))\n \n \n+class QuantizedAddOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    x = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.quantized_add(\n+              x=x,\n+              y=y,\n+              min_x=[],\n+              max_x=1.0,\n+              min_y=0.0,\n+              max_y=1.0,\n+              Toutput=dtypes.qint32))\n+\n+\n+class QuantizedReluOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n+class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu6(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n if __name__ == \"__main__\":\n   googletest.main()\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const float min_input = context->input(1).flat<float>()(0);",
            "    const float max_input = context->input(2).flat<float>()(0);",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "    const T min_as_quantized = FloatToQuantized<T>(0.0f, min_input, max_input);",
            "",
            "    if (meta::IsSupportedAndEnabled() && std::is_same<T, quint8>()) {",
            "      auto input_ui8_array = input.flat<quint8>();",
            "      meta::Clamp(context, input_ui8_array.data(), input_ui8_array.size(),",
            "                  min_as_quantized, 255, output->flat<quint8>().data());",
            "    } else {",
            "      output->flat<T>().device(context->eigen_cpu_device()) =",
            "          input.flat<T>().cwiseMax(min_as_quantized).template cast<T>();",
            "    }",
            "",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));",
            "    output_min->flat<float>()(0) = min_input;"
        ],
        [
            "                  min_as_quantized, max_as_quantized,",
            "                  output->flat<quint8>().data());",
            "    } else {",
            "      output->flat<T>().device(context->eigen_cpu_device()) =",
            "          input.flat<T>()",
            "              .cwiseMax(min_as_quantized)",
            "              .cwiseMin(max_as_quantized)",
            "              .template cast<T>();",
            "    }",
            "",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));",
            "    output_min->flat<float>()(0) = min_input;",
            "    Tensor* output_max = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));",
            "    output_max->flat<float>()(0) = max_input;",
            "  }",
            "};",
            "",
            "REGISTER_KERNEL_BUILDER(Name(\"QuantizedRelu\")",
            "                            .Device(DEVICE_CPU)"
        ],
        [
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/kernels/meta_support.h\"",
            "#include \"tensorflow/core/kernels/quantization_utils.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/util/bcast.h\"",
            ""
        ],
        [
            "    const Tensor& y = context->input(1);",
            "    const float min_x = context->input(2).flat<float>()(0);",
            "    const float max_x = context->input(3).flat<float>()(0);",
            "    const float min_y = context->input(4).flat<float>()(0);",
            "    const float max_y = context->input(5).flat<float>()(0);",
            "",
            "    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
            "    if (!bcast.IsValid()) {",
            "      context->SetStatus(errors::InvalidArgument(",
            "          \"Incompatible shapes: \", x.shape().DebugString(), \" vs. \",",
            "          y.shape().DebugString()));",
            "      return;",
            "    }",
            "    Tensor* z;",
            "    OP_REQUIRES_OK(context, context->allocate_output(",
            "                                0, BCast::ToShape(bcast.output_shape()), &z));",
            "",
            "    // Make sure that we have valid quantization ranges for the input buffers.",
            "    // If the difference between the min and max is negative or zero, it makes",
            "    // it hard to do meaningful intermediate operations on the values.",
            "    OP_REQUIRES(context, (max_x > min_x),",
            "                errors::InvalidArgument(\"max_x must be larger than min_x.\"));",
            "    OP_REQUIRES(context, (max_y > min_y),",
            "                errors::InvalidArgument(\"max_y must be larger than min_y.\"));",
            "    const T* x_data = x.flat<T>().data();",
            "    const T* y_data = y.flat<T>().data();",
            "    Toutput* z_data = z->flat<Toutput>().data();",
            ""
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const Tensor& min_input_tensor = context->input(1);",
            "    const Tensor& max_input_tensor = context->input(2);",
            "",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
            "                                min_input_tensor.dims()));",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
            "                                max_input_tensor.dims()));",
            "",
            "    const float min_input = min_input_tensor.scalar<float>()();",
            "    const float max_input = max_input_tensor.scalar<float>()();",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "    const T min_as_quantized = FloatToQuantized<T>(0.0f, min_input, max_input);"
        ],
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const Tensor& min_input_tensor = context->input(1);",
            "    const Tensor& max_input_tensor = context->input(2);",
            "",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
            "                                min_input_tensor.dims()));",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
            "        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
            "                                max_input_tensor.dims()));",
            "",
            "    const float min_input = min_input_tensor.scalar<float>()();",
            "    const float max_input = max_input_tensor.scalar<float>()();",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "    const T min_as_quantized = FloatToQuantized<T>(0.0f, min_input, max_input);"
        ],
        [
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/kernels/meta_support.h\"",
            "#include \"tensorflow/core/kernels/quantization_utils.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/util/bcast.h\""
        ],
        [
            "    const Tensor& x = context->input(0);",
            "    const Tensor& y = context->input(1);",
            "    const Tensor& min_x_tensor = context->input(2);",
            "    const Tensor& max_x_tensor = context->input(3);",
            "    const Tensor& min_y_tensor = context->input(4);",
            "    const Tensor& max_y_tensor = context->input(5);",
            "",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),",
            "                errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",",
            "                                        min_x_tensor.dims()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),",
            "                errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",",
            "                                        max_x_tensor.dims()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),",
            "                errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",",
            "                                        min_y_tensor.dims()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),",
            "                errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",",
            "                                        max_y_tensor.dims()));",
            "",
            "    const float min_x = min_x_tensor.scalar<float>()();",
            "    const float max_x = max_x_tensor.scalar<float>()();",
            "    const float min_y = min_y_tensor.scalar<float>()();",
            "    const float max_y = max_y_tensor.scalar<float>()();",
            "",
            "    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
            "    if (!bcast.IsValid()) {",
            "      context->SetStatus(errors::InvalidArgument("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v6h3-348g-6h5x",
    "API Signature": "tf.raw_ops.QuantizedAdd(\n    x,\n    y,\n    min_x,\n    max_x,\n    min_y,\n    max_y,\n    Toutput=tf.dtypes.qint32,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "min_x = tf.constant([], shape=[0], dtype=tf.float32)\nmax_x = tf.constant(0, shape=[], dtype=tf.float32)\nmin_y = tf.constant(0, shape=[], dtype=tf.float32)\nmax_y = tf.constant(0, shape=[], dtype=tf.float32)"
},
{
    "Title": "\n        Segfault in `QuantizedAvgPool`\n      ",
    "Bug description": "If  QuantizedAvgPool  is given  min_input  or  max_input  tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "ksize = [1, 2, 2, 1]\nstrides = [1, 2, 2, 1]\npadding = \"SAME\"\ninput = tf.constant(1, shape=[1,4,4,2], dtype=tf.quint8)\nmin_input = tf.constant([], shape=[0], dtype=tf.float32)\nmax_input = tf.constant(0, shape=[1], dtype=tf.float32)\n)\ntf.raw_ops.QuantizedAvgPool(input=input, min_input=min_input, max_input=max_input, ksize=ksize, strides=strides, padding=padding)",
    "Code change": [
        "@@ -15,18 +15,18 @@ limitations under the License.\n \n // See docs in ../ops/nn_ops.cc.\n \n-#include \"tensorflow/core/framework/op_requires.h\"\n-#include \"tensorflow/core/platform/errors.h\"\n #define EIGEN_USE_THREADS\n \n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/ops_util.h\"\n #include \"tensorflow/core/kernels/pooling_ops_common.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/util/padding.h\"\n #include \"tensorflow/core/util/tensor_format.h\"\n@@ -67,8 +67,20 @@ class QuantizedAvgPoolingOp : public OpKernel {\n       return;\n     }\n \n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+                errors::InvalidArgument(\n+                    \"min_input shape must be rank 0 but is rank \",\n+                    min_input_tensor.dims(),\n+                    \", received shape: \", min_input_tensor.shape()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+                errors::InvalidArgument(\n+                    \"max_input shape must be rank 0 but is rank \",\n+                    max_input_tensor.dims(),\n+                    \", received shape: \", max_input_tensor.shape()));\n+    const float min_input = context->input(1).scalar<float>()();\n+    const float max_input = context->input(2).scalar<float>()();\n \n     OP_REQUIRES(context, params.depth_window == 1,\n                 errors::Unimplemented(\"Non-spatial pooling is not \"\n@@ -119,20 +131,20 @@ class QuantizedMaxPoolingOp : public MaxPoolingOp<Device, T> {\n       : MaxPoolingOp<Device, T>(context) {}\n \n   void Compute(OpKernelContext* context) override {\n-    auto min_input_tensor = context->input(1);\n-    auto max_input_tensor = context->input(2);\n-    OP_REQUIRES(\n-        context, min_input_tensor.NumElements() == 1,\n-        errors::InvalidArgument(\n-            \"min_input must be a scalar float value, got tensor with shape \",\n-            min_input_tensor.shape()));\n-    OP_REQUIRES(\n-        context, max_input_tensor.NumElements() == 1,\n-        errors::InvalidArgument(\n-            \"max_input must be a scalar float value, got tensor with shape \",\n-            max_input_tensor.shape()));\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+                errors::InvalidArgument(\n+                    \"min_input shape must be rank 0 but is rank \",\n+                    min_input_tensor.dims(),\n+                    \", received shape: \", min_input_tensor.shape()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+                errors::InvalidArgument(\n+                    \"max_input shape must be rank 0 but is rank \",\n+                    max_input_tensor.dims(),\n+                    \", received shape: \", max_input_tensor.shape()));\n+    const float min_input = context->input(1).scalar<float>()();\n+    const float max_input = context->input(2).scalar<float>()();\n     MaxPoolingOp<Device, T>::Compute(context);\n     Tensor* output_min = nullptr;\n     OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));\n",
        "@@ -69,8 +69,8 @@ TEST_F(QuantizedPoolingTest, SmallAveragePooling) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -114,8 +114,8 @@ TEST_F(QuantizedPoolingTest, SmallMaxPooling) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n",
        "@@ -154,6 +154,72 @@ class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):\n               x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))\n \n \n+class QuantizedAvgPoolingOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+    ksize = [1, 1, 1, 1]\n+    strides = [1, 1, 1, 1]\n+    padding = \"SAME\"\n+\n+    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n+                                \"must be.* rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_avg_pool(\n+              input=inputs,\n+              min_input=[],\n+              max_input=1.0,\n+              ksize=ksize,\n+              strides=strides,\n+              padding=padding))\n+\n+    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n+                                \"must be.* rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_avg_pool(\n+              input=inputs,\n+              min_input=0.0,\n+              max_input=[],\n+              ksize=ksize,\n+              strides=strides,\n+              padding=padding))\n+\n+\n+class QuantizedMaxPoolingOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+    ksize = [1, 1, 1, 1]\n+    strides = [1, 1, 1, 1]\n+    padding = \"SAME\"\n+\n+    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n+                                \"must be.* rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_max_pool(\n+              input=inputs,\n+              min_input=[],\n+              max_input=1.0,\n+              ksize=ksize,\n+              strides=strides,\n+              padding=padding))\n+\n+    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n+                                \"must be.* rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_max_pool(\n+              input=inputs,\n+              min_input=0.0,\n+              max_input=[],\n+              ksize=ksize,\n+              strides=strides,\n+              padding=padding))\n+\n+\n class RequantizeOpTest(test_util.TensorFlowTestCase):\n \n   @test_util.run_in_graph_and_eager_modes\n"
    ],
    "Buggy Code": [
        [
            "// See docs in ../ops/nn_ops.cc.",
            "",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#define EIGEN_USE_THREADS",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/numeric_op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/kernels/ops_util.h\"",
            "#include \"tensorflow/core/kernels/pooling_ops_common.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/util/padding.h\"",
            "#include \"tensorflow/core/util/tensor_format.h\"",
            ""
        ],
        [
            "    }",
            "",
            "    const float min_input = context->input(1).flat<float>()(0);",
            "    const float max_input = context->input(2).flat<float>()(0);",
            "",
            "    OP_REQUIRES(context, params.depth_window == 1,",
            "                errors::Unimplemented(\"Non-spatial pooling is not \"",
            "                                      \"yet supported. Volunteers? :)\"));",
            "",
            "    OP_REQUIRES(context, tensor_in.dims() == 4,",
            "                errors::InvalidArgument(\"tensor_in must be 4-dimensional\"));",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(",
            "                                0, params.forward_output_shape(), &output));",
            "    const int32_t highest = static_cast<int32>(Eigen::NumTraits<T>::highest());",
            "    const int32_t lowest = static_cast<int32>(Eigen::NumTraits<T>::lowest());",
            "",
            "    // TODO(vrv): Switch this to the Eigen::Tensor version of",
            "    // SpatialAvgPooling once that version is running quickly."
        ],
        [
            "            \"max_input must be a scalar float value, got tensor with shape \",",
            "            max_input_tensor.shape()));",
            "    const float min_input = context->input(1).flat<float>()(0);",
            "    const float max_input = context->input(2).flat<float>()(0);",
            "    MaxPoolingOp<Device, T>::Compute(context);",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));",
            "    output_min->flat<float>()(0) = min_input;",
            "    Tensor* output_max = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));",
            "    output_max->flat<float>()(0) = max_input;",
            "  }",
            "};",
            "",
            "REGISTER_KERNEL_BUILDER(",
            "    Name(\"QuantizedAvgPool\").Device(DEVICE_CPU).TypeConstraint<quint8>(\"T\"),",
            "    QuantizedAvgPoolingOp<CPUDevice, quint8>);",
            "",
            "REGISTER_KERNEL_BUILDER(",
            "    Name(\"QuantizedMaxPool\").Device(DEVICE_CPU).TypeConstraint<quint8>(\"T\"),"
        ]
    ],
    "Clean Code": [
        [
            "// See docs in ../ops/nn_ops.cc.",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/numeric_op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/kernels/ops_util.h\"",
            "#include \"tensorflow/core/kernels/pooling_ops_common.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/util/padding.h\"",
            "#include \"tensorflow/core/util/tensor_format.h\"",
            ""
        ],
        [
            "    }",
            "",
            "    const Tensor& min_input_tensor = context->input(1);",
            "    const Tensor& max_input_tensor = context->input(2);",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
            "                errors::InvalidArgument(",
            "                    \"min_input shape must be rank 0 but is rank \",",
            "                    min_input_tensor.dims(),",
            "                    \", received shape: \", min_input_tensor.shape()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
            "                errors::InvalidArgument(",
            "                    \"max_input shape must be rank 0 but is rank \",",
            "                    max_input_tensor.dims(),",
            "                    \", received shape: \", max_input_tensor.shape()));",
            "    const float min_input = context->input(1).scalar<float>()();",
            "    const float max_input = context->input(2).scalar<float>()();",
            "",
            "    OP_REQUIRES(context, params.depth_window == 1,",
            "                errors::Unimplemented(\"Non-spatial pooling is not \"",
            "                                      \"yet supported. Volunteers? :)\"));"
        ],
        [
            "",
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& min_input_tensor = context->input(1);",
            "    const Tensor& max_input_tensor = context->input(2);",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
            "                errors::InvalidArgument(",
            "                    \"min_input shape must be rank 0 but is rank \",",
            "                    min_input_tensor.dims(),",
            "                    \", received shape: \", min_input_tensor.shape()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
            "                errors::InvalidArgument(",
            "                    \"max_input shape must be rank 0 but is rank \",",
            "                    max_input_tensor.dims(),",
            "                    \", received shape: \", max_input_tensor.shape()));",
            "    const float min_input = context->input(1).scalar<float>()();",
            "    const float max_input = context->input(2).scalar<float>()();",
            "    MaxPoolingOp<Device, T>::Compute(context);",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));",
            "    output_min->flat<float>()(0) = min_input;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4w68-4x85-mjj9",
    "API Signature": "tf.raw_ops.QuantizedAvgPool(\n    input, min_input, max_input, ksize, strides, padding, name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "min_input = tf.constant([], shape=[0], dtype=tf.float32)\nmax_input = tf.constant(0, shape=[1], dtype=tf.float32"
},
{
    "Title": "\n        Segfault in `LowerBound` and `UpperBound`\n      ",
    "Bug description": "If  LowerBound  or  UpperBound  is given an empty sorted_inputs  input, it results in a  nullptr  dereference, leading to a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.int64\nsorted_inputs = tf.constant([], shape=[2,2,0,0,0,0,0,2], dtype=tf.float32)\nvalues = tf.constant(0.372660398, shape=[2,4], dtype=tf.float32)\n)\ntf.raw_ops.UpperBound(sorted_inputs=sorted_inputs, values=values, out_type=out_type)",
    "Code change": [
        "@@ -22,6 +22,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/kernels/fill_functor.h\"\n #include \"tensorflow/core/lib/core/bits.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/threadpool.h\"\n@@ -129,6 +130,14 @@ class UpperBoundOp : public OpKernel {\n     auto output = output_t->template flat<OutType>();\n     const auto sorted_inputs = sorted_inputs_t.template flat<T>();\n     const auto values = values_t.template flat<T>();\n+\n+    // For empty inputs, all values will be placed at the zeroth position.\n+    if (sorted_inputs.size() == 0) {\n+      functor::SetZeroFunctor<Device, OutType> set_zero;\n+      set_zero(ctx->eigen_device<Device>(), output);\n+      return;\n+    }\n+\n     OP_REQUIRES_OK(\n         ctx, functor::UpperBoundFunctor<Device, T, OutType>::Compute(\n                  ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),\n@@ -174,6 +183,14 @@ class LowerBoundOp : public OpKernel {\n     auto output = output_t->template flat<OutType>();\n     const auto sorted_inputs = sorted_inputs_t.template flat<T>();\n     const auto values = values_t.template flat<T>();\n+\n+    // For empty inputs, all values will be placed at the zeroth position.\n+    if (sorted_inputs.size() == 0) {\n+      functor::SetZeroFunctor<Device, OutType> set_zero;\n+      set_zero(ctx->eigen_device<Device>(), output);\n+      return;\n+    }\n+\n     OP_REQUIRES_OK(\n         ctx, functor::LowerBoundFunctor<Device, T, OutType>::Compute(\n                  ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),\n",
        "@@ -2060,6 +2060,17 @@ class SortedSearchTest(test_util.TensorFlowTestCase):\n                 side=side,\n                 out_type=dtype), array_ops.zeros([2, 0], dtype))\n \n+  def testZeroInputSize(self):\n+    dtype = dtypes.int32\n+    for side in (\"left\", \"right\"):\n+      with self.subTest(side=side):\n+        self.assertAllEqual(\n+            array_ops.searchsorted(\n+                array_ops.ones([2, 0]),\n+                array_ops.ones([2, 3]),\n+                side=side,\n+                out_type=dtype), array_ops.zeros([2, 3], dtype))\n+\n   def testInt64(self):\n \n     @def_function.function\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/lib/core/bits.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/threadpool.h\"",
            "#include \"tensorflow/core/platform/types.h\"",
            ""
        ],
        [
            "    const auto values = values_t.template flat<T>();",
            "    OP_REQUIRES_OK(",
            "        ctx, functor::UpperBoundFunctor<Device, T, OutType>::Compute(",
            "                 ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),",
            "                 sorted_inputs_t.dim_size(1), values_t.dim_size(1), &output));",
            "  }",
            "};",
            "",
            "template <typename Device, typename T, typename OutType>",
            "class LowerBoundOp : public OpKernel {",
            " public:",
            "  explicit LowerBoundOp(OpKernelConstruction* ctx) : OpKernel(ctx) {}",
            "",
            "  void Compute(OpKernelContext* ctx) override {"
        ],
        [
            "#define REGISTER_KERNELS(type)                                    \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"UpperBound\")                      \\",
            "                              .Device(DEVICE_CPU)                 \\",
            "                              .TypeConstraint<type>(\"T\")          \\",
            "                              .TypeConstraint<int32>(\"out_type\"), \\",
            "                          UpperBoundOp<CPUDevice, type, int32>);",
            "",
            "TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);",
            "#undef REGISTER_KERNELS",
            "",
            "#define REGISTER_KERNELS(type)                                      \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"UpperBound\")                        \\",
            "                              .Device(DEVICE_CPU)                   \\",
            "                              .TypeConstraint<type>(\"T\")            \\"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/kernels/fill_functor.h\"",
            "#include \"tensorflow/core/lib/core/bits.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/threadpool.h\"",
            "#include \"tensorflow/core/platform/types.h\""
        ],
        [
            "    const auto sorted_inputs = sorted_inputs_t.template flat<T>();",
            "    const auto values = values_t.template flat<T>();",
            "",
            "    // For empty inputs, all values will be placed at the zeroth position.",
            "    if (sorted_inputs.size() == 0) {",
            "      functor::SetZeroFunctor<Device, OutType> set_zero;",
            "      set_zero(ctx->eigen_device<Device>(), output);",
            "      return;",
            "    }",
            "",
            "    OP_REQUIRES_OK(",
            "        ctx, functor::UpperBoundFunctor<Device, T, OutType>::Compute(",
            "                 ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),",
            "                 sorted_inputs_t.dim_size(1), values_t.dim_size(1), &output));"
        ],
        [
            "    const auto sorted_inputs = sorted_inputs_t.template flat<T>();",
            "    const auto values = values_t.template flat<T>();",
            "",
            "    // For empty inputs, all values will be placed at the zeroth position.",
            "    if (sorted_inputs.size() == 0) {",
            "      functor::SetZeroFunctor<Device, OutType> set_zero;",
            "      set_zero(ctx->eigen_device<Device>(), output);",
            "      return;",
            "    }",
            "",
            "    OP_REQUIRES_OK(",
            "        ctx, functor::LowerBoundFunctor<Device, T, OutType>::Compute(",
            "                 ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),",
            "                 sorted_inputs_t.dim_size(1), values_t.dim_size(1), &output));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qxpx-j395-pw36",
    "API Signature": "tf.raw_ops.LowerBound(\n    sorted_inputs,\n    values,\n    out_type=tf.dtypes.int32,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "sorted_inputs = tf.constant([], shape=[10,0], dtype=tf.float32)"
},
{
    "Title": "\n        Segfault in `LowerBound` and `UpperBound`\n      ",
    "Bug description": "If  LowerBound  or  UpperBound  is given an empty sorted_inputs  input, it results in a  nullptr  dereference, leading to a segfault that can be used to trigger a denial of service attack.",
    "Sample Code": "out_type = tf.int64\nsorted_inputs = tf.constant([], shape=[2,2,0,0,0,0,0,2], dtype=tf.float32)\nvalues = tf.constant(0.372660398, shape=[2,4], dtype=tf.float32)\n)\ntf.raw_ops.UpperBound(sorted_inputs=sorted_inputs, values=values, out_type=out_type)",
    "Code change": [
        "@@ -22,6 +22,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/kernels/fill_functor.h\"\n #include \"tensorflow/core/lib/core/bits.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/threadpool.h\"\n@@ -129,6 +130,14 @@ class UpperBoundOp : public OpKernel {\n     auto output = output_t->template flat<OutType>();\n     const auto sorted_inputs = sorted_inputs_t.template flat<T>();\n     const auto values = values_t.template flat<T>();\n+\n+    // For empty inputs, all values will be placed at the zeroth position.\n+    if (sorted_inputs.size() == 0) {\n+      functor::SetZeroFunctor<Device, OutType> set_zero;\n+      set_zero(ctx->eigen_device<Device>(), output);\n+      return;\n+    }\n+\n     OP_REQUIRES_OK(\n         ctx, functor::UpperBoundFunctor<Device, T, OutType>::Compute(\n                  ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),\n@@ -174,6 +183,14 @@ class LowerBoundOp : public OpKernel {\n     auto output = output_t->template flat<OutType>();\n     const auto sorted_inputs = sorted_inputs_t.template flat<T>();\n     const auto values = values_t.template flat<T>();\n+\n+    // For empty inputs, all values will be placed at the zeroth position.\n+    if (sorted_inputs.size() == 0) {\n+      functor::SetZeroFunctor<Device, OutType> set_zero;\n+      set_zero(ctx->eigen_device<Device>(), output);\n+      return;\n+    }\n+\n     OP_REQUIRES_OK(\n         ctx, functor::LowerBoundFunctor<Device, T, OutType>::Compute(\n                  ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),\n",
        "@@ -2060,6 +2060,17 @@ class SortedSearchTest(test_util.TensorFlowTestCase):\n                 side=side,\n                 out_type=dtype), array_ops.zeros([2, 0], dtype))\n \n+  def testZeroInputSize(self):\n+    dtype = dtypes.int32\n+    for side in (\"left\", \"right\"):\n+      with self.subTest(side=side):\n+        self.assertAllEqual(\n+            array_ops.searchsorted(\n+                array_ops.ones([2, 0]),\n+                array_ops.ones([2, 3]),\n+                side=side,\n+                out_type=dtype), array_ops.zeros([2, 3], dtype))\n+\n   def testInt64(self):\n \n     @def_function.function\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/lib/core/bits.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/threadpool.h\"",
            "#include \"tensorflow/core/platform/types.h\"",
            ""
        ],
        [
            "    const auto values = values_t.template flat<T>();",
            "    OP_REQUIRES_OK(",
            "        ctx, functor::UpperBoundFunctor<Device, T, OutType>::Compute(",
            "                 ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),",
            "                 sorted_inputs_t.dim_size(1), values_t.dim_size(1), &output));",
            "  }",
            "};",
            "",
            "template <typename Device, typename T, typename OutType>",
            "class LowerBoundOp : public OpKernel {",
            " public:",
            "  explicit LowerBoundOp(OpKernelConstruction* ctx) : OpKernel(ctx) {}",
            "",
            "  void Compute(OpKernelContext* ctx) override {"
        ],
        [
            "#define REGISTER_KERNELS(type)                                    \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"UpperBound\")                      \\",
            "                              .Device(DEVICE_CPU)                 \\",
            "                              .TypeConstraint<type>(\"T\")          \\",
            "                              .TypeConstraint<int32>(\"out_type\"), \\",
            "                          UpperBoundOp<CPUDevice, type, int32>);",
            "",
            "TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);",
            "#undef REGISTER_KERNELS",
            "",
            "#define REGISTER_KERNELS(type)                                      \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"UpperBound\")                        \\",
            "                              .Device(DEVICE_CPU)                   \\",
            "                              .TypeConstraint<type>(\"T\")            \\"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/kernels/fill_functor.h\"",
            "#include \"tensorflow/core/lib/core/bits.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/threadpool.h\"",
            "#include \"tensorflow/core/platform/types.h\""
        ],
        [
            "    const auto sorted_inputs = sorted_inputs_t.template flat<T>();",
            "    const auto values = values_t.template flat<T>();",
            "",
            "    // For empty inputs, all values will be placed at the zeroth position.",
            "    if (sorted_inputs.size() == 0) {",
            "      functor::SetZeroFunctor<Device, OutType> set_zero;",
            "      set_zero(ctx->eigen_device<Device>(), output);",
            "      return;",
            "    }",
            "",
            "    OP_REQUIRES_OK(",
            "        ctx, functor::UpperBoundFunctor<Device, T, OutType>::Compute(",
            "                 ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),",
            "                 sorted_inputs_t.dim_size(1), values_t.dim_size(1), &output));"
        ],
        [
            "    const auto sorted_inputs = sorted_inputs_t.template flat<T>();",
            "    const auto values = values_t.template flat<T>();",
            "",
            "    // For empty inputs, all values will be placed at the zeroth position.",
            "    if (sorted_inputs.size() == 0) {",
            "      functor::SetZeroFunctor<Device, OutType> set_zero;",
            "      set_zero(ctx->eigen_device<Device>(), output);",
            "      return;",
            "    }",
            "",
            "    OP_REQUIRES_OK(",
            "        ctx, functor::LowerBoundFunctor<Device, T, OutType>::Compute(",
            "                 ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),",
            "                 sorted_inputs_t.dim_size(1), values_t.dim_size(1), &output));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qxpx-j395-pw36",
    "API Signature": "tf.raw_ops.UpperBound(\n    sorted_inputs,\n    values,\n    out_type=tf.dtypes.int32,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "sorted_inputs = tf.constant([], shape=[2,2,0,0,0,0,0,2], dtype=tf.float32)"
},
{
    "Title": "\n        Segfault in `BlockLSTMGradV2`\n      ",
    "Bug description": "The implementation of  BlockLSTMGradV2  does not fully validate its inputs.",
    "Sample Code": "use_peephole = False\nseq_len_max = tf.constant(1, shape=[], dtype=tf.int64)\nx = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\ncs_prev = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nh_prev = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nw = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nwci = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nwcf = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nwco = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nb = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\ni = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\ncs = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nf = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\no = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nci = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nco = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nh = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\ncs_grad = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nh_grad = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\n)\ntf.raw_ops.BlockLSTMGradV2(seq_len_max=seq_len_max, x=x, cs_prev=cs_prev, h_prev=h_prev, w=w, wci=wci, wcf=wcf, wco=wco, b=b, i=i, cs=cs, f=f, o=o, ci=ci, co=co, h=h, cs_grad=cs_grad, h_grad=h_grad, use_peephole=use_peephole)",
    "Code change": [
        "@@ -1138,19 +1138,30 @@ class BlockLSTMGradOp : public OpKernel {\n \n     const Tensor* x;\n     OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x));\n-    OP_REQUIRES(ctx, x->dims() == 3, errors::InvalidArgument(\"x must be 3D\"));\n+    OP_REQUIRES(\n+        ctx, x->dims() == 3,\n+        errors::InvalidArgument(\"x must be rank 3 but is rank \", x->dims()));\n     const int64_t timelen = x->dim_size(0);\n     const int64_t batch_size = x->dim_size(1);\n     const int64_t input_size = x->dim_size(2);\n \n     const Tensor* cs_prev_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));\n+    OP_REQUIRES(ctx, cs_prev_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_prev must be rank 2 but is rank \",\n+                                        cs_prev_tensor->dims()));\n \n     const Tensor* h_prev_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));\n+    OP_REQUIRES(ctx, h_prev_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_prev must be rank 2 but is rank \",\n+                                        h_prev_tensor->dims()));\n \n     const Tensor* w_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w must be rank 2 but is rank \",\n+                                        w_tensor->dims()));\n     const int64_t cell_size = w_tensor->dim_size(1) / 4;\n     OP_REQUIRES(ctx, input_size + cell_size == w_tensor->dim_size(0),\n                 errors::InvalidArgument(\n@@ -1159,15 +1170,27 @@ class BlockLSTMGradOp : public OpKernel {\n \n     const Tensor* wci_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));\n+    OP_REQUIRES(ctx, wci_tensor->dims() == 1,\n+                errors::InvalidArgument(\"wci must be rank 1 but is rank \",\n+                                        wci_tensor->dims()));\n \n     const Tensor* wcf_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));\n+    OP_REQUIRES(ctx, wcf_tensor->dims() == 1,\n+                errors::InvalidArgument(\"wcf must be rank 1 but is rank \",\n+                                        wcf_tensor->dims()));\n \n     const Tensor* wco_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"wco\", &wco_tensor));\n+    OP_REQUIRES(ctx, wco_tensor->dims() == 1,\n+                errors::InvalidArgument(\"wco must be rank 1 but is rank \",\n+                                        wco_tensor->dims()));\n \n     const Tensor* b_tensor = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->input(\"b\", &b_tensor));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b must be rank 1 but is rank \",\n+                                        b_tensor->dims()));\n     OP_REQUIRES(\n         ctx, cell_size == b_tensor->dim_size(0) / 4,\n         errors::InvalidArgument(\"w and b cell_size don't match: \", cell_size,\n",
        "@@ -1354,6 +1354,58 @@ class LSTMTest(test.TestCase):\n               cell_clip=cell_clip,\n               use_peephole=use_peephole))\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellGradErrorHandling(self):\n+    use_peephole = False\n+    seq_len_max = constant_op.constant(1, shape=[], dtype=dtypes.int64)\n+    x = constant_op.constant(0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.504355371, shape=[1, 1], dtype=dtypes.float32)\n+    w = constant_op.constant(0.504355371, shape=[1, 1], dtype=dtypes.float32)\n+    wci = constant_op.constant(0.504355371, shape=[1], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0.504355371, shape=[1], dtype=dtypes.float32)\n+    wco = constant_op.constant(0.504355371, shape=[1], dtype=dtypes.float32)\n+    b = constant_op.constant(0.504355371, shape=[1], dtype=dtypes.float32)\n+    i = constant_op.constant(0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    cs = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    f = constant_op.constant(0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    o = constant_op.constant(0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    ci = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    co = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    h = constant_op.constant(0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    cs_grad = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    h_grad = constant_op.constant(\n+        0.504355371, shape=[1, 1, 1], dtype=dtypes.float32)\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                \"must be rank\"):\n+      self.evaluate(\n+          gen_rnn_ops.block_lstm_grad_v2(\n+              seq_len_max=seq_len_max,\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              i=i,\n+              cs=cs,\n+              f=f,\n+              o=o,\n+              ci=ci,\n+              co=co,\n+              h=h,\n+              cs_grad=cs_grad,\n+              h_grad=h_grad,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Buggy Code": [
        [
            "    const Tensor* x;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x));",
            "    OP_REQUIRES(ctx, x->dims() == 3, errors::InvalidArgument(\"x must be 3D\"));",
            "    const int64_t timelen = x->dim_size(0);",
            "    const int64_t batch_size = x->dim_size(1);",
            "    const int64_t input_size = x->dim_size(2);",
            "",
            "    const Tensor* cs_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));",
            "",
            "    const Tensor* h_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));",
            "",
            "    const Tensor* w_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));",
            "    const int64_t cell_size = w_tensor->dim_size(1) / 4;",
            "    OP_REQUIRES(ctx, input_size + cell_size == w_tensor->dim_size(0),",
            "                errors::InvalidArgument(",
            "                    \"w matrix rows don't match: \", input_size + cell_size,",
            "                    \" vs. \", w_tensor->dim_size(0)));",
            "",
            "    const Tensor* wci_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));",
            "",
            "    const Tensor* wcf_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));",
            "",
            "    const Tensor* wco_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wco\", &wco_tensor));",
            ""
        ],
        [
            "    OP_REQUIRES(",
            "        ctx, cell_size == b_tensor->dim_size(0) / 4,",
            "        errors::InvalidArgument(\"w and b cell_size don't match: \", cell_size,",
            "                                \" vs. \", b_tensor->dim_size(0)));",
            "",
            "    const Tensor* i_out = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"i\", &i_out));",
            "",
            "    const Tensor* cs_out = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"cs\", &cs_out));",
            "",
            "    const Tensor* f_out = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"f\", &f_out));",
            "",
            "    const Tensor* o_out = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"o\", &o_out));",
            "",
            "    const Tensor* ci_out = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"ci\", &ci_out));",
            "",
            "    const Tensor* co_out = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"co\", &co_out));",
            "",
            "    const Tensor* h_out = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"h\", &h_out));",
            "",
            "    const Tensor* cs_grad = nullptr;"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor* x;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x));",
            "    OP_REQUIRES(",
            "        ctx, x->dims() == 3,",
            "        errors::InvalidArgument(\"x must be rank 3 but is rank \", x->dims()));",
            "    const int64_t timelen = x->dim_size(0);",
            "    const int64_t batch_size = x->dim_size(1);",
            "    const int64_t input_size = x->dim_size(2);",
            "",
            "    const Tensor* cs_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));",
            "    OP_REQUIRES(ctx, cs_prev_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"cs_prev must be rank 2 but is rank \",",
            "                                        cs_prev_tensor->dims()));",
            "",
            "    const Tensor* h_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));",
            "    OP_REQUIRES(ctx, h_prev_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"h_prev must be rank 2 but is rank \",",
            "                                        h_prev_tensor->dims()));",
            "",
            "    const Tensor* w_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));",
            "    OP_REQUIRES(ctx, w_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"w must be rank 2 but is rank \",",
            "                                        w_tensor->dims()));",
            "    const int64_t cell_size = w_tensor->dim_size(1) / 4;",
            "    OP_REQUIRES(ctx, input_size + cell_size == w_tensor->dim_size(0),",
            "                errors::InvalidArgument(",
            "                    \"w matrix rows don't match: \", input_size + cell_size,"
        ],
        [
            "    const Tensor* wci_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));",
            "    OP_REQUIRES(ctx, wci_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"wci must be rank 1 but is rank \",",
            "                                        wci_tensor->dims()));",
            "",
            "    const Tensor* wcf_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));",
            "    OP_REQUIRES(ctx, wcf_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"wcf must be rank 1 but is rank \",",
            "                                        wcf_tensor->dims()));",
            "",
            "    const Tensor* wco_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wco\", &wco_tensor));",
            "    OP_REQUIRES(ctx, wco_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"wco must be rank 1 but is rank \",",
            "                                        wco_tensor->dims()));",
            "",
            "    const Tensor* b_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"b\", &b_tensor));",
            "    OP_REQUIRES(ctx, b_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"b must be rank 1 but is rank \",",
            "                                        b_tensor->dims()));",
            "    OP_REQUIRES(",
            "        ctx, cell_size == b_tensor->dim_size(0) / 4,",
            "        errors::InvalidArgument(\"w and b cell_size don't match: \", cell_size,",
            "                                \" vs. \", b_tensor->dim_size(0)));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-f7r5-q7cx-h668",
    "API Signature": "tf.raw_ops.BlockLSTMGradV2(\n    seq_len_max,\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    i,\n    cs,\n    f,\n    o,\n    ci,\n    co,\n    h,\n    cs_grad,\n    h_grad,\n    use_peephole,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "wci = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nwcf = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nwco = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)\nb = tf.constant(0.504355371, shape=[1,1,1], dtype=tf.float32)"
},
{
    "Title": "\n        `CHECK` failures in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation of  FractionalAvgPoolGrad  does not fully validate the input  orig_input_tensor_shape . This results in an overflow that results in a   CHECK  failure which can be used to trigger a denial of service attack.",
    "Sample Code": "overlapping = True\norig_input_tensor_shape = tf.constant(-1879048192, shape=[4], dtype=tf.int64)\nout_backprop = tf.constant([], shape=[0,0,0,0], dtype=tf.float64)\nrow_pooling_sequence = tf.constant(1, shape=[4], dtype=tf.int64)\ncol_pooling_sequence = tf.constant(1, shape=[4], dtype=tf.int64)\n)\ntf.raw_ops.FractionalAvgPoolGrad(orig_input_tensor_shape=orig_input_tensor_shape, out_backprop=out_backprop, row_pooling_sequence=row_pooling_sequence, col_pooling_sequence=col_pooling_sequence, overlapping=overlapping)",
    "Code change": [
        "@@ -12,6 +12,7 @@ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n+\n #define EIGEN_USE_THREADS\n \n #include <algorithm>\n@@ -19,15 +20,15 @@ limitations under the License.\n #include <random>\n #include <vector>\n \n-#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n-\n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n #include \"tensorflow/core/lib/random/random.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n #include \"tensorflow/core/util/guarded_philox_random.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n typedef Eigen::ThreadPoolDevice CPUDevice;\n@@ -241,7 +242,32 @@ class FractionalAvgPoolGradOp : public OpKernel {\n                     orig_input_tensor_shape.NumElements() == 4,\n                 errors::InvalidArgument(\"original input tensor shape must be\"\n                                         \"1-dimensional and 4 elements\"));\n+    int64_t num_elements = 1;\n+    for (int i = 0; i < orig_input_tensor_shape.dims(); i++) {\n+      OP_REQUIRES(context, orig_input_tensor_shape.dim_size(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"orig_input_tensor_shape must be positive, got: \",\n+                      orig_input_tensor_shape.dim_size(i)));\n+      num_elements = MultiplyWithoutOverflow(\n+          num_elements, orig_input_tensor_shape.dim_size(i));\n+      OP_REQUIRES(\n+          context, num_elements > 0,\n+          errors::InvalidArgument(\n+              \"The total elements specified by orig_input_tensor_shape\",\n+              \" is too large. Encountered overflow after multiplying \",\n+              orig_input_tensor_shape.dim_size(i), \", result: \", num_elements));\n+    }\n+\n     const Tensor& out_backprop = context->input(1);\n+    OP_REQUIRES(context, out_backprop.dims() == 4,\n+                errors::InvalidArgument(\"out_backprop must be 4-dimensional\"));\n+    for (int i = 0; i < out_backprop.dims(); i++) {\n+      OP_REQUIRES(context, out_backprop.dim_size(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"out_backprop must be positive for all dimension, got:\",\n+                      out_backprop.dim_size(i)));\n+    }\n+\n     const Tensor& row_seq_tensor = context->input(2);\n     const Tensor& col_seq_tensor = context->input(3);\n \n",
        "@@ -541,6 +541,27 @@ class FractionalAvgPoolGradTest(test.TestCase):\n           delta=1e-2)\n       self.assertLess(gradient_error, error_margin)\n \n+  def testInvalidSeqRaiseErrorForFractionalAvgPoolGrad(self):\n+    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n+      with self.cached_session() as _:\n+        overlapping = True\n+        orig_input_tensor_shape = constant_op.constant(\n+            -1879048192, shape=[4], dtype=dtypes.int64)\n+        out_backprop = constant_op.constant([],\n+                                            shape=[0, 0, 0, 0],\n+                                            dtype=dtypes.float64)\n+        row_pooling_sequence = constant_op.constant(\n+            1, shape=[4], dtype=dtypes.int64)\n+        col_pooling_sequence = constant_op.constant(\n+            1, shape=[4], dtype=dtypes.int64)\n+        t = gen_nn_ops.fractional_avg_pool_grad(\n+            orig_input_tensor_shape=orig_input_tensor_shape,\n+            out_backprop=out_backprop,\n+            row_pooling_sequence=row_pooling_sequence,\n+            col_pooling_sequence=col_pooling_sequence,\n+            overlapping=overlapping)\n+        self.evaluate(t)\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "limitations under the License.",
            "==============================================================================*/",
            "#define EIGEN_USE_THREADS",
            "",
            "#include <algorithm>",
            "#include <cmath>",
            "#include <random>"
        ],
        [
            "",
            "#include \"tensorflow/core/kernels/fractional_pool_common.h\"",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/numeric_op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/lib/random/random.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/mutex.h\"",
            "#include \"tensorflow/core/util/guarded_philox_random.h\"",
            "",
            "namespace tensorflow {",
            "typedef Eigen::ThreadPoolDevice CPUDevice;",
            "",
            "template <typename T>"
        ],
        [
            "                                        \"1-dimensional and 4 elements\"));",
            "    const Tensor& out_backprop = context->input(1);",
            "    const Tensor& row_seq_tensor = context->input(2);",
            "    const Tensor& col_seq_tensor = context->input(3);",
            "",
            "    const int64_t out_batch = out_backprop.dim_size(0);",
            "    const int64_t out_rows = out_backprop.dim_size(1);",
            "    const int64_t out_cols = out_backprop.dim_size(2);",
            "    const int64_t out_depth = out_backprop.dim_size(3);",
            "",
            "    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,",
            "                errors::InvalidArgument(\"Given out_backprop shape \",",
            "                                        out_backprop.shape().DebugString(),",
            "                                        \", row_seq_tensor must have at least \",",
            "                                        out_rows + 1, \" elements, but got \",",
            "                                        row_seq_tensor.NumElements()));",
            "    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,",
            "                errors::InvalidArgument(\"Given out_backprop shape \",",
            "                                        out_backprop.shape().DebugString(),",
            "                                        \", col_seq_tensor must have at least \",",
            "                                        out_cols + 1, \" elements, but got \",",
            "                                        col_seq_tensor.NumElements()));",
            "",
            "    auto row_seq_tensor_flat = row_seq_tensor.flat<int64_t>();",
            "    auto col_seq_tensor_flat = col_seq_tensor.flat<int64_t>();",
            "    auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64_t>();",
            "",
            "    const int64_t in_batch = orig_input_tensor_shape_flat(0);",
            "    const int64_t in_rows = orig_input_tensor_shape_flat(1);",
            "    const int64_t in_cols = orig_input_tensor_shape_flat(2);",
            "    const int64_t in_depth = orig_input_tensor_shape_flat(3);",
            "    OP_REQUIRES("
        ]
    ],
    "Clean Code": [
        [
            "limitations under the License.",
            "==============================================================================*/",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#include <algorithm>",
            "#include <cmath>"
        ],
        [
            "#include <vector>",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/numeric_op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/kernels/fractional_pool_common.h\"",
            "#include \"tensorflow/core/lib/random/random.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/mutex.h\"",
            "#include \"tensorflow/core/util/guarded_philox_random.h\"",
            "#include \"tensorflow/core/util/overflow.h\"",
            "",
            "namespace tensorflow {",
            "typedef Eigen::ThreadPoolDevice CPUDevice;",
            ""
        ],
        [
            "                errors::InvalidArgument(\"original input tensor shape must be\"",
            "                                        \"1-dimensional and 4 elements\"));",
            "    int64_t num_elements = 1;",
            "    for (int i = 0; i < orig_input_tensor_shape.dims(); i++) {",
            "      OP_REQUIRES(context, orig_input_tensor_shape.dim_size(i) > 0,",
            "                  errors::InvalidArgument(",
            "                      \"orig_input_tensor_shape must be positive, got: \",",
            "                      orig_input_tensor_shape.dim_size(i)));",
            "      num_elements = MultiplyWithoutOverflow(",
            "          num_elements, orig_input_tensor_shape.dim_size(i));",
            "      OP_REQUIRES(",
            "          context, num_elements > 0,",
            "          errors::InvalidArgument(",
            "              \"The total elements specified by orig_input_tensor_shape\",",
            "              \" is too large. Encountered overflow after multiplying \",",
            "              orig_input_tensor_shape.dim_size(i), \", result: \", num_elements));",
            "    }",
            "",
            "    const Tensor& out_backprop = context->input(1);",
            "    OP_REQUIRES(context, out_backprop.dims() == 4,",
            "                errors::InvalidArgument(\"out_backprop must be 4-dimensional\"));",
            "    for (int i = 0; i < out_backprop.dims(); i++) {",
            "      OP_REQUIRES(context, out_backprop.dim_size(i) > 0,",
            "                  errors::InvalidArgument(",
            "                      \"out_backprop must be positive for all dimension, got:\",",
            "                      out_backprop.dim_size(i)));",
            "    }",
            "",
            "    const Tensor& row_seq_tensor = context->input(2);",
            "    const Tensor& col_seq_tensor = context->input(3);",
            "",
            "    const int64_t out_batch = out_backprop.dim_size(0);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-84jm-4cf3-9jfm",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Negative input tensor",
    "Anomaly Description": "A negative input tensor refers to a tensor that contains negative values. In other words, the elements of the tensor have a value less than zero.",
    "Category": "Tensor",
    "Argument": "orig_input_tensor_shape = tf.constant(-1879048192, shape=[4], dtype=tf.int64)"
},
{
    "Title": "\n        `CHECK` failures in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation of  FractionalAvgPoolGrad  does not fully validate the input  orig_input_tensor_shape . This results in an overflow that results in a   CHECK  failure which can be used to trigger a denial of service attack.",
    "Sample Code": "overlapping = True\norig_input_tensor_shape = tf.constant(-1879048192, shape=[4], dtype=tf.int64)\nout_backprop = tf.constant([], shape=[0,0,0,0], dtype=tf.float64)\nrow_pooling_sequence = tf.constant(1, shape=[4], dtype=tf.int64)\ncol_pooling_sequence = tf.constant(1, shape=[4], dtype=tf.int64)\n)\ntf.raw_ops.FractionalAvgPoolGrad(orig_input_tensor_shape=orig_input_tensor_shape, out_backprop=out_backprop, row_pooling_sequence=row_pooling_sequence, col_pooling_sequence=col_pooling_sequence, overlapping=overlapping)",
    "Code change": [
        "@@ -12,6 +12,7 @@ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n+\n #define EIGEN_USE_THREADS\n \n #include <algorithm>\n@@ -19,15 +20,15 @@ limitations under the License.\n #include <random>\n #include <vector>\n \n-#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n-\n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/numeric_op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n #include \"tensorflow/core/lib/random/random.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n #include \"tensorflow/core/util/guarded_philox_random.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n typedef Eigen::ThreadPoolDevice CPUDevice;\n@@ -241,7 +242,32 @@ class FractionalAvgPoolGradOp : public OpKernel {\n                     orig_input_tensor_shape.NumElements() == 4,\n                 errors::InvalidArgument(\"original input tensor shape must be\"\n                                         \"1-dimensional and 4 elements\"));\n+    int64_t num_elements = 1;\n+    for (int i = 0; i < orig_input_tensor_shape.dims(); i++) {\n+      OP_REQUIRES(context, orig_input_tensor_shape.dim_size(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"orig_input_tensor_shape must be positive, got: \",\n+                      orig_input_tensor_shape.dim_size(i)));\n+      num_elements = MultiplyWithoutOverflow(\n+          num_elements, orig_input_tensor_shape.dim_size(i));\n+      OP_REQUIRES(\n+          context, num_elements > 0,\n+          errors::InvalidArgument(\n+              \"The total elements specified by orig_input_tensor_shape\",\n+              \" is too large. Encountered overflow after multiplying \",\n+              orig_input_tensor_shape.dim_size(i), \", result: \", num_elements));\n+    }\n+\n     const Tensor& out_backprop = context->input(1);\n+    OP_REQUIRES(context, out_backprop.dims() == 4,\n+                errors::InvalidArgument(\"out_backprop must be 4-dimensional\"));\n+    for (int i = 0; i < out_backprop.dims(); i++) {\n+      OP_REQUIRES(context, out_backprop.dim_size(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"out_backprop must be positive for all dimension, got:\",\n+                      out_backprop.dim_size(i)));\n+    }\n+\n     const Tensor& row_seq_tensor = context->input(2);\n     const Tensor& col_seq_tensor = context->input(3);\n \n",
        "@@ -541,6 +541,27 @@ class FractionalAvgPoolGradTest(test.TestCase):\n           delta=1e-2)\n       self.assertLess(gradient_error, error_margin)\n \n+  def testInvalidSeqRaiseErrorForFractionalAvgPoolGrad(self):\n+    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n+      with self.cached_session() as _:\n+        overlapping = True\n+        orig_input_tensor_shape = constant_op.constant(\n+            -1879048192, shape=[4], dtype=dtypes.int64)\n+        out_backprop = constant_op.constant([],\n+                                            shape=[0, 0, 0, 0],\n+                                            dtype=dtypes.float64)\n+        row_pooling_sequence = constant_op.constant(\n+            1, shape=[4], dtype=dtypes.int64)\n+        col_pooling_sequence = constant_op.constant(\n+            1, shape=[4], dtype=dtypes.int64)\n+        t = gen_nn_ops.fractional_avg_pool_grad(\n+            orig_input_tensor_shape=orig_input_tensor_shape,\n+            out_backprop=out_backprop,\n+            row_pooling_sequence=row_pooling_sequence,\n+            col_pooling_sequence=col_pooling_sequence,\n+            overlapping=overlapping)\n+        self.evaluate(t)\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "limitations under the License.",
            "==============================================================================*/",
            "#define EIGEN_USE_THREADS",
            "",
            "#include <algorithm>",
            "#include <cmath>",
            "#include <random>"
        ],
        [
            "",
            "#include \"tensorflow/core/kernels/fractional_pool_common.h\"",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/numeric_op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/lib/random/random.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/mutex.h\"",
            "#include \"tensorflow/core/util/guarded_philox_random.h\"",
            "",
            "namespace tensorflow {",
            "typedef Eigen::ThreadPoolDevice CPUDevice;",
            "",
            "template <typename T>"
        ],
        [
            "                                        \"1-dimensional and 4 elements\"));",
            "    const Tensor& out_backprop = context->input(1);",
            "    const Tensor& row_seq_tensor = context->input(2);",
            "    const Tensor& col_seq_tensor = context->input(3);",
            "",
            "    const int64_t out_batch = out_backprop.dim_size(0);",
            "    const int64_t out_rows = out_backprop.dim_size(1);",
            "    const int64_t out_cols = out_backprop.dim_size(2);",
            "    const int64_t out_depth = out_backprop.dim_size(3);",
            "",
            "    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,",
            "                errors::InvalidArgument(\"Given out_backprop shape \",",
            "                                        out_backprop.shape().DebugString(),",
            "                                        \", row_seq_tensor must have at least \",",
            "                                        out_rows + 1, \" elements, but got \",",
            "                                        row_seq_tensor.NumElements()));",
            "    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,",
            "                errors::InvalidArgument(\"Given out_backprop shape \",",
            "                                        out_backprop.shape().DebugString(),",
            "                                        \", col_seq_tensor must have at least \",",
            "                                        out_cols + 1, \" elements, but got \",",
            "                                        col_seq_tensor.NumElements()));",
            "",
            "    auto row_seq_tensor_flat = row_seq_tensor.flat<int64_t>();",
            "    auto col_seq_tensor_flat = col_seq_tensor.flat<int64_t>();",
            "    auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64_t>();",
            "",
            "    const int64_t in_batch = orig_input_tensor_shape_flat(0);",
            "    const int64_t in_rows = orig_input_tensor_shape_flat(1);",
            "    const int64_t in_cols = orig_input_tensor_shape_flat(2);",
            "    const int64_t in_depth = orig_input_tensor_shape_flat(3);",
            "    OP_REQUIRES("
        ]
    ],
    "Clean Code": [
        [
            "limitations under the License.",
            "==============================================================================*/",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#include <algorithm>",
            "#include <cmath>"
        ],
        [
            "#include <vector>",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/numeric_op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/kernels/fractional_pool_common.h\"",
            "#include \"tensorflow/core/lib/random/random.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/mutex.h\"",
            "#include \"tensorflow/core/util/guarded_philox_random.h\"",
            "#include \"tensorflow/core/util/overflow.h\"",
            "",
            "namespace tensorflow {",
            "typedef Eigen::ThreadPoolDevice CPUDevice;",
            ""
        ],
        [
            "                errors::InvalidArgument(\"original input tensor shape must be\"",
            "                                        \"1-dimensional and 4 elements\"));",
            "    int64_t num_elements = 1;",
            "    for (int i = 0; i < orig_input_tensor_shape.dims(); i++) {",
            "      OP_REQUIRES(context, orig_input_tensor_shape.dim_size(i) > 0,",
            "                  errors::InvalidArgument(",
            "                      \"orig_input_tensor_shape must be positive, got: \",",
            "                      orig_input_tensor_shape.dim_size(i)));",
            "      num_elements = MultiplyWithoutOverflow(",
            "          num_elements, orig_input_tensor_shape.dim_size(i));",
            "      OP_REQUIRES(",
            "          context, num_elements > 0,",
            "          errors::InvalidArgument(",
            "              \"The total elements specified by orig_input_tensor_shape\",",
            "              \" is too large. Encountered overflow after multiplying \",",
            "              orig_input_tensor_shape.dim_size(i), \", result: \", num_elements));",
            "    }",
            "",
            "    const Tensor& out_backprop = context->input(1);",
            "    OP_REQUIRES(context, out_backprop.dims() == 4,",
            "                errors::InvalidArgument(\"out_backprop must be 4-dimensional\"));",
            "    for (int i = 0; i < out_backprop.dims(); i++) {",
            "      OP_REQUIRES(context, out_backprop.dim_size(i) > 0,",
            "                  errors::InvalidArgument(",
            "                      \"out_backprop must be positive for all dimension, got:\",",
            "                      out_backprop.dim_size(i)));",
            "    }",
            "",
            "    const Tensor& row_seq_tensor = context->input(2);",
            "    const Tensor& col_seq_tensor = context->input(3);",
            "",
            "    const int64_t out_batch = out_backprop.dim_size(0);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-84jm-4cf3-9jfm",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "out_backprop = tf.constant([], shape=[0,0,0,0], dtype=tf.float64)"
},
{
    "Title": "\n        `CHECK` failures in `AvgPool3DGrad`\n      ",
    "Bug description": "The implementation of  AvgPool3DGradOp  does not fully validate the input  orig_input_shape . This results in an overflow that results in a   CHECK  failure which can be used to trigger a denial of service attack:",
    "Sample Code": "ksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\ndata_format = \"NDHWC\"\norig_input_shape = tf.constant(1879048192, shape=[5], dtype=tf.int32)\ngrad = tf.constant(1, shape=[1,3,2,4,2], dtype=tf.float32)\n)\ntf.raw_ops.AvgPool3DGrad(orig_input_shape=orig_input_shape, grad=grad, ksize=ksize, strides=strides, padding=padding, data_format=data_format)",
    "Code change": [
        "@@ -403,6 +403,7 @@ cc_library(\n         \"//tensorflow/compiler/xla/client:xla_builder\",\n         \"//tensorflow/compiler/xla/client:xla_computation\",\n         \"//tensorflow/compiler/xla/service:hlo\",\n+        \"//tensorflow/core/util:overflow\",\n         \"//tensorflow/core:core_cpu\",\n         \"//tensorflow/core:core_cpu_internal\",\n         \"//tensorflow/core:framework\",\n",
        "@@ -30,6 +30,7 @@ limitations under the License.\n #include \"tensorflow/compiler/xla/status_macros.h\"\n #include \"tensorflow/core/common_runtime/dma_helper.h\"\n #include \"tensorflow/core/platform/errors.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n \n@@ -443,6 +444,16 @@ Status XlaOpKernelContext::ConstantInputAsShape(int index, TensorShape* shape,\n   TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n   std::vector<int64_t> dims;\n   TF_RETURN_IF_ERROR(LiteralToInt64Vector(literal, &dims));\n+\n+  int64_t num_elements = 1;\n+  for (auto i = dims.begin(); i != dims.end(); ++i) {\n+    num_elements = MultiplyWithoutOverflow(num_elements, *i);\n+    if (num_elements < 0)\n+      return errors::InvalidArgument(\n+          \"The total elements specified by orig_input_shape is too large.\",\n+          \"Encountered overflow after multiplying\", *i,\n+          \", result: \", num_elements);\n+  }\n   *shape = TensorShape(dims);\n   return OkStatus();\n }\n",
        "@@ -523,7 +523,7 @@ class AvgPooling3dGradOp : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n \n     Tensor* output;\n",
        "@@ -500,6 +500,7 @@ cuda_py_test(\n     srcs = [\"pooling_ops_3d_test.py\"],\n     deps = [\n         \"//tensorflow/python:client_testlib\",\n+        \"//tensorflow/python:dtypes\",\n         \"//tensorflow/python:framework_for_generated_wrappers\",\n         \"//tensorflow/python:nn_grad\",\n         \"//tensorflow/python:nn_ops\",\n",
        "@@ -18,6 +18,7 @@ import numpy as np\n \n from tensorflow.python.eager import context\n from tensorflow.python.framework import constant_op\n+from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors\n from tensorflow.python.framework import errors_impl\n from tensorflow.python.framework import test_util\n@@ -67,7 +68,7 @@ class PoolingTest(test.TestCase):\n     # Initializes the input tensor with array containing incrementing\n     # numbers from 1.\n     x = [f * 1.0 for f in range(1, total_size + 1)]\n-    with self.cached_session(use_gpu=use_gpu) as sess:\n+    with self.cached_session(use_gpu=use_gpu):\n       t = constant_op.constant(x, shape=input_sizes)\n       window = [1] + list(window) + [1]\n       strides = [1] + list(strides) + [1]\n@@ -124,6 +125,23 @@ class PoolingTest(test.TestCase):\n         padding=\"SAME\",\n         expected=expected_output)\n \n+  def testMaxPool3dGrad(self):\n+    with self.assertRaises(\n+        (errors.ResourceExhaustedError, errors.InvalidArgumentError)):\n+      with self.cached_session():\n+        orig_input_shape = constant_op.constant(\n+            1879048192, shape=[5], dtype=dtypes.int32)\n+        grad = constant_op.constant(\n+            1, shape=[1, 3, 2, 4, 2], dtype=dtypes.float32)\n+        t = gen_nn_ops.AvgPool3DGrad(\n+            orig_input_shape=orig_input_shape,\n+            grad=grad,\n+            ksize=[1, 1, 1, 1, 1],\n+            strides=[1, 1, 1, 1, 1],\n+            padding=\"SAME\",\n+            data_format=\"NDHWC\")\n+        self.evaluate(t)\n+\n   def testMaxPool3dValidPadding(self):\n     expected_output = [40.0, 41.0, 42.0]\n     self._VerifyValues(\n"
    ],
    "Buggy Code": [
        [
            "        \"//tensorflow/compiler/xla/client:xla_computation\",",
            "        \"//tensorflow/compiler/xla/service:hlo\",",
            "        \"//tensorflow/core:core_cpu\",",
            "        \"//tensorflow/core:core_cpu_internal\",",
            "        \"//tensorflow/core:framework\",",
            "        \"//tensorflow/core:lib\",",
            "        \"//tensorflow/core:lib_internal\","
        ],
        [
            "#include \"tensorflow/core/common_runtime/dma_helper.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "namespace tensorflow {",
            "",
            "XlaOpKernelContext::XlaOpKernelContext(OpKernelContext* context)",
            "    : context_(context),"
        ],
        [
            "  TF_RETURN_IF_ERROR(LiteralToInt64Vector(literal, &dims));",
            "  *shape = TensorShape(dims);",
            "  return OkStatus();",
            "}",
            "",
            "Status XlaOpKernelContext::ConstantInputAsPartialShape(",
            "    int index, PartialTensorShape* shape) {",
            "  xla::Literal literal;",
            "  TF_RETURN_IF_ERROR(ConstantInput(index, &literal));",
            "  // If `literal` is a scalar it's value must be -1.",
            "  if (literal.shape().rank() == 0) {",
            "    int64_t shape_val;",
            "    TF_RETURN_IF_ERROR(LiteralToInt64Scalar(literal, &shape_val));",
            "    if (shape_val != -1) {",
            "      return errors::InvalidArgument(",
            "          \"Cannot convert value to PartialTensorShape: \", shape_val);"
        ],
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      output_shape.AddDim(shape_vec(i));",
            "    }",
            "",
            "    Tensor* output;",
            "    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));"
        ],
        [
            "    deps = [",
            "        \"//tensorflow/python:client_testlib\",",
            "        \"//tensorflow/python:framework_for_generated_wrappers\",",
            "        \"//tensorflow/python:nn_grad\",",
            "        \"//tensorflow/python:nn_ops\",",
            "        \"//third_party/py/numpy\",",
            "    ],"
        ]
    ],
    "Clean Code": [
        [
            "        \"//tensorflow/compiler/xla/client:xla_computation\",",
            "        \"//tensorflow/compiler/xla/service:hlo\",",
            "        \"//tensorflow/core/util:overflow\",",
            "        \"//tensorflow/core:core_cpu\",",
            "        \"//tensorflow/core:core_cpu_internal\",",
            "        \"//tensorflow/core:framework\",",
            "        \"//tensorflow/core:lib\","
        ],
        [
            "#include \"tensorflow/core/common_runtime/dma_helper.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#include \"tensorflow/core/util/overflow.h\"",
            "",
            "namespace tensorflow {",
            "",
            "XlaOpKernelContext::XlaOpKernelContext(OpKernelContext* context)"
        ],
        [
            "  std::vector<int64_t> dims;",
            "  TF_RETURN_IF_ERROR(LiteralToInt64Vector(literal, &dims));",
            "",
            "  int64_t num_elements = 1;",
            "  for (auto i = dims.begin(); i != dims.end(); ++i) {",
            "    num_elements = MultiplyWithoutOverflow(num_elements, *i);",
            "    if (num_elements < 0)",
            "      return errors::InvalidArgument(",
            "          \"The total elements specified by orig_input_shape is too large.\",",
            "          \"Encountered overflow after multiplying\", *i,",
            "          \", result: \", num_elements);",
            "  }",
            "  *shape = TensorShape(dims);",
            "  return OkStatus();",
            "}",
            ""
        ],
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));",
            "    }",
            "",
            "    Tensor* output;",
            "    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));"
        ],
        [
            "    deps = [",
            "        \"//tensorflow/python:client_testlib\",",
            "        \"//tensorflow/python:dtypes\",",
            "        \"//tensorflow/python:framework_for_generated_wrappers\",",
            "        \"//tensorflow/python:nn_grad\",",
            "        \"//tensorflow/python:nn_ops\",",
            "        \"//third_party/py/numpy\","
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wxjj-cgcx-r3vq",
    "API Signature": "tf.raw_ops.AvgPool3DGrad(\n    orig_input_shape,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NDHWC',\n    name=None\n)\n",
    "Score": 0.02158273381294964,
    "Anomaly": "Large input tensor",
    "Anomaly Description": "A large tensor refers to a tensor that has a large number of elements or values or occupies a significant amount of memory.",
    "Category": "Tensor",
    "Argument": "orig_input_shape = tf.constant(1879048192, shape=[5], dtype=tf.int32)"
},
{
    "Title": "\n        `CHECK` failures in `UnbatchGradOp`\n      ",
    "Bug description": "The  UnbatchGradOp  function takes an argument  id  that is assumed to be a scalar. A nonscalar  id  can trigger a  CHECK  failure and crash the program.",
    "Sample Code": "import tensorflow as tf\n\n# batch_index's size is not 3\n\ntf.raw_ops.UnbatchGrad(original_input= tf.constant([1]),batch_index=tf.constant([[0,0], ], dtype=tf.int64),grad=tf.constant([1,]),id=tf.constant([1,], dtype=tf.int64))",
    "Code change": [
        "@@ -885,8 +885,13 @@ class UnbatchGradResource : public ResourceBase {\n     const Tensor& data_t = context->input(0);\n     const Tensor& batch_index_t = context->input(1);\n     const Tensor& grad_t = context->input(2);\n+    const Tensor& batch_key_t = context->input(3);\n \n     mutex_lock ml(mu_);\n+    if (batch_key_t.NumElements() != 1) {\n+      return errors::InvalidArgument(\"Expected `id` to be scalar. Received \",\n+                                     batch_key_t.DebugString());\n+    }\n \n     const int64_t batch_key = context->input(3).scalar<int64_t>()();\n     // Mark our tensor as available.\n@@ -902,6 +907,11 @@ class UnbatchGradResource : public ResourceBase {\n             \"batch_index is empty while the tensor isn't.\");\n       }\n       std::unordered_set<int64_t> missing_tensors;\n+      if (batch_index_t.NumElements() != batch_index_t.dim_size(0) * 3) {\n+        return errors::InvalidArgument(\n+            \"batch_index should contain \", batch_index_t.dim_size(0) * 3,\n+            \" elements. Received \", batch_index_t.NumElements());\n+      }\n       const auto batch_index =\n           batch_index_t.shaped<int64_t, 2>({batch_index_t.dim_size(0), 3});\n       for (int i = 0; i < batch_index_t.dim_size(0); ++i) {\n",
        "@@ -20,7 +20,9 @@ import numpy as np\n \n from tensorflow.core.protobuf import config_pb2\n from tensorflow.python.eager import context\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import function\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n@@ -30,6 +32,7 @@ from tensorflow.python.ops import batch_ops\n from tensorflow.python.ops import gen_batch_ops\n from tensorflow.python.ops import gen_functional_ops\n from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import random_ops\n from tensorflow.python.ops import resource_variable_ops\n from tensorflow.python.ops import script_ops\n from tensorflow.python.ops import variables\n@@ -557,6 +560,56 @@ class BatchOpsTest(test.TestCase):\n       # The thread's call should hit the timeout, and thus get 0 results.\n       self.assertEqual(len(thread_results), 0)\n \n+  def testUnbatchGradInvalidId(self):\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      self.evaluate(\n+          gen_batch_ops.unbatch_grad(\n+              original_input=constant_op.constant([1]),\n+              batch_index=constant_op.constant([\n+                  [0, 0, 0],\n+              ], dtype=dtypes.int64),\n+              grad=constant_op.constant([\n+                  1,\n+              ]),\n+              id=constant_op.constant([\n+                  1,\n+                  1,\n+              ], dtype=dtypes.int64)))\n+\n+  def testUnbatchGradInvalidBatchId(self):\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      self.evaluate(\n+          gen_batch_ops.unbatch_grad(\n+              original_input=constant_op.constant([1]),\n+              batch_index=constant_op.constant([\n+                  [0, 0],\n+              ], dtype=dtypes.int64),\n+              grad=constant_op.constant([\n+                  1,\n+              ]),\n+              id=constant_op.constant([\n+                  1,\n+              ], dtype=dtypes.int64)))\n+\n+  def testUnbatchGradInvalidArgs(self):\n+    original_input = random_ops.random_uniform(\n+        shape=(3, 1), dtype=dtypes.float64, maxval=None)\n+    batch_index = random_ops.random_uniform(\n+        shape=(3, 1), dtype=dtypes.int64, maxval=65536)\n+    grad = random_ops.random_uniform(\n+        shape=(3, 1), dtype=dtypes.float64, maxval=None)\n+    batch_id = random_ops.random_uniform(\n+        shape=(3, 1), dtype=dtypes.int64, maxval=65536)\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      self.evaluate(\n+          gen_batch_ops.unbatch_grad(\n+              original_input=original_input,\n+              batch_index=batch_index,\n+              grad=grad,\n+              id=batch_id,\n+              container=\"\",\n+              shared_name=\"\",\n+              name=\"\"))\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor& batch_index_t = context->input(1);",
            "    const Tensor& grad_t = context->input(2);",
            "",
            "    mutex_lock ml(mu_);",
            "",
            "    const int64_t batch_key = context->input(3).scalar<int64_t>()();",
            "    // Mark our tensor as available.",
            "    if (!available_tensors_.emplace(batch_key, grad_t).second) {",
            "      return errors::InvalidArgument(\"Two runs with the same batch key.\");",
            "    }",
            "",
            "    // Check whether we have a valid input tensor and, if so, create its",
            "    // dispatch logic."
        ],
        [
            "        const int64_t batch_key = batch_index(i, 0);",
            "        if (available_tensors_.find(batch_key) == available_tensors_.end()) {",
            "          missing_tensors.emplace(batch_key);",
            "        }",
            "      }",
            "      if (missing_tensors.empty()) {",
            "        return OutputBatch(context, done);",
            "      }",
            "      if (!available_batches_",
            "               .emplace(batch_key, Batch{missing_tensors, context, done})",
            "               .second) {"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor& batch_index_t = context->input(1);",
            "    const Tensor& grad_t = context->input(2);",
            "    const Tensor& batch_key_t = context->input(3);",
            "",
            "    mutex_lock ml(mu_);",
            "    if (batch_key_t.NumElements() != 1) {",
            "      return errors::InvalidArgument(\"Expected `id` to be scalar. Received \",",
            "                                     batch_key_t.DebugString());",
            "    }",
            "",
            "    const int64_t batch_key = context->input(3).scalar<int64_t>()();",
            "    // Mark our tensor as available.",
            "    if (!available_tensors_.emplace(batch_key, grad_t).second) {"
        ],
        [
            "      }",
            "      std::unordered_set<int64_t> missing_tensors;",
            "      if (batch_index_t.NumElements() != batch_index_t.dim_size(0) * 3) {",
            "        return errors::InvalidArgument(",
            "            \"batch_index should contain \", batch_index_t.dim_size(0) * 3,",
            "            \" elements. Received \", batch_index_t.NumElements());",
            "      }",
            "      const auto batch_index =",
            "          batch_index_t.shaped<int64_t, 2>({batch_index_t.dim_size(0), 3});",
            "      for (int i = 0; i < batch_index_t.dim_size(0); ++i) {",
            "        const int64_t batch_key = batch_index(i, 0);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h5vq-gw2c-pq47",
    "API Signature": "tf.raw_ops.UnbatchGrad(\n    original_input,\n    batch_index,\n    grad,\n    id,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "id=tf.constant([1,], dtype=tf.int64)"
},
{
    "Title": "\n        `CHECK` failure in `AvgPoolOp`\n      ",
    "Bug description": "The  AvgPoolOp  function takes an argument  ksize  that must be positive but is not checked. A negative  ksize  can trigger a  CHECK  failure and crash the program.",
    "Sample Code": "import numpy as np\n\nvalue = np.ones([1, 1, 1, 1])\nksize = [1, 1e20, 1, 1]\nstrides = [1, 1, 1, 1]\npadding = 'SAME'\ndata_format = 'NHWC'\n\n\n\ntf.raw_ops.AvgPool(value=value, ksize=ksize, strides=strides, padding=padding, data_format=data_format)",
    "Code change": [
        "@@ -298,7 +298,7 @@ class AvgPoolingGradOp : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n     const int64_t in_rows = output_shape.dim_size(1);\n     const int64_t in_cols = output_shape.dim_size(2);\n@@ -457,7 +457,7 @@ class AvgPoolingGradOp<GPUDevice, T> : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n \n     if (output_shape.num_elements() == 0) {\n@@ -543,7 +543,7 @@ class AvgPoolingGradOpCustomGPUKernel : public OpKernel {\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n     if (output_shape.num_elements() == 0) {\n       Tensor* output = nullptr;\n",
        "@@ -2470,6 +2470,22 @@ class PoolingTest(test.TestCase, parameterized.TestCase):\n               inp, grad, argmax, ksize=[1, 1, 1, 1], strides=[1, 1, 1, 1],\n               padding=\"VALID\")\n \n+  def testAvgPoolGradInvalidInputShapeRaiseError(self):\n+    with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n+      with self.cached_session():\n+        orig_input_shape = constant_op.constant(\n+            -536870912, shape=[4], dtype=dtypes.int32)\n+        grad = constant_op.constant(\n+            .0890338004362538, shape=[1, 5, 7, 1], dtype=dtypes.float64)\n+        t = gen_nn_ops.AvgPoolGrad(\n+            orig_input_shape=orig_input_shape,\n+            grad=grad,\n+            ksize=[1, 2, 2, 1],\n+            strides=[1, 2, 2, 1],\n+            padding=\"VALID\",\n+            data_format=\"NHWC\")\n+        self.evaluate(t)\n+\n \n def GetMaxPoolFwdTest(input_size, filter_size, strides, padding):\n \n"
    ],
    "Buggy Code": [
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      output_shape.AddDim(shape_vec(i));",
            "    }",
            "    const int64_t in_rows = output_shape.dim_size(1);",
            "    const int64_t in_cols = output_shape.dim_size(2);",
            ""
        ],
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      output_shape.AddDim(shape_vec(i));",
            "    }",
            "",
            "    if (output_shape.num_elements() == 0) {",
            "      Tensor* output = nullptr;"
        ],
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      output_shape.AddDim(shape_vec(i));",
            "    }",
            "    if (output_shape.num_elements() == 0) {",
            "      Tensor* output = nullptr;",
            "      OP_REQUIRES_OK(context,"
        ]
    ],
    "Clean Code": [
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));",
            "    }",
            "    const int64_t in_rows = output_shape.dim_size(1);",
            "    const int64_t in_cols = output_shape.dim_size(2);",
            ""
        ],
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));",
            "    }",
            "",
            "    if (output_shape.num_elements() == 0) {",
            "      Tensor* output = nullptr;"
        ],
        [
            "    auto shape_vec = tensor_in_shape.vec<int32>();",
            "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
            "      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));",
            "    }",
            "    if (output_shape.num_elements() == 0) {",
            "      Tensor* output = nullptr;",
            "      OP_REQUIRES_OK(context,"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mgmh-g2v6-mqw5",
    "API Signature": "tf.raw_ops.AvgPool(\n    value, ksize, strides, padding, data_format='NHWC', name=None\n)\n",
    "Score": 0.02877697841726619,
    "Anomaly": "Negative integer list element",
    "Anomaly Description": "A negative integer list element in Python refers to an element within a list that has a negative integer value. It means that the element is a negative number represented by an integer data type.",
    "Category": "List",
    "Argument": "ksize = [1, 1e20, 1, 1]"
},
{
    "Title": "\n        Int overflow in `RaggedRangeOp`\n      ",
    "Bug description": "The  RaggedRangOp  function takes an argument  limits  that is eventually used to construct a  TensorShape  as an  int64 . If  limits  is a very large float, it can overflow when converted to an  int64 . This triggers an  InvalidArgument  but also throws an abort signal that crashes the program.",
    "Sample Code": " tensorflow as tf\ntf.raw_ops.RaggedRange(starts=[1.1,0.1],limits=[10.0,1e20],deltas=[1,1])",
    "Code change": [
        "@@ -12,6 +12,7 @@ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n+#include <cstdint>\n #include <limits>\n #include <memory>\n #include <string>\n@@ -78,8 +79,25 @@ class RaggedRangeOp : public OpKernel {\n       T limit = broadcast_limits ? limits(0) : limits(row);\n       T delta = broadcast_deltas ? deltas(0) : deltas(row);\n       OP_REQUIRES(context, delta != 0, InvalidArgument(\"Requires delta != 0\"));\n-      rt_nested_splits(row + 1) =\n-          rt_nested_splits(row) + RangeSize(start, limit, delta);\n+      int64_t size;  // The number of elements in the specified range.\n+      if (((delta > 0) && (limit < start)) ||\n+          ((delta < 0) && (limit > start))) {\n+        size = 0;\n+      } else if (std::is_integral<T>::value) {\n+        // The following is copied from tensorflow::RangeOp::Compute().\n+        size = Eigen::divup(Eigen::numext::abs(limit - start),\n+                            Eigen::numext::abs(delta));\n+      } else {\n+        // The following is copied from tensorflow::RangeOp::Compute().\n+        auto size_auto =\n+            Eigen::numext::ceil(Eigen::numext::abs((limit - start) / delta));\n+        OP_REQUIRES(\n+            context, size_auto <= std::numeric_limits<int64_t>::max(),\n+            errors::InvalidArgument(\"Requires ((limit - start) / delta) <= \",\n+                                    std::numeric_limits<int64_t>::max()));\n+        size = static_cast<int64_t>(size_auto);\n+      }\n+      rt_nested_splits(row + 1) = rt_nested_splits(row) + size;\n     }\n     SPLITS_TYPE nvals = rt_nested_splits(nrows);\n \n@@ -99,19 +117,6 @@ class RaggedRangeOp : public OpKernel {\n       }\n     }\n   }\n-\n- private:\n-  // Returns the number of elements in the specified range.\n-  SPLITS_TYPE RangeSize(T start, T limit, T delta) {\n-    if (((delta > 0) && (limit < start)) || ((delta < 0) && (limit > start))) {\n-      return 0;\n-    }\n-    // The following is copied from tensorflow::RangeOp::Compute().\n-    return (std::is_integral<T>::value\n-                ? ((std::abs(limit - start) + std::abs(delta) - 1) /\n-                   std::abs(delta))\n-                : std::ceil(std::abs((limit - start) / delta)));\n-  }\n };\n \n #define REGISTER_CPU_KERNEL(TYPE)                                  \\\n",
        "@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include <gtest/gtest.h>\n #include \"tensorflow/core/framework/fake_input.h\"\n #include \"tensorflow/core/framework/node_def_builder.h\"\n #include \"tensorflow/core/framework/shape_inference.h\"\n@@ -77,6 +78,17 @@ TEST_F(RaggedRangeOpTest, FloatValues) {\n       test::AsTensor<float>({0, 2, 4, 6, 5, 6, 5, 4, 3, 2}), 0.1);\n }\n \n+TEST_F(RaggedRangeOpTest, RangeSizeOverflow) {\n+  BuildRaggedRangeGraph<float>();\n+  AddInputFromArray<float>(TensorShape({2}), {1.1, 0.1});    // starts\n+  AddInputFromArray<float>(TensorShape({2}), {10.0, 1e10});  // limits\n+  AddInputFromArray<float>(TensorShape({2}), {1, 1e-10});    // deltas\n+\n+  EXPECT_EQ(absl::StrCat(\"Requires ((limit - start) / delta) <= \",\n+                         std::numeric_limits<int64_t>::max()),\n+            RunOpKernel().error_message());\n+}\n+\n TEST_F(RaggedRangeOpTest, BroadcastDeltas) {\n   BuildRaggedRangeGraph<int>();\n   AddInputFromArray<int>(TensorShape({3}), {0, 5, 8});  // starts\n",
        "@@ -84,8 +84,7 @@ class RaggedRangeOpTest(test_util.TensorFlowTestCase):\n          list(range(5, 15, 3))])\n \n     # Broadcast all arguments.\n-    self.assertAllEqual(\n-        ragged_math_ops.range(0, 5, 1), [list(range(0, 5, 1))])\n+    self.assertAllEqual(ragged_math_ops.range(0, 5, 1), [list(range(0, 5, 1))])\n \n   def testEmptyRanges(self):\n     rt1 = ragged_math_ops.range([0, 5, 3], [0, 3, 5])\n@@ -108,6 +107,10 @@ class RaggedRangeOpTest(test_util.TensorFlowTestCase):\n                                 r'Requires delta != 0'):\n       self.evaluate(ragged_math_ops.range(0, 0, 0))\n \n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                r'Requires \\(\\(limit - start\\) / delta\\) <='):\n+      self.evaluate(ragged_math_ops.range(0.1, 1e10, 1e-10))\n+\n   def testShape(self):\n     self.assertAllEqual(\n         ragged_math_ops.range(0, 0, 1).shape.as_list(), [1, None])\n"
    ],
    "Buggy Code": [
        [
            "limitations under the License.",
            "==============================================================================*/",
            "#include <limits>",
            "#include <memory>",
            "#include <string>",
            "#include <vector>",
            ""
        ],
        [
            "      OP_REQUIRES(context, delta != 0, InvalidArgument(\"Requires delta != 0\"));",
            "      rt_nested_splits(row + 1) =",
            "          rt_nested_splits(row) + RangeSize(start, limit, delta);",
            "    }",
            "    SPLITS_TYPE nvals = rt_nested_splits(nrows);",
            "",
            "    // Construct the rt_dense_values tensor.",
            "    Tensor* rt_dense_values_out = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(1, TensorShape({nvals}),",
            "                                                     &rt_dense_values_out));",
            "    auto rt_dense_values = rt_dense_values_out->flat<T>();",
            "    int value_index = 0;",
            "    for (int row = 0; row < nrows; ++row) {",
            "      SPLITS_TYPE row_size = rt_nested_splits(row + 1) - rt_nested_splits(row);",
            "      T value = broadcast_starts ? starts(0) : starts(row);",
            "      T delta = broadcast_deltas ? deltas(0) : deltas(row);",
            "      for (SPLITS_TYPE i = 0; i < row_size; ++i) {",
            "        rt_dense_values(value_index++) = T(value);",
            "        value += delta;",
            "      }",
            "    }",
            "  }",
            "",
            " private:",
            "  // Returns the number of elements in the specified range."
        ],
        [
            "  REGISTER_KERNEL_BUILDER(Name(\"RaggedRange\")                      \\",
            "                              .Device(DEVICE_CPU)                  \\",
            "                              .TypeConstraint<TYPE>(\"T\")           \\",
            "                              .TypeConstraint<int32>(\"Tsplits\"),   \\",
            "                          RaggedRangeOp<TYPE, int32>);             \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"RaggedRange\")                      \\"
        ]
    ],
    "Clean Code": [
        [
            "limitations under the License.",
            "==============================================================================*/",
            "#include <cstdint>",
            "#include <limits>",
            "#include <memory>",
            "#include <string>",
            "#include <vector>"
        ],
        [
            "      T delta = broadcast_deltas ? deltas(0) : deltas(row);",
            "      OP_REQUIRES(context, delta != 0, InvalidArgument(\"Requires delta != 0\"));",
            "      int64_t size;  // The number of elements in the specified range.",
            "      if (((delta > 0) && (limit < start)) ||",
            "          ((delta < 0) && (limit > start))) {",
            "        size = 0;",
            "      } else if (std::is_integral<T>::value) {",
            "        // The following is copied from tensorflow::RangeOp::Compute().",
            "        size = Eigen::divup(Eigen::numext::abs(limit - start),",
            "                            Eigen::numext::abs(delta));",
            "      } else {",
            "        // The following is copied from tensorflow::RangeOp::Compute().",
            "        auto size_auto =",
            "            Eigen::numext::ceil(Eigen::numext::abs((limit - start) / delta));",
            "        OP_REQUIRES(",
            "            context, size_auto <= std::numeric_limits<int64_t>::max(),",
            "            errors::InvalidArgument(\"Requires ((limit - start) / delta) <= \",",
            "                                    std::numeric_limits<int64_t>::max()));",
            "        size = static_cast<int64_t>(size_auto);",
            "      }",
            "      rt_nested_splits(row + 1) = rt_nested_splits(row) + size;",
            "    }",
            "    SPLITS_TYPE nvals = rt_nested_splits(nrows);",
            "",
            "    // Construct the rt_dense_values tensor."
        ],
        [
            "    }",
            "  }",
            "};",
            "",
            "#define REGISTER_CPU_KERNEL(TYPE)                                  \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"RaggedRange\")                      \\"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x989-q2pq-4q5x",
    "API Signature": "tf.raw_ops.RaggedRange(\n    starts,\n    limits,\n    deltas,\n    Tsplits=tf.dtypes.int64,\n    name=None\n)\n",
    "Score": 0.03597122302158273,
    "Anomaly": "Large integer list element",
    "Anomaly Description": "A large integer list element in Python refers to an element within a list that has a large integer value. It means that the element is an integer with a value that exceeds the typical range of integer values.",
    "Category": "List",
    "Argument": "limits=[10.0,1e20]"
},
{
    "Title": "\n        `CHECK` failure in `TensorListReserve` via missing validation\n      ",
    "Bug description": "In  core/kernels/list_kernels.cc's TensorListReserve ,  num_elements  is assumed to be a tensor of size 1. When a  num_elements  of more than 1 element is provided, then  tf.raw_ops.TensorListReserve  fails the  CHECK_EQ  in  CheckIsAlignedAndSingleElement .",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.TensorListReserve(element_shape=(1,1), num_elements=tf.constant([1,1], dtype=tf.int32), element_dtype=tf.int8)",
    "Code change": [
        "@@ -31,9 +31,11 @@ limitations under the License.\n #include \"tensorflow/core/framework/allocator.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/tensor_types.h\"\n #include \"tensorflow/core/framework/variant.h\"\n #include \"tensorflow/core/framework/variant_op_registry.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -322,6 +324,11 @@ class TensorListReserve : public OpKernel {\n   void Compute(OpKernelContext* c) override {\n     PartialTensorShape element_shape;\n     OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(0), &element_shape));\n+    OP_REQUIRES(\n+        c, TensorShapeUtils::IsScalar(c->input(1).shape()),\n+        errors::InvalidArgument(\n+            \"The num_elements to reserve must be a tensor size 1, but got \",\n+            c->input(1).shape()));\n     int32_t num_elements = c->input(1).scalar<int32>()();\n     OP_REQUIRES(c, num_elements >= 0,\n                 errors::InvalidArgument(\"The num_elements to reserve must be a \"\n",
        "@@ -94,6 +94,16 @@ class ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n       l = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n       self.evaluate(l)\n \n+  def testTensorListReserveWithNonScalarNumElements(self):\n+    # list_kernels.cc in tf/core/kernels raises InvalidArgumentError, and\n+    # tf_ops_n_z.cc in tf/compiler/mlir/tf/ir raises UnknownError.\n+    with self.assertRaises((errors.InvalidArgumentError, errors.UnknownError)):\n+      l = list_ops.tensor_list_reserve(\n+          element_dtype=dtypes.float32,\n+          element_shape=[2, 3],\n+          num_elements=constant_op.constant([1, 1]))\n+      self.evaluate(l)\n+\n   def testPopUninitializedTensorUseListElementShape(self):\n     l = list_ops.tensor_list_reserve(\n         element_dtype=dtypes.float32, element_shape=[2, 3], num_elements=3)\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor_types.h\"",
            "#include \"tensorflow/core/framework/variant.h\"",
            "#include \"tensorflow/core/framework/variant_op_registry.h\"",
            "",
            "namespace tensorflow {",
            "",
            "typedef Eigen::ThreadPoolDevice CPUDevice;",
            "",
            "Status TensorShapeFromTensor(const Tensor& t, PartialTensorShape* out) {"
        ],
        [
            "    int32_t num_elements = c->input(1).scalar<int32>()();",
            "    OP_REQUIRES(c, num_elements >= 0,",
            "                errors::InvalidArgument(\"The num_elements to reserve must be a \"",
            "                                        \"non negative number, but got \",",
            "                                        num_elements));",
            "    TensorList output;",
            "    output.element_shape = element_shape;",
            "    output.element_dtype = element_dtype_;",
            "    output.tensors().resize(num_elements, Tensor(DT_INVALID));",
            "    Tensor* result;",
            "    AllocatorAttributes attr;"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/framework/tensor_types.h\"",
            "#include \"tensorflow/core/framework/variant.h\"",
            "#include \"tensorflow/core/framework/variant_op_registry.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "namespace tensorflow {",
            "",
            "typedef Eigen::ThreadPoolDevice CPUDevice;"
        ],
        [
            "    PartialTensorShape element_shape;",
            "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(0), &element_shape));",
            "    OP_REQUIRES(",
            "        c, TensorShapeUtils::IsScalar(c->input(1).shape()),",
            "        errors::InvalidArgument(",
            "            \"The num_elements to reserve must be a tensor size 1, but got \",",
            "            c->input(1).shape()));",
            "    int32_t num_elements = c->input(1).scalar<int32>()();",
            "    OP_REQUIRES(c, num_elements >= 0,",
            "                errors::InvalidArgument(\"The num_elements to reserve must be a \"",
            "                                        \"non negative number, but got \","
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v5xg-3q2c-c2r4",
    "API Signature": "tf.raw_ops.TensorListReserve(\n    element_shape, num_elements, element_dtype, name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "num_elements=tf.constant([1,1], dtype=tf.int32)"
},
{
    "Title": "\n        `CHECK` failure in `SobolSample` via missing validation\n      ",
    "Bug description": "The implementation of SobolSampleOp is vulnerable to a denial of service via CHECK-failure (assertion failure) caused by assuming  input(0) ,  input(1) , and  input(2)  to be scalar.",
    "Sample Code": " tensorflow as tf\ntf.raw_ops.SobolSample(dim=tf.constant([1,0]), num_results=tf.constant([1]), skip=tf.constant([1]))",
    "Code change": [
        "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"sobol_data.h\"  // from @sobol_data\n #include \"tensorflow/core/framework/device_base.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/lib/core/threadpool.h\"\n #include \"tensorflow/core/platform/platform_strings.h\"\n \n@@ -134,8 +135,14 @@ class SobolSampleOp : public OpKernel {\n       : OpKernel(context) {}\n \n   void Compute(OpKernelContext* context) override {\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n+                errors::InvalidArgument(\"dim must be a scalar\"));\n     int32_t dim = context->input(0).scalar<int32_t>()();\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n+                errors::InvalidArgument(\"num_results must be a scalar\"));\n     int32_t num_results = context->input(1).scalar<int32_t>()();\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n+                errors::InvalidArgument(\"skip must be a scalar\"));\n     int32_t skip = context->input(2).scalar<int32_t>()();\n \n     OP_REQUIRES(context, dim >= 1,\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/device_base.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/lib/core/threadpool.h\"",
            "#include \"tensorflow/core/platform/platform_strings.h\"",
            "",
            "namespace tensorflow {",
            ""
        ],
        [
            "  void Compute(OpKernelContext* context) override {",
            "    int32_t dim = context->input(0).scalar<int32_t>()();",
            "    int32_t num_results = context->input(1).scalar<int32_t>()();",
            "    int32_t skip = context->input(2).scalar<int32_t>()();",
            "",
            "    OP_REQUIRES(context, dim >= 1,",
            "                errors::InvalidArgument(\"dim must be at least one\"));",
            "    OP_REQUIRES(context, dim <= sobol_data::kMaxSobolDim,",
            "                errors::InvalidArgument(\"dim must be at most \",",
            "                                        sobol_data::kMaxSobolDim));",
            "    OP_REQUIRES(context, num_results >= 1,",
            "                errors::InvalidArgument(\"num_results must be at least one\"));",
            "    OP_REQUIRES(context, skip >= 0,",
            "                errors::InvalidArgument(\"skip must be non-negative\"));"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/device_base.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/lib/core/threadpool.h\"",
            "#include \"tensorflow/core/platform/platform_strings.h\"",
            "",
            "namespace tensorflow {"
        ],
        [
            "",
            "  void Compute(OpKernelContext* context) override {",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),",
            "                errors::InvalidArgument(\"dim must be a scalar\"));",
            "    int32_t dim = context->input(0).scalar<int32_t>()();",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),",
            "                errors::InvalidArgument(\"num_results must be a scalar\"));",
            "    int32_t num_results = context->input(1).scalar<int32_t>()();",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),",
            "                errors::InvalidArgument(\"skip must be a scalar\"));",
            "    int32_t skip = context->input(2).scalar<int32_t>()();",
            "",
            "    OP_REQUIRES(context, dim >= 1,",
            "                errors::InvalidArgument(\"dim must be at least one\"));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-97p7-w86h-vcf9",
    "API Signature": "tf.raw_ops.SobolSample(\n    dim,\n    num_results,\n    skip,\n    dtype=tf.dtypes.float32,\n    name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "dim=tf.constant([1,0]), num_results=tf.constant([1]), skip=tf.constant([1])"
},
{
    "Title": "\n        `CHECK` failure in tf.reshape via overflows\n      ",
    "Bug description": "The implementation of tf.reshape op in TensorFlow is vulnerable to a denial of service via CHECK-failure (assertion failure) caused by overflowing the number of elements in a tensor:",
    "Sample Code": " tensorflow as tf\n\ntf.reshape(tensor=[[1]],shape=tf.constant([0 for i in range(255)], dtype=tf.int64))",
    "Code change": [
        "@@ -45,6 +45,11 @@ class ReshapeOp : public OpKernel {\n          TensorShapeUtils::IsScalar(sizes.shape())),\n         errors::InvalidArgument(\"sizes input must be 1-D, not \",\n                                 sizes.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, sizes.NumElements() < TensorShape::MaxDimensions(),\n+        errors::InvalidArgument(\"too many dimensions: must be < \",\n+                                TensorShape::MaxDimensions(), \", but received \",\n+                                sizes.NumElements()));\n \n     // Compute the output shape.  Determine product of specified\n     // dimensions, and find the index of the unspecified one.\n",
        "@@ -351,6 +351,15 @@ class OperatorShapeTest(test_util.TensorFlowTestCase):\n                                 \"must be a tensor with a single value\"):\n       array_ops.expand_dims(1, axis=[0, 1])\n \n+  def testReshapeWithManyDims(self):\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                \"too many dimensions\"):\n+      self.evaluate(\n+          array_ops.reshape(\n+              tensor=[[1]],\n+              shape=constant_op.constant([1 for i in range(254)],\n+                                         dtype=dtypes.int64)))\n+\n \n @test_util.with_eager_op_as_function\n class ReverseV2Test(test_util.TensorFlowTestCase):\n"
    ],
    "Buggy Code": [
        [
            "        errors::InvalidArgument(\"sizes input must be 1-D, not \",",
            "                                sizes.shape().DebugString()));",
            "",
            "    // Compute the output shape.  Determine product of specified",
            "    // dimensions, and find the index of the unspecified one.",
            "    TensorShape shape;",
            "    int64_t product = 1;",
            "    int unknown_index = -1;",
            "    bool sizes_has_zero_dim;",
            "    switch (sizes.dtype()) {",
            "      case DT_INT32:"
        ]
    ],
    "Clean Code": [
        [
            "        errors::InvalidArgument(\"sizes input must be 1-D, not \",",
            "                                sizes.shape().DebugString()));",
            "    OP_REQUIRES(",
            "        context, sizes.NumElements() < TensorShape::MaxDimensions(),",
            "        errors::InvalidArgument(\"too many dimensions: must be < \",",
            "                                TensorShape::MaxDimensions(), \", but received \",",
            "                                sizes.NumElements()));",
            "",
            "    // Compute the output shape.  Determine product of specified",
            "    // dimensions, and find the index of the unspecified one.",
            "    TensorShape shape;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-f4w6-h4f5-wx45",
    "API Signature": "tf.reshape(\n    tensor, shape, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "shape=tf.constant([0 for i in range(255)]"
},
{
    "Title": "\n        Segfault if `tf.histogram_fixed_width` is called with NaN values\n      ",
    "Bug description": "The implementation of  tf.histogram_fixed_width  is vulnerable to a crash when the values array contain  NaN  elements:",
    "Sample Code": "import numpy as np\n\n\n\ntf.histogram_fixed_width(values=np.nan, value_range=[1,2])",
    "Code change": [
        "@@ -50,6 +50,15 @@ struct HistogramFixedWidthFunctor<CPUDevice, T, Tout> {\n                         static_cast<double>(nbins);\n     const double nbins_minus_1 = static_cast<double>(nbins - 1);\n \n+    // We cannot handle NANs in the algorithm below (due to the case to int32)\n+    const Eigen::Tensor<int32, 1, 1> nans_tensor =\n+        values.isnan().template cast<int32>();\n+    const Eigen::Tensor<int32, 0, 1> reduced_tensor = nans_tensor.sum();\n+    const int num_nans = reduced_tensor(0);\n+    if (num_nans > 0) {\n+      return errors::InvalidArgument(\"Histogram values must not contain NaN\");\n+    }\n+\n     // The calculation is done by finding the slot of each value in `values`.\n     // With [a, b]:\n     //   step = (b - a) / nbins\n@@ -98,12 +107,12 @@ class HistogramFixedWidthOp : public OpKernel {\n     const auto nbins = nbins_tensor.scalar<int32>()();\n \n     OP_REQUIRES(\n-        ctx, (value_range(0) < value_range(1)),\n+        ctx, value_range(0) < value_range(1),\n         errors::InvalidArgument(\"value_range should satisfy value_range[0] < \"\n                                 \"value_range[1], but got '[\",\n                                 value_range(0), \", \", value_range(1), \"]'\"));\n     OP_REQUIRES(\n-        ctx, (nbins > 0),\n+        ctx, nbins > 0,\n         errors::InvalidArgument(\"nbins should be a positive number, but got '\",\n                                 nbins, \"'\"));\n \n"
    ],
    "Buggy Code": [
        [
            "    const double nbins_minus_1 = static_cast<double>(nbins - 1);",
            "",
            "    // The calculation is done by finding the slot of each value in `values`.",
            "    // With [a, b]:",
            "    //   step = (b - a) / nbins",
            "    //   (x - a) / step",
            "    // , then the entries are mapped to output.",
            "",
            "    // Bug fix: Switch the order of cwiseMin and int32-casting to avoid",
            "    // producing a negative index when casting an big int64 number to int32",
            "    index_to_bin.device(d) =",
            "        ((values.cwiseMax(value_range(0)) - values.constant(value_range(0)))",
            "             .template cast<double>() /",
            "         step)",
            "            .cwiseMin(nbins_minus_1)"
        ],
        [
            "                                nbins, \"'\"));",
            "",
            "    Tensor* out_tensor;",
            "    OP_REQUIRES_OK(ctx,",
            "                   ctx->allocate_output(0, TensorShape({nbins}), &out_tensor));",
            "    auto out = out_tensor->flat<Tout>();",
            "",
            "    OP_REQUIRES_OK(",
            "        ctx, functor::HistogramFixedWidthFunctor<Device, T, Tout>::Compute(",
            "                 ctx, values, value_range, nbins, out));",
            "  }",
            "};"
        ]
    ],
    "Clean Code": [
        [
            "    const double nbins_minus_1 = static_cast<double>(nbins - 1);",
            "",
            "    // We cannot handle NANs in the algorithm below (due to the case to int32)",
            "    const Eigen::Tensor<int32, 1, 1> nans_tensor =",
            "        values.isnan().template cast<int32>();",
            "    const Eigen::Tensor<int32, 0, 1> reduced_tensor = nans_tensor.sum();",
            "    const int num_nans = reduced_tensor(0);",
            "    if (num_nans > 0) {",
            "      return errors::InvalidArgument(\"Histogram values must not contain NaN\");",
            "    }",
            "",
            "    // The calculation is done by finding the slot of each value in `values`.",
            "    // With [a, b]:",
            "    //   step = (b - a) / nbins",
            "    //   (x - a) / step"
        ],
        [
            "",
            "    OP_REQUIRES(",
            "        ctx, value_range(0) < value_range(1),",
            "        errors::InvalidArgument(\"value_range should satisfy value_range[0] < \"",
            "                                \"value_range[1], but got '[\",",
            "                                value_range(0), \", \", value_range(1), \"]'\"));",
            "    OP_REQUIRES(",
            "        ctx, nbins > 0,",
            "        errors::InvalidArgument(\"nbins should be a positive number, but got '\",",
            "                                nbins, \"'\"));",
            "",
            "    Tensor* out_tensor;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xrp2-fhq4-4q3w",
    "API Signature": "tf.histogram_fixed_width(\n    values,\n    value_range,\n    nbins=100,\n    dtype=tf.dtypes.int32,\n    name=None\n)\n",
    "Score": 0.0035971223021582736,
    "Anomaly": "NaN input tensor",
    "Anomaly Description": "NaN stands for \"Not a Number\" and is a special value used to represent undefined or unrepresentable results in numerical computations. In the context of an input tensor, a NaN input tensor refers to a tensor that contains one or more NaN values. Also, when arguments of type tensor are assign with NaN values.",
    "Category": "Tensor",
    "Argument": "values=np.nan"
},
{
    "Title": "\n        Denial of service in `tf.ragged.constant` due to lack of validation\n      ",
    "Bug description": "The implementation of  tf.ragged.constant  does not fully validate the input arguments. This results in a denial of service by consuming all available memory:",
    "Sample Code": " tensorflow as tf\ntf.ragged.constant(pylist=[],ragged_rank=8968073515812833920)",
    "Code change": [
        "@@ -188,6 +188,9 @@ def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,\n     if max_depth > scalar_depth:\n       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"\n                        \"than scalar value nesting\" % pylist)\n+    if ragged_rank is not None and max_depth < ragged_rank:\n+      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"\n+                       f\"ragged_rank={ragged_rank}\")\n \n   # If both inner_shape and ragged_rank were specified, then check that\n   # they are compatible with pylist.\n"
    ],
    "Buggy Code": [
        [
            "      raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"",
            "                       \"than scalar value nesting\" % pylist)",
            "",
            "  # If both inner_shape and ragged_rank were specified, then check that",
            "  # they are compatible with pylist.",
            "  if inner_shape is not None and ragged_rank is not None:",
            "    expected_depth = ragged_rank + len(inner_shape) + 1",
            "    if ((scalar_depth is not None and expected_depth != scalar_depth) or",
            "        (scalar_depth is None and expected_depth < max_depth)):"
        ]
    ],
    "Clean Code": [
        [
            "      raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"",
            "                       \"than scalar value nesting\" % pylist)",
            "    if ragged_rank is not None and max_depth < ragged_rank:",
            "      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"",
            "                       f\"ragged_rank={ragged_rank}\")",
            "",
            "  # If both inner_shape and ragged_rank were specified, then check that",
            "  # they are compatible with pylist.",
            "  if inner_shape is not None and ragged_rank is not None:"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cwpm-f78v-7m5c",
    "API Signature": "tf.ragged.constant([[0], [1, 2]]).shape",
    "Score": 0.025179856115107913,
    "Anomaly": "Large integer argument",
    "Anomaly Description": "A large integer argument refers to an argument passed to a function or operation that represents a large integer value. It means that the argument is an integer value that exceeds the typical range of integer values supported by the underlying programming language or system.\n\nThe specific definition of a \"large\" integer may vary depending on the context and the limitations of the programming language or system being used. For example, in Python, integers have arbitrary precision, allowing you to work with integers of any size. However, other programming languages may have predefined limits on the range of integer values they can handle.\n\nIn the context of function arguments, a large integer argument can be used to represent various concepts or quantities. It may be used to specify an index, a count, a value, or any other numerical parameter required by the function or operation.",
    "Category": "Integer",
    "Argument": "ragged_rank=8968073515812833920"
},
{
    "Title": "\n        Missing validation causes denial of service via `Conv3DBackpropFilterV2`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.UnsortedSegmentJoin  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.strings.unsorted_segment_join(\n  inputs=['123'],\n  segment_ids=[0],\n  ],\n  num_segments=-1)",
    "Code change": [
        "@@ -94,6 +94,8 @@ class UnsortedSegmentJoinOp : public OpKernel {\n                 errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n+    OP_REQUIRES(context, num_segments > 0,\n+                errors::InvalidArgument(\"Number of segments must be positive\"));\n     OP_REQUIRES(context, segment_dims != 0,\n                 errors::InvalidArgument(\"Segment_id cannot have rank 0\"));\n \n"
    ],
    "Buggy Code": [
        [
            "    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();",
            "",
            "    OP_REQUIRES(context, segment_dims != 0,",
            "                errors::InvalidArgument(\"Segment_id cannot have rank 0\"));",
            "",
            "    OP_REQUIRES(",
            "        context, segment_dims <= input_dims,",
            "        errors::OutOfRange(\"Invalid segment_id rank \", segment_dims,"
        ]
    ],
    "Clean Code": [
        [
            "    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();",
            "",
            "    OP_REQUIRES(context, num_segments > 0,",
            "                errors::InvalidArgument(\"Number of segments must be positive\"));",
            "    OP_REQUIRES(context, segment_dims != 0,",
            "                errors::InvalidArgument(\"Segment_id cannot have rank 0\"));",
            "",
            "    OP_REQUIRES("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hx9q-2mx4-m4pg",
    "API Signature": "tf.strings.unsorted_segment_join(\n    inputs, segment_ids, num_segments, separator='', name=None\n)\n",
    "Score": 0.039568345323741004,
    "Anomaly": "Negative integer argument",
    "Anomaly Description": "A negative integer argument in Python refers to an integer value that is less than zero. It is a numeric value that represents a negative quantity or position in a numerical sequence. In Python, negative integers are denoted by placing a minus sign (-) before the numerical value. For example, -1, -2, -3, and so on.",
    "Category": "Integer",
    "Argument": "num_segments=-1"
},
{
    "Title": "\n        Segfault and OOB write due to incomplete validation in `EditDistance`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.EditDistance  has incomplete validation. Users can pass negative values to cause a segmentation fault based denial of service:",
    "Sample Code": "hypothesis_indices = tf.constant(-1250999896764, shape=[3, 3], dtype=tf.int64) \nhypothesis_values = tf.constant(0, shape=[3], dtype=tf.int64)\nhypothesis_shape = tf.constant(0, shape=[3], dtype=tf.int64)\n\ntruth_indices = tf.constant(-1250999896764, shape=[3, 3], dtype=tf.int64)\ntruth_values = tf.constant(2, shape=[3], dtype=tf.int64)\ntruth_shape = tf.constant(2, shape=[3], dtype=tf.int64) \n\ntf.raw_ops.EditDistance(\n  hypothesis_indices=hypothesis_indices,\n  hypothesis_values=hypothesis_values,\n  hypothesis_shape=hypothesis_shape,\n  truth_indices=truth_indices,\n  truth_values=truth_values,\n  ,\n  truth_shape=truth_shape)",
    "Code change": [
        "@@ -203,9 +203,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) =\n@@ -218,9 +218,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) = hypothesis_seq.size();\n@@ -232,9 +232,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n@@ -248,9 +248,9 @@ class EditDistanceOp : public OpKernel {\n       auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                     output_strides.begin(), int64_t{0});\n       OP_REQUIRES(\n-          ctx, loc < output_elements,\n+          ctx, 0 <= loc && loc < output_elements,\n           errors::Internal(\"Got an inner product \", loc,\n-                           \" which would require in writing to outside of the \"\n+                           \" which would require writing to outside of the \"\n                            \"buffer for the output tensor (max elements \",\n                            output_elements, \")\"));\n       output_t(loc) = hypothesis_seq.size();\n@@ -266,9 +266,9 @@ class EditDistanceOp : public OpKernel {\n       auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                     output_strides.begin(), int64_t{0});\n       OP_REQUIRES(\n-          ctx, loc < output_elements,\n+          ctx, 0 <= loc && loc < output_elements,\n           errors::Internal(\"Got an inner product \", loc,\n-                           \" which would require in writing to outside of the \"\n+                           \" which would require writing to outside of the \"\n                            \"buffer for the output tensor (max elements \",\n                            output_elements, \")\"));\n       output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n",
        "@@ -207,6 +207,24 @@ class EditDistanceTest(test.TestCase):\n         normalize=True,\n         expected_output=expected_output)\n \n+  def testEditDistanceBadIndices(self):\n+    hypothesis_indices = np.full((3, 3), -1250999896764, dtype=np.int64)\n+    hypothesis_values = np.empty(3, dtype=np.int64)\n+    hypothesis_shape = np.empty(3, dtype=np.int64)\n+    truth_indices = np.full((3, 3), -1250999896764, dtype=np.int64)\n+    truth_values = np.full([3], 2, dtype=np.int64)\n+    truth_shape = np.full([3], 2, dtype=np.int64)\n+    expected_output = []  # dummy; ignored\n+\n+    self._testEditDistance(\n+        hypothesis=(hypothesis_indices, hypothesis_values, hypothesis_shape),\n+        truth=(truth_indices, truth_values, truth_shape),\n+        normalize=False,\n+        expected_output=expected_output,\n+        expected_err_re=(r\"inner product -\\d+ which would require writing \"\n+                         \"to outside of the buffer for the output tensor\")\n+    )\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "                                      output_strides.begin(), int64_t{0});",
            "        OP_REQUIRES(",
            "            ctx, loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require in writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) =",
            "            gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);"
        ],
        [
            "                                      output_strides.begin(), int64_t{0});",
            "        OP_REQUIRES(",
            "            ctx, loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require in writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) = hypothesis_seq.size();",
            "        if (normalize_ && output_t(loc) != 0.0f) {"
        ],
        [
            "                                      output_strides.begin(), int64_t{0});",
            "        OP_REQUIRES(",
            "            ctx, loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require in writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "        ++truth_iter;"
        ],
        [
            "                                    output_strides.begin(), int64_t{0});",
            "      OP_REQUIRES(",
            "          ctx, loc < output_elements,",
            "          errors::Internal(\"Got an inner product \", loc,",
            "                           \" which would require in writing to outside of the \"",
            "                           \"buffer for the output tensor (max elements \",",
            "                           output_elements, \")\"));",
            "      output_t(loc) = hypothesis_seq.size();",
            "      if (normalize_ && output_t(loc) != 0.0f) {"
        ],
        [
            "                                    output_strides.begin(), int64_t{0});",
            "      OP_REQUIRES(",
            "          ctx, loc < output_elements,",
            "          errors::Internal(\"Got an inner product \", loc,",
            "                           \" which would require in writing to outside of the \"",
            "                           \"buffer for the output tensor (max elements \",",
            "                           output_elements, \")\"));",
            "      output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "      ++truth_iter;"
        ]
    ],
    "Clean Code": [
        [
            "                                      output_strides.begin(), int64_t{0});",
            "        OP_REQUIRES(",
            "            ctx, 0 <= loc && loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) =",
            "            gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);"
        ],
        [
            "                                      output_strides.begin(), int64_t{0});",
            "        OP_REQUIRES(",
            "            ctx, 0 <= loc && loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) = hypothesis_seq.size();",
            "        if (normalize_ && output_t(loc) != 0.0f) {"
        ],
        [
            "                                      output_strides.begin(), int64_t{0});",
            "        OP_REQUIRES(",
            "            ctx, 0 <= loc && loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "        ++truth_iter;"
        ],
        [
            "                                    output_strides.begin(), int64_t{0});",
            "      OP_REQUIRES(",
            "          ctx, 0 <= loc && loc < output_elements,",
            "          errors::Internal(\"Got an inner product \", loc,",
            "                           \" which would require writing to outside of the \"",
            "                           \"buffer for the output tensor (max elements \",",
            "                           output_elements, \")\"));",
            "      output_t(loc) = hypothesis_seq.size();",
            "      if (normalize_ && output_t(loc) != 0.0f) {"
        ],
        [
            "                                    output_strides.begin(), int64_t{0});",
            "      OP_REQUIRES(",
            "          ctx, 0 <= loc && loc < output_elements,",
            "          errors::Internal(\"Got an inner product \", loc,",
            "                           \" which would require writing to outside of the \"",
            "                           \"buffer for the output tensor (max elements \",",
            "                           output_elements, \")\"));",
            "      output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "      ++truth_iter;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2r2f-g8mw-9gvr",
    "API Signature": "tf.raw_ops.EditDistance(\n    hypothesis_indices,\n    hypothesis_values,\n    hypothesis_shape,\n    truth_indices,\n    truth_values,\n    truth_shape,\n    normalize=True,\n    name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Negative input tensor",
    "Anomaly Description": "A negative input tensor refers to a tensor that contains negative values. In other words, the elements of the tensor have a value less than zero.",
    "Category": "Tensor",
    "Argument": "hypothesis_indices = tf.constant(-1250999896764, shape=[3, 3], dtype=tf.int64), truth_indices = tf.constant(-1250999896764, shape=[3, 3], dtype=tf.int64)"
},
{
    "Title": "\n        Integer overflow in `SpaceToBatchND`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SpaceToBatchND  (in all backends such as XLA and handwritten kernels) is vulnerable to an integer overflow:",
    "Sample Code": "input = tf.constant(-3.5e+35, shape=[10,19,22], dtype=tf.float32)\nblock_shape = tf.constant(-1879048192, shape=[2], dtype=tf.int64)\npaddings = tf.constant(0, shape=[2,2], dtype=tf.int32)\n)\ntf.raw_ops.SpaceToBatchND(input=input, block_shape=block_shape, paddings=paddings)",
    "Code change": [
        "@@ -17,6 +17,7 @@\n import numpy as np\n \n from tensorflow.compiler.tests import xla_test\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gen_array_ops\n@@ -145,6 +146,29 @@ class SpaceToBatchTest(xla_test.XLATestCase):\n     self._testOne(x_np, block_size, x_out)\n \n \n+class SpaceToBatchNDErrorHandlingTest(xla_test.XLATestCase):\n+\n+  def testInvalidBlockShape(self):\n+    with self.assertRaisesRegex(ValueError, \"block_shape must be positive\"):\n+      with self.session() as sess, self.test_scope():\n+        tf_in = constant_op.constant(\n+            -3.5e+35, shape=[10, 20, 20], dtype=dtypes.float32)\n+        block_shape = constant_op.constant(-10, shape=[2], dtype=dtypes.int64)\n+        paddings = constant_op.constant(0, shape=[2, 2], dtype=dtypes.int32)\n+        sess.run(array_ops.space_to_batch_nd(tf_in, block_shape, paddings))\n+\n+  def testOutputSizeOutOfBounds(self):\n+    with self.assertRaisesRegex(ValueError,\n+                                \"Negative.* dimension size caused by overflow\"):\n+      with self.session() as sess, self.test_scope():\n+        tf_in = constant_op.constant(\n+            -3.5e+35, shape=[10, 19, 22], dtype=dtypes.float32)\n+        block_shape = constant_op.constant(\n+            1879048192, shape=[2], dtype=dtypes.int64)\n+        paddings = constant_op.constant(0, shape=[2, 2], dtype=dtypes.int32)\n+        sess.run(array_ops.space_to_batch_nd(tf_in, block_shape, paddings))\n+\n+\n class SpaceToBatchNDTest(xla_test.XLATestCase):\n   \"\"\"Tests input-output pairs for the SpaceToBatchND and BatchToSpaceND ops.\"\"\"\n \n",
        "@@ -211,6 +211,7 @@ tf_kernel_library(\n         \"//tensorflow/core/kernels:stateful_random_ops_header\",\n         \"//tensorflow/core/kernels:stateless_random_ops_v2_header\",\n         \"//tensorflow/core/tpu:tpu_defs\",\n+        \"//tensorflow/core/util:overflow\",\n         \"//tensorflow/stream_executor/lib\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n",
        "@@ -17,6 +17,7 @@ limitations under the License.\n #include \"tensorflow/compiler/tf2xla/xla_op_kernel.h\"\n #include \"tensorflow/compiler/tf2xla/xla_op_registry.h\"\n #include \"tensorflow/compiler/xla/client/xla_builder.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n namespace {\n@@ -60,10 +61,14 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n     int64_t pad_end = paddings.Get<int64_t>({i, 1});\n     OP_REQUIRES(ctx, pad_start >= 0 && pad_end >= 0,\n                 errors::InvalidArgument(\"Paddings must be non-negative\"));\n+    OP_REQUIRES(ctx, block_shape[i] >= 1,\n+                errors::InvalidArgument(\n+                    \"All values in block_shape must be positive, got value, \",\n+                    block_shape[i], \" at index \", i, \".\"));\n     dim->set_edge_padding_low(pad_start);\n     dim->set_edge_padding_high(pad_end);\n     padded_shape[1 + i] += pad_start + pad_end;\n-    block_num_elems *= block_shape[i];\n+    block_num_elems = MultiplyWithoutOverflow(block_num_elems, block_shape[i]);\n   }\n   // Don't pad the remainder dimensions.\n   for (int i = 0; i < remainder_shape.size(); ++i) {\n@@ -72,6 +77,16 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n   OP_REQUIRES(ctx, block_num_elems > 0,\n               errors::InvalidArgument(\n                   \"The product of the block dimensions must be positive\"));\n+  const int64_t batch_size = input_shape[0];\n+  const int64_t output_dim =\n+      MultiplyWithoutOverflow(batch_size, block_num_elems);\n+  if (output_dim < 0) {\n+    OP_REQUIRES(\n+        ctx, output_dim >= 0,\n+        errors::InvalidArgument(\"Negative output dimension size caused by \"\n+                                \"overflow when multiplying \",\n+                                batch_size, \" and \", block_num_elems));\n+  }\n \n   xla::XlaOp padded =\n       xla::Pad(input, XlaHelpers::Zero(b, input_dtype), padding_config);\n@@ -85,7 +100,6 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n   //       padded_shape[M] / block_shape[M-1],\n   //       block_shape[M-1]] +\n   //      remaining_shape\n-  const int64_t batch_size = input_shape[0];\n   std::vector<int64_t> reshaped_padded_shape(input_rank + block_rank);\n   reshaped_padded_shape[0] = batch_size;\n   for (int i = 0; i < block_rank; ++i) {\n@@ -134,7 +148,7 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n   // Determine the length of the prefix of block dims that can be combined\n   // into the batch dimension due to having no padding and block_shape=1.\n   std::vector<int64_t> output_shape(input_rank);\n-  output_shape[0] = batch_size * block_num_elems;\n+  output_shape[0] = output_dim;\n   for (int i = 0; i < block_rank; ++i) {\n     output_shape[1 + i] = padded_shape[1 + i] / block_shape[i];\n   }\n",
        "@@ -891,6 +891,7 @@ cc_library(\n         \"//tensorflow/core/lib/strings:scanner\",\n         \"//tensorflow/core/lib/strings:str_util\",\n         \"//tensorflow/core/platform:macros\",\n+        \"//tensorflow/core/util:overflow\",\n         \"@com_google_absl//absl/memory\",\n     ],\n )\n",
        "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"tensorflow/core/lib/strings/numbers.h\"\n #include \"tensorflow/core/lib/strings/scanner.h\"\n #include \"tensorflow/core/lib/strings/str_util.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n namespace shape_inference {\n@@ -1111,7 +1112,7 @@ Status InferenceContext::Multiply(DimensionHandle first,\n     *out = UnknownDim();\n   } else {\n     // Invariant: Both values are known and greater than 1.\n-    const int64_t product = first_value * second_value;\n+    const int64_t product = MultiplyWithoutOverflow(first_value, second_value);\n     if (product < 0) {\n       return errors::InvalidArgument(\n           \"Negative dimension size caused by overflow when multiplying \",\n",
        "@@ -29,6 +29,7 @@ load(\n load(\n     \"//third_party/mkl:build_defs.bzl\",\n     \"if_mkl\",\n+    \"mkl_deps\",\n )\n \n # buildifier: disable=same-origin-load\n@@ -61,10 +62,6 @@ load(\n     \"//tensorflow/core/platform:build_config_root.bzl\",\n     \"tf_cuda_tests_tags\",\n )\n-load(\n-    \"//third_party/mkl:build_defs.bzl\",\n-    \"mkl_deps\",\n-)\n load(\"@local_config_cuda//cuda:build_defs.bzl\", \"if_cuda\")\n load(\n     \"@local_config_rocm//rocm:build_defs.bzl\",\n@@ -4569,6 +4566,7 @@ tf_kernel_library(\n         \"//tensorflow/core:framework\",\n         \"//tensorflow/core:lib\",\n         \"//tensorflow/core/framework:bounds_check\",\n+        \"//tensorflow/core/util:overflow\",\n         \"//third_party/eigen3\",\n     ],\n )\n",
        "@@ -21,8 +21,6 @@ limitations under the License.\n #include <string>\n #include <utility>\n \n-#include \"tensorflow/core/kernels/spacetobatch_functor.h\"\n-\n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n@@ -31,8 +29,10 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/tensor_types.h\"\n #include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/kernels/spacetobatch_functor.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/types.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n \n@@ -99,7 +99,13 @@ Status SpaceToBatchOpCompute(OpKernelContext* context,\n   // Compute the product of the block_shape values.\n   int64_t block_shape_product = 1;\n   for (int block_dim = 0; block_dim < block_dims; ++block_dim) {\n-    block_shape_product *= block_shape[block_dim];\n+    if (block_shape[block_dim] < 1) {\n+      return errors::InvalidArgument(\n+          \"All values in block_shape must be positive, got value, \",\n+          block_shape[block_dim], \" at index \", block_dim, \".\");\n+    }\n+    block_shape_product =\n+        MultiplyWithoutOverflow(block_shape_product, block_shape[block_dim]);\n   }\n   if (block_shape_product <= 0) {\n     return errors::InvalidArgument(\n@@ -131,8 +137,14 @@ Status SpaceToBatchOpCompute(OpKernelContext* context,\n   // The actual output shape exposed to callers.\n   TensorShape external_output_shape;\n \n-  external_output_shape.AddDim(orig_input_tensor.dim_size(0) *\n-                               block_shape_product);\n+  const int64_t output_shape = MultiplyWithoutOverflow(\n+      orig_input_tensor.dim_size(0), block_shape_product);\n+  if (output_shape < 0) {\n+    return errors::InvalidArgument(\n+        \"Negative output dimension size caused by overflow when multiplying \",\n+        orig_input_tensor.dim_size(0), \" and \", block_shape_product);\n+  }\n+  external_output_shape.AddDim(output_shape);\n \n   int64_t input_batch_size = orig_input_tensor.dim_size(0);\n   for (int block_dim = 0; block_dim < removed_prefix_block_dims; ++block_dim) {\n",
        "@@ -533,6 +533,9 @@ tf_cuda_library(\n cc_library(\n     name = \"overflow\",\n     hdrs = [\"overflow.h\"],\n+    visibility = [\n+        \"//tensorflow:internal\",\n+    ],\n     deps = [\n         \"//tensorflow/core/platform:logging\",\n         \"//tensorflow/core/platform:macros\",\n",
        "@@ -16,7 +16,9 @@\n \n import numpy as np\n \n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import tensor_util\n from tensorflow.python.framework import test_util\n@@ -516,6 +518,27 @@ class SpaceToBatchNDErrorHandlingTest(test.TestCase):\n             dtypes.float32, shape=(3, 2, 3, 2)), [2, 3], [[1, 1], [0, 0]])\n     self.assertEqual([3 * 2 * 3, 2, 1, 2], t.get_shape().as_list())\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testInvalidBlockShape(self):\n+    tf_in = constant_op.constant(\n+        -3.5e+35, shape=[10, 20, 20], dtype=dtypes.float32)\n+    block_shape = constant_op.constant(-10, shape=[2], dtype=dtypes.int64)\n+    paddings = constant_op.constant(0, shape=[2, 2], dtype=dtypes.int32)\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"block_shape must be positive\"):\n+      array_ops.space_to_batch_nd(tf_in, block_shape, paddings)\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def testOutputSizeOutOfBounds(self):\n+    tf_in = constant_op.constant(\n+        -3.5e+35, shape=[10, 19, 22], dtype=dtypes.float32)\n+    block_shape = constant_op.constant(\n+        1879048192, shape=[2], dtype=dtypes.int64)\n+    paddings = constant_op.constant(0, shape=[2, 2], dtype=dtypes.int32)\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"Negative.* dimension size caused by overflow\"):\n+      array_ops.space_to_batch_nd(tf_in, block_shape, paddings)\n+\n \n class SpaceToBatchGradientTest(test.TestCase, PythonOpImpl):\n \n"
    ],
    "Buggy Code": [
        [
            "        \"//tensorflow/core/kernels:stateless_random_ops_v2_header\",",
            "        \"//tensorflow/core/tpu:tpu_defs\",",
            "        \"//tensorflow/stream_executor/lib\",",
            "        \"@com_google_absl//absl/algorithm:container\",",
            "        \"@com_google_absl//absl/container:flat_hash_map\",",
            "        \"@com_google_absl//absl/strings\",",
            "        \"@com_google_absl//absl/strings:str_format\","
        ],
        [
            "#include \"tensorflow/compiler/tf2xla/xla_op_registry.h\"",
            "#include \"tensorflow/compiler/xla/client/xla_builder.h\"",
            "",
            "namespace tensorflow {",
            "namespace {",
            "",
            "void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,"
        ],
        [
            "                errors::InvalidArgument(\"Paddings must be non-negative\"));",
            "    dim->set_edge_padding_low(pad_start);",
            "    dim->set_edge_padding_high(pad_end);",
            "    padded_shape[1 + i] += pad_start + pad_end;",
            "    block_num_elems *= block_shape[i];",
            "  }",
            "  // Don't pad the remainder dimensions.",
            "  for (int i = 0; i < remainder_shape.size(); ++i) {",
            "    padding_config.add_dimensions();",
            "  }",
            "  OP_REQUIRES(ctx, block_num_elems > 0,",
            "              errors::InvalidArgument(",
            "                  \"The product of the block dimensions must be positive\"));",
            ""
        ],
        [
            "",
            "  // 2. Reshape `padded` to `reshaped_padded` of shape:",
            "  //",
            "  //      [batch] +",
            "  //      [padded_shape[1] / block_shape[0],",
            "  //        block_shape[0],",
            "  //       ...,",
            "  //       padded_shape[M] / block_shape[M-1],",
            "  //       block_shape[M-1]] +",
            "  //      remaining_shape",
            "  const int64_t batch_size = input_shape[0];",
            "  std::vector<int64_t> reshaped_padded_shape(input_rank + block_rank);",
            "  reshaped_padded_shape[0] = batch_size;",
            "  for (int i = 0; i < block_rank; ++i) {",
            "    OP_REQUIRES(ctx, padded_shape[1 + i] % block_shape[i] == 0,",
            "                errors::InvalidArgument(\"padded_shape[\", 1 + i,"
        ],
        [
            "  std::copy(remainder_shape.begin(), remainder_shape.end(),",
            "            reshaped_padded_shape.begin() + 1 + 2 * block_rank);",
            "",
            "  xla::XlaOp reshaped_padded = xla::Reshape(padded, reshaped_padded_shape);",
            "",
            "  // 3. Permute dimensions of `reshaped_padded` to produce"
        ],
        [
            " public:",
            "  explicit SpaceToBatchNDOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
            "",
            "  void Compile(XlaOpKernelContext* ctx) override {",
            "    std::vector<int64_t> block_shape;",
            "    OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(1, &block_shape));",
            ""
        ],
        [
            "        \"//tensorflow/core/lib/strings:str_util\",",
            "        \"//tensorflow/core/platform:macros\",",
            "        \"@com_google_absl//absl/memory\",",
            "    ],",
            ")",
            "",
            "cc_library("
        ],
        [
            "#include \"tensorflow/core/lib/strings/scanner.h\"",
            "#include \"tensorflow/core/lib/strings/str_util.h\"",
            "",
            "namespace tensorflow {",
            "namespace shape_inference {",
            "",
            "constexpr int32_t InferenceContext::kUnknownRank;"
        ],
        [
            "    // Invariant: Both values are known and greater than 1.",
            "    const int64_t product = first_value * second_value;",
            "    if (product < 0) {",
            "      return errors::InvalidArgument(",
            "          \"Negative dimension size caused by overflow when multiplying \",",
            "          first_value, \" and \", second_value);",
            "    }"
        ],
        [
            "    \"//third_party/mkl:build_defs.bzl\",",
            "    \"if_mkl\",",
            ")",
            "",
            "# buildifier: disable=same-origin-load",
            "load(\"//tensorflow:tensorflow.bzl\", \"cc_header_only_library\")",
            ""
        ],
        [
            ")",
            "load(",
            "    \"//third_party/mkl:build_defs.bzl\",",
            "    \"mkl_deps\",",
            ")",
            "load(\"@local_config_cuda//cuda:build_defs.bzl\", \"if_cuda\")"
        ],
        [
            "    visibility = [\":friends\"],",
            "    deps = [",
            "        \"//tensorflow/core:framework\",",
            "        \"//tensorflow/core:lib\",",
            "        \"//tensorflow/core/framework:bounds_check\",",
            "        \"//third_party/eigen3\",",
            "    ],"
        ],
        [
            "#include <utility>",
            "",
            "#include \"tensorflow/core/kernels/spacetobatch_functor.h\"",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/op.h\""
        ],
        [
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/framework/tensor_types.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/types.h\"",
            "",
            "namespace tensorflow {",
            "",
            "typedef Eigen::ThreadPoolDevice CPUDevice;"
        ],
        [
            "  int64_t block_shape_product = 1;",
            "  for (int block_dim = 0; block_dim < block_dims; ++block_dim) {",
            "    block_shape_product *= block_shape[block_dim];",
            "  }",
            "  if (block_shape_product <= 0) {",
            "    return errors::InvalidArgument(",
            "        \"Product of block sizes must be positive, got \", block_shape_product);",
            "  }",
            "",
            "  const int internal_block_dims =",
            "      block_dims - removed_prefix_block_dims - removed_suffix_block_dims;",
            "  if (internal_block_dims > kMaxSpaceToBatchBlockDims) {",
            "    return errors::InvalidArgument("
        ],
        [
            "  for (int block_dim = 0; block_dim < removed_prefix_block_dims; ++block_dim) {",
            "    const int64_t size = orig_input_tensor.dim_size(block_dim + 1);",
            "    input_batch_size *= size;",
            "    external_output_shape.AddDim(size);",
            "  }",
            "  internal_input_shape.AddDim(input_batch_size);",
            "  internal_output_shape.AddDim(input_batch_size * block_shape_product);",
            "",
            "  for (int block_dim = removed_prefix_block_dims;",
            "       block_dim < block_dims - removed_suffix_block_dims; ++block_dim) {",
            "    const int64_t pad_start = paddings[2 * block_dim],",
            "                  pad_end = paddings[2 * block_dim + 1];",
            "    if (pad_start < 0 || pad_end < 0) {",
            "      return errors::InvalidArgument(\"Paddings must be non-negative\");"
        ],
        [
            "    name = \"overflow\",",
            "    hdrs = [\"overflow.h\"],",
            "    deps = [",
            "        \"//tensorflow/core/platform:logging\",",
            "        \"//tensorflow/core/platform:macros\",",
            "        \"//tensorflow/core/platform:types\",",
            "    ],",
            ")",
            ""
        ]
    ],
    "Clean Code": [
        [
            "        \"//tensorflow/core/kernels:stateless_random_ops_v2_header\",",
            "        \"//tensorflow/core/tpu:tpu_defs\",",
            "        \"//tensorflow/core/util:overflow\",",
            "        \"//tensorflow/stream_executor/lib\",",
            "        \"@com_google_absl//absl/algorithm:container\",",
            "        \"@com_google_absl//absl/container:flat_hash_map\",",
            "        \"@com_google_absl//absl/strings\","
        ],
        [
            "#include \"tensorflow/compiler/tf2xla/xla_op_registry.h\"",
            "#include \"tensorflow/compiler/xla/client/xla_builder.h\"",
            "#include \"tensorflow/core/util/overflow.h\"",
            "",
            "namespace tensorflow {",
            "namespace {",
            ""
        ],
        [
            "    OP_REQUIRES(ctx, pad_start >= 0 && pad_end >= 0,",
            "                errors::InvalidArgument(\"Paddings must be non-negative\"));",
            "    OP_REQUIRES(ctx, block_shape[i] >= 1,",
            "                errors::InvalidArgument(",
            "                    \"All values in block_shape must be positive, got value, \",",
            "                    block_shape[i], \" at index \", i, \".\"));",
            "    dim->set_edge_padding_low(pad_start);",
            "    dim->set_edge_padding_high(pad_end);",
            "    padded_shape[1 + i] += pad_start + pad_end;",
            "    block_num_elems = MultiplyWithoutOverflow(block_num_elems, block_shape[i]);",
            "  }",
            "  // Don't pad the remainder dimensions.",
            "  for (int i = 0; i < remainder_shape.size(); ++i) {",
            "    padding_config.add_dimensions();"
        ],
        [
            "              errors::InvalidArgument(",
            "                  \"The product of the block dimensions must be positive\"));",
            "  const int64_t batch_size = input_shape[0];",
            "  const int64_t output_dim =",
            "      MultiplyWithoutOverflow(batch_size, block_num_elems);",
            "  if (output_dim < 0) {",
            "    OP_REQUIRES(",
            "        ctx, output_dim >= 0,",
            "        errors::InvalidArgument(\"Negative output dimension size caused by \"",
            "                                \"overflow when multiplying \",",
            "                                batch_size, \" and \", block_num_elems));",
            "  }",
            "",
            "  xla::XlaOp padded =",
            "      xla::Pad(input, XlaHelpers::Zero(b, input_dtype), padding_config);",
            ""
        ],
        [
            "  //       block_shape[M-1]] +",
            "  //      remaining_shape",
            "  std::vector<int64_t> reshaped_padded_shape(input_rank + block_rank);",
            "  reshaped_padded_shape[0] = batch_size;",
            "  for (int i = 0; i < block_rank; ++i) {",
            "    OP_REQUIRES(ctx, padded_shape[1 + i] % block_shape[i] == 0,"
        ],
        [
            "  // into the batch dimension due to having no padding and block_shape=1.",
            "  std::vector<int64_t> output_shape(input_rank);",
            "  output_shape[0] = output_dim;",
            "  for (int i = 0; i < block_rank; ++i) {",
            "    output_shape[1 + i] = padded_shape[1 + i] / block_shape[i];",
            "  }",
            "  std::copy(remainder_shape.begin(), remainder_shape.end(),"
        ],
        [
            "        \"//tensorflow/core/lib/strings:str_util\",",
            "        \"//tensorflow/core/platform:macros\",",
            "        \"//tensorflow/core/util:overflow\",",
            "        \"@com_google_absl//absl/memory\",",
            "    ],",
            ")",
            ""
        ],
        [
            "#include \"tensorflow/core/lib/strings/scanner.h\"",
            "#include \"tensorflow/core/lib/strings/str_util.h\"",
            "#include \"tensorflow/core/util/overflow.h\"",
            "",
            "namespace tensorflow {",
            "namespace shape_inference {",
            ""
        ],
        [
            "  } else {",
            "    // Invariant: Both values are known and greater than 1.",
            "    const int64_t product = MultiplyWithoutOverflow(first_value, second_value);",
            "    if (product < 0) {",
            "      return errors::InvalidArgument(",
            "          \"Negative dimension size caused by overflow when multiplying \",",
            "          first_value, \" and \", second_value);"
        ],
        [
            "    \"//third_party/mkl:build_defs.bzl\",",
            "    \"if_mkl\",",
            "    \"mkl_deps\",",
            ")",
            "",
            "# buildifier: disable=same-origin-load",
            "load(\"//tensorflow:tensorflow.bzl\", \"cc_header_only_library\")"
        ],
        [
            "    \"tf_cuda_tests_tags\",",
            ")",
            "load(\"@local_config_cuda//cuda:build_defs.bzl\", \"if_cuda\")",
            "load(",
            "    \"@local_config_rocm//rocm:build_defs.bzl\",",
            "    \"if_rocm\","
        ],
        [
            "        \"//tensorflow/core:lib\",",
            "        \"//tensorflow/core/framework:bounds_check\",",
            "        \"//tensorflow/core/util:overflow\",",
            "        \"//third_party/eigen3\",",
            "    ],",
            ")",
            ""
        ],
        [
            "#include <utility>",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\""
        ],
        [
            "#include \"tensorflow/core/framework/tensor_types.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/kernels/spacetobatch_functor.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/types.h\"",
            "#include \"tensorflow/core/util/overflow.h\"",
            "",
            "namespace tensorflow {",
            "",
            "typedef Eigen::ThreadPoolDevice CPUDevice;"
        ],
        [
            "  int64_t block_shape_product = 1;",
            "  for (int block_dim = 0; block_dim < block_dims; ++block_dim) {",
            "    if (block_shape[block_dim] < 1) {",
            "      return errors::InvalidArgument(",
            "          \"All values in block_shape must be positive, got value, \",",
            "          block_shape[block_dim], \" at index \", block_dim, \".\");",
            "    }",
            "    block_shape_product =",
            "        MultiplyWithoutOverflow(block_shape_product, block_shape[block_dim]);",
            "  }",
            "  if (block_shape_product <= 0) {",
            "    return errors::InvalidArgument(",
            "        \"Product of block sizes must be positive, got \", block_shape_product);"
        ],
        [
            "  TensorShape external_output_shape;",
            "",
            "  const int64_t output_shape = MultiplyWithoutOverflow(",
            "      orig_input_tensor.dim_size(0), block_shape_product);",
            "  if (output_shape < 0) {",
            "    return errors::InvalidArgument(",
            "        \"Negative output dimension size caused by overflow when multiplying \",",
            "        orig_input_tensor.dim_size(0), \" and \", block_shape_product);",
            "  }",
            "  external_output_shape.AddDim(output_shape);",
            "",
            "  int64_t input_batch_size = orig_input_tensor.dim_size(0);",
            "  for (int block_dim = 0; block_dim < removed_prefix_block_dims; ++block_dim) {",
            "    const int64_t size = orig_input_tensor.dim_size(block_dim + 1);"
        ],
        [
            "    name = \"overflow\",",
            "    hdrs = [\"overflow.h\"],",
            "    visibility = [",
            "        \"//tensorflow:internal\",",
            "    ],",
            "    deps = [",
            "        \"//tensorflow/core/platform:logging\",",
            "        \"//tensorflow/core/platform:macros\",",
            "        \"//tensorflow/core/platform:types\","
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jjm6-4vf7-cjh4",
    "API Signature": "tf.raw_ops.SpaceToBatchND(\n    input, block_shape, paddings, name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Negative input tensor",
    "Anomaly Description": "A negative input tensor refers to a tensor that contains negative values. In other words, the elements of the tensor have a value less than zero.",
    "Category": "Tensor",
    "Argument": "block_shape = tf.constant(-1879048192, shape=[2], dtype=tf.int64)"
},
{
    "Title": "\n        Missing validation results in undefined behavior in `QuantizedConv2D`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.QuantizedConv2D  does not fully validate the input arguments:",
    "Sample Code": "input = tf.constant(1, shape=[1, 2, 3, 3], dtype=tf.quint8)\nfilter = tf.constant(1, shape=[1, 2, 3, 3], dtype=tf.quint8)\n\n# bad args\nmin_input = tf.constant([], shape=[0], dtype=tf.float32)\nmax_input = tf.constant(0, shape=[], dtype=tf.float32)\nmin_filter = tf.constant(0, shape=[], dtype=tf.float32)\nmax_filter = tf.constant(0, shape=[], dtype=tf.float32)\n\ntf.raw_ops.QuantizedConv2D(\n  input=input,\n  filter=filter,\n  min_input=min_input,\n  max_input=max_input,\n  min_filter=min_filter,\n  max_filter=max_filter, \n  strides=[1, 1, 1, 1],\n  ],\n  padding=\"SAME\")",
    "Code change": [
        "@@ -18,8 +18,6 @@ limitations under the License.\n #include <algorithm>\n #include <vector>\n \n-#include \"tensorflow/core/platform/errors.h\"\n-\n #define EIGEN_USE_THREADS\n \n #define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\n@@ -32,6 +30,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/kernels/reference_gemm.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/util/padding.h\"\n \n namespace tensorflow {\n@@ -499,11 +498,26 @@ class QuantizedConv2DOp : public OpKernel {\n \n     // For 2D convolution, there should be 4 dimensions.\n     OP_REQUIRES(context, input.dims() == 4,\n-                errors::InvalidArgument(\"input must be 4-dimensional\",\n-                                        input.shape().DebugString()));\n+                errors::InvalidArgument(\"input must be rank 4 but is rank \",\n+                                        input.shape().dims()));\n     OP_REQUIRES(context, filter.dims() == 4,\n-                errors::InvalidArgument(\"filter must be 4-dimensional: \",\n-                                        filter.shape().DebugString()));\n+                errors::InvalidArgument(\"filter must be rank 4 but is rank \",\n+                                        filter.shape().dims()));\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(2).shape()),\n+                errors::InvalidArgument(\"min_input must be rank 0 but is rank \",\n+                                        context->input(2).shape().dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(3).shape()),\n+                errors::InvalidArgument(\"max_input must be rank 0 but is rank \",\n+                                        context->input(3).shape().dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(context->input(4).shape()),\n+        errors::InvalidArgument(\"min_filter must be rank 0 but is rank \",\n+                                context->input(4).shape().dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(context->input(5).shape()),\n+        errors::InvalidArgument(\"max_filter must be rank 0 but is rank \",\n+                                context->input(5).shape().dims()));\n \n     const float min_input = context->input(2).flat<float>()(0);\n     const float max_input = context->input(3).flat<float>()(0);\n",
        "@@ -91,10 +91,10 @@ TEST_F(QuantizedConv2DTest, Small) {\n                             image_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(filter_quantized.shape(),\n                             filter_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {image_min});\n-  AddInputFromArray<float>(TensorShape({1}), {image_max});\n-  AddInputFromArray<float>(TensorShape({1}), {filter_min});\n-  AddInputFromArray<float>(TensorShape({1}), {filter_max});\n+  AddInputFromArray<float>(TensorShape({}), {image_min});\n+  AddInputFromArray<float>(TensorShape({}), {image_max});\n+  AddInputFromArray<float>(TensorShape({}), {filter_min});\n+  AddInputFromArray<float>(TensorShape({}), {filter_max});\n   TF_ASSERT_OK(RunOpKernel());\n \n   // We're sliding the 3x3 filter across the 3x4 image, with accesses outside\n@@ -158,10 +158,10 @@ TEST_F(QuantizedConv2DTest, Small32Bit) {\n   AddInputFromArray<quint8>(\n       TensorShape({filter_size, filter_size, depth, filter_count}),\n       {10, 40, 70, 20, 50, 80, 30, 60, 90});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n \n   TF_ASSERT_OK(RunOpKernel());\n   const int expected_width = image_width;\n@@ -201,10 +201,10 @@ TEST_F(QuantizedConv2DTest, OddPadding) {\n   AddInputFromArray<quint8>(\n       TensorShape({filter_size, filter_size, depth, filter_count}),\n       {1, 2, 3, 4, 5, 6, 7, 8, 9});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n \n   TF_ASSERT_OK(RunOpKernel());\n   const int expected_width = image_width / stride;\n@@ -244,10 +244,10 @@ TEST_F(QuantizedConv2DTest, OddPaddingBatch) {\n   AddInputFromArray<quint8>(\n       TensorShape({filter_size, filter_size, depth, filter_count}),\n       {1, 2, 3, 4, 5, 6, 7, 8, 9});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n \n   TF_ASSERT_OK(RunOpKernel());\n   const int expected_width = image_width / stride;\n@@ -302,10 +302,10 @@ TEST_F(QuantizedConv2DTest, SmallWithNoZero) {\n                             image_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(filter_quantized.shape(),\n                             filter_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {image_min});\n-  AddInputFromArray<float>(TensorShape({1}), {image_max});\n-  AddInputFromArray<float>(TensorShape({1}), {filter_min});\n-  AddInputFromArray<float>(TensorShape({1}), {filter_max});\n+  AddInputFromArray<float>(TensorShape({}), {image_min});\n+  AddInputFromArray<float>(TensorShape({}), {image_max});\n+  AddInputFromArray<float>(TensorShape({}), {filter_min});\n+  AddInputFromArray<float>(TensorShape({}), {filter_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const int expected_width = image_width;\n   const int expected_height = image_height * filter_count;\n",
        "@@ -18,6 +18,8 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n+from tensorflow.python.ops import math_ops\n from tensorflow.python.ops import nn_ops\n from tensorflow.python.platform import test\n \n@@ -196,6 +198,71 @@ class Conv2DTest(test.TestCase):\n         padding=\"SAME\",\n         expected=expected_output)\n \n+  def _testBadInputSize(self,\n+                        tin=None,\n+                        tfilter=None,\n+                        min_input=None,\n+                        max_input=None,\n+                        min_filter=None,\n+                        max_filter=None,\n+                        error_regex=\"\"):\n+    strides = [1, 1, 1, 1]\n+    padding = \"SAME\"\n+    if tin is None:\n+      tin = math_ops.cast(\n+          constant_op.constant(1, shape=[1, 2, 3, 3]), dtype=dtypes.quint8)\n+\n+    if tfilter is None:\n+      tfilter = math_ops.cast(\n+          constant_op.constant(1, shape=[1, 2, 3, 3]), dtype=dtypes.quint8)\n+\n+    if min_input is None:\n+      min_input = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+\n+    if max_input is None:\n+      max_input = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+\n+    if min_filter is None:\n+      min_filter = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+\n+    if max_filter is None:\n+      max_filter = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                error_regex):\n+      self.evaluate(\n+          nn_ops.quantized_conv2d(\n+              tin,\n+              tfilter,\n+              out_type=dtypes.qint32,\n+              strides=strides,\n+              padding=padding,\n+              min_input=min_input,\n+              max_input=max_input,\n+              min_filter=min_filter,\n+              max_filter=max_filter))\n+\n+  def testBadInputSizes(self):\n+    self._testBadInputSize(\n+        tin=math_ops.cast(\n+            constant_op.constant(1, shape=[1, 2]), dtype=dtypes.quint8),\n+        error_regex=\"must be rank 4\")\n+    self._testBadInputSize(\n+        tfilter=math_ops.cast(\n+            constant_op.constant(1, shape=[1, 2]), dtype=dtypes.quint8),\n+        error_regex=\"must be rank 4\")\n+    self._testBadInputSize(\n+        min_input=constant_op.constant(0, shape=[1], dtype=dtypes.float32),\n+        error_regex=\"must be rank 0\")\n+    self._testBadInputSize(\n+        max_input=constant_op.constant(0, shape=[1], dtype=dtypes.float32),\n+        error_regex=\"must be rank 0\")\n+    self._testBadInputSize(\n+        min_filter=constant_op.constant(0, shape=[1], dtype=dtypes.float32),\n+        error_regex=\"must be rank 0\")\n+    self._testBadInputSize(\n+        max_filter=constant_op.constant(0, shape=[1], dtype=dtypes.float32),\n+        error_regex=\"must be rank 0\")\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "#include <vector>",
            "",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "#define EIGEN_USE_THREADS",
            ""
        ],
        [
            "#include \"tensorflow/core/kernels/meta_support.h\"",
            "#include \"tensorflow/core/kernels/quantization_utils.h\"",
            "#include \"tensorflow/core/kernels/reference_gemm.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/util/padding.h\"",
            "",
            "namespace tensorflow {"
        ],
        [
            "",
            "    // For 2D convolution, there should be 4 dimensions.",
            "    OP_REQUIRES(context, input.dims() == 4,",
            "                errors::InvalidArgument(\"input must be 4-dimensional\",",
            "                                        input.shape().DebugString()));",
            "    OP_REQUIRES(context, filter.dims() == 4,",
            "                errors::InvalidArgument(\"filter must be 4-dimensional: \",",
            "                                        filter.shape().DebugString()));",
            "",
            "    const float min_input = context->input(2).flat<float>()(0);",
            "    const float max_input = context->input(3).flat<float>()(0);",
            "    const float min_filter = context->input(4).flat<float>()(0);",
            "    const float max_filter = context->input(5).flat<float>()(0);",
            "    const int32_t offset_input =",
            "        FloatToQuantizedUnclamped<T1>(0.0f, min_input, max_input);",
            "    const int32_t offset_filter =",
            "        FloatToQuantizedUnclamped<T2>(0.0f, min_filter, max_filter);",
            "    const int32_t offset_output = 0;",
            "    const int32_t mult_output = 1;",
            "    const int32_t shift_output = 0;",
            "",
            "    // The last dimension for input is in_depth. It must be the same as the",
            "    // filter's in_depth.",
            "    const int64_t in_depth = input.dim_size(3);",
            "    OP_REQUIRES(context, in_depth == filter.dim_size(2),",
            "                errors::InvalidArgument("
        ]
    ],
    "Clean Code": [
        [
            "#include <vector>",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK",
            "#include \"public/gemmlowp.h\""
        ],
        [
            "#include \"tensorflow/core/kernels/reference_gemm.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#include \"tensorflow/core/util/padding.h\"",
            "",
            "namespace tensorflow {",
            ""
        ],
        [
            "    // For 2D convolution, there should be 4 dimensions.",
            "    OP_REQUIRES(context, input.dims() == 4,",
            "                errors::InvalidArgument(\"input must be rank 4 but is rank \",",
            "                                        input.shape().dims()));",
            "    OP_REQUIRES(context, filter.dims() == 4,",
            "                errors::InvalidArgument(\"filter must be rank 4 but is rank \",",
            "                                        filter.shape().dims()));",
            "",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(2).shape()),",
            "                errors::InvalidArgument(\"min_input must be rank 0 but is rank \",",
            "                                        context->input(2).shape().dims()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(3).shape()),",
            "                errors::InvalidArgument(\"max_input must be rank 0 but is rank \",",
            "                                        context->input(3).shape().dims()));",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(context->input(4).shape()),",
            "        errors::InvalidArgument(\"min_filter must be rank 0 but is rank \",",
            "                                context->input(4).shape().dims()));",
            "    OP_REQUIRES(",
            "        context, TensorShapeUtils::IsScalar(context->input(5).shape()),",
            "        errors::InvalidArgument(\"max_filter must be rank 0 but is rank \",",
            "                                context->input(5).shape().dims()));",
            "",
            "    const float min_input = context->input(2).flat<float>()(0);",
            "    const float max_input = context->input(3).flat<float>()(0);",
            "    const float min_filter = context->input(4).flat<float>()(0);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-pqhm-4wvf-2jg8",
    "API Signature": "tf.raw_ops.QuantizedConv2D(\n    input,\n    filter,\n    min_input,\n    max_input,\n    min_filter,\n    max_filter,\n    strides,\n    padding,\n    out_type=tf.dtypes.qint32,\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "min_input = tf.constant([], shape=[0], dtype=tf.float32)\nmax_input = tf.constant(0, shape=[], dtype=tf.float32)\nmin_filter = tf.constant(0, shape=[], dtype=tf.float32)\nmax_filter = tf.constant(0, shape=[], dtype=tf.float32)"
},
{
    "Title": "\n        Missing validation results in undefined behavior in `SparseTensorDenseAdd\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SparseTensorDenseAdd  does not fully validate the input arguments:",
    "Sample Code": "a_indices = tf.constant(0, shape=[17, 2], dtype=tf.int64)\na_values = tf.constant([], shape=[0], dtype=tf.float32)\na_shape = tf.constant([6, 12], shape=[2], dtype=tf.int64)\n\nb = tf.constant(-0.223668531, shape=[6, 12], dtype=tf.float32)\n\ntf.raw_ops.SparseTensorDenseAdd(\n    (\n    a_indices=a_indices, a_values=a_values, a_shape=a_shape, b=b)",
    "Code change": [
        "@@ -18,6 +18,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/sparse_tensor_dense_add_op.h\"\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n@@ -47,6 +48,17 @@ Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n         a_values->shape().DebugString(), \" and \",\n         a_shape->shape().DebugString());\n   }\n+  int64_t nnz = a_indices->dim_size(0);\n+  int64_t ndims = a_indices->dim_size(1);\n+  if (a_values->dim_size(0) != nnz) {\n+    return errors::InvalidArgument(\"Dimensions \", nnz, \" and \",\n+                                   a_values->dim_size(0),\n+                                   \" are not compatible\");\n+  }\n+  if (a_shape->dim_size(0) != ndims) {\n+    return errors::InvalidArgument(\"Dimensions \", ndims, \" and \",\n+                                   a_shape->dim_size(0), \" are not compatible\");\n+  }\n   if (a_shape->NumElements() != b->dims()) {\n     return errors::InvalidArgument(\n         \"Two operands have different ranks; received: \", a_shape->NumElements(),\n@@ -61,6 +73,24 @@ Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n           a_shape_flat(i), \" vs dense side \", b->dim_size(i));\n     }\n   }\n+\n+  // Check for invalid indices.\n+  const auto a_indices_mat = a_indices->flat_inner_dims<Index>();\n+\n+  for (int64_t zidx = 0; zidx < nnz; ++zidx) {\n+    for (int64_t didx = 0; didx < ndims; ++didx) {\n+      const Index idx = a_indices_mat(zidx, didx);\n+      if (idx < 0 || idx >= a_shape_flat(didx)) {\n+        return errors::InvalidArgument(\n+            \"Sparse tensor has an invalid index on dimension \", didx,\n+            \": \"\n+            \"a_indices(\",\n+            zidx, \",\", didx, \") = \", idx,\n+            \", dense tensor shape: \", a_shape_flat);\n+      }\n+    }\n+  }\n+\n   return Status::OK();\n }\n \n",
        "@@ -189,7 +189,6 @@ class SparseAddTest(test.TestCase):\n                                                     [(nnz,), (n, m)], s, (n, m))\n       self.assertLess(err, 1e-3)\n \n-  @test_util.run_deprecated_v1\n   def testInvalidSparseTensor(self):\n     with test_util.force_cpu():\n       shape = [2, 2]\n@@ -201,12 +200,49 @@ class SparseAddTest(test.TestCase):\n           [[1, 3]],  # ...so is 3.\n       ]:\n         sparse = sparse_tensor.SparseTensorValue(bad_idx, val, shape)\n-        s = sparse_ops.sparse_add(sparse, dense)\n-\n-        with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n-                                    \"invalid index\"):\n+        with self.assertRaisesRegex(\n+            (ValueError, errors_impl.InvalidArgumentError), \"invalid index\"):\n+          s = sparse_ops.sparse_add(sparse, dense)\n           self.evaluate(s)\n \n+  def _testSparseDenseInvalidInputs(self,\n+                                    a_indices,\n+                                    a_values,\n+                                    a_shape,\n+                                    b,\n+                                    expected_error=\"\"):\n+    # Public API call to sparse-dense add.\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                expected_error):\n+      a = sparse_tensor.SparseTensor(a_indices, a_values, a_shape)\n+      self.evaluate(sparse_ops.sparse_add(a, b))\n+    # Directly call generated kernel, by-passing SparseTensor validation.\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                expected_error):\n+      self.evaluate(\n+          sparse_ops.gen_sparse_ops.sparse_tensor_dense_add(\n+              a_indices, a_values, a_shape, b))\n+\n+  def testSparseDenseInvalidInputs(self):\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(0, shape=[17, 2], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[5], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"Dimensions 17 and 5 are not compatible\")\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(0, shape=[17, 4], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[17], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"Dimensions 4 and 2 are not compatible\")\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(7, shape=[17, 2], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[17], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"invalid index\")\n+\n ######################## Benchmarking code\n \n \n",
        "@@ -665,7 +665,7 @@ class SparseFillEmptyRowsTest(test_util.TensorFlowTestCase):\n class SparseAddTest(test_util.TensorFlowTestCase):\n \n   def testValuesInVariable(self):\n-    indices = constant_op.constant([[1]], dtype=dtypes.int64)\n+    indices = constant_op.constant([[0]], dtype=dtypes.int64)\n     values = variables.Variable([1], trainable=False, dtype=dtypes.float32)\n     shape = constant_op.constant([1], dtype=dtypes.int64)\n \n"
    ],
    "Buggy Code": [
        [
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/util/sparse/sparse_tensor.h\""
        ],
        [
            "  }",
            "  if (a_shape->NumElements() != b->dims()) {",
            "    return errors::InvalidArgument(",
            "        \"Two operands have different ranks; received: \", a_shape->NumElements(),",
            "        \" and \", b->dims());",
            "  }",
            "  const auto a_shape_flat = a_shape->flat<Index>();",
            "  for (int i = 0; i < b->dims(); ++i) {",
            "    if (a_shape_flat(i) != b->dim_size(i)) {",
            "      return errors::InvalidArgument(",
            "          \"Dimension \", i,",
            "          \" does not equal (no broadcasting is supported): sparse side \",",
            "          a_shape_flat(i), \" vs dense side \", b->dim_size(i));",
            "    }",
            "  }",
            "  return Status::OK();",
            "}"
        ],
        [
            "  void Compute(OpKernelContext *ctx) override {",
            "    const Tensor *a_indices_t, *a_values_t, *a_shape_t, *b;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"a_indices\", &a_indices_t));",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"a_values\", &a_values_t));",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"a_shape\", &a_shape_t));",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"b\", &b));",
            "    OP_REQUIRES_OK(",
            "        ctx, ValidateInputs<Index>(a_indices_t, a_values_t, a_shape_t, b));",
            "",
            "    Tensor *out_t;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, b->shape(), &out_t));",
            "",
            "    const int ndims = static_cast<int>(a_indices_t->dim_size(1));",
            "    const auto a_indices_mat = a_indices_t->flat_inner_dims<Index>();",
            "    const auto a_values_flat = a_values_t->flat<T>();",
            "",
            "    switch (ndims) {",
            "#define NDIMS_CASE(N)                                                     \\",
            "  case N: {                                                               \\",
            "    auto out_tensor = out_t->tensor<T, N>();                              \\",
            "    out_tensor.device(ctx->eigen_device<Device>()) = b->tensor<T, N>();   \\",
            "    const Index result =                                                  \\",
            "        functor::ScatterNdFunctor<Device, T, Index, N,                    \\",
            "                                  scatter_op::UpdateOp::ADD>()(           \\"
        ]
    ],
    "Clean Code": [
        [
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\""
        ],
        [
            "        a_shape->shape().DebugString());",
            "  }",
            "  int64_t nnz = a_indices->dim_size(0);",
            "  int64_t ndims = a_indices->dim_size(1);",
            "  if (a_values->dim_size(0) != nnz) {",
            "    return errors::InvalidArgument(\"Dimensions \", nnz, \" and \",",
            "                                   a_values->dim_size(0),",
            "                                   \" are not compatible\");",
            "  }",
            "  if (a_shape->dim_size(0) != ndims) {",
            "    return errors::InvalidArgument(\"Dimensions \", ndims, \" and \",",
            "                                   a_shape->dim_size(0), \" are not compatible\");",
            "  }",
            "  if (a_shape->NumElements() != b->dims()) {",
            "    return errors::InvalidArgument(",
            "        \"Two operands have different ranks; received: \", a_shape->NumElements(),",
            "        \" and \", b->dims());"
        ],
        [
            "    }",
            "  }",
            "",
            "  // Check for invalid indices.",
            "  const auto a_indices_mat = a_indices->flat_inner_dims<Index>();",
            "",
            "  for (int64_t zidx = 0; zidx < nnz; ++zidx) {",
            "    for (int64_t didx = 0; didx < ndims; ++didx) {",
            "      const Index idx = a_indices_mat(zidx, didx);",
            "      if (idx < 0 || idx >= a_shape_flat(didx)) {",
            "        return errors::InvalidArgument(",
            "            \"Sparse tensor has an invalid index on dimension \", didx,",
            "            \": \"",
            "            \"a_indices(\",",
            "            zidx, \",\", didx, \") = \", idx,",
            "            \", dense tensor shape: \", a_shape_flat);",
            "      }",
            "    }",
            "  }",
            "",
            "  return Status::OK();",
            "}",
            "",
            "}  // namespace"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rc9w-5c64-9vqq",
    "API Signature": "tf.raw_ops.SparseTensorDenseAdd(\n    a_indices, a_values, a_shape, b, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "a_values = tf.constant([], shape=[0], dtype=tf.float32)\na_shape = tf.constant([6, 12], shape=[2], dtype=tf.int64) a_indices = tf.constant(0, shape=[17, 2], dtype=tf.int64)"
},
{
    "Title": "\n        Undefined behavior when users supply invalid resource handles\n      ",
    "Bug description": "Multiple TensorFlow operations misbehave in eager mode when the resource handle provided to them is invalid:",
    "Sample Code": " tensorflow as tf\n\ntf.summary.flush(writer=())",
    "Code change": [
        "@@ -304,6 +304,9 @@ Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n     const Tensor* tensor;\n     // TODO(fishx): Avoid blocking here.\n     TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));\n+    if (tensor->NumElements() == 0) {\n+      return errors::InvalidArgument(\"Empty resource handle\");\n+    }\n     const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);\n     device_name = handle.device();\n \n"
    ],
    "Buggy Code": [
        [
            "    // TODO(fishx): Avoid blocking here.",
            "    TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));",
            "    const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);",
            "    device_name = handle.device();",
            "",
            "    Device* input_device;",
            "    TF_RETURN_IF_ERROR(",
            "        ctx.FindDeviceFromName(device_name.c_str(), &input_device));",
            "    *result = input_device;"
        ]
    ],
    "Clean Code": [
        [
            "    // TODO(fishx): Avoid blocking here.",
            "    TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));",
            "    if (tensor->NumElements() == 0) {",
            "      return errors::InvalidArgument(\"Empty resource handle\");",
            "    }",
            "    const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);",
            "    device_name = handle.device();",
            "",
            "    Device* input_device;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5wpj-c6f7-24x8",
    "API Signature": "tf.raw_ops.QueueIsClosedV2(\n    handle, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "handle=[]"
},
{
    "Title": "\n        Undefined behavior when users supply invalid resource handles\n      ",
    "Bug description": "Multiple TensorFlow operations misbehave in eager mode when the resource handle provided to them is invalid:",
    "Sample Code": " tensorflow as tf\n\ntf.summary.flush(writer=())",
    "Code change": [
        "@@ -304,6 +304,9 @@ Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n     const Tensor* tensor;\n     // TODO(fishx): Avoid blocking here.\n     TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));\n+    if (tensor->NumElements() == 0) {\n+      return errors::InvalidArgument(\"Empty resource handle\");\n+    }\n     const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);\n     device_name = handle.device();\n \n"
    ],
    "Buggy Code": [
        [
            "    // TODO(fishx): Avoid blocking here.",
            "    TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));",
            "    const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);",
            "    device_name = handle.device();",
            "",
            "    Device* input_device;",
            "    TF_RETURN_IF_ERROR(",
            "        ctx.FindDeviceFromName(device_name.c_str(), &input_device));",
            "    *result = input_device;"
        ]
    ],
    "Clean Code": [
        [
            "    // TODO(fishx): Avoid blocking here.",
            "    TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));",
            "    if (tensor->NumElements() == 0) {",
            "      return errors::InvalidArgument(\"Empty resource handle\");",
            "    }",
            "    const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);",
            "    device_name = handle.device();",
            "",
            "    Device* input_device;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5wpj-c6f7-24x8",
    "API Signature": "tf.summary.flush(\n    writer=None, name=None\n)\n",
    "Score": 0.0035971223021582736,
    "Anomaly": "Empty input argument",
    "Anomaly Description": "Empty input argument",
    "Category": "TF_OBJECT",
    "Argument": "writer=()"
},
{
    "Title": "\n        Missing validation causes denial of service via `Conv3DBackpropFilterV2`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.Conv3DBackpropFilterV2  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.Conv3DBackpropFilterV2(\n  input=tf.constant(.5053710941, shape=[2,2,2,2,1], dtype=tf.float16),\n  filter_sizes=tf.constant(0, shape=[], dtype=tf.int32),\n  out_backprop=tf.constant(.5053710941, shape=[2,2,2,2,1], dtype=tf.float16),\n  strides=[1, 1, 1, 1, 1],\n  padding=\"VALID\",\n  data_format=\"NDHWC\",\n  ,\n  dilations=[1, 1, 1, 1, 1])",
    "Code change": [
        "@@ -741,6 +741,10 @@ class Conv3DBackpropFilterOp : public OpKernel {\n     TensorShape filter_shape;\n     if (takes_shape_) {\n       const Tensor& filter_sizes = context->input(1);\n+      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),\n+                  errors::InvalidArgument(\n+                      \"filter_sizes shape must be rank 1 but is rank \",\n+                      filter_sizes.shape().dims()));\n       OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                   filter_sizes.vec<int32>(), &filter_shape));\n     } else {\n@@ -875,6 +879,10 @@ class Conv3DCustomBackpropFilterOp : public OpKernel {\n     TensorShape filter_shape;\n     if (takes_shape_) {\n       const Tensor& filter_sizes = context->input(1);\n+      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),\n+                  errors::InvalidArgument(\n+                      \"filter_sizes shape must be rank 1 but is rank \",\n+                      filter_sizes.shape().dims()));\n       OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                   filter_sizes.vec<int32>(), &filter_shape));\n     } else {\n@@ -1638,6 +1646,10 @@ class Conv3DBackpropFilterOp<GPUDevice, T> : public OpKernel {\n     TensorShape filter_shape;\n     if (takes_shape_) {\n       const Tensor& filter_sizes = context->input(1);\n+      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),\n+                  errors::InvalidArgument(\n+                      \"filter_sizes shape must be rank 1 but is rank \",\n+                      filter_sizes.shape().dims()));\n       OP_REQUIRES_OK(context, tensor::MakeShape(filter_sizes, &filter_shape));\n     } else {\n       filter_shape = context->input(1).shape();\n",
        "@@ -18,6 +18,7 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gradient_checker\n@@ -58,6 +59,23 @@ class Conv3DBackpropFilterV2GradTest(test.TestCase):\n           err_tolerance = 1e-3\n           self.assertLess(err, err_tolerance)\n \n+  def testBadFilterShape(self):\n+    strides = [1, 1, 1, 1, 1]\n+    padding = \"VALID\"\n+    tin = constant_op.constant(\n+        .5053710941, shape=[2, 2, 2, 2, 1], dtype=dtypes.float32)\n+    filter_sizes = constant_op.constant(0, shape=[], dtype=dtypes.int32)\n+    out_backprop = constant_op.constant(\n+        .5053710941, shape=[2, 2, 2, 2, 1], dtype=dtypes.float32)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      nn_ops.conv3d_backprop_filter_v2(\n+          input=tin,\n+          filter_sizes=filter_sizes,\n+          out_backprop=out_backprop,\n+          strides=strides,\n+          padding=padding)\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "    if (takes_shape_) {",
            "      const Tensor& filter_sizes = context->input(1);",
            "      OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(",
            "                                  filter_sizes.vec<int32>(), &filter_shape));",
            "    } else {",
            "      filter_shape = context->input(1).shape();",
            "    }",
            "",
            "    OP_REQUIRES(context, input_shape.dims() == 5,",
            "                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));"
        ],
        [
            "    } else {",
            "      filter_shape = context->input(1).shape();",
            "    }",
            "",
            "    OP_REQUIRES(context, input_shape.dims() == 5,",
            "                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, filter_shape.dims() == 5,",
            "        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));",
            "    OP_REQUIRES("
        ],
        [
            "    OP_REQUIRES_OK(",
            "        context,",
            "        ConvBackpropComputeDimensionsV2(",
            "            \"Conv3DBackpropFilterOp\", /*num_spatial_dims=*/3, input_shape,",
            "            filter_shape, out_backprop_shape, dilation_, stride_, padding_,",
            "            /*explicit_paddings=*/{}, data_format_, &dims));",
            "",
            "    Tensor* filter_backprop;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, filter_shape, &filter_backprop));"
        ]
    ],
    "Clean Code": [
        [
            "    if (takes_shape_) {",
            "      const Tensor& filter_sizes = context->input(1);",
            "      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),",
            "                  errors::InvalidArgument(",
            "                      \"filter_sizes shape must be rank 1 but is rank \",",
            "                      filter_sizes.shape().dims()));",
            "      OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(",
            "                                  filter_sizes.vec<int32>(), &filter_shape));",
            "    } else {",
            "      filter_shape = context->input(1).shape();"
        ],
        [
            "    if (takes_shape_) {",
            "      const Tensor& filter_sizes = context->input(1);",
            "      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),",
            "                  errors::InvalidArgument(",
            "                      \"filter_sizes shape must be rank 1 but is rank \",",
            "                      filter_sizes.shape().dims()));",
            "      OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(",
            "                                  filter_sizes.vec<int32>(), &filter_shape));",
            "    } else {",
            "      filter_shape = context->input(1).shape();"
        ],
        [
            "    if (takes_shape_) {",
            "      const Tensor& filter_sizes = context->input(1);",
            "      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),",
            "                  errors::InvalidArgument(",
            "                      \"filter_sizes shape must be rank 1 but is rank \",",
            "                      filter_sizes.shape().dims()));",
            "      OP_REQUIRES_OK(context, tensor::MakeShape(filter_sizes, &filter_shape));",
            "    } else {",
            "      filter_shape = context->input(1).shape();",
            "    }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5v77-j66x-4c4g",
    "API Signature": "tf.raw_ops.Conv3DBackpropFilterV2(\n    input,\n    filter_sizes,\n    out_backprop,\n    strides,\n    padding,\n    data_format='NDHWC',\n    dilations=[1, 1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "filter_sizes=tf.constant(0, shape=[], dtype=tf.int32)"
},
{
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
        "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
        "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Buggy Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),",
            "        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),",
            "        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),",
            "        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),",
            "        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),",
            "        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),",
            "        h_tensor->matrix<T>());",
            "  }",
            "",
            " private:",
            "  float forget_bias_;",
            "  float cell_clip_;",
            "  bool use_peephole_;",
            "};",
            "",
            "#define REGISTER_KERNEL(T)                                             \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<CPUDevice, T, false, ICFO>);",
            "",
            "REGISTER_KERNEL(Eigen::half);",
            "REGISTER_KERNEL(float);",
            "#undef REGISTER_KERNEL",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "#define REGISTER_GPU_KERNEL(T)                                         \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<GPUDevice, T, true, ICFO>);",
            "",
            "REGISTER_GPU_KERNEL(Eigen::half);",
            "REGISTER_GPU_KERNEL(float);",
            "#undef REGISTER_GPU_KERNEL",
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "",
            "template <typename Device, typename T, bool USE_CUBLAS, GateLayout gate_layout>",
            "class LSTMBlockCellGradOp : public OpKernel {",
            " public:",
            "  explicit LSTMBlockCellGradOp(OpKernelConstruction* ctx) : OpKernel(ctx) {",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"use_peephole\", &use_peephole_));",
            "  }",
            "",
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor* x_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));",
            "",
            "    const Tensor* cs_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));",
            "",
            "    const Tensor* h_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));",
            "",
            "    const Tensor* w_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));",
            "",
            "    const Tensor* wci_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));",
            "",
            "    const Tensor* wcf_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));"
        ]
    ],
    "Clean Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    // Sanity check that each of the tensors have the required NDIMS.",
            "    OP_REQUIRES(ctx, x_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",",
            "                                        x_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, cs_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",",
            "                                cs_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, h_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",",
            "                                h_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, w_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",",
            "                                        w_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wci_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wcf_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wco_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",",
            "                                wco_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, b_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",",
            "                                        b_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, xh_tensor.dims() == 2,",
            "                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",",
            "                                        xh_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, i_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",",
            "                                        i_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, cs_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",",
            "                                        cs_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, f_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",",
            "                                        f_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, o_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",",
            "                                        o_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, ci_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",",
            "                                        ci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, co_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",",
            "                                        co_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, gates_tensor.dims() == 2,",
            "        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",",
            "                                gates_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, h_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",",
            "                                        h_tensor->dims(), \".\"));",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),"
},
{
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
        "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
        "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Buggy Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),",
            "        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),",
            "        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),",
            "        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),",
            "        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),",
            "        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),",
            "        h_tensor->matrix<T>());",
            "  }",
            "",
            " private:",
            "  float forget_bias_;",
            "  float cell_clip_;",
            "  bool use_peephole_;",
            "};",
            "",
            "#define REGISTER_KERNEL(T)                                             \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<CPUDevice, T, false, ICFO>);",
            "",
            "REGISTER_KERNEL(Eigen::half);",
            "REGISTER_KERNEL(float);",
            "#undef REGISTER_KERNEL",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "#define REGISTER_GPU_KERNEL(T)                                         \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<GPUDevice, T, true, ICFO>);",
            "",
            "REGISTER_GPU_KERNEL(Eigen::half);",
            "REGISTER_GPU_KERNEL(float);",
            "#undef REGISTER_GPU_KERNEL",
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "",
            "template <typename Device, typename T, bool USE_CUBLAS, GateLayout gate_layout>",
            "class LSTMBlockCellGradOp : public OpKernel {",
            " public:",
            "  explicit LSTMBlockCellGradOp(OpKernelConstruction* ctx) : OpKernel(ctx) {",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"use_peephole\", &use_peephole_));",
            "  }",
            "",
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor* x_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));",
            "",
            "    const Tensor* cs_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));",
            "",
            "    const Tensor* h_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));",
            "",
            "    const Tensor* w_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));",
            "",
            "    const Tensor* wci_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));",
            "",
            "    const Tensor* wcf_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));"
        ]
    ],
    "Clean Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    // Sanity check that each of the tensors have the required NDIMS.",
            "    OP_REQUIRES(ctx, x_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",",
            "                                        x_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, cs_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",",
            "                                cs_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, h_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",",
            "                                h_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, w_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",",
            "                                        w_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wci_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wcf_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wco_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",",
            "                                wco_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, b_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",",
            "                                        b_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, xh_tensor.dims() == 2,",
            "                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",",
            "                                        xh_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, i_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",",
            "                                        i_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, cs_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",",
            "                                        cs_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, f_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",",
            "                                        f_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, o_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",",
            "                                        o_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, ci_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",",
            "                                        ci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, co_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",",
            "                                        co_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, gates_tensor.dims() == 2,",
            "        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",",
            "                                gates_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, h_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",",
            "                                        h_tensor->dims(), \".\"));",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),"
},
{
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
        "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
        "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Buggy Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),",
            "        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),",
            "        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),",
            "        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),",
            "        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),",
            "        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),",
            "        h_tensor->matrix<T>());",
            "  }",
            "",
            " private:",
            "  float forget_bias_;",
            "  float cell_clip_;",
            "  bool use_peephole_;",
            "};",
            "",
            "#define REGISTER_KERNEL(T)                                             \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<CPUDevice, T, false, ICFO>);",
            "",
            "REGISTER_KERNEL(Eigen::half);",
            "REGISTER_KERNEL(float);",
            "#undef REGISTER_KERNEL",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "#define REGISTER_GPU_KERNEL(T)                                         \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<GPUDevice, T, true, ICFO>);",
            "",
            "REGISTER_GPU_KERNEL(Eigen::half);",
            "REGISTER_GPU_KERNEL(float);",
            "#undef REGISTER_GPU_KERNEL",
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "",
            "template <typename Device, typename T, bool USE_CUBLAS, GateLayout gate_layout>",
            "class LSTMBlockCellGradOp : public OpKernel {",
            " public:",
            "  explicit LSTMBlockCellGradOp(OpKernelConstruction* ctx) : OpKernel(ctx) {",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"use_peephole\", &use_peephole_));",
            "  }",
            "",
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor* x_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));",
            "",
            "    const Tensor* cs_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));",
            "",
            "    const Tensor* h_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));",
            "",
            "    const Tensor* w_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));",
            "",
            "    const Tensor* wci_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));",
            "",
            "    const Tensor* wcf_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));"
        ]
    ],
    "Clean Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    // Sanity check that each of the tensors have the required NDIMS.",
            "    OP_REQUIRES(ctx, x_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",",
            "                                        x_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, cs_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",",
            "                                cs_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, h_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",",
            "                                h_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, w_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",",
            "                                        w_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wci_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wcf_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wco_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",",
            "                                wco_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, b_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",",
            "                                        b_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, xh_tensor.dims() == 2,",
            "                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",",
            "                                        xh_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, i_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",",
            "                                        i_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, cs_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",",
            "                                        cs_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, f_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",",
            "                                        f_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, o_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",",
            "                                        o_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, ci_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",",
            "                                        ci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, co_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",",
            "                                        co_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, gates_tensor.dims() == 2,",
            "        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",",
            "                                gates_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, h_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",",
            "                                        h_tensor->dims(), \".\"));",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),"
},
{
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
        "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
        "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Buggy Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),",
            "        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),",
            "        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),",
            "        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),",
            "        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),",
            "        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),",
            "        h_tensor->matrix<T>());",
            "  }",
            "",
            " private:",
            "  float forget_bias_;",
            "  float cell_clip_;",
            "  bool use_peephole_;",
            "};",
            "",
            "#define REGISTER_KERNEL(T)                                             \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<CPUDevice, T, false, ICFO>);",
            "",
            "REGISTER_KERNEL(Eigen::half);",
            "REGISTER_KERNEL(float);",
            "#undef REGISTER_KERNEL",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "#define REGISTER_GPU_KERNEL(T)                                         \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<GPUDevice, T, true, ICFO>);",
            "",
            "REGISTER_GPU_KERNEL(Eigen::half);",
            "REGISTER_GPU_KERNEL(float);",
            "#undef REGISTER_GPU_KERNEL",
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "",
            "template <typename Device, typename T, bool USE_CUBLAS, GateLayout gate_layout>",
            "class LSTMBlockCellGradOp : public OpKernel {",
            " public:",
            "  explicit LSTMBlockCellGradOp(OpKernelConstruction* ctx) : OpKernel(ctx) {",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"use_peephole\", &use_peephole_));",
            "  }",
            "",
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor* x_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));",
            "",
            "    const Tensor* cs_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));",
            "",
            "    const Tensor* h_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));",
            "",
            "    const Tensor* w_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));",
            "",
            "    const Tensor* wci_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));",
            "",
            "    const Tensor* wcf_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));"
        ]
    ],
    "Clean Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    // Sanity check that each of the tensors have the required NDIMS.",
            "    OP_REQUIRES(ctx, x_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",",
            "                                        x_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, cs_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",",
            "                                cs_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, h_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",",
            "                                h_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, w_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",",
            "                                        w_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wci_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wcf_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wco_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",",
            "                                wco_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, b_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",",
            "                                        b_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, xh_tensor.dims() == 2,",
            "                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",",
            "                                        xh_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, i_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",",
            "                                        i_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, cs_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",",
            "                                        cs_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, f_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",",
            "                                        f_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, o_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",",
            "                                        o_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, ci_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",",
            "                                        ci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, co_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",",
            "                                        co_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, gates_tensor.dims() == 2,",
            "        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",",
            "                                gates_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, h_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",",
            "                                        h_tensor->dims(), \".\"));",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),"
},
{
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
        "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
        "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Buggy Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),",
            "        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),",
            "        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),",
            "        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),",
            "        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),",
            "        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),",
            "        h_tensor->matrix<T>());",
            "  }",
            "",
            " private:",
            "  float forget_bias_;",
            "  float cell_clip_;",
            "  bool use_peephole_;",
            "};",
            "",
            "#define REGISTER_KERNEL(T)                                             \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<CPUDevice, T, false, ICFO>);",
            "",
            "REGISTER_KERNEL(Eigen::half);",
            "REGISTER_KERNEL(float);",
            "#undef REGISTER_KERNEL",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "#define REGISTER_GPU_KERNEL(T)                                         \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<GPUDevice, T, true, ICFO>);",
            "",
            "REGISTER_GPU_KERNEL(Eigen::half);",
            "REGISTER_GPU_KERNEL(float);",
            "#undef REGISTER_GPU_KERNEL",
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "",
            "template <typename Device, typename T, bool USE_CUBLAS, GateLayout gate_layout>",
            "class LSTMBlockCellGradOp : public OpKernel {",
            " public:",
            "  explicit LSTMBlockCellGradOp(OpKernelConstruction* ctx) : OpKernel(ctx) {",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"use_peephole\", &use_peephole_));",
            "  }",
            "",
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor* x_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));",
            "",
            "    const Tensor* cs_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));",
            "",
            "    const Tensor* h_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));",
            "",
            "    const Tensor* w_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));",
            "",
            "    const Tensor* wci_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));",
            "",
            "    const Tensor* wcf_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));"
        ]
    ],
    "Clean Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    // Sanity check that each of the tensors have the required NDIMS.",
            "    OP_REQUIRES(ctx, x_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",",
            "                                        x_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, cs_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",",
            "                                cs_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, h_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",",
            "                                h_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, w_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",",
            "                                        w_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wci_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wcf_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wco_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",",
            "                                wco_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, b_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",",
            "                                        b_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, xh_tensor.dims() == 2,",
            "                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",",
            "                                        xh_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, i_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",",
            "                                        i_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, cs_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",",
            "                                        cs_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, f_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",",
            "                                        f_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, o_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",",
            "                                        o_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, ci_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",",
            "                                        ci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, co_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",",
            "                                        co_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, gates_tensor.dims() == 2,",
            "        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",",
            "                                gates_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, h_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",",
            "                                        h_tensor->dims(), \".\"));",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "wci=tf.constant(0, shape=[], dtype=tf.float32),"
},
{
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
        "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
        "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Buggy Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),",
            "        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),",
            "        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),",
            "        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),",
            "        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),",
            "        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),",
            "        h_tensor->matrix<T>());",
            "  }",
            "",
            " private:",
            "  float forget_bias_;",
            "  float cell_clip_;",
            "  bool use_peephole_;",
            "};",
            "",
            "#define REGISTER_KERNEL(T)                                             \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<CPUDevice, T, false, ICFO>);",
            "",
            "REGISTER_KERNEL(Eigen::half);",
            "REGISTER_KERNEL(float);",
            "#undef REGISTER_KERNEL",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "#define REGISTER_GPU_KERNEL(T)                                         \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<GPUDevice, T, true, ICFO>);",
            "",
            "REGISTER_GPU_KERNEL(Eigen::half);",
            "REGISTER_GPU_KERNEL(float);",
            "#undef REGISTER_GPU_KERNEL",
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "",
            "template <typename Device, typename T, bool USE_CUBLAS, GateLayout gate_layout>",
            "class LSTMBlockCellGradOp : public OpKernel {",
            " public:",
            "  explicit LSTMBlockCellGradOp(OpKernelConstruction* ctx) : OpKernel(ctx) {",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"use_peephole\", &use_peephole_));",
            "  }",
            "",
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor* x_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));",
            "",
            "    const Tensor* cs_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));",
            "",
            "    const Tensor* h_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));",
            "",
            "    const Tensor* w_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));",
            "",
            "    const Tensor* wci_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));",
            "",
            "    const Tensor* wcf_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));"
        ]
    ],
    "Clean Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    // Sanity check that each of the tensors have the required NDIMS.",
            "    OP_REQUIRES(ctx, x_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",",
            "                                        x_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, cs_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",",
            "                                cs_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, h_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",",
            "                                h_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, w_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",",
            "                                        w_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wci_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wcf_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wco_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",",
            "                                wco_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, b_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",",
            "                                        b_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, xh_tensor.dims() == 2,",
            "                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",",
            "                                        xh_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, i_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",",
            "                                        i_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, cs_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",",
            "                                        cs_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, f_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",",
            "                                        f_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, o_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",",
            "                                        o_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, ci_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",",
            "                                        ci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, co_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",",
            "                                        co_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, gates_tensor.dims() == 2,",
            "        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",",
            "                                gates_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, h_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",",
            "                                        h_tensor->dims(), \".\"));",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "wcf=tf.constant(0, shape=[17], dtype=tf.float32),"
},
{
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
        "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
        "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Buggy Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),",
            "        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),",
            "        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),",
            "        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),",
            "        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),",
            "        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),",
            "        h_tensor->matrix<T>());",
            "  }",
            "",
            " private:",
            "  float forget_bias_;",
            "  float cell_clip_;",
            "  bool use_peephole_;",
            "};",
            "",
            "#define REGISTER_KERNEL(T)                                             \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<CPUDevice, T, false, ICFO>);",
            "",
            "REGISTER_KERNEL(Eigen::half);",
            "REGISTER_KERNEL(float);",
            "#undef REGISTER_KERNEL",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "#define REGISTER_GPU_KERNEL(T)                                         \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<GPUDevice, T, true, ICFO>);",
            "",
            "REGISTER_GPU_KERNEL(Eigen::half);",
            "REGISTER_GPU_KERNEL(float);",
            "#undef REGISTER_GPU_KERNEL",
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "",
            "template <typename Device, typename T, bool USE_CUBLAS, GateLayout gate_layout>",
            "class LSTMBlockCellGradOp : public OpKernel {",
            " public:",
            "  explicit LSTMBlockCellGradOp(OpKernelConstruction* ctx) : OpKernel(ctx) {",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"use_peephole\", &use_peephole_));",
            "  }",
            "",
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor* x_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));",
            "",
            "    const Tensor* cs_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));",
            "",
            "    const Tensor* h_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));",
            "",
            "    const Tensor* w_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));",
            "",
            "    const Tensor* wci_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));",
            "",
            "    const Tensor* wcf_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));"
        ]
    ],
    "Clean Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    // Sanity check that each of the tensors have the required NDIMS.",
            "    OP_REQUIRES(ctx, x_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",",
            "                                        x_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, cs_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",",
            "                                cs_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, h_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",",
            "                                h_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, w_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",",
            "                                        w_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wci_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wcf_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wco_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",",
            "                                wco_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, b_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",",
            "                                        b_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, xh_tensor.dims() == 2,",
            "                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",",
            "                                        xh_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, i_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",",
            "                                        i_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, cs_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",",
            "                                        cs_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, f_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",",
            "                                        f_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, o_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",",
            "                                        o_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, ci_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",",
            "                                        ci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, co_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",",
            "                                        co_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, gates_tensor.dims() == 2,",
            "        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",",
            "                                gates_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, h_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",",
            "                                        h_tensor->dims(), \".\"));",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),"
},
{
    "Title": "\n        Missing validation causes denial of service via `LSTMBlockCell`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LSTMBlockCell  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.LSTMBlockCell( \n  x=tf.constant(0.837607, shape=[28,29], dtype=tf.float32),\n  cs_prev=tf.constant(0, shape=[28,17], dtype=tf.float32),\n  h_prev=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  w=tf.constant(0.887386262, shape=[46,68], dtype=tf.float32),\n  wci=tf.constant(0, shape=[], dtype=tf.float32),\n  wcf=tf.constant(0, shape=[17], dtype=tf.float32),\n  wco=tf.constant(0.592631638, shape=[28,17], dtype=tf.float32),\n  b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),\n  ),\n  forget_bias=1, cell_clip=0, use_peephole=False)",
    "Code change": [
        "@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\n",
        "@@ -33,6 +33,7 @@ from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ class LSTMTest(test.TestCase):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
    ],
    "Buggy Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),",
            "        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),",
            "        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),",
            "        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),",
            "        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),",
            "        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),",
            "        h_tensor->matrix<T>());",
            "  }",
            "",
            " private:",
            "  float forget_bias_;",
            "  float cell_clip_;",
            "  bool use_peephole_;",
            "};",
            "",
            "#define REGISTER_KERNEL(T)                                             \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<CPUDevice, T, false, ICFO>);",
            "",
            "REGISTER_KERNEL(Eigen::half);",
            "REGISTER_KERNEL(float);",
            "#undef REGISTER_KERNEL",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "#define REGISTER_GPU_KERNEL(T)                                         \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\",
            "      Name(\"LSTMBlockCell\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
            "      LSTMBlockCellOp<GPUDevice, T, true, ICFO>);",
            "",
            "REGISTER_GPU_KERNEL(Eigen::half);",
            "REGISTER_GPU_KERNEL(float);",
            "#undef REGISTER_GPU_KERNEL",
            "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "",
            "template <typename Device, typename T, bool USE_CUBLAS, GateLayout gate_layout>",
            "class LSTMBlockCellGradOp : public OpKernel {",
            " public:",
            "  explicit LSTMBlockCellGradOp(OpKernelConstruction* ctx) : OpKernel(ctx) {",
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"use_peephole\", &use_peephole_));",
            "  }",
            "",
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor* x_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));",
            "",
            "    const Tensor* cs_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));",
            "",
            "    const Tensor* h_prev_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));",
            "",
            "    const Tensor* w_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));",
            "",
            "    const Tensor* wci_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));",
            "",
            "    const Tensor* wcf_tensor = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));"
        ]
    ],
    "Clean Code": [
        [
            "    const Device& device = ctx->eigen_device<Device>();",
            "",
            "    // Sanity check that each of the tensors have the required NDIMS.",
            "    OP_REQUIRES(ctx, x_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",",
            "                                        x_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, cs_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",",
            "                                cs_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, h_prev_tensor->dims() == 2,",
            "        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",",
            "                                h_prev_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, w_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",",
            "                                        w_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wci_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wcf_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",",
            "                                wci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, wco_tensor->dims() == 1,",
            "        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",",
            "                                wco_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, b_tensor->dims() == 1,",
            "                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",",
            "                                        b_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, xh_tensor.dims() == 2,",
            "                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",",
            "                                        xh_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, i_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",",
            "                                        i_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, cs_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",",
            "                                        cs_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, f_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",",
            "                                        f_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, o_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",",
            "                                        o_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, ci_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",",
            "                                        ci_tensor->dims(), \".\"));",
            "    OP_REQUIRES(ctx, co_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",",
            "                                        co_tensor->dims(), \".\"));",
            "    OP_REQUIRES(",
            "        ctx, gates_tensor.dims() == 2,",
            "        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",",
            "                                gates_tensor.dims(), \".\"));",
            "    OP_REQUIRES(ctx, h_tensor->dims() == 2,",
            "                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",",
            "                                        h_tensor->dims(), \".\"));",
            "",
            "    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(",
            "        batch_size, input_size, cell_size)(",
            "        ctx, device, forget_bias_, cell_clip_, use_peephole_,",
            "        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2vv3-56qg-g2cf",
    "API Signature": "tf.raw_ops.LSTMBlockCell(\n    x,\n    cs_prev,\n    h_prev,\n    w,\n    wci,\n    wcf,\n    wco,\n    b,\n    forget_bias=1,\n    cell_clip=3,\n    use_peephole=False,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "b=tf.constant(0.75259006, shape=[68], dtype=tf.float32),"
},
{
    "Title": "\n        Missing validation causes denial of service via `SparseTensorToCSRSparseMatrix`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SparseTensorToCSRSparseMatrix  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "indices = tf.constant(53, shape=[3], dtype=tf.int64)\nvalues = tf.constant(0.554979503, shape=[218650], dtype=tf.float32)\ndense_shape = tf.constant(53, shape=[3], dtype=tf.int64)\n    \ntf.raw_ops.SparseTensorToCSRSparseMatrix(\n  indices=indices,\n  values=values,\n  ,\n  dense_shape=dense_shape)",
    "Code change": [
        "@@ -67,6 +67,13 @@ class SparseTensorToCSRSparseMatrixCPUOp : public OpKernel {\n     const Tensor& values = ctx->input(1);\n     const Tensor& dense_shape = ctx->input(2);\n     const int rank = dense_shape.NumElements();\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsVector(dense_shape.shape()),\n+        errors::InvalidArgument(\"dense_shape must be rank 1 but got rank\",\n+                                dense_shape.shape().dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices.shape()),\n+                errors::InvalidArgument(\"indices must be rank 2 but got rank\",\n+                                        indices.shape().dims()));\n     OP_REQUIRES(ctx, rank == 2 || rank == 3,\n                 errors::InvalidArgument(\"SparseTensor must have rank 2 or 3; \",\n                                         \"but indices has rank: \", rank));\n",
        "@@ -168,6 +168,25 @@ class CSRSparseMatrixOpsTest(test.TestCase):\n     self.assertAllClose(a_values, a_st_rt_value.values)\n     self.assertAllEqual(a_dense_shape, a_st_rt_value.dense_shape)\n \n+  def testSparseTensorConversionInvalidInputShapes(self):\n+    values = constant_op.constant(\n+        0.554979503, shape=[5], dtype=dtypes.float32)\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      indices = constant_op.constant(0, shape=[5, 2], dtype=dtypes.int64)\n+      dense_shape = constant_op.constant(53, shape=[], dtype=dtypes.int64)\n+      csr = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n+          indices=indices, values=values, dense_shape=dense_shape)\n+      self.evaluate(csr)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 2\"):\n+      indices = constant_op.constant(0, shape=[5], dtype=dtypes.int64)\n+      dense_shape = constant_op.constant(53, shape=[1], dtype=dtypes.int64)\n+      csr = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n+          indices=indices, values=values, dense_shape=dense_shape)\n+      self.evaluate(csr)\n+\n   # TODO(b/139491352): Add handle_data propagation to array_ops.identity.\n   @test_util.run_deprecated_v1\n   def testCSRSparseMatrixResourceVariable(self):\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor& dense_shape = ctx->input(2);",
            "    const int rank = dense_shape.NumElements();",
            "    OP_REQUIRES(ctx, rank == 2 || rank == 3,",
            "                errors::InvalidArgument(\"SparseTensor must have rank 2 or 3; \",",
            "                                        \"but indices has rank: \", rank));",
            "    auto dense_shape_vec = dense_shape.vec<int64_t>();",
            "    const int64_t batch_size = (rank == 2) ? 1 : dense_shape_vec(0);",
            "    const int64_t num_rows = dense_shape_vec((rank == 2) ? 0 : 1);",
            "    const int64_t total_nnz = values.NumElements();",
            "",
            "    // Allocate output Tensors.",
            "    TensorShape batch_ptr_shape;",
            "    OP_REQUIRES_OK("
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor& dense_shape = ctx->input(2);",
            "    const int rank = dense_shape.NumElements();",
            "    OP_REQUIRES(",
            "        ctx, TensorShapeUtils::IsVector(dense_shape.shape()),",
            "        errors::InvalidArgument(\"dense_shape must be rank 1 but got rank\",",
            "                                dense_shape.shape().dims()));",
            "    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices.shape()),",
            "                errors::InvalidArgument(\"indices must be rank 2 but got rank\",",
            "                                        indices.shape().dims()));",
            "    OP_REQUIRES(ctx, rank == 2 || rank == 3,",
            "                errors::InvalidArgument(\"SparseTensor must have rank 2 or 3; \",",
            "                                        \"but indices has rank: \", rank));",
            "    auto dense_shape_vec = dense_shape.vec<int64_t>();"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mg66-qvc5-rm93",
    "API Signature": "tf.raw_ops.SparseTensorToCSRSparseMatrix(\n    indices, values, dense_shape, name=None\n)\n",
    "Score": 0.02158273381294964,
    "Anomaly": "Scalar input tensor",
    "Anomaly Description": "A scalar input tensor refers to a tensor with a rank of 0, meaning it has zero dimensions. In other words, a scalar input tensor represents a single value without any additional structure or dimensions.",
    "Category": "Tensor",
    "Argument": "indices = tf.constant(53, shape=[3], dtype=tf.int64)"
},
{
    "Title": "\n        Missing validation causes denial of service via `SparseTensorToCSRSparseMatrix`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SparseTensorToCSRSparseMatrix  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "indices = tf.constant(53, shape=[3], dtype=tf.int64)\nvalues = tf.constant(0.554979503, shape=[218650], dtype=tf.float32)\ndense_shape = tf.constant(53, shape=[3], dtype=tf.int64)\n    \ntf.raw_ops.SparseTensorToCSRSparseMatrix(\n  indices=indices,\n  values=values,\n  ,\n  dense_shape=dense_shape)",
    "Code change": [
        "@@ -67,6 +67,13 @@ class SparseTensorToCSRSparseMatrixCPUOp : public OpKernel {\n     const Tensor& values = ctx->input(1);\n     const Tensor& dense_shape = ctx->input(2);\n     const int rank = dense_shape.NumElements();\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsVector(dense_shape.shape()),\n+        errors::InvalidArgument(\"dense_shape must be rank 1 but got rank\",\n+                                dense_shape.shape().dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices.shape()),\n+                errors::InvalidArgument(\"indices must be rank 2 but got rank\",\n+                                        indices.shape().dims()));\n     OP_REQUIRES(ctx, rank == 2 || rank == 3,\n                 errors::InvalidArgument(\"SparseTensor must have rank 2 or 3; \",\n                                         \"but indices has rank: \", rank));\n",
        "@@ -168,6 +168,25 @@ class CSRSparseMatrixOpsTest(test.TestCase):\n     self.assertAllClose(a_values, a_st_rt_value.values)\n     self.assertAllEqual(a_dense_shape, a_st_rt_value.dense_shape)\n \n+  def testSparseTensorConversionInvalidInputShapes(self):\n+    values = constant_op.constant(\n+        0.554979503, shape=[5], dtype=dtypes.float32)\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 1\"):\n+      indices = constant_op.constant(0, shape=[5, 2], dtype=dtypes.int64)\n+      dense_shape = constant_op.constant(53, shape=[], dtype=dtypes.int64)\n+      csr = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n+          indices=indices, values=values, dense_shape=dense_shape)\n+      self.evaluate(csr)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 2\"):\n+      indices = constant_op.constant(0, shape=[5], dtype=dtypes.int64)\n+      dense_shape = constant_op.constant(53, shape=[1], dtype=dtypes.int64)\n+      csr = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n+          indices=indices, values=values, dense_shape=dense_shape)\n+      self.evaluate(csr)\n+\n   # TODO(b/139491352): Add handle_data propagation to array_ops.identity.\n   @test_util.run_deprecated_v1\n   def testCSRSparseMatrixResourceVariable(self):\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor& dense_shape = ctx->input(2);",
            "    const int rank = dense_shape.NumElements();",
            "    OP_REQUIRES(ctx, rank == 2 || rank == 3,",
            "                errors::InvalidArgument(\"SparseTensor must have rank 2 or 3; \",",
            "                                        \"but indices has rank: \", rank));",
            "    auto dense_shape_vec = dense_shape.vec<int64_t>();",
            "    const int64_t batch_size = (rank == 2) ? 1 : dense_shape_vec(0);",
            "    const int64_t num_rows = dense_shape_vec((rank == 2) ? 0 : 1);",
            "    const int64_t total_nnz = values.NumElements();",
            "",
            "    // Allocate output Tensors.",
            "    TensorShape batch_ptr_shape;",
            "    OP_REQUIRES_OK("
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor& dense_shape = ctx->input(2);",
            "    const int rank = dense_shape.NumElements();",
            "    OP_REQUIRES(",
            "        ctx, TensorShapeUtils::IsVector(dense_shape.shape()),",
            "        errors::InvalidArgument(\"dense_shape must be rank 1 but got rank\",",
            "                                dense_shape.shape().dims()));",
            "    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices.shape()),",
            "                errors::InvalidArgument(\"indices must be rank 2 but got rank\",",
            "                                        indices.shape().dims()));",
            "    OP_REQUIRES(ctx, rank == 2 || rank == 3,",
            "                errors::InvalidArgument(\"SparseTensor must have rank 2 or 3; \",",
            "                                        \"but indices has rank: \", rank));",
            "    auto dense_shape_vec = dense_shape.vec<int64_t>();"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mg66-qvc5-rm93",
    "API Signature": "tf.raw_ops.SparseTensorToCSRSparseMatrix(\n    indices, values, dense_shape, name=None\n)\n",
    "Score": 0.02158273381294964,
    "Anomaly": "Scalar input tensor",
    "Anomaly Description": "A scalar input tensor refers to a tensor with a rank of 0, meaning it has zero dimensions. In other words, a scalar input tensor represents a single value without any additional structure or dimensions.",
    "Category": "Tensor",
    "Argument": "values = tf.constant(0.554979503, shape=[218650], dtype=tf.float32)"
},
{
    "Title": "\n        Missing validation causes denial of service via `LoadAndRemapMatrix`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.LoadAndRemapMatrix  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "ckpt_path = tf.constant(\n    \"/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0\", shape=[], dtype=tf.string)\nold_tensor_name = tf.constant(\n    \"/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0\", shape=[], dtype=tf.string)\n\nrow_remapping = tf.constant(0, shape=[], dtype=tf.int64)\ncol_remapping = tf.constant(3, shape=[3], dtype=tf.int64)\ninitializing_values = tf.constant([], shape=[0, 1], dtype=tf.float32)\n\ntf.raw_ops.LoadAndRemapMatrix(\n  ckpt_path=ckpt_path,\n  old_tensor_name=old_tensor_name,\n  row_remapping=row_remapping,\n  col_remapping=col_remapping,\n  initializing_values=initializing_values,\n  num_rows=1,\n  ,\n  num_cols=1)",
    "Code change": [
        "@@ -74,6 +74,11 @@ class LoadAndRemapMatrixOp : public OpKernel {\n     std::vector<bool> row_id_present;\n     const Tensor* row_remapping_t;\n     OP_REQUIRES_OK(context, context->input(\"row_remapping\", &row_remapping_t));\n+    OP_REQUIRES(\n+        context, row_remapping_t->dims() == 1,\n+        errors::InvalidArgument(\"The `row_remapping` tensor must be 1-D, got \"\n+                                \"a tensor of shape \",\n+                                row_remapping_t->shape().DebugString()));\n     const auto row_remapping = row_remapping_t->vec<int64_t>();\n     OP_REQUIRES(context, row_remapping.size() == num_rows_,\n                 errors::InvalidArgument(strings::StrCat(\n",
        "@@ -227,6 +227,32 @@ class LoadAndRemapMatrixTest(test.TestCase):\n           np.reshape(initializing_values, (num_rows, num_cols)),\n           self.evaluate(remapped_matrix))\n \n+  def test_load_and_remap_invalid_dims(self):\n+    ckpt_path = constant_op.constant(\n+        '/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0',\n+        shape=[],\n+        dtype=dtypes.string)\n+    old_tensor_name = constant_op.constant(\n+        '/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0',\n+        shape=[],\n+        dtype=dtypes.string)\n+    row_remapping = constant_op.constant(0, shape=[], dtype=dtypes.int64)\n+    col_remapping = constant_op.constant(3, shape=[3], dtype=dtypes.int64)\n+    initializing_values = constant_op.constant([],\n+                                               shape=[0, 1],\n+                                               dtype=dtypes.float32)\n+    with self.cached_session(), self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError), 'tensor must be 1-D'):\n+      self.evaluate(\n+          gen_checkpoint_ops.load_and_remap_matrix(\n+              ckpt_path=ckpt_path,\n+              old_tensor_name=old_tensor_name,\n+              row_remapping=row_remapping,\n+              col_remapping=col_remapping,\n+              initializing_values=initializing_values,\n+              num_rows=1,\n+              num_cols=1))\n+\n   @test_util.run_deprecated_v1\n   def test_load_and_remap_invalid_remapping(self):\n     \"\"\"Tests that errors are raised when an ID maps to multiple new IDs.\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor* row_remapping_t;",
            "    OP_REQUIRES_OK(context, context->input(\"row_remapping\", &row_remapping_t));",
            "    const auto row_remapping = row_remapping_t->vec<int64_t>();",
            "    OP_REQUIRES(context, row_remapping.size() == num_rows_,",
            "                errors::InvalidArgument(strings::StrCat(",
            "                    \"Size of row_remapping is \", row_remapping.size(),",
            "                    \" instead of being equal to num_rows=\", num_rows_)));",
            "    OP_REQUIRES_OK(context, RemapVectorToMap(row_remapping, &row_id_present,",
            "                                             &old_row_to_new_row_map));",
            "",
            "    // Calculates the min/max old row ID that we need to read, to save us from"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor* row_remapping_t;",
            "    OP_REQUIRES_OK(context, context->input(\"row_remapping\", &row_remapping_t));",
            "    OP_REQUIRES(",
            "        context, row_remapping_t->dims() == 1,",
            "        errors::InvalidArgument(\"The `row_remapping` tensor must be 1-D, got \"",
            "                                \"a tensor of shape \",",
            "                                row_remapping_t->shape().DebugString()));",
            "    const auto row_remapping = row_remapping_t->vec<int64_t>();",
            "    OP_REQUIRES(context, row_remapping.size() == num_rows_,",
            "                errors::InvalidArgument(strings::StrCat(",
            "                    \"Size of row_remapping is \", row_remapping.size(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-p9rc-rmr5-529j",
    "API Signature": "tf.raw_ops.LoadAndRemapMatrix(\n    ckpt_path,\n    old_tensor_name,\n    row_remapping,\n    col_remapping,\n    initializing_values,\n    num_rows,\n    num_cols,\n    max_rows_in_memory=-1,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "initializing_values = tf.constant([], shape=[0, 1], dtype=tf.float32)"
},
{
    "Title": "\n        Missing validation causes denial of service via `UnsortedSegmentJoin`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.UnsortedSegmentJoin  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.UnsortedSegmentJoin(\n  inputs=tf.constant(\"this\", shape=[12], dtype=tf.string),\n  segment_ids=tf.constant(0, shape=[12], dtype=tf.int64),\n  ),\n  num_segments=tf.constant(0, shape=[12], dtype=tf.int64))",
    "Code change": [
        "@@ -92,6 +92,9 @@ class UnsortedSegmentJoinOp : public OpKernel {\n     const Tensor& num_segments_tensor = context->input(2);\n     OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,\n                 errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n+    OP_REQUIRES(context,\n+                TensorShapeUtils::IsScalar(num_segments_tensor.shape()),\n+                errors::InvalidArgument(\"Number of segments must be a scalar\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n     OP_REQUIRES(\n"
    ],
    "Buggy Code": [
        [
            "    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,",
            "                errors::InvalidArgument(\"Number of segments cannot be empty.\"));",
            "    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();",
            "",
            "    OP_REQUIRES(",
            "        context, num_segments >= 0,",
            "        errors::InvalidArgument(",
            "            \"Number of segments must be non-negative but got \", num_segments));",
            "    OP_REQUIRES(context, segment_dims != 0,"
        ]
    ],
    "Clean Code": [
        [
            "    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,",
            "                errors::InvalidArgument(\"Number of segments cannot be empty.\"));",
            "    OP_REQUIRES(context,",
            "                TensorShapeUtils::IsScalar(num_segments_tensor.shape()),",
            "                errors::InvalidArgument(\"Number of segments must be a scalar\"));",
            "    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();",
            "",
            "    OP_REQUIRES(",
            "        context, num_segments >= 0,"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hrg5-737c-2p56",
    "API Signature": "tf.raw_ops.UnsortedSegmentJoin(\n    inputs, segment_ids, num_segments, separator='', name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "num_segments=tf.constant(0, shape=[12], dtype=tf.int64))"
},
{
    "Title": "\n        Missing validation causes denial of service via `StagePeek`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.StagePeek  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "index = tf.constant([], shape=[0], dtype=tf.int32)\n)\ntf.raw_ops.StagePeek(index=index, dtypes=[tf.int32])",
    "Code change": [
        "@@ -258,6 +258,8 @@ class StagePeekOp : public OpKernel {\n     core::ScopedUnref scope(buf);\n     Buffer::Tuple tuple;\n \n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(ctx->input(0).shape()),\n+                errors::InvalidArgument(\"index must be scalar\"));\n     std::size_t index = ctx->input(0).scalar<int>()();\n \n     OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));\n",
        "@@ -13,6 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n@@ -134,6 +135,16 @@ class StageTest(test.TestCase):\n       for i in range(10):\n         self.assertTrue(sess.run(peek, feed_dict={p: i}) == [i])\n \n+  def testPeekBadIndex(self):\n+    stager = data_flow_ops.StagingArea([\n+        dtypes.int32,\n+    ], shapes=[[10]])\n+    stager.put([array_ops.zeros([10], dtype=dtypes.int32)])\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                'must be scalar'):\n+      self.evaluate(stager.peek([]))\n+\n   @test_util.run_deprecated_v1\n   def testSizeAndClear(self):\n     with ops.Graph().as_default() as G:\n",
        "@@ -1737,7 +1737,7 @@ class BaseStagingArea:\n \n     # Sanity check number of values\n     if not len(vals) <= len(self._dtypes):\n-      raise ValueError(f\"Unexpected number of inputs {len(vals)} vs\"\n+      raise ValueError(f\"Unexpected number of inputs {len(vals)} vs \"\n                        f\"{len(self._dtypes)}\")\n \n     tensors = []\n"
    ],
    "Buggy Code": [
        [
            "    Buffer::Tuple tuple;",
            "",
            "    std::size_t index = ctx->input(0).scalar<int>()();",
            "",
            "    OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));",
            "",
            "    OP_REQUIRES(",
            "        ctx, tuple.size() == (size_t)ctx->num_outputs(),"
        ],
        [
            "    # Sanity check number of values",
            "    if not len(vals) <= len(self._dtypes):",
            "      raise ValueError(f\"Unexpected number of inputs {len(vals)} vs\"",
            "                       f\"{len(self._dtypes)}\")",
            "",
            "    tensors = []",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    Buffer::Tuple tuple;",
            "",
            "    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(ctx->input(0).shape()),",
            "                errors::InvalidArgument(\"index must be scalar\"));",
            "    std::size_t index = ctx->input(0).scalar<int>()();",
            "",
            "    OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));",
            ""
        ],
        [
            "    # Sanity check number of values",
            "    if not len(vals) <= len(self._dtypes):",
            "      raise ValueError(f\"Unexpected number of inputs {len(vals)} vs \"",
            "                       f\"{len(self._dtypes)}\")",
            "",
            "    tensors = []",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h48f-q7rw-hvr7",
    "API Signature": "tf.raw_ops.StagePeek(\n    index,\n    dtypes,\n    capacity=0,\n    memory_limit=0,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "index = tf.constant([], shape=[0], dtype=tf.int32)"
},
{
    "Title": "\n        Missing validation causes denial of service via `GetSessionTensor`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.GetSessionTensor  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "handle = tf.constant(\"[]\", shape=[0], dtype=tf.string)\n)\ntf.raw_ops.GetSessionTensor(handle=handle)",
    "Code change": [
        "@@ -98,6 +98,8 @@ class GetSessionTensorOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& handle = ctx->input(0);\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),\n+                errors::InvalidArgument(\"handle must be scalar\"));\n     const string& name = handle.scalar<tstring>()();\n     Tensor val;\n     auto session_state = ctx->session_state();\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& handle = ctx->input(0);",
            "    const string& name = handle.scalar<tstring>()();",
            "    Tensor val;",
            "    auto session_state = ctx->session_state();",
            "    OP_REQUIRES(ctx, session_state != nullptr,",
            "                errors::FailedPrecondition(",
            "                    \"GetSessionTensor called on null session state\"));"
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& handle = ctx->input(0);",
            "    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),",
            "                errors::InvalidArgument(\"handle must be scalar\"));",
            "    const string& name = handle.scalar<tstring>()();",
            "    Tensor val;",
            "    auto session_state = ctx->session_state();",
            "    OP_REQUIRES(ctx, session_state != nullptr,"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fv25-wrff-wf86",
    "API Signature": "tf.raw_ops.GetSessionTensor(\n    handle, dtype, name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "handle = tf.constant(\"[]\", shape=[0], dtype=tf.string)"
},
{
    "Title": "\n        Missing validation causes denial of service via `DeleteSessionTensor`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.DeleteSessionTensor  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "handle = tf.constant(\"[]\", shape=[0], dtype=tf.string)\n)\ntf.raw_ops.DeleteSessionTensor(handle=handle)",
    "Code change": [
        "@@ -134,6 +134,8 @@ class DeleteSessionTensorOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& handle = ctx->input(0);\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),\n+                errors::InvalidArgument(\"`handle` must be scalar\"));\n     const string& name = handle.scalar<tstring>()();\n     auto session_state = ctx->session_state();\n     OP_REQUIRES(ctx, session_state != nullptr,\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& handle = ctx->input(0);",
            "    const string& name = handle.scalar<tstring>()();",
            "    auto session_state = ctx->session_state();",
            "    OP_REQUIRES(ctx, session_state != nullptr,",
            "                errors::FailedPrecondition(",
            "                    \"DeleteSessionTensor called on null session state\"));",
            "    OP_REQUIRES_OK(ctx, session_state->DeleteTensor(name));"
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& handle = ctx->input(0);",
            "    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),",
            "                errors::InvalidArgument(\"`handle` must be scalar\"));",
            "    const string& name = handle.scalar<tstring>()();",
            "    auto session_state = ctx->session_state();",
            "    OP_REQUIRES(ctx, session_state != nullptr,",
            "                errors::FailedPrecondition("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h5g4-ppwx-48q2",
    "API Signature": "tf.raw_ops.DeleteSessionTensor(\n    handle, name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "handle = tf.constant(\"[]\", shape=[0], dtype=tf.string)"
},
{
    "Title": "\n        Missing validation crashes `QuantizeAndDequantizeV4Grad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.QuantizeAndDequantizeV4Grad  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n  gradients=tf.constant(1, shape=[2,2], dtype=tf.float64),\n  input=tf.constant(1, shape=[2,2], dtype=tf.float64),\n  input_min=tf.constant([], shape=[0], dtype=tf.float64),\n  input_max=tf.constant(-10, shape=[], dtype=tf.float64),\n  ),\n  axis=-1)",
    "Code change": [
        "@@ -174,13 +174,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n     OP_REQUIRES(ctx,\n                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                 errors::InvalidArgument(\n-                    \"Input min tensor must have dimension 1. Recieved \",\n+                    \"Input min tensor must have dimension 0 or 1. Received \",\n                     input_min_tensor.dims(), \".\"));\n     const Tensor& input_max_tensor = ctx->input(3);\n     OP_REQUIRES(ctx,\n                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                 errors::InvalidArgument(\n-                    \"Input max tensor must have dimension 1. Recieved \",\n+                    \"Input max tensor must have dimension 0 or 1. Received \",\n                     input_max_tensor.dims(), \".\"));\n     if (axis_ != -1) {\n       OP_REQUIRES(\n@@ -203,6 +203,12 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n \n     if (axis_ == -1) {\n+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n+                  errors::InvalidArgument(\n+                      \"input_min must be a scalar if axis is unspecified\"));\n+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n+                  errors::InvalidArgument(\n+                      \"input_max must be a scalar if axis is unspecified\"));\n       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n         input.template flat<T>(), input_min_tensor.scalar<T>(),\n"
    ],
    "Buggy Code": [
        [
            "                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,",
            "                errors::InvalidArgument(",
            "                    \"Input min tensor must have dimension 1. Recieved \",",
            "                    input_min_tensor.dims(), \".\"));",
            "    const Tensor& input_max_tensor = ctx->input(3);",
            "    OP_REQUIRES(ctx,",
            "                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,",
            "                errors::InvalidArgument(",
            "                    \"Input max tensor must have dimension 1. Recieved \",",
            "                    input_max_tensor.dims(), \".\"));",
            "    if (axis_ != -1) {",
            "      OP_REQUIRES(",
            "          ctx, input_min_tensor.dim_size(0) == depth,"
        ],
        [
            "",
            "    if (axis_ == -1) {",
            "      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;",
            "      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),",
            "        input.template flat<T>(), input_min_tensor.scalar<T>(),",
            "        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),",
            "        input_min_backprop->template scalar<T>(),",
            "        input_max_backprop->template scalar<T>());",
            "    } else {",
            "      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;",
            "      f(ctx->eigen_device<Device>(),",
            "        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),"
        ]
    ],
    "Clean Code": [
        [
            "                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,",
            "                errors::InvalidArgument(",
            "                    \"Input min tensor must have dimension 0 or 1. Received \",",
            "                    input_min_tensor.dims(), \".\"));",
            "    const Tensor& input_max_tensor = ctx->input(3);",
            "    OP_REQUIRES(ctx,",
            "                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,",
            "                errors::InvalidArgument(",
            "                    \"Input max tensor must have dimension 0 or 1. Received \",",
            "                    input_max_tensor.dims(), \".\"));",
            "    if (axis_ != -1) {",
            "      OP_REQUIRES(",
            "          ctx, input_min_tensor.dim_size(0) == depth,"
        ],
        [
            "",
            "    if (axis_ == -1) {",
            "      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),",
            "                  errors::InvalidArgument(",
            "                      \"input_min must be a scalar if axis is unspecified\"));",
            "      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),",
            "                  errors::InvalidArgument(",
            "                      \"input_max must be a scalar if axis is unspecified\"));",
            "      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;",
            "      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),",
            "        input.template flat<T>(), input_min_tensor.scalar<T>(),",
            "        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h2wq-prv9-2f56",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n    gradients, input, input_min, input_max, axis=-1, name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "input_min=tf.constant([], shape=[0], dtype=tf.float64),\ninput_max=tf.constant(-10, shape=[], dtype=tf.float64),"
},
{
    "Title": "\n        Missing validation causes `TensorSummaryV2` to crash\n      ",
    "Bug description": "The implementation of  tf.raw_ops.TensorSummaryV2  does not fully validate the input arguments. This results in a  CHECK -failure which can be used to trigger a denial of service attack:",
    "Sample Code": "import tensorflow as tf\n\ntf.raw_ops.TensorSummaryV2(\n  tag=np.array('test'),\n  tensor=np.array(3),\n  ),\n  serialized_summary_metadata=tf.io.encode_base64(np.empty((0))))",
    "Code change": [
        "@@ -36,6 +36,10 @@ class SummaryTensorOpV2 : public OpKernel {\n                 errors::InvalidArgument(\"tag must be scalar\"));\n     const Tensor& tensor = c->input(1);\n     const Tensor& serialized_summary_metadata_tensor = c->input(2);\n+    OP_REQUIRES(\n+        c,\n+        TensorShapeUtils::IsScalar(serialized_summary_metadata_tensor.shape()),\n+        errors::InvalidArgument(\"serialized_summary_metadata must be scalar\"));\n \n     Summary s;\n     Summary::Value* v = s.add_value();\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor& tensor = c->input(1);",
            "    const Tensor& serialized_summary_metadata_tensor = c->input(2);",
            "",
            "    Summary s;",
            "    Summary::Value* v = s.add_value();",
            "    v->set_tag(string(tag.scalar<tstring>()()));  // NOLINT",
            "",
            "    if (tensor.dtype() == DT_STRING) {",
            "      // tensor_util.makeNdarray doesn't work for strings in tensor_content",
            "      tensor.AsProtoField(v->mutable_tensor());"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor& tensor = c->input(1);",
            "    const Tensor& serialized_summary_metadata_tensor = c->input(2);",
            "    OP_REQUIRES(",
            "        c,",
            "        TensorShapeUtils::IsScalar(serialized_summary_metadata_tensor.shape()),",
            "        errors::InvalidArgument(\"serialized_summary_metadata must be scalar\"));",
            "",
            "    Summary s;",
            "    Summary::Value* v = s.add_value();",
            "    v->set_tag(string(tag.scalar<tstring>()()));  // NOLINT"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2p9q-h29j-3f5v",
    "API Signature": null,
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "serialized_summary_metadata=tf.io.encode_base64(np.empty((0)))"
},
{
    "Title": "\n        Integer overflow leading to crash in `SparseCountSparseOutput`\n      ",
    "Bug description": "The  implementation of   can be made to crash a TensorFlow process by an integer overflow whose result is then used in a memory allocation:",
    "Sample Code": "import numpy as np\n    \ntf.raw_ops.SparseCountSparseOutput(\n  indices=[[1,1]],\n  values=[2],\n  dense_shape=[2 ** 31, 2 ** 32],\n  weights=[1],\n  binary_output=True,\n  minlength=-1,\n  maxlength=-1,\n  ,\n  name=None)",
    "Code change": [
        "@@ -13,6 +13,8 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include <limits>\n+\n #include \"absl/container/flat_hash_map.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/op_requires.h\"\n@@ -23,6 +25,9 @@ limitations under the License.\n \n namespace tensorflow {\n \n+// Don't allocate too large `BatchedMap<T>` objects\n+static int kMaxBatches = std::numeric_limits<int>::max();\n+\n template <class T>\n using BatchedMap = std::vector<absl::flat_hash_map<int64_t, T>>;\n \n@@ -235,6 +240,10 @@ class SparseCount : public OpKernel {\n \n     bool is_1d = shape.NumElements() == 1;\n     int num_batches = is_1d ? 1 : shape_vector(0);\n+    OP_REQUIRES(\n+        context, 0 < num_batches && num_batches < kMaxBatches,\n+        errors::InvalidArgument(\"Cannot allocate \", num_batches,\n+                                \" batches, is the dense shape too wide?\"));\n \n     const auto values_values = values.flat<T>();\n     const auto weight_values = weights.flat<W>();\n"
    ],
    "Buggy Code": [
        [
            "==============================================================================*/",
            "",
            "#include \"absl/container/flat_hash_map.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/platform/errors.h\""
        ],
        [
            "template <class T>",
            "using BatchedMap = std::vector<absl::flat_hash_map<int64_t, T>>;",
            "",
            "namespace {",
            "// TODO(momernick): Extend this function to work with outputs of rank > 2.",
            "template <class T>",
            "Status OutputSparse(const BatchedMap<T>& per_batch_counts, int num_values,",
            "                    bool is_1d, OpKernelContext* context) {",
            "  int total_values = 0;"
        ],
        [
            "",
            "    auto per_batch_counts = BatchedMap<W>(num_batches);",
            "",
            "    T max_value = 0;",
            "",
            "    for (int idx = 0; idx < num_values; ++idx) {",
            "      int batch = is_1d ? 0 : indices_values(idx, 0);",
            "      if (batch >= num_batches) {",
            "        OP_REQUIRES(context, batch < num_batches,",
            "                    errors::InvalidArgument("
        ]
    ],
    "Clean Code": [
        [
            "==============================================================================*/",
            "",
            "#include <limits>",
            "",
            "#include \"absl/container/flat_hash_map.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/framework/register_types.h\""
        ],
        [
            "namespace tensorflow {",
            "",
            "// Don't allocate too large `BatchedMap<T>` objects",
            "static int kMaxBatches = std::numeric_limits<int>::max();",
            "",
            "template <class T>",
            "using BatchedMap = std::vector<absl::flat_hash_map<int64_t, T>>;",
            "",
            "namespace {"
        ],
        [
            "    bool is_1d = shape.NumElements() == 1;",
            "    int num_batches = is_1d ? 1 : shape_vector(0);",
            "    OP_REQUIRES(",
            "        context, 0 < num_batches && num_batches < kMaxBatches,",
            "        errors::InvalidArgument(\"Cannot allocate \", num_batches,",
            "                                \" batches, is the dense shape too wide?\"));",
            "",
            "    const auto values_values = values.flat<T>();",
            "    const auto weight_values = weights.flat<W>();",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x4qx-4fjv-hmw6",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.03597122302158273,
    "Anomaly": "Large integer list element",
    "Anomaly Description": "A large integer list element in Python refers to an element within a list that has a large integer value. It means that the element is an integer with a value that exceeds the typical range of integer values.",
    "Category": "List",
    "Argument": "dense_shape=[2 ** 31, 2 ** 32],"
},
{
    "Title": "\n        Reference binding to null pointer in `QuantizedMaxPool`\n      ",
    "Bug description": "The  implementation of   has an undefined behavior where user controlled inputs can trigger a reference binding to null pointer.",
    "Sample Code": "tf.raw_ops.QuantizedMaxPool(\n    input = tf.constant([[[[4]]]], dtype=tf.quint8),\n    min_input = [],\n    max_input = [1],\n    ksize = [1, 1, 1, 1],\n    strides = [1, 1, 1, 1],\n    padding = \"SAME\", name=None\n)\n)",
    "Code change": [
        "@@ -15,6 +15,8 @@ limitations under the License.\n \n // See docs in ../ops/nn_ops.cc.\n \n+#include \"tensorflow/core/framework/op_requires.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #define EIGEN_USE_THREADS\n \n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n@@ -117,6 +119,18 @@ class QuantizedMaxPoolingOp : public MaxPoolingOp<Device, T> {\n       : MaxPoolingOp<Device, T>(context) {}\n \n   void Compute(OpKernelContext* context) override {\n+    auto min_input_tensor = context->input(1);\n+    auto max_input_tensor = context->input(2);\n+    OP_REQUIRES(\n+        context, min_input_tensor.NumElements() == 1,\n+        errors::InvalidArgument(\n+            \"min_input must be a scalar float value, got tensor with shape \",\n+            min_input_tensor.shape()));\n+    OP_REQUIRES(\n+        context, max_input_tensor.NumElements() == 1,\n+        errors::InvalidArgument(\n+            \"max_input must be a scalar float value, got tensor with shape \",\n+            max_input_tensor.shape()));\n     const float min_input = context->input(1).flat<float>()(0);\n     const float max_input = context->input(2).flat<float>()(0);\n     MaxPoolingOp<Device, T>::Compute(context);\n"
    ],
    "Buggy Code": [
        [
            "// See docs in ../ops/nn_ops.cc.",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/numeric_op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/tensor.h\""
        ],
        [
            "    const float min_input = context->input(1).flat<float>()(0);",
            "    const float max_input = context->input(2).flat<float>()(0);",
            "    MaxPoolingOp<Device, T>::Compute(context);",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));",
            "    output_min->flat<float>()(0) = min_input;",
            "    Tensor* output_max = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));",
            "    output_max->flat<float>()(0) = max_input;",
            "  }",
            "};",
            "",
            "REGISTER_KERNEL_BUILDER(",
            "    Name(\"QuantizedAvgPool\").Device(DEVICE_CPU).TypeConstraint<quint8>(\"T\"),",
            "    QuantizedAvgPoolingOp<CPUDevice, quint8>);",
            "",
            "REGISTER_KERNEL_BUILDER(",
            "    Name(\"QuantizedMaxPool\").Device(DEVICE_CPU).TypeConstraint<quint8>(\"T\"),"
        ]
    ],
    "Clean Code": [
        [
            "// See docs in ../ops/nn_ops.cc.",
            "",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#define EIGEN_USE_THREADS",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            "#include \"tensorflow/core/framework/numeric_op.h\""
        ],
        [
            "",
            "  void Compute(OpKernelContext* context) override {",
            "    auto min_input_tensor = context->input(1);",
            "    auto max_input_tensor = context->input(2);",
            "    OP_REQUIRES(",
            "        context, min_input_tensor.NumElements() == 1,",
            "        errors::InvalidArgument(",
            "            \"min_input must be a scalar float value, got tensor with shape \",",
            "            min_input_tensor.shape()));",
            "    OP_REQUIRES(",
            "        context, max_input_tensor.NumElements() == 1,",
            "        errors::InvalidArgument(",
            "            \"max_input must be a scalar float value, got tensor with shape \",",
            "            max_input_tensor.shape()));",
            "    const float min_input = context->input(1).flat<float>()(0);",
            "    const float max_input = context->input(2).flat<float>()(0);",
            "    MaxPoolingOp<Device, T>::Compute(context);",
            "    Tensor* output_min = nullptr;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-3mw4-6rj6-74g5",
    "API Signature": "tf.raw_ops.QuantizedMaxPool(\n    input, min_input, max_input, ksize, strides, padding, name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "input = tf.constant([[[[4]]]], dtype=tf.quint8)"
},
{
    "Title": "\n        Division by zero in `FractionalMaxPool`\n      ",
    "Bug description": "The  implementation of   can be made to crash a TensorFlow process via a division by 0:",
    "Sample Code": "import numpy as np\n\ntf.raw_ops.FractionalMaxPool(\n  value=tf.constant(value=[[[[1, 4, 2, 3]]]], dtype=tf.int64),\n  pooling_ratio=[1.0, 1.44, 1.73, 1.0],\n  pseudo_random=False,\n  overlapping=False,\n  deterministic=False,\n  seed=0,\n  seed2=0,\n  ,\n  name=None)",
    "Code change": [
        "@@ -83,6 +83,13 @@ class FractionalMaxPoolOp : public OpKernel {\n     std::vector<int> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n       input_size[i] = tensor_in.dim_size(i);\n+\n+      OP_REQUIRES(\n+          context, input_size[i] >= pooling_ratio_[i],\n+          errors::InvalidArgument(\"Pooling ratio is higher than input \"\n+                                  \"dimension size for dimension \",\n+                                  i, \". Input dim size: \", input_size[i],\n+                                  \" pooling ratio: \", pooling_ratio_[i]));\n     }\n     // Output size.\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n",
        "@@ -20,6 +20,7 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gen_nn_ops\n@@ -319,6 +320,24 @@ class FractionalMaxPoolTest(test.TestCase):\n       nn_ops.fractional_max_pool(\n           rand_mat, [1, 1.5, 1.5, 1], seed=1, seed2=1, deterministic=True)\n \n+  def testPoolingRatio(self):\n+    with self.cached_session() as _:\n+      with self.assertRaisesRegex(\n+          errors.InvalidArgumentError,\n+          r\"Pooling ratio is higher than input dimension size for dimension 1.*\"\n+      ):\n+        result = nn_ops.gen_nn_ops.fractional_max_pool(\n+            value=constant_op.constant(\n+                value=[[[[1, 4, 2, 3]]]], dtype=dtypes.int64),\n+            pooling_ratio=[1.0, 1.44, 1.73, 1.0],\n+            pseudo_random=False,\n+            overlapping=False,\n+            deterministic=False,\n+            seed=0,\n+            seed2=0,\n+            name=None)\n+        self.evaluate(result)\n+\n \n class FractionalMaxPoolGradTest(test.TestCase):\n   \"\"\"Tests for FractionalMaxPoolGrad.\n"
    ],
    "Buggy Code": [
        [
            "    for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      input_size[i] = tensor_in.dim_size(i);",
            "    }",
            "    // Output size.",
            "    for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      // This must match the same logic in the shape function in",
            "      // core/ops/nn_ops.cc.",
            "      output_size[i] =",
            "          static_cast<int>(std::floor(input_size[i] / pooling_ratio_[i]));",
            "      DCHECK_GT(output_size[i], 0);",
            "    }",
            "",
            "    // Generate pooling sequence."
        ]
    ],
    "Clean Code": [
        [
            "    for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      input_size[i] = tensor_in.dim_size(i);",
            "",
            "      OP_REQUIRES(",
            "          context, input_size[i] >= pooling_ratio_[i],",
            "          errors::InvalidArgument(\"Pooling ratio is higher than input \"",
            "                                  \"dimension size for dimension \",",
            "                                  i, \". Input dim size: \", input_size[i],",
            "                                  \" pooling ratio: \", pooling_ratio_[i]));",
            "    }",
            "    // Output size.",
            "    for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      // This must match the same logic in the shape function in"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-87v6-crgm-2gfj",
    "API Signature": "tf.raw_ops.FractionalMaxPool(\n    value,\n    pooling_ratio,\n    pseudo_random=False,\n    overlapping=False,\n    deterministic=False,\n    seed=0,\n    seed2=0,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "value=tf.constant(value=[[[[1, 4, 2, 3]]]], dtype=tf.int64),\npooling_ratio=[1.0, 1.44, 1.73, 1.0]"
},
{
    "Title": "\n        Integer overflows in `AddManySparseToTensorsMap`\n      ",
    "Bug description": "The  implementation of   is vulnerable to an integer overflow which results in a  CHECK -fail when building new  TensorShape  objects (so, an assert failure based denial of service):",
    "Sample Code": "import numpy as np\n\ntf.raw_ops.AddManySparseToTensorsMap(\n    sparse_indices=[(0,0),(0,1),(0,2),(4,3),(5,0),(5,1)],\n    sparse_values=[1,1,1,1,1,1],\n    sparse_shape=[2**32,2**32],\n    container='',\n    shared_name='',\n    ,\n    name=None)",
    "Code change": [
        "@@ -231,16 +231,29 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n                 errors::InvalidArgument(\n                     \"Input indices should be a matrix but received shape \",\n                     input_indices->shape().DebugString()));\n-\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                 errors::InvalidArgument(\n                     \"Input values should be a vector but received shape \",\n                     input_values->shape().DebugString()));\n-\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                 errors::InvalidArgument(\n                     \"Input shape should be a vector but received shape \",\n                     input_shape->shape().DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Number of values must match first dimension of indices. \", \"Got \",\n+            input_values->shape().dim_size(0),\n+            \" values, indices shape: \", input_indices->shape().DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", input_shape->shape().dim_size(0),\n+            \" dimensions, indices shape: \",\n+            input_indices->shape().DebugString()));\n \n     int rank = input_shape->NumElements();\n \n"
    ],
    "Buggy Code": [
        [
            "                    \"Input indices should be a matrix but received shape \",",
            "                    input_indices->shape().DebugString()));",
            "",
            "    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),",
            "                errors::InvalidArgument(",
            "                    \"Input values should be a vector but received shape \",",
            "                    input_values->shape().DebugString()));",
            "",
            "    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),",
            "                errors::InvalidArgument(",
            "                    \"Input shape should be a vector but received shape \",",
            "                    input_shape->shape().DebugString()));",
            "",
            "    int rank = input_shape->NumElements();",
            "",
            "    OP_REQUIRES(",
            "        context, rank > 1,",
            "        errors::InvalidArgument(",
            "            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));",
            "",
            "    auto input_shape_vec = input_shape->vec<int64_t>();",
            "    int new_num_elements = 1;",
            "    bool overflow_ocurred = false;",
            "    for (int i = 0; i < input_shape_vec.size(); i++) {",
            "      new_num_elements =",
            "          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));",
            "      if (new_num_elements < 0) {",
            "        overflow_ocurred = true;",
            "        break;"
        ]
    ],
    "Clean Code": [
        [
            "                    \"Input indices should be a matrix but received shape \",",
            "                    input_indices->shape().DebugString()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),",
            "                errors::InvalidArgument(",
            "                    \"Input values should be a vector but received shape \",",
            "                    input_values->shape().DebugString()));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),",
            "                errors::InvalidArgument(",
            "                    \"Input shape should be a vector but received shape \",",
            "                    input_shape->shape().DebugString()));",
            "    OP_REQUIRES(",
            "        context,",
            "        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),",
            "        errors::InvalidArgument(",
            "            \"Number of values must match first dimension of indices. \", \"Got \",",
            "            input_values->shape().dim_size(0),",
            "            \" values, indices shape: \", input_indices->shape().DebugString()));",
            "    OP_REQUIRES(",
            "        context,",
            "        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),",
            "        errors::InvalidArgument(",
            "            \"Number of dimensions must match second dimension of indices. \",",
            "            \"Got \", input_shape->shape().dim_size(0),",
            "            \" dimensions, indices shape: \",",
            "            input_indices->shape().DebugString()));",
            "",
            "    int rank = input_shape->NumElements();",
            "",
            "    OP_REQUIRES("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6445-fm66-fvq2",
    "API Signature": "tf.raw_ops.AddManySparseToTensorsMap(\n    sparse_indices,\n    sparse_values,\n    sparse_shape,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "sparse_indices=[(0,0),(0,1),(0,2),(4,3),(5,0),(5,1)],\nsparse_values=[1,1,1,1,1,1],\nsparse_shape=[2**32,2**32],"
},
{
    "Title": "\n        Integer overflows in most sparse component-wise ops\n      ",
    "Bug description": "The  implementations of   are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or  CHECK -fails when building new  TensorShape  objects (so, assert failures based denial of service):",
    "Sample Code": "import numpy as np\n\ntf.raw_ops.SparseDenseCwiseDiv(\n    sp_indices=np.array([[9]]),\n    sp_values=np.array([5]),\n    sp_shape=np.array([92233720368., 92233720368]),\n    ]),\n    dense=np.array([4]))",
    "Code change": [
        "@@ -78,11 +78,24 @@ class SparseDenseBinaryOpShared : public OpKernel {\n                     \"but received shapes: \",\n                     values_t->shape().DebugString(), \" and \",\n                     shape_t->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsVector(shape_t->shape()),\n+        errors::InvalidArgument(\"Input sp_shape must be a vector. Got: \",\n+                                shape_t->shape().DebugString()));\n     OP_REQUIRES(\n         ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n         errors::InvalidArgument(\n             \"The first dimension of values and indices should match. (\",\n             values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n+    OP_REQUIRES(\n+        ctx, shape_t->shape().dim_size(0) == indices_t->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", shape_t->shape().dim_size(0),\n+            \" dimensions, indices shape: \", indices_t->shape().DebugString()));\n+    OP_REQUIRES(ctx, shape_t->NumElements() > 0,\n+                errors::InvalidArgument(\n+                    \"The shape argument requires at least one element.\"));\n \n     const auto indices_mat = indices_t->matrix<int64_t>();\n     const auto shape_vec = shape_t->vec<int64_t>();\n"
    ],
    "Buggy Code": [
        [
            "                    values_t->shape().DebugString(), \" and \",",
            "                    shape_t->shape().DebugString()));",
            "    OP_REQUIRES(",
            "        ctx, values_t->dim_size(0) == indices_t->dim_size(0),",
            "        errors::InvalidArgument(",
            "            \"The first dimension of values and indices should match. (\",",
            "            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));",
            "",
            "    const auto indices_mat = indices_t->matrix<int64_t>();",
            "    const auto shape_vec = shape_t->vec<int64_t>();",
            "    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));",
            "    const auto rhs_dims = BCast::FromShape(dense_t->shape());",
            "    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.",
            "",
            "    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal",
            "    // to dims in rhs (from right to left).",
            "    auto VecGreaterEq = [](ArraySlice<int64_t> lhs, ArraySlice<int64_t> rhs) {",
            "      if (lhs.size() < rhs.size()) return false;",
            "      for (size_t i = 0; i < rhs.size(); ++i) {",
            "        if (lhs[lhs.size() - 1 - i] < rhs[rhs.size() - 1 - i]) return false;",
            "      }",
            "      return true;",
            "    };",
            "    OP_REQUIRES(ctx, VecGreaterEq(lhs_dims, rhs_dims) && b.IsValid(),"
        ]
    ],
    "Clean Code": [
        [
            "                    values_t->shape().DebugString(), \" and \",",
            "                    shape_t->shape().DebugString()));",
            "    OP_REQUIRES(",
            "        ctx, TensorShapeUtils::IsVector(shape_t->shape()),",
            "        errors::InvalidArgument(\"Input sp_shape must be a vector. Got: \",",
            "                                shape_t->shape().DebugString()));",
            "    OP_REQUIRES(",
            "        ctx, values_t->dim_size(0) == indices_t->dim_size(0),",
            "        errors::InvalidArgument(",
            "            \"The first dimension of values and indices should match. (\",",
            "            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));",
            "    OP_REQUIRES(",
            "        ctx, shape_t->shape().dim_size(0) == indices_t->shape().dim_size(1),",
            "        errors::InvalidArgument(",
            "            \"Number of dimensions must match second dimension of indices. \",",
            "            \"Got \", shape_t->shape().dim_size(0),",
            "            \" dimensions, indices shape: \", indices_t->shape().DebugString()));",
            "    OP_REQUIRES(ctx, shape_t->NumElements() > 0,",
            "                errors::InvalidArgument(",
            "                    \"The shape argument requires at least one element.\"));",
            "",
            "    const auto indices_mat = indices_t->matrix<int64_t>();",
            "    const auto shape_vec = shape_t->vec<int64_t>();",
            "    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rrx2-r989-2c43",
    "API Signature": "tf.raw_ops.SparseDenseCwiseDiv(\n    sp_indices, sp_values, sp_shape, dense, name=None\n)\n",
    "Score": 0.03597122302158273,
    "Anomaly": "Large integer list element",
    "Anomaly Description": "A large integer list element in Python refers to an element within a list that has a large integer value. It means that the element is an integer with a value that exceeds the typical range of integer values.",
    "Category": "List",
    "Argument": "sp_shape=np.array([92233720368., 92233720368]),"
},
{
    "Title": "\n        OOM due to integer overflow in `StringNGrams`\n      ",
    "Bug description": "The  implementation of   can be used to trigger a denial of service attack by causing an OOM condition after an integer overflow:",
    "Sample Code": "tf.raw_ops.StringNGrams(\n  data=['123456'],\n  data_splits=[0,1],\n  separator='a'*15,\n  ngram_widths=[],\n  left_pad='',\n  right_pad='',\n  pad_width=-5, \n  , \n  preserve_short_sequences=True)",
    "Code change": [
        "@@ -152,6 +152,16 @@ class StringNGramsOp : public tensorflow::OpKernel {\n         // We don't have to worry about dynamic padding sizes here: if padding\n         // was dynamic, every sequence would have had sufficient padding to\n         // generate at least one ngram.\n+\n+        // If reached here, pad_width should be > 0, pad_width_ = -1,\n+        // which indicates max(ngram_widths) - 1 cannot be used here since\n+        // ngram_width is not known.\n+        OP_REQUIRES(\n+            context, pad_width_ >= 0,\n+            errors::InvalidArgument(\"Pad width should be >= 0 when \"\n+                                    \"preserve_short_sequences is True and \"\n+                                    \"ngram_widths are not provided, got \",\n+                                    pad_width_));\n         int ngram_width = data_length + 2 * pad_width_;\n         auto output_start = &ngrams_data[output_start_idx];\n         int num_ngrams = 1;\n",
        "@@ -28,7 +28,6 @@ from tensorflow.python.platform import test\n \n \n @test_util.run_all_in_graph_and_eager_modes\n-@test_util.disable_tfrt\n class RawOpsTest(test.TestCase, parameterized.TestCase):\n \n   def testSimple(self):\n@@ -63,8 +62,9 @@ class RawOpsTest(test.TestCase, parameterized.TestCase):\n   @parameterized.parameters([[0, 8]], [[-1, 6]])\n   def testStringNGramsBadDataSplits(self, splits):\n     data = [\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\"]\n-    with self.assertRaisesRegex(errors.InvalidArgumentError,\n-                                \"Invalid split value\"):\n+    with self.assertRaisesRegex(\n+        errors.InvalidArgumentError,\n+        r\"Invalid split value|First split value must be 0\"):\n       self.evaluate(\n           gen_string_ops.string_n_grams(\n               data=data,\n@@ -76,6 +76,25 @@ class RawOpsTest(test.TestCase, parameterized.TestCase):\n               pad_width=0,\n               preserve_short_sequences=False))\n \n+  def testStringSplit(self):\n+    data = [\"123456\"]\n+    data_splits = [0, 1]\n+    separator = \"a\" * 15\n+    ngram_widths = []\n+    pad_width = -5\n+    left_pad = right_pad = \"\"\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                \"Pad width should be >= 0\"):\n+      self.evaluate(gen_string_ops.string_n_grams(\n+          data=data,\n+          data_splits=data_splits,\n+          separator=separator,\n+          ngram_widths=ngram_widths,\n+          left_pad=left_pad,\n+          right_pad=right_pad,\n+          pad_width=pad_width,\n+          preserve_short_sequences=True))\n+\n   def testGetSessionHandle(self):\n     if context.executing_eagerly():\n       with self.assertRaisesRegex(\n"
    ],
    "Buggy Code": [
        [
            "        // was dynamic, every sequence would have had sufficient padding to",
            "        // generate at least one ngram.",
            "        int ngram_width = data_length + 2 * pad_width_;",
            "        auto output_start = &ngrams_data[output_start_idx];",
            "        int num_ngrams = 1;",
            "        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);",
            "      }",
            "    }",
            "  }",
            "",
            "  void CreateNgrams(const tstring* data, tstring* output, int num_ngrams,",
            "                    int ngram_width) const {",
            "    for (int ngram_index = 0; ngram_index < num_ngrams; ++ngram_index) {",
            "      int pad_width = get_pad_width(ngram_width);",
            "      int left_padding = std::max(0, pad_width - ngram_index);",
            "      int right_padding ="
        ]
    ],
    "Clean Code": [
        [
            "        // was dynamic, every sequence would have had sufficient padding to",
            "        // generate at least one ngram.",
            "",
            "        // If reached here, pad_width should be > 0, pad_width_ = -1,",
            "        // which indicates max(ngram_widths) - 1 cannot be used here since",
            "        // ngram_width is not known.",
            "        OP_REQUIRES(",
            "            context, pad_width_ >= 0,",
            "            errors::InvalidArgument(\"Pad width should be >= 0 when \"",
            "                                    \"preserve_short_sequences is True and \"",
            "                                    \"ngram_widths are not provided, got \",",
            "                                    pad_width_));",
            "        int ngram_width = data_length + 2 * pad_width_;",
            "        auto output_start = &ngrams_data[output_start_idx];",
            "        int num_ngrams = 1;",
            "        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-98j8-c9q4-r38g",
    "API Signature": "tf.raw_ops.StringNGrams(\n    data,\n    data_splits,\n    separator,\n    ngram_widths,\n    left_pad,\n    right_pad,\n    pad_width,\n    preserve_short_sequences,\n    name=None\n)\n",
    "Score": 0.039568345323741004,
    "Anomaly": "Negative integer argument",
    "Anomaly Description": "A negative integer argument in Python refers to an integer value that is less than zero. It is a numeric value that represents a negative quantity or position in a numerical sequence. In Python, negative integers are denoted by placing a minus sign (-) before the numerical value. For example, -1, -2, -3, and so on.",
    "Category": "Integer",
    "Argument": "pad_width=-5, "
},
{
    "Title": "\n        OOM in `ThreadPoolHandle`\n      ",
    "Bug description": "The  implementation of   can be used to trigger a denial of service attack by allocating too much memory:",
    "Sample Code": " tensorflow as tf\ny = tf.raw_ops.ThreadPoolHandle(num_threads=0x60000000,display_name='tf')",
    "Code change": [
        "@@ -39,6 +39,22 @@ namespace experimental {\n     PrivateThreadPoolDatasetOp::kDatasetType;\n /* static */ constexpr const char* const PrivateThreadPoolDatasetOp::kDatasetOp;\n \n+namespace {\n+// To prevent integer overflow issues when allocating threadpool memory for an\n+// unreasonable number of threads.\n+constexpr int kThreadLimit = 65536;\n+\n+Status ValidateNumThreads(int32_t num_threads) {\n+  if (num_threads < 0) {\n+    return errors::InvalidArgument(\"`num_threads` must be >= 0\");\n+  }\n+  if (num_threads >= kThreadLimit) {\n+    return errors::InvalidArgument(\"`num_threads` must be < \", kThreadLimit);\n+  }\n+  return Status::OK();\n+}\n+}  // namespace\n+\n class ThreadPoolResource : public ResourceBase {\n  public:\n   ThreadPoolResource(Env* env, const ThreadOptions& thread_options,\n@@ -83,9 +99,7 @@ class ThreadPoolHandleOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_threads\", &num_threads_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"max_intra_op_parallelism\",\n                                      &max_intra_op_parallelism_));\n-    OP_REQUIRES(\n-        ctx, num_threads_ > 0,\n-        errors::InvalidArgument(\"`num_threads` must be greater than zero.\"));\n+    OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads_));\n   }\n \n   // The resource is deleted from the resource manager only when it is private\n@@ -531,8 +545,7 @@ void PrivateThreadPoolDatasetOp::MakeDatasetFromOptions(OpKernelContext* ctx,\n                                                         DatasetBase* input,\n                                                         int32_t num_threads,\n                                                         DatasetBase** output) {\n-  OP_REQUIRES(ctx, num_threads >= 0,\n-              errors::InvalidArgument(\"`num_threads` must be >= 0\"));\n+  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));\n   *output = new Dataset(ctx,\n                         DatasetContext(DatasetContext::Params(\n                             {PrivateThreadPoolDatasetOp::kDatasetType,\n@@ -546,8 +559,7 @@ void PrivateThreadPoolDatasetOp::MakeDataset(OpKernelContext* ctx,\n   int64_t num_threads = 0;\n   OP_REQUIRES_OK(\n       ctx, ParseScalarArgument<int64_t>(ctx, \"num_threads\", &num_threads));\n-  OP_REQUIRES(ctx, num_threads >= 0,\n-              errors::InvalidArgument(\"`num_threads` must be >= 0\"));\n+  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));\n   *output = new Dataset(ctx, input, num_threads);\n }\n \n"
    ],
    "Buggy Code": [
        [
            "/* static */ constexpr const char* const PrivateThreadPoolDatasetOp::kDatasetOp;",
            "",
            "class ThreadPoolResource : public ResourceBase {",
            " public:",
            "  ThreadPoolResource(Env* env, const ThreadOptions& thread_options,",
            "                     const string& name, int num_threads, bool low_latency_hint,",
            "                     int max_intra_op_parallelism)",
            "      : thread_pool_(env, thread_options, name, num_threads, low_latency_hint),",
            "        max_intra_op_parallelism_(max_intra_op_parallelism) {}",
            "",
            "  // Schedules fn() for execution in the pool of threads.",
            "  void Schedule(std::function<void()> fn) {",
            "    if (max_intra_op_parallelism_ < 0) {",
            "      thread_pool_.Schedule(std::move(fn));",
            "    } else {",
            "      thread_pool_.Schedule(std::bind(",
            "          [this](std::function<void()> bound_fn) {",
            "            // TODO(mrry): Consider moving this thread-local configuration to",
            "            // the threads themselves.",
            "            ScopedPerThreadMaxParallelism scope(max_intra_op_parallelism_);",
            "            bound_fn();",
            "          },"
        ],
        [
            "      }",
            "    }",
            "  }",
            "",
            "  void Compute(OpKernelContext* ctx) override TF_LOCKS_EXCLUDED(mu_) {",
            "    mutex_lock l(mu_);",
            "    if (!initialized_) {"
        ],
        [
            "  int64_t num_threads = 0;",
            "  OP_REQUIRES_OK(",
            "      ctx, ParseScalarArgument<int64_t>(ctx, \"num_threads\", &num_threads));",
            "  OP_REQUIRES(ctx, num_threads >= 0,",
            "              errors::InvalidArgument(\"`num_threads` must be >= 0\"));",
            "  *output = new Dataset(ctx, input, num_threads);",
            "}"
        ],
        [
            "    MaxIntraOpParallelismDatasetOp);",
            "",
            "REGISTER_KERNEL_BUILDER(Name(\"PrivateThreadPoolDataset\").Device(DEVICE_CPU),",
            "                        PrivateThreadPoolDatasetOp);",
            "REGISTER_KERNEL_BUILDER(",
            "    Name(\"ExperimentalPrivateThreadPoolDataset\").Device(DEVICE_CPU),",
            "    PrivateThreadPoolDatasetOp);"
        ]
    ],
    "Clean Code": [
        [
            "/* static */ constexpr const char* const PrivateThreadPoolDatasetOp::kDatasetOp;",
            "",
            "namespace {",
            "// To prevent integer overflow issues when allocating threadpool memory for an",
            "// unreasonable number of threads.",
            "constexpr int kThreadLimit = 65536;",
            "",
            "Status ValidateNumThreads(int32_t num_threads) {",
            "  if (num_threads < 0) {",
            "    return errors::InvalidArgument(\"`num_threads` must be >= 0\");",
            "  }",
            "  if (num_threads >= kThreadLimit) {",
            "    return errors::InvalidArgument(\"`num_threads` must be < \", kThreadLimit);",
            "  }",
            "  return Status::OK();",
            "}",
            "}  // namespace",
            "",
            "class ThreadPoolResource : public ResourceBase {",
            " public:",
            "  ThreadPoolResource(Env* env, const ThreadOptions& thread_options,",
            "                     const string& name, int num_threads, bool low_latency_hint,"
        ],
        [
            "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"max_intra_op_parallelism\",",
            "                                     &max_intra_op_parallelism_));",
            "    OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads_));",
            "  }",
            "",
            "  // The resource is deleted from the resource manager only when it is private",
            "  // to kernel. Ideally the resource should be deleted when it is no longer held"
        ],
        [
            "                                                        int32_t num_threads,",
            "                                                        DatasetBase** output) {",
            "  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));",
            "  *output = new Dataset(ctx,",
            "                        DatasetContext(DatasetContext::Params(",
            "                            {PrivateThreadPoolDatasetOp::kDatasetType,",
            "                             PrivateThreadPoolDatasetOp::kDatasetOp})),"
        ],
        [
            "  OP_REQUIRES_OK(",
            "      ctx, ParseScalarArgument<int64_t>(ctx, \"num_threads\", &num_threads));",
            "  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));",
            "  *output = new Dataset(ctx, input, num_threads);",
            "}",
            "",
            "namespace {"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c582-c96p-r5cq",
    "API Signature": "tf.raw_ops.ThreadPoolHandle(\n    num_threads,\n    display_name,\n    max_intra_op_parallelism=1,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Large integer argument",
    "Anomaly Description": "A large integer argument refers to an argument passed to a function or operation that represents a large integer value. It means that the argument is an integer value that exceeds the typical range of integer values supported by the underlying programming language or system.\n\nThe specific definition of a \"large\" integer may vary depending on the context and the limitations of the programming language or system being used. For example, in Python, integers have arbitrary precision, allowing you to work with integers of any size. However, other programming languages may have predefined limits on the range of integer values they can handle.\n\nIn the context of function arguments, a large integer argument can be used to represent various concepts or quantities. It may be used to specify an index, a count, a value, or any other numerical parameter required by the function or operation.",
    "Category": "Integer",
    "Argument": "num_threads=0x60000000"
},
{
    "Title": "\n        Type confusion in shape inference for `ConcatV2`\n      ",
    "Bug description": "The  implementation of shape inference for   can be used to trigger a denial of service attack via a segfault caused by a type confusion:",
    "Sample Code": "@\ndef test():\n  y = tf.raw_ops.ConcatV2(\n    values=[[1,2,3],[4,5,6]],\n    axis = 0xb500005b)\n  return y\n\n\n\ntest()",
    "Code change": [
        "@@ -2005,7 +2005,7 @@ Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n   }\n \n   // Minimum required number of dimensions.\n-  const int min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n+  const int64 min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n \n   ShapeHandle output_before;\n   ShapeHandle output_after;\n",
        "@@ -16,6 +16,7 @@\n \n import numpy as np\n \n+from tensorflow.python.eager import def_function\n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors_impl\n@@ -570,6 +571,17 @@ class ConcatOpTest(test.TestCase):\n         t2 = [2]\n         gen_array_ops.concat_v2([t1, t2], 1).eval()\n \n+  def testConcatInvalidAxisInTfFunction(self):\n+\n+    @def_function.function\n+    def concat_wrapper():\n+      y = gen_array_ops.concat_v2(\n+          values=[[1, 2, 3], [4, 5, 6]], axis=0xb500005b)\n+      return y\n+\n+    with self.assertRaises(ValueError):\n+      concat_wrapper()\n+\n   def testConcatNegativeAxis(self):\n     with test_util.use_gpu():\n       t1 = [[1, 2, 3], [4, 5, 6]]\n"
    ],
    "Buggy Code": [
        [
            "",
            "  // Minimum required number of dimensions.",
            "  const int min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;",
            "",
            "  ShapeHandle output_before;",
            "  ShapeHandle output_after;",
            ""
        ]
    ],
    "Clean Code": [
        [
            "",
            "  // Minimum required number of dimensions.",
            "  const int64 min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;",
            "",
            "  ShapeHandle output_before;",
            "  ShapeHandle output_after;",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m4hf-j54p-p353",
    "API Signature": "tf.raw_ops.ConcatV2(\n    values, axis, name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Large integer argument",
    "Anomaly Description": "A large integer argument refers to an argument passed to a function or operation that represents a large integer value. It means that the argument is an integer value that exceeds the typical range of integer values supported by the underlying programming language or system.\n\nThe specific definition of a \"large\" integer may vary depending on the context and the limitations of the programming language or system being used. For example, in Python, integers have arbitrary precision, allowing you to work with integers of any size. However, other programming languages may have predefined limits on the range of integer values they can handle.\n\nIn the context of function arguments, a large integer argument can be used to represent various concepts or quantities. It may be used to specify an index, a count, a value, or any other numerical parameter required by the function or operation.",
    "Category": "Integer",
    "Argument": "axis = 0xb500005b"
},
{
    "Title": "\n        Overflow and divide by zero in `UnravelIndex`\n      ",
    "Bug description": "The  implementation of   is vulnerable to a division by zero caused by an integer overflow bug:",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.UnravelIndex(indices=-0x100000,dims=[0x100000,0x100000])",
    "Code change": [
        "@@ -13,6 +13,10 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include <cstdint>\n+\n+#include \"tensorflow/core/framework/types.pb.h\"\n+#include \"tensorflow/core/platform/types.h\"\n #define EIGEN_USE_THREADS\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n@@ -35,7 +39,8 @@ typedef Eigen::ThreadPoolDevice CPUDevice;\n template <typename Tidx>\n class UnravelIndexOp : public OpKernel {\n  public:\n-  explicit UnravelIndexOp(OpKernelConstruction* ctx) : OpKernel(ctx) {}\n+  explicit UnravelIndexOp(OpKernelConstruction* ctx)\n+      : OpKernel(ctx), dtidx_(DataTypeToEnum<Tidx>::v()) {}\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& indices_tensor = ctx->input(0);\n@@ -54,12 +59,31 @@ class UnravelIndexOp : public OpKernel {\n \n     auto dims = dims_tensor.vec<Tidx>();\n     // Make sure dims does not contain a zero\n+    double prod = 1;\n+    uint64_t limit;\n+    if (dtidx_ == DataType::DT_INT64) {\n+      limit = kint64max;\n+    } else {\n+      limit = kint32max;\n+    }\n+\n     for (int i = 0; i < dims.size(); i++) {\n       OP_REQUIRES(\n           ctx, dims(i) != 0,\n           errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"\n                                   \"but dims contains zero at index \",\n                                   i));\n+      OP_REQUIRES(ctx, dims(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"Input dims cannot be negative. Got dim = \", dims(i),\n+                      \" at index \", i));\n+      // Check interger overflow\n+      OP_REQUIRES(\n+          ctx, prod <= limit / dims(i),\n+          errors::InvalidArgument(\"Input dims product is causing integer \"\n+                                  \"overflow: (\",\n+                                  dims, \")\"));\n+      prod = (prod * dims(i));\n     }\n \n     // Check to make sure indices is not out of boundary\n@@ -132,6 +156,7 @@ class UnravelIndexOp : public OpKernel {\n                strides_shifted.reshape(reshape).broadcast(bcast);\n     }\n   }\n+  const DataType dtidx_;\n };\n \n #define REGISTER_KERNEL(type)                                               \\\n",
        "@@ -1580,6 +1580,20 @@ class UnravelIndexTest(test_util.TensorFlowTestCase):\n           dims = constant_op.constant([3, 0], dtype=dtype)\n           self.evaluate(array_ops.unravel_index(indices=indices, dims=dims))\n \n+  def testUnravelIndexIntegerOverflow(self):\n+    with self.cached_session():\n+      for dtype in [dtypes.int32, dtypes.int64]:\n+        with self.assertRaisesRegex(\n+            errors.InvalidArgumentError,\n+            r\"Input dims product is causing integer overflow\"):\n+          indices = constant_op.constant(-0x100000, dtype=dtype)\n+          if dtype == dtypes.int32:\n+            value = 0x10000000\n+          else:\n+            value = 0x7FFFFFFFFFFFFFFF\n+          dims = constant_op.constant([value, value], dtype=dtype)\n+          self.evaluate(array_ops.unravel_index(indices=indices, dims=dims))\n+\n \n class GuaranteeConstOpTest(test_util.TensorFlowTestCase):\n \n"
    ],
    "Buggy Code": [
        [
            "==============================================================================*/",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
            ""
        ],
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& indices_tensor = ctx->input(0);",
            "    OP_REQUIRES(ctx,",
            "                TensorShapeUtils::IsVector(indices_tensor.shape()) ||",
            "                    TensorShapeUtils::IsScalar(indices_tensor.shape()),",
            "                errors::InvalidArgument(",
            "                    \"The indices can only be scalar or vector, got \\\"\",",
            "                    indices_tensor.shape().DebugString(), \"\\\"\"));"
        ],
        [
            "          errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"",
            "                                  \"but dims contains zero at index \",",
            "                                  i));",
            "    }",
            "",
            "    // Check to make sure indices is not out of boundary",
            "    Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();",
            "    Tidx dims_prod = dims_prod_eigen();",
            "    const Tidx* indices = indices_tensor.flat<Tidx>().data();",
            "    int64_t size = indices_tensor.NumElements();",
            "    bool check = std::all_of(indices, indices + size,",
            "                             [&](Tidx index) { return index < dims_prod; });",
            "    OP_REQUIRES(ctx, check,",
            "                errors::InvalidArgument(\"index is out of bound as with dims\"));",
            "",
            "    Eigen::array<bool, 1> reverse({true});",
            "",
            "    Tensor strides_tensor;",
            "    OP_REQUIRES_OK(ctx,",
            "                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,",
            "                                      TensorShape({dims_tensor.NumElements()}),",
            "                                      &strides_tensor));",
            "",
            "    auto strides = strides_tensor.vec<Tidx>();",
            "    strides = dims.reverse(reverse)",
            "                  .scan(0, Eigen::internal::ProdReducer<Tidx>(), false)",
            "                  .reverse(reverse);",
            "",
            "    Tensor strides_shifted_tensor;",
            "    OP_REQUIRES_OK(ctx,",
            "                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,"
        ],
        []
    ],
    "Clean Code": [
        [
            "==============================================================================*/",
            "",
            "#include <cstdint>",
            "",
            "#include \"tensorflow/core/framework/types.pb.h\"",
            "#include \"tensorflow/core/platform/types.h\"",
            "#define EIGEN_USE_THREADS",
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\""
        ],
        [
            "class UnravelIndexOp : public OpKernel {",
            " public:",
            "  explicit UnravelIndexOp(OpKernelConstruction* ctx)",
            "      : OpKernel(ctx), dtidx_(DataTypeToEnum<Tidx>::v()) {}",
            "",
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& indices_tensor = ctx->input(0);",
            "    OP_REQUIRES(ctx,"
        ],
        [
            "    auto dims = dims_tensor.vec<Tidx>();",
            "    // Make sure dims does not contain a zero",
            "    double prod = 1;",
            "    uint64_t limit;",
            "    if (dtidx_ == DataType::DT_INT64) {",
            "      limit = kint64max;",
            "    } else {",
            "      limit = kint32max;",
            "    }",
            "",
            "    for (int i = 0; i < dims.size(); i++) {",
            "      OP_REQUIRES(",
            "          ctx, dims(i) != 0,",
            "          errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"",
            "                                  \"but dims contains zero at index \",",
            "                                  i));",
            "      OP_REQUIRES(ctx, dims(i) > 0,",
            "                  errors::InvalidArgument(",
            "                      \"Input dims cannot be negative. Got dim = \", dims(i),",
            "                      \" at index \", i));",
            "      // Check interger overflow",
            "      OP_REQUIRES(",
            "          ctx, prod <= limit / dims(i),",
            "          errors::InvalidArgument(\"Input dims product is causing integer \"",
            "                                  \"overflow: (\",",
            "                                  dims, \")\"));",
            "      prod = (prod * dims(i));",
            "    }",
            "",
            "    // Check to make sure indices is not out of boundary",
            "    Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();"
        ],
        [
            "    }",
            "  }",
            "  const DataType dtidx_;",
            "};",
            "",
            "#define REGISTER_KERNEL(type)                                               \\",
            "  REGISTER_KERNEL_BUILDER(                                                  \\"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-34f9-hjfq-rr8j",
    "API Signature": "tf.raw_ops.UnravelIndex(\n    indices, dims, name=None\n)\n",
    "Score": 0.03597122302158273,
    "Anomaly": "Large integer list element",
    "Anomaly Description": "A large integer list element in Python refers to an element within a list that has a large integer value. It means that the element is an integer with a value that exceeds the typical range of integer values.",
    "Category": "List",
    "Argument": "dims=[0x100000,0x100000]"
},
{
    "Title": "\n        Heap OOB access in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The  implementation of   does not consider cases where the input tensors are invalid allowing an attacker to read from outside of bounds of heap:",
    "Sample Code": "@\ndef test():\n  y = tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape=[2,2,2,2],\n    out_backprop=[[[[1,2], [3, 4], [5, 6]], [[7, 8], [9,10], [11,12]]]],\n    row_pooling_sequence=[-10,1,2,3],\n    col_pooling_sequence=[1,2,3,4],\n    overlapping=True)\n  return y\n    \n\n    \ntest()",
    "Code change": [
        "@@ -311,15 +311,26 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     for (int64_t b = 0; b < out_batch; ++b) {\n       for (int64_t r = 0; r < out_rows; ++r) {\n         const int64_t in_row_start = row_seq_tensor_flat(r);\n+\n         int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)\n                                           : row_seq_tensor_flat(r + 1) - 1;\n         in_row_end = std::min(in_row_end, in_max_row_index);\n+        OP_REQUIRES(context, in_row_start >= 0 && in_row_end >= 0,\n+                    errors::InvalidArgument(\n+                        \"Row sequence tensor values must not be negative, got \",\n+                        row_seq_tensor_flat));\n+\n         for (int64_t c = 0; c < out_cols; ++c) {\n           const int64_t in_col_start = col_seq_tensor_flat(c);\n           int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)\n                                             : col_seq_tensor_flat(c + 1) - 1;\n           in_col_end = std::min(in_col_end, in_max_col_index);\n \n+          OP_REQUIRES(\n+              context, in_col_start >= 0 && in_col_end >= 0,\n+              errors::InvalidArgument(\n+                  \"Column sequence tensor values must not be negative, got \",\n+                  col_seq_tensor_flat));\n           const int64_t num_elements_in_pooling_cell =\n               (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);\n           const int64_t out_index = (b * out_rows + r) * out_cols + c;\n",
        "@@ -20,6 +20,7 @@ import numpy as np\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gen_nn_ops\n@@ -306,6 +307,32 @@ class FractionalAvgTest(test.TestCase):\n           input_b, row_seq, col_seq, overlapping)\n       self.assertSequenceEqual(expected.shape, actual.shape)\n \n+  def testNegativeSeqValuesForGradOp(self):\n+    with self.assertRaisesRegex(\n+        errors.InvalidArgumentError,\n+        r\"Row sequence tensor values must not be negative.*\"):\n+      y = nn_ops.gen_nn_ops.fractional_avg_pool_grad(\n+          orig_input_tensor_shape=[2, 2, 2, 2],\n+          out_backprop=[[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11,\n+                                                                      12]]]],\n+          row_pooling_sequence=[-10, 1, 2, 3],\n+          col_pooling_sequence=[1, 2, 3, 4],\n+          overlapping=True)\n+\n+      self.evaluate(y)\n+      with self.assertRaisesRegex(\n+          errors.InvalidArgumentError,\n+          r\"Column sequence tensor values must not be negative.*\"):\n+        z = nn_ops.gen_nn_ops.fractional_avg_pool_grad(\n+            orig_input_tensor_shape=[2, 2, 2, 2],\n+            out_backprop=[[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11,\n+                                                                        12]]]],\n+            row_pooling_sequence=[10, 1, 2, 3],\n+            col_pooling_sequence=[1, 2, -3, 4],\n+            overlapping=True)\n+\n+        self.evaluate(z)\n+\n \n class FractionalAvgPoolGradTest(test.TestCase):\n   \"\"\"Tests for FractionalAvgPoolGrad.\n"
    ],
    "Buggy Code": [
        [
            "      for (int64_t r = 0; r < out_rows; ++r) {",
            "        const int64_t in_row_start = row_seq_tensor_flat(r);",
            "        int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)",
            "                                          : row_seq_tensor_flat(r + 1) - 1;",
            "        in_row_end = std::min(in_row_end, in_max_row_index);",
            "        for (int64_t c = 0; c < out_cols; ++c) {",
            "          const int64_t in_col_start = col_seq_tensor_flat(c);",
            "          int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)",
            "                                            : col_seq_tensor_flat(c + 1) - 1;",
            "          in_col_end = std::min(in_col_end, in_max_col_index);",
            "",
            "          const int64_t num_elements_in_pooling_cell =",
            "              (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);",
            "          const int64_t out_index = (b * out_rows + r) * out_cols + c;",
            "          // Now we can evenly distribute out_backprop(b, h, w, *) to",
            "          // in_backprop(b, hs:he, ws:we, *).",
            "          for (int64_t in_r = in_row_start; in_r <= in_row_end; ++in_r) {",
            "            for (int64_t in_c = in_col_start; in_c <= in_col_end; ++in_c) {",
            "              const int64_t in_index = (b * in_rows + in_r) * in_cols + in_c;",
            "              // Walk through each channel (depth).",
            "              for (int64_t d = 0; d < out_depth; ++d) {",
            "                const double out_backprop_element = static_cast<double>(",
            "                    out_backprop_mat.coeffRef(d, out_index));",
            "                double& in_backprop_ref =",
            "                    in_backprop_tensor_temp_mat.coeffRef(d, in_index);",
            "                in_backprop_ref +="
        ]
    ],
    "Clean Code": [
        [
            "      for (int64_t r = 0; r < out_rows; ++r) {",
            "        const int64_t in_row_start = row_seq_tensor_flat(r);",
            "",
            "        int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)",
            "                                          : row_seq_tensor_flat(r + 1) - 1;",
            "        in_row_end = std::min(in_row_end, in_max_row_index);",
            "        OP_REQUIRES(context, in_row_start >= 0 && in_row_end >= 0,",
            "                    errors::InvalidArgument(",
            "                        \"Row sequence tensor values must not be negative, got \",",
            "                        row_seq_tensor_flat));",
            "",
            "        for (int64_t c = 0; c < out_cols; ++c) {",
            "          const int64_t in_col_start = col_seq_tensor_flat(c);",
            "          int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)",
            "                                            : col_seq_tensor_flat(c + 1) - 1;",
            "          in_col_end = std::min(in_col_end, in_max_col_index);",
            "",
            "          OP_REQUIRES(",
            "              context, in_col_start >= 0 && in_col_end >= 0,",
            "              errors::InvalidArgument(",
            "                  \"Column sequence tensor values must not be negative, got \",",
            "                  col_seq_tensor_flat));",
            "          const int64_t num_elements_in_pooling_cell =",
            "              (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);",
            "          const int64_t out_index = (b * out_rows + r) * out_cols + c;",
            "          // Now we can evenly distribute out_backprop(b, h, w, *) to"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vjg4-v33c-ggc4",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.02877697841726619,
    "Anomaly": "Negative integer list element",
    "Anomaly Description": "A negative integer list element in Python refers to an element within a list that has a negative integer value. It means that the element is a negative number represented by an integer data type.",
    "Category": "List",
    "Argument": "row_pooling_sequence=[-10,1,2,3],\ncol_pooling_sequence=[1,2,3,4],"
},
{
    "Title": "\n        Integer overflow in shape inference for `Dequantize`\n      ",
    "Bug description": "The  implementation of shape inference for   is vulnerable to an integer overflow weakness:",
    "Sample Code": "input = tf.constant([1,1],dtype=tf.qint32)\n\n@\ndef test():\n  y = tf.raw_ops.Dequantize(\n    input=input,\n    min_range=[1.0],\n    max_range=[10.0],\n    mode='MIN_COMBINED',\n    narrow_range=False,\n    axis=2**31-1,\n    dtype=tf.bfloat16)\n  return y\n\n\n\ntest()",
    "Code change": [
        "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/framework/types.pb.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/types.h\"\n #include \"tensorflow/core/util/mirror_pad_mode.h\"\n #include \"tensorflow/core/util/padding.h\"\n #include \"tensorflow/core/util/strided_slice_op.h\"\n@@ -3028,6 +3029,12 @@ REGISTER_OP(\"Dequantize\")\n         return errors::InvalidArgument(\"axis should be at least -1, got \",\n                                        axis);\n       }\n+      auto input_dims = c->Rank(c->input(0));\n+      if (axis > input_dims) {\n+        return errors::InvalidArgument(\n+            \"Axis must be less than input dimension(\", input_dims, \"), got \",\n+            axis);\n+      }\n       const int minmax_rank = (axis == -1) ? 0 : 1;\n       TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n       ShapeHandle minmax;\n@@ -3035,6 +3042,13 @@ REGISTER_OP(\"Dequantize\")\n       TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));\n       if (axis != -1) {\n         ShapeHandle input;\n+        if (axis >= kint32max) {\n+          // Check int32 max bound for a corner case to prevent integer flow\n+          // when input actually has kint32max rank and above bound check is not\n+          // triggered.\n+          return errors::InvalidArgument(\n+              \"Axis cannot be >= kint32max value, got \", axis);\n+        }\n         TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n         DimensionHandle depth;\n         TF_RETURN_IF_ERROR(\n",
        "@@ -1704,6 +1704,21 @@ class QuantizeAndDequantizeTest(test_util.TensorFlowTestCase):\n       output_grad = gradient_checker_v2.compute_gradient(f, [input_tensor])\n       self.assertAllClose(output_grad[0], np.zeros([1, 4, 4]))\n \n+  def testOutOfBoundAxis(self):\n+    input_tensor = constant_op.constant([1., 1.])\n+    input_min = [0]\n+    input_max = [1]\n+    q_input, _, _ = array_ops.quantize(input_tensor, 0, 1, dtypes.qint32)\n+    error = (errors.InvalidArgumentError, ValueError)\n+    with self.assertRaisesRegex(error,\n+                                r\".*Axis must be less than input dimension.*\"):\n+      self.evaluate(\n+          gen_array_ops.dequantize(\n+              input=q_input,\n+              min_range=input_min,\n+              max_range=input_max,\n+              axis=2**31 - 1))\n+\n \n @test_util.run_all_in_graph_and_eager_modes\n class SortedSearchTest(test_util.TensorFlowTestCase):\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/types.pb.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/util/mirror_pad_mode.h\"",
            "#include \"tensorflow/core/util/padding.h\"",
            "#include \"tensorflow/core/util/strided_slice_op.h\"",
            "#include \"tensorflow/core/util/tensor_format.h\"",
            ""
        ],
        [
            "      }",
            "      const int minmax_rank = (axis == -1) ? 0 : 1;",
            "      TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));",
            "      ShapeHandle minmax;",
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));",
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));",
            "      if (axis != -1) {",
            "        ShapeHandle input;",
            "        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));",
            "        DimensionHandle depth;",
            "        TF_RETURN_IF_ERROR(",
            "            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));"
        ],
        [
            "      return Status::OK();",
            "    });",
            "",
            "REGISTER_OP(\"QuantizedConcat\")",
            "    .Input(\"concat_dim: int32\")",
            "    .Input(\"values: N * T\")",
            "    .Input(\"input_mins: N * float32\")",
            "    .Input(\"input_maxes: N * float32\")",
            "    .Output(\"output: T\")",
            "    .Output(\"output_min: float\")",
            "    .Output(\"output_max: float\")",
            "    .Attr(\"N: int >= 2\")",
            "    .Attr(\"T: type\")"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/types.pb.h\"",
            "#include \"tensorflow/core/lib/core/errors.h\"",
            "#include \"tensorflow/core/platform/types.h\"",
            "#include \"tensorflow/core/util/mirror_pad_mode.h\"",
            "#include \"tensorflow/core/util/padding.h\"",
            "#include \"tensorflow/core/util/strided_slice_op.h\"",
            "#include \"tensorflow/core/util/tensor_format.h\""
        ],
        [
            "                                       axis);",
            "      }",
            "      auto input_dims = c->Rank(c->input(0));",
            "      if (axis > input_dims) {",
            "        return errors::InvalidArgument(",
            "            \"Axis must be less than input dimension(\", input_dims, \"), got \",",
            "            axis);",
            "      }",
            "      const int minmax_rank = (axis == -1) ? 0 : 1;",
            "      TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));",
            "      ShapeHandle minmax;",
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));"
        ],
        [
            "      if (axis != -1) {",
            "        ShapeHandle input;",
            "        if (axis >= kint32max) {",
            "          // Check int32 max bound for a corner case to prevent integer flow",
            "          // when input actually has kint32max rank and above bound check is not",
            "          // triggered.",
            "          return errors::InvalidArgument(",
            "              \"Axis cannot be >= kint32max value, got \", axis);",
            "        }",
            "        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));",
            "        DimensionHandle depth;",
            "        TF_RETURN_IF_ERROR(",
            "            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c6fh-56w7-fvjw",
    "API Signature": "tf.raw_ops.Dequantize(\n    input,\n    min_range,\n    max_range,\n    mode='MIN_COMBINED',\n    narrow_range=False,\n    axis=-1,\n    dtype=tf.dtypes.float32,\n    name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Large integer argument",
    "Anomaly Description": "A large integer argument refers to an argument passed to a function or operation that represents a large integer value. It means that the argument is an integer value that exceeds the typical range of integer values supported by the underlying programming language or system.\n\nThe specific definition of a \"large\" integer may vary depending on the context and the limitations of the programming language or system being used. For example, in Python, integers have arbitrary precision, allowing you to work with integers of any size. However, other programming languages may have predefined limits on the range of integer values they can handle.\n\nIn the context of function arguments, a large integer argument can be used to represent various concepts or quantities. It may be used to specify an index, a count, a value, or any other numerical parameter required by the function or operation.",
    "Category": "Integer",
    "Argument": "axis=2**31-1,"
},
{
    "Title": "\n        Heap OOB read in shape inference for `ReverseSequence`\n      ",
    "Bug description": "The  implementation of shape inference for   does not fully validate the value of  batch_dim  and can result in a heap OOB read:",
    "Sample Code": "@\ndef test():\n  y = tf.raw_ops.ReverseSequence(\n    input = ['aaa','bbb'],\n    seq_lengths = [1,1,1],\n    seq_dim = -10,\n    batch_dim = -10 )\n  return y\n    \n\n    \ntest()",
    "Code change": [
        "@@ -1653,11 +1653,21 @@ REGISTER_OP(\"ReverseSequence\")\n         return errors::InvalidArgument(\n             \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);\n       }\n+\n       if (seq_dim >= input_rank) {\n         return errors::InvalidArgument(\n             \"seq_dim must be < input rank: \", seq_dim, \" vs. \", input_rank);\n       }\n \n+      // To prevent out of bound access when calling c->Dim(input, batch_dim),\n+      // batch_dim range [-1 * input rank, input rank) is allowed. However,\n+      // the op implementation has a stricter bound for batch_dim requiring >= 0\n+      // value. Thus, perform strict check here.\n+      if (batch_dim < 0) {\n+        return errors::InvalidArgument(\"batch_dim must be >=0, got \",\n+                                       batch_dim);\n+      }\n+\n       DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);\n       TF_RETURN_IF_ERROR(\n           c->Merge(batch_dim_dim, c->Dim(seq_lens_shape, 0), &batch_dim_dim));\n"
    ],
    "Buggy Code": [
        [
            "            \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);",
            "      }",
            "      if (seq_dim >= input_rank) {",
            "        return errors::InvalidArgument(",
            "            \"seq_dim must be < input rank: \", seq_dim, \" vs. \", input_rank);",
            "      }",
            "",
            "      DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);",
            "      TF_RETURN_IF_ERROR(",
            "          c->Merge(batch_dim_dim, c->Dim(seq_lens_shape, 0), &batch_dim_dim));",
            "",
            "      // Replace batch_dim of input with batch_size",
            "      ShapeHandle output_shape;",
            "      TF_RETURN_IF_ERROR(",
            "          c->ReplaceDim(input, batch_dim, batch_dim_dim, &output_shape));",
            "      c->set_output(0, output_shape);",
            "      return Status::OK();",
            "    });",
            "",
            "// --------------------------------------------------------------------------",
            "REGISTER_OP(\"Rank\")"
        ]
    ],
    "Clean Code": [
        [
            "            \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);",
            "      }",
            "",
            "      if (seq_dim >= input_rank) {",
            "        return errors::InvalidArgument(",
            "            \"seq_dim must be < input rank: \", seq_dim, \" vs. \", input_rank);",
            "      }",
            "",
            "      // To prevent out of bound access when calling c->Dim(input, batch_dim),",
            "      // batch_dim range [-1 * input rank, input rank) is allowed. However,",
            "      // the op implementation has a stricter bound for batch_dim requiring >= 0",
            "      // value. Thus, perform strict check here.",
            "      if (batch_dim < 0) {",
            "        return errors::InvalidArgument(\"batch_dim must be >=0, got \",",
            "                                       batch_dim);",
            "      }",
            "",
            "      DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);",
            "      TF_RETURN_IF_ERROR(",
            "          c->Merge(batch_dim_dim, c->Dim(seq_lens_shape, 0), &batch_dim_dim));",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6gmv-pjp9-p8w8",
    "API Signature": "tf.raw_ops.ReverseSequence(\n    input, seq_lengths, seq_dim, batch_dim=0, name=None\n)\n",
    "Score": 0.039568345323741004,
    "Anomaly": "Negative integer argument",
    "Anomaly Description": "A negative integer argument in Python refers to an integer value that is less than zero. It is a numeric value that represents a negative quantity or position in a numerical sequence. In Python, negative integers are denoted by placing a minus sign (-) before the numerical value. For example, -1, -2, -3, and so on.",
    "Category": "Integer",
    "Argument": "batch_dim = -10"
},
{
    "Title": "\n        Floating point division by 0 when executing convolution operators\n      ",
    "Bug description": "The  estimator for the cost of some convolution operations  can be made to execute a division by 0:",
    "Sample Code": "@\ndef test():\n  y=tf.raw_ops.AvgPoolGrad(\n    orig_input_shape=[1,1,1,1],\n    grad=[[[[1.0],[1.0],[1.0]]],[[[2.0],[2.0],[2.0]]],[[[3.0],[3.0],[3.0]]]],\n    ksize=[1,1,1,1],\n    strides=[1,1,1,0],\n    padding='VALID',\n    data_format='NCHW')\n  return y\n\n\n\ntest()",
    "Code change": [
        "@@ -355,6 +355,7 @@ tf_cc_test(\n         \"//tensorflow/core:protos_all_cc\",\n         \"//tensorflow/core:test\",\n         \"//tensorflow/core:test_main\",\n+        \"//tensorflow/core/platform:status_matchers\",\n     ],\n )\n \n",
        "@@ -2153,7 +2153,7 @@ OpInfo::TensorProperties OpLevelCostEstimator::DescribeTensor(\n }\n \n /* static */\n-OpLevelCostEstimator::ConvolutionDimensions\n+StatusOr<OpLevelCostEstimator::ConvolutionDimensions>\n OpLevelCostEstimator::OpDimensionsFromInputs(\n     const TensorShapeProto& original_image_shape, const OpInfo& op_info,\n     bool* found_unknown_shapes) {\n@@ -2190,6 +2190,11 @@ OpLevelCostEstimator::OpDimensionsFromInputs(\n   std::vector<int64_t> strides = GetStrides(op_info);\n   int64_t sx = strides[x_index];\n   int64_t sy = strides[y_index];\n+  if (sx == 0 || sy == 0) {\n+    return errors::InvalidArgument(\n+        \"Stride must be > 0 for Height and Width, but got (\", sy, \", \", sx,\n+        \")\");\n+  }\n   const auto padding = GetPadding(op_info);\n \n   int64_t ox = GetOutputSize(ix, kx, sx, padding);\n@@ -2206,8 +2211,9 @@ Status OpLevelCostEstimator::PredictMaxPool(const OpContext& op_context,\n   bool found_unknown_shapes = false;\n   const auto& op_info = op_context.op_info;\n   // x: op_info.inputs(0)\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n   // kx * ky - 1 comparisons per output (kx * xy > 1)\n   // or 1 copy per output (kx * k1 = 1).\n   int per_output_ops = dims.kx * dims.ky == 1 ? 1 : dims.kx * dims.ky - 1;\n@@ -2248,8 +2254,9 @@ Status OpLevelCostEstimator::PredictMaxPoolGrad(const OpContext& op_context,\n                                    op_info.ShortDebugString());\n   }\n \n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n \n   int64_t ops = 0;\n   if (dims.kx == 1 && dims.ky == 1) {\n@@ -2324,8 +2331,9 @@ Status OpLevelCostEstimator::PredictAvgPool(const OpContext& op_context,\n   bool found_unknown_shapes = false;\n   const auto& op_info = op_context.op_info;\n   // x: op_info.inputs(0)\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n \n   // kx * ky - 1 additions and 1 multiplication per output.\n   int64_t ops = dims.batch * dims.ox * dims.oy * dims.oz * dims.kx * dims.ky;\n@@ -2382,8 +2390,9 @@ Status OpLevelCostEstimator::PredictAvgPoolGrad(const OpContext& op_context,\n     found_unknown_shapes = true;\n   }\n \n-  ConvolutionDimensions dims =\n-      OpDimensionsFromInputs(x_shape, op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(\n+      ConvolutionDimensions dims,\n+      OpDimensionsFromInputs(x_shape, op_info, &found_unknown_shapes));\n \n   int64_t ops = 0;\n   if (dims.kx <= dims.sx && dims.ky <= dims.sy) {\n@@ -2409,8 +2418,9 @@ Status OpLevelCostEstimator::PredictFusedBatchNorm(\n   // offset: op_info.inputs(2)\n   // mean: op_info.inputs(3)  --> only for inference\n   // variance: op_info.inputs(4) --> only for inference\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n   const bool is_training = IsTraining(op_info);\n \n   int64_t ops = 0;\n@@ -2459,8 +2469,9 @@ Status OpLevelCostEstimator::PredictFusedBatchNormGrad(\n   // scale: op_info.inputs(2)\n   // mean: op_info.inputs(3)\n   // variance or inverse of variance: op_info.inputs(4)\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(1).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(1).shape(), op_info,\n+                                             &found_unknown_shapes));\n \n   int64_t ops = 0;\n   const auto rsqrt_cost = Eigen::internal::functor_traits<\n",
        "@@ -290,7 +290,7 @@ class OpLevelCostEstimator {\n       bool* found_unknown_shapes);\n \n   // For Pooling, FusedBatchNorm, and their grad ops.\n-  static ConvolutionDimensions OpDimensionsFromInputs(\n+  static StatusOr<ConvolutionDimensions> OpDimensionsFromInputs(\n       const TensorShapeProto& original_image_shape, const OpInfo& op_info,\n       bool* found_unknown_shapes);\n \n",
        "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/tensor_shape.pb.h\"\n #include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/platform/status_matchers.h\"\n #include \"tensorflow/core/platform/test.h\"\n #include \"tensorflow/core/protobuf/device_properties.pb.h\"\n \n@@ -558,9 +559,10 @@ class OpLevelCostEstimatorTest : public ::testing::Test {\n     }\n \n     bool found_unknown_shapes;\n-    auto dims = OpLevelCostEstimator::OpDimensionsFromInputs(\n-        op_context.op_info.inputs(0).shape(), op_context.op_info,\n-        &found_unknown_shapes);\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto dims, OpLevelCostEstimator::OpDimensionsFromInputs(\n+                       op_context.op_info.inputs(0).shape(), op_context.op_info,\n+                       &found_unknown_shapes));\n     Padding padding_enum;\n     if (padding == \"VALID\") {\n       padding_enum = Padding::VALID;\n@@ -581,6 +583,38 @@ class OpLevelCostEstimatorTest : public ::testing::Test {\n     EXPECT_EQ(padding_enum, dims.padding);\n   }\n \n+  StatusOr<OpLevelCostEstimator::ConvolutionDimensions>\n+  CallOpDimensionsFromInputs(const int n, const int h, const int w, const int c,\n+                             const int kx, const int ky, const int sx,\n+                             const int sy, const string& data_format,\n+                             const string& padding) {\n+    OpContext op_context;\n+\n+    const std::vector<int> x = {n, h, w, c};\n+    const std::vector<int> ksize = {1, kx, ky, 1};\n+    std::vector<int> strides;\n+    if (data_format == \"NHWC\") {\n+      strides = {1, sy, sx, 1};\n+    } else {\n+      strides = {1, 1, sy, sx};\n+    }\n+\n+    auto& op_info = op_context.op_info;\n+    SetCpuDevice(&op_info);\n+    op_info.set_op(\"MaxPool\");\n+\n+    DescribeTensor4D(x[0], x[1], x[2], x[3], op_info.add_inputs());\n+    auto* attr = op_info.mutable_attr();\n+    SetAttrValue(data_format, &(*attr)[\"data_format\"]);\n+    SetAttrValue(padding, &(*attr)[\"padding\"]);\n+    SetAttrValue(strides, &(*attr)[\"strides\"]);\n+    SetAttrValue(ksize, &(*attr)[\"ksize\"]);\n+    bool found_unknown_shapes;\n+    return OpLevelCostEstimator::OpDimensionsFromInputs(\n+        op_context.op_info.inputs(0).shape(), op_context.op_info,\n+        &found_unknown_shapes);\n+  }\n+\n   OpLevelCostEstimator estimator_;\n };\n \n@@ -1383,6 +1417,26 @@ TEST_F(OpLevelCostEstimatorTest, OpDimensionsFromInputs) {\n   }\n }\n \n+TEST_F(OpLevelCostEstimatorTest, OpDimensionsFromInputsError) {\n+  std::vector<string> paddings = {\"VALID\", \"SAME\"};\n+  std::vector<string> formats = {\"NHWC\", \"NCHW\"};\n+  for (const auto& p : paddings) {\n+    for (const auto& f : formats) {\n+      // n, h, w, c, kx, ky, sx, sy, data_format, padding.\n+      ASSERT_THAT(\n+          CallOpDimensionsFromInputs(10, 14, 14, 3840, 3, 3, 0, 2, f, p),\n+          testing::StatusIs(\n+              error::INVALID_ARGUMENT,\n+              \"Stride must be > 0 for Height and Width, but got (2, 0)\"));\n+      ASSERT_THAT(\n+          CallOpDimensionsFromInputs(10, 14, 14, 3840, 3, 3, 2, 0, f, p),\n+          testing::StatusIs(\n+              error::INVALID_ARGUMENT,\n+              \"Stride must be > 0 for Height and Width, but got (0, 2)\"));\n+    }\n+  }\n+}\n+\n TEST_F(OpLevelCostEstimatorTest, PredictMaxPool) {\n   auto predict_max_pool = [this](const int n, const int in, const int c,\n                                  const int k, const int s,\n"
    ],
    "Buggy Code": [
        [
            "        \"//tensorflow/core:test\",",
            "        \"//tensorflow/core:test_main\",",
            "    ],",
            ")",
            "",
            "cc_library(",
            "    name = \"analytical_cost_estimator\","
        ],
        [
            "",
            "/* static */",
            "OpLevelCostEstimator::ConvolutionDimensions",
            "OpLevelCostEstimator::OpDimensionsFromInputs(",
            "    const TensorShapeProto& original_image_shape, const OpInfo& op_info,",
            "    bool* found_unknown_shapes) {",
            "  VLOG(2) << \"op features: \" << op_info.DebugString();"
        ],
        [
            "  int64_t sx = strides[x_index];",
            "  int64_t sy = strides[y_index];",
            "  const auto padding = GetPadding(op_info);",
            "",
            "  int64_t ox = GetOutputSize(ix, kx, sx, padding);",
            "  int64_t oy = GetOutputSize(iy, ky, sy, padding);",
            "  int64_t oz = iz;",
            "",
            "  OpLevelCostEstimator::ConvolutionDimensions conv_dims = {",
            "      batch, ix, iy, iz, kx, ky, kz, oz, ox, oy, sx, sy, padding};",
            "  return conv_dims;"
        ],
        [
            "  // or 1 copy per output (kx * k1 = 1).",
            "  int per_output_ops = dims.kx * dims.ky == 1 ? 1 : dims.kx * dims.ky - 1;",
            "  int64_t ops = dims.batch * dims.ox * dims.oy * dims.oz * per_output_ops;",
            "  node_costs->num_compute_ops = ops;",
            "",
            "  int64_t input_size = 0;",
            "  if (dims.ky >= dims.sy) {",
            "    input_size = CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);",
            "  } else {  // dims.ky < dims.sy"
        ],
        [
            "  if (dims.kx == 1 && dims.ky == 1) {",
            "    // 1x1 window. No need to know which input was max.",
            "    ops = dims.batch * dims.ix * dims.iy * dims.iz;",
            "  } else if (dims.kx <= dims.sx && dims.ky <= dims.sy) {",
            "    // Non-overlapping window: re-run maxpool, then assign zero or y_grad.",
            "    ops = dims.batch * dims.iz *",
            "          (dims.ox * dims.oy * (dims.kx * dims.ky - 1) + dims.ix * dims.iy);",
            "  } else {",
            "    // Overlapping window: initialize with zeros, re-run maxpool, then"
        ],
        [
            "  node_costs->num_compute_ops = ops;",
            "",
            "  int64_t input_size;",
            "  if (dims.ky >= dims.sy) {",
            "    input_size = CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);",
            "  } else {  // dims.ky < dims.sy",
            "    // vertical stride is larger than vertical kernel; assuming row-major",
            "    // format, skip unnecessary rows (or read every kx rows per sy rows, as the",
            "    // others are not used for output)."
        ],
        [
            "    ops = dims.batch * dims.iz * (dims.ix * dims.iy + dims.ox * dims.oy);",
            "  } else {",
            "    // Overlapping window.",
            "    ops = dims.batch * dims.iz *",
            "          (dims.ix * dims.iy + dims.ox * dims.oy * (dims.kx * dims.ky + 1));",
            "  }",
            "  auto s = PredictDefaultNodeCosts(ops, op_context, &found_unknown_shapes,",
            "                                   node_costs);",
            "  node_costs->max_memory = node_costs->num_total_output_bytes();"
        ],
        [
            "  if (is_training) {",
            "    ops = dims.iz * (dims.batch * dims.ix * dims.iy * 4 + 6 + rsqrt_cost);",
            "  } else {",
            "    ops = dims.batch * dims.ix * dims.iy * dims.iz * 2;",
            "  }",
            "  node_costs->num_compute_ops = ops;",
            "",
            "  const int64_t size_nhwc =",
            "      CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);"
        ],
        [
            "",
            "  const int64_t size_nhwc =",
            "      CalculateTensorSize(op_info.inputs(1), &found_unknown_shapes);",
            "  const int64_t size_c =",
            "      CalculateTensorSize(op_info.inputs(2), &found_unknown_shapes);",
            "  // TODO(dyoon): fix missing memory cost for variance input (size_c) and",
            "  // yet another read of y_backprop (size_nhwc) internally.",
            "  node_costs->num_input_bytes_accessed = {size_nhwc, size_nhwc, size_c, size_c};",
            "  node_costs->num_output_bytes_accessed = {size_nhwc, size_c, size_c};"
        ],
        [
            "",
            "  // For Pooling, FusedBatchNorm, and their grad ops.",
            "  static ConvolutionDimensions OpDimensionsFromInputs(",
            "      const TensorShapeProto& original_image_shape, const OpInfo& op_info,",
            "      bool* found_unknown_shapes);",
            "",
            "  // Helper to construct child operation contexts for the component operations"
        ]
    ],
    "Clean Code": [
        [
            "        \"//tensorflow/core:test\",",
            "        \"//tensorflow/core:test_main\",",
            "        \"//tensorflow/core/platform:status_matchers\",",
            "    ],",
            ")",
            "",
            "cc_library("
        ],
        [
            "",
            "/* static */",
            "StatusOr<OpLevelCostEstimator::ConvolutionDimensions>",
            "OpLevelCostEstimator::OpDimensionsFromInputs(",
            "    const TensorShapeProto& original_image_shape, const OpInfo& op_info,",
            "    bool* found_unknown_shapes) {",
            "  VLOG(2) << \"op features: \" << op_info.DebugString();"
        ],
        [
            "  int64_t sx = strides[x_index];",
            "  int64_t sy = strides[y_index];",
            "  if (sx == 0 || sy == 0) {",
            "    return errors::InvalidArgument(",
            "        \"Stride must be > 0 for Height and Width, but got (\", sy, \", \", sx,",
            "        \")\");",
            "  }",
            "  const auto padding = GetPadding(op_info);",
            "",
            "  int64_t ox = GetOutputSize(ix, kx, sx, padding);",
            "  int64_t oy = GetOutputSize(iy, ky, sy, padding);"
        ],
        [
            "  const auto& op_info = op_context.op_info;",
            "  // x: op_info.inputs(0)",
            "  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,",
            "                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,",
            "                                             &found_unknown_shapes));",
            "  // kx * ky - 1 comparisons per output (kx * xy > 1)",
            "  // or 1 copy per output (kx * k1 = 1).",
            "  int per_output_ops = dims.kx * dims.ky == 1 ? 1 : dims.kx * dims.ky - 1;",
            "  int64_t ops = dims.batch * dims.ox * dims.oy * dims.oz * per_output_ops;"
        ],
        [
            "  }",
            "",
            "  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,",
            "                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,",
            "                                             &found_unknown_shapes));",
            "",
            "  int64_t ops = 0;",
            "  if (dims.kx == 1 && dims.ky == 1) {",
            "    // 1x1 window. No need to know which input was max."
        ],
        [
            "  const auto& op_info = op_context.op_info;",
            "  // x: op_info.inputs(0)",
            "  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,",
            "                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,",
            "                                             &found_unknown_shapes));",
            "",
            "  // kx * ky - 1 additions and 1 multiplication per output.",
            "  int64_t ops = dims.batch * dims.ox * dims.oy * dims.oz * dims.kx * dims.ky;",
            "  node_costs->num_compute_ops = ops;"
        ],
        [
            "  }",
            "",
            "  TF_ASSIGN_OR_RETURN(",
            "      ConvolutionDimensions dims,",
            "      OpDimensionsFromInputs(x_shape, op_info, &found_unknown_shapes));",
            "",
            "  int64_t ops = 0;",
            "  if (dims.kx <= dims.sx && dims.ky <= dims.sy) {",
            "    // Non-overlapping window."
        ],
        [
            "  // mean: op_info.inputs(3)  --> only for inference",
            "  // variance: op_info.inputs(4) --> only for inference",
            "  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,",
            "                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,",
            "                                             &found_unknown_shapes));",
            "  const bool is_training = IsTraining(op_info);",
            "",
            "  int64_t ops = 0;",
            "  const auto rsqrt_cost = Eigen::internal::functor_traits<"
        ],
        [
            "  // mean: op_info.inputs(3)",
            "  // variance or inverse of variance: op_info.inputs(4)",
            "  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,",
            "                      OpDimensionsFromInputs(op_info.inputs(1).shape(), op_info,",
            "                                             &found_unknown_shapes));",
            "",
            "  int64_t ops = 0;",
            "  const auto rsqrt_cost = Eigen::internal::functor_traits<",
            "      Eigen::internal::scalar_rsqrt_op<float>>::Cost;"
        ],
        [
            "",
            "  // For Pooling, FusedBatchNorm, and their grad ops.",
            "  static StatusOr<ConvolutionDimensions> OpDimensionsFromInputs(",
            "      const TensorShapeProto& original_image_shape, const OpInfo& op_info,",
            "      bool* found_unknown_shapes);",
            "",
            "  // Helper to construct child operation contexts for the component operations"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v3f7-j968-4h5f",
    "API Signature": "tf.raw_ops.AvgPoolGrad(\n    orig_input_shape,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NHWC',\n    name=None\n)\n",
    "Score": 0.02877697841726619,
    "Anomaly": "Negative integer list element",
    "Anomaly Description": "A negative integer list element in Python refers to an element within a list that has a negative integer value. It means that the element is a negative number represented by an integer data type.",
    "Category": "List",
    "Argument": "strides=[1,1,1,0],"
},
{
    "Title": "\n        `SparseFillEmptyRows` heap OOB\n      ",
    "Bug description": "The  implementation  of  SparseFillEmptyRows  can be made to trigger a heap OOB access:",
    "Sample Code": "data=tf.raw_ops.SparseFillEmptyRows(\n  indices=[[0,0],[0,0],[0,0]],\n  values=['sssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss'],\n  dense_shape=[5,3],\n  ],\n  default_value='o')",
    "Code change": [
        "@@ -24,11 +24,13 @@ limitations under the License.\n #include <vector>\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/util/sparse/sparse_tensor.h\"\n \n namespace tensorflow {\n@@ -222,6 +224,12 @@ void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                     errors::InvalidArgument(\"values must be a vector, saw: \",\n                                             values_t.shape().DebugString()),\n                     done);\n+  OP_REQUIRES_ASYNC(\n+      context, indices_t.dim_size(0) == values_t.dim_size(0),\n+      errors::InvalidArgument(\"The length of `values` (\", values_t.dim_size(0),\n+                              \") must match the first dimension of `indices` (\",\n+                              indices_t.dim_size(0), \").\"),\n+      done);\n   OP_REQUIRES_ASYNC(\n       context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n       errors::InvalidArgument(\"default_value must be a scalar, saw: \",\n"
    ],
    "Buggy Code": [
        [
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "#include \"tensorflow/core/util/sparse/sparse_tensor.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using CPUDevice = Eigen::ThreadPoolDevice;",
            "using GPUDevice = Eigen::GpuDevice;"
        ],
        [
            "  OP_REQUIRES_ASYNC(",
            "      context, TensorShapeUtils::IsScalar(default_value_t.shape()),",
            "      errors::InvalidArgument(\"default_value must be a scalar, saw: \",",
            "                              default_value_t.shape().DebugString()),",
            "      done);",
            "  // TODO(ebrevdo): add shape checks between values, indices,",
            "  // Also add check that dense rank > 0.",
            "  OP_REQUIRES_ASYNC(context, dense_shape_t.NumElements() != 0,",
            "                    errors::InvalidArgument(\"Dense shape cannot be empty.\"),",
            "                    done);",
            "",
            "  using FunctorType = functor::SparseFillEmptyRows<Device, T, Tindex>;"
        ]
    ],
    "Clean Code": [
        [
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#include \"tensorflow/core/util/sparse/sparse_tensor.h\"",
            "",
            "namespace tensorflow {",
            ""
        ],
        [
            "                                            values_t.shape().DebugString()),",
            "                    done);",
            "  OP_REQUIRES_ASYNC(",
            "      context, indices_t.dim_size(0) == values_t.dim_size(0),",
            "      errors::InvalidArgument(\"The length of `values` (\", values_t.dim_size(0),",
            "                              \") must match the first dimension of `indices` (\",",
            "                              indices_t.dim_size(0), \").\"),",
            "      done);",
            "  OP_REQUIRES_ASYNC(",
            "      context, TensorShapeUtils::IsScalar(default_value_t.shape()),",
            "      errors::InvalidArgument(\"default_value must be a scalar, saw: \",",
            "                              default_value_t.shape().DebugString()),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rg3m-hqc5-344v",
    "API Signature": "tf.raw_ops.SparseFillEmptyRows(\n    indices, values, dense_shape, default_value, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "List",
    "Argument": "indices=[[0,0],[0,0],[0,0]],\nvalues=['sssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss'],"
},
{
    "Title": "\n        Segfault due to negative splits in `SplitV`\n      ",
    "Bug description": "The  implementation  of  SplitV  can trigger a segfault is an attacker supplies negative arguments:",
    "Sample Code": "tf.raw_ops.SplitV(\n  value=tf.constant([]),\n  size_splits=[-1, -2]\n  ,axis=0,\n  ,\n  num_split=2)",
    "Code change": [
        "@@ -138,6 +138,13 @@ class SplitVOpBase : public OpKernel {\n       (*split_sizes_vec)[neg_one_dim] = input_size_split_dim - determined_size;\n     }\n \n+    for (int i = 0; i < split_sizes_vec->size(); ++i) {\n+      const Tlen& split_size = (*split_sizes_vec)[i];\n+      OP_REQUIRES(context, split_size >= Tlen(0),\n+                  errors::InvalidArgument(\"Split size at index \", i,\n+                                          \" must be >= 0. Got: \", split_size));\n+    }\n+\n     // Special case 2: split along the 1st dimension. The requirements are that\n     // either we are splitting the outer dimension of two or more such that\n     // every outer subpart is aligned or that the split sizes mean that they are\n",
        "@@ -681,6 +681,12 @@ REGISTER_OP(\"SplitV\")\n           if (data[i] == -1 && c->ValueKnown(split_dim_size)) {\n             size = split_dim_size - total_size;\n           }\n+          // If we have a negative known size (either explicit, or computed\n+          // via -1), then the split sizes are invalid.\n+          if (size < -1 || (size == -1 && c->ValueKnown(split_dim_size))) {\n+            return errors::InvalidArgument(\"Split size at index \", i,\n+                                           \" must be >= 0. Got: \", size);\n+          }\n           TF_RETURN_IF_ERROR(\n               c->ReplaceDim(input, split_dim, c->MakeDim(size), &output_shape));\n           c->set_output(i, output_shape);\n",
        "@@ -384,6 +384,24 @@ class SplitOpTest(test.TestCase):\n                                   \"must have exactly one element\"):\n         sess.run(y, {x: np.array([], dtype=np.int32), splits: [4, 11, 15]})\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testNegativeSizes(self):\n+    x = constant_op.constant([1, 2, 3], dtypes.float32)\n+    # A size of -1 signifies to determine size based on sum of other splits.\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                \"Split size at index 1 must be >= 0. Got: -2\"):\n+      splits = [-1, -2]\n+      self.evaluate(array_ops.split(x, splits, axis=0))\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def testBadSplitSizes(self):\n+    x = constant_op.constant([1, 2], dtypes.float32)\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                \"Determined shape must either match input\"\n+                                \"|can't split axis\"):\n+      splits = [1, 2]\n+      self.evaluate(array_ops.split(x, splits, axis=0))\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "    }",
            "",
            "    // Special case 2: split along the 1st dimension. The requirements are that",
            "    // either we are splitting the outer dimension of two or more such that",
            "    // every outer subpart is aligned or that the split sizes mean that they are",
            "    // always aligned. In these cases, we can share the underlying buffer.",
            "    //",
            "    // Apply this optimization conservatively: if input is aligned,",
            "    // the resulting tensors must be aligned. It's conservative",
            "    // because if the immediate consumer of the resulting tensors are",
            "    // not using eigen for computation, its perfectly fine to avoid",
            "    // the copying.",
            "    if (SplitHasAlignedOutputsInFirstDimension("
        ],
        [
            "            size = split_dim_size - total_size;",
            "          }",
            "          TF_RETURN_IF_ERROR(",
            "              c->ReplaceDim(input, split_dim, c->MakeDim(size), &output_shape));",
            "          c->set_output(i, output_shape);",
            "        }",
            "        if (c->ValueKnown(split_dim_size)) {",
            "          if (has_neg_one ? total_size > split_dim_size",
            "                          : total_size != split_dim_size) {",
            "            return errors::InvalidArgument(",
            "                \"can't split axis of size \", split_dim_size,",
            "                \" into pieces of size [\", absl::StrJoin(data, \",\"), \"]\");"
        ]
    ],
    "Clean Code": [
        [
            "    }",
            "",
            "    for (int i = 0; i < split_sizes_vec->size(); ++i) {",
            "      const Tlen& split_size = (*split_sizes_vec)[i];",
            "      OP_REQUIRES(context, split_size >= Tlen(0),",
            "                  errors::InvalidArgument(\"Split size at index \", i,",
            "                                          \" must be >= 0. Got: \", split_size));",
            "    }",
            "",
            "    // Special case 2: split along the 1st dimension. The requirements are that",
            "    // either we are splitting the outer dimension of two or more such that",
            "    // every outer subpart is aligned or that the split sizes mean that they are",
            "    // always aligned. In these cases, we can share the underlying buffer."
        ],
        [
            "            size = split_dim_size - total_size;",
            "          }",
            "          // If we have a negative known size (either explicit, or computed",
            "          // via -1), then the split sizes are invalid.",
            "          if (size < -1 || (size == -1 && c->ValueKnown(split_dim_size))) {",
            "            return errors::InvalidArgument(\"Split size at index \", i,",
            "                                           \" must be >= 0. Got: \", size);",
            "          }",
            "          TF_RETURN_IF_ERROR(",
            "              c->ReplaceDim(input, split_dim, c->MakeDim(size), &output_shape));",
            "          c->set_output(i, output_shape);",
            "        }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cpf4-wx82-gxp6",
    "API Signature": "tf.raw_ops.SplitV(\n    value, size_splits, axis, num_split, name=None\n)\n",
    "Score": 0.02877697841726619,
    "Anomaly": "Negative integer list element",
    "Anomaly Description": "A negative integer list element in Python refers to an element within a list that has a negative integer value. It means that the element is a negative number represented by an integer data type.",
    "Category": "List",
    "Argument": "size_splits=[-1, -2]"
},
{
    "Title": "\n        Access to invalid memory during shape inference in `Cudnn*` ops\n      ",
    "Bug description": "The  shape inference code  for the  Cudnn*  operations in TensorFlow can be tricked into accessing invalid memory, via a heap buffer overflow:",
    "Sample Code": "@\ndef func():\n  return tf.raw_ops.CudnnRNNV3(\n    input=[0.1, 0.1],\n    input_h=[0.5],\n    input_c=[0.1, 0.1, 0.1], \n    params=[0.5, 0.5],\n    sequence_lengths=[-1, 0, 1])\n  \n])\n  \nfunc() ",
    "Code change": [
        "@@ -81,11 +81,17 @@ REGISTER_OP(\"CudnnRNN\")\n     .Attr(\"seed2: int = 0\")\n     .Attr(\"is_training: bool = true\")\n     .SetShapeFn([](InferenceContext* c) {\n+      ShapeHandle unused;\n       auto input_shape = c->input(0);\n       auto input_h_shape = c->input(1);\n+      TF_RETURN_IF_ERROR(c->WithRank(input_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(input_h_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 1, &unused));\n+\n       auto seq_length = c->Dim(input_shape, 0);\n       auto batch_size = c->Dim(input_shape, 1);\n       auto num_units = c->Dim(input_h_shape, 2);\n+\n       string direction;\n       TF_RETURN_IF_ERROR(c->GetAttr(\"direction\", &direction));\n       string rnn_mode;\n@@ -124,8 +130,13 @@ REGISTER_OP(\"CudnnRNNV2\")\n     .Attr(\"seed2: int = 0\")\n     .Attr(\"is_training: bool = true\")\n     .SetShapeFn([](InferenceContext* c) {\n+      ShapeHandle unused;\n       auto input_shape = c->input(0);\n       auto input_h_shape = c->input(1);\n+      TF_RETURN_IF_ERROR(c->WithRank(input_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(input_h_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 1, &unused));\n+\n       auto seq_length = c->Dim(input_shape, 0);\n       auto batch_size = c->Dim(input_shape, 1);\n       auto num_units = c->Dim(input_h_shape, 2);\n@@ -171,16 +182,26 @@ REGISTER_OP(\"CudnnRNNV3\")\n     .Attr(\"is_training: bool = true\")\n     .Attr(\"time_major: bool = true\")\n     .SetShapeFn([](InferenceContext* c) {\n+      ShapeHandle unused;\n       auto input_shape = c->input(0);\n       auto input_h_shape = c->input(1);\n       auto input_c_shape = c->input(2);\n+      TF_RETURN_IF_ERROR(c->WithRank(input_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(input_h_shape, 3, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 1, &unused));\n+      TF_RETURN_IF_ERROR(c->WithRank(c->input(4), 1, &unused));\n+\n       auto max_seq_length = c->Dim(input_shape, 0);\n       auto batch_size = c->Dim(input_shape, 1);\n       auto num_units = c->Dim(input_h_shape, 2);\n+\n       string direction;\n       TF_RETURN_IF_ERROR(c->GetAttr(\"direction\", &direction));\n       string rnn_mode;\n       TF_RETURN_IF_ERROR(c->GetAttr(\"rnn_mode\", &rnn_mode));\n+      if (rnn_mode == \"lstm\") {\n+        TF_RETURN_IF_ERROR(c->WithRank(input_c_shape, 3, &unused));\n+      }\n       int dir_count = (direction == \"bidirectional\") ? 2 : 1;\n       DimensionHandle output_size;\n       TF_RETURN_IF_ERROR(c->Multiply(num_units, dir_count, &output_size));\n",
        "@@ -68,6 +68,11 @@ TEST(CudnnRNNOpsTest, ForwardLstm_ShapeFn) {\n                    .Attr(\"direction\", \"unidirectional\")\n                    .Finalize(&op.node_def));\n   INFER_OK(op, input_shapes_desc, output_shapes_desc);\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[];[?,?,?];[?,?,?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[];[?,?,?];[?]\");\n+  // Disabled because the kernel does not check shape of input_c.\n+  // INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[?,?,?];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[?,?,?];[]\");\n }\n \n TEST(CudnnRNNOpsTest, ForwardV2Lstm_ShapeFn) {\n@@ -100,6 +105,11 @@ TEST(CudnnRNNOpsTest, ForwardV2Lstm_ShapeFn) {\n                    .Attr(\"direction\", \"unidirectional\")\n                    .Finalize(&op.node_def));\n   INFER_OK(op, input_shapes_desc, output_shapes_desc);\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[];[?,?,?];[?,?,?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[];[?,?,?];[?]\");\n+  // Disabled because the kernel does not check shape of input_c.\n+  // INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[?,?,?];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[?,?,?];[]\");\n }\n \n TEST(CudnnRNNOpsTest, ForwardV3Lstm_ShapeFn) {\n@@ -137,6 +147,52 @@ TEST(CudnnRNNOpsTest, ForwardV3Lstm_ShapeFn) {\n                    .Attr(\"direction\", \"unidirectional\")\n                    .Finalize(&op.node_def));\n   INFER_OK(op, input_shapes_desc, output_shapes_desc);\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[];[?,?,?];[?,?,?];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[];[?,?,?];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[?,?,?];[];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[?,?,?];[];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[?,?,?];[?];[]\");\n+}\n+\n+TEST(CudnnRNNOpsTest, ForwardV3Gru) {\n+  int max_seq_length = 2;\n+  int batch_size = 3;\n+  int num_units = 4;\n+  int num_layers = 5;\n+  int dir_count = 1;\n+  std::vector<int> input_shape = {max_seq_length, batch_size, num_units};\n+  std::vector<int> input_h_shape = {num_layers * dir_count, batch_size,\n+                                    num_units};\n+  std::vector<int> input_c_shape = {num_layers * dir_count, batch_size,\n+                                    num_units};\n+  std::vector<int> output_shape = {max_seq_length, batch_size,\n+                                   num_units * dir_count};\n+  std::vector<int> seq_lengths_shape = {batch_size};\n+  auto shape_to_str = [](const std::vector<int>& v) {\n+    return strings::StrCat(\"[\", absl::StrJoin(v, \",\"), \"]\");\n+  };\n+  string input_shapes_desc = strings::StrCat(\n+      shape_to_str(input_shape), \";\", shape_to_str(input_h_shape), \";\",\n+      shape_to_str(input_c_shape), \";\", \"[?]\", \";\",\n+      shape_to_str(seq_lengths_shape));\n+  string output_shapes_desc = \"[d0_0,d0_1,d1_2];in1;[];?;?\";\n+\n+  ShapeInferenceTestOp op(\"CudnnRNNV3\");\n+  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"CudnnRNNV3\")\n+                   .Input({\"input\", 0, DT_FLOAT})\n+                   .Input({\"input_h\", 0, DT_FLOAT})\n+                   .Input({\"input_c\", 0, DT_FLOAT})\n+                   .Input({\"params\", 0, DT_FLOAT})\n+                   .Input({\"sequence_lengths\", 0, DT_INT32})\n+                   .Attr(\"rnn_mode\", \"gru\")\n+                   .Attr(\"input_mode\", \"auto_select\")\n+                   .Attr(\"direction\", \"unidirectional\")\n+                   .Finalize(&op.node_def));\n+  INFER_OK(op, input_shapes_desc, output_shapes_desc);\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[];[?,?,?];[];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 3 \", op, \"[?,?,?];[];[];[?];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[];[];[?]\");\n+  INFER_ERROR(\"Shape must be rank 1 \", op, \"[?,?,?];[?,?,?];[];[?];[]\");\n }\n \n }  // end namespace tensorflow\n"
    ],
    "Buggy Code": [
        [
            "    .Attr(\"is_training: bool = true\")",
            "    .SetShapeFn([](InferenceContext* c) {",
            "      auto input_shape = c->input(0);",
            "      auto input_h_shape = c->input(1);",
            "      auto seq_length = c->Dim(input_shape, 0);",
            "      auto batch_size = c->Dim(input_shape, 1);",
            "      auto num_units = c->Dim(input_h_shape, 2);",
            "      string direction;",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"direction\", &direction));",
            "      string rnn_mode;",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"rnn_mode\", &rnn_mode));",
            "      int dir_count = (direction == \"bidirectional\") ? 2 : 1;",
            "      DimensionHandle output_size;",
            "      TF_RETURN_IF_ERROR(c->Multiply(num_units, dir_count, &output_size));",
            "      auto output_shape = c->MakeShape({seq_length, batch_size, output_size});",
            "      auto output_h_shape = input_h_shape;",
            "      auto output_c_shape TF_ATTRIBUTE_UNUSED ="
        ],
        [
            "      auto num_units = c->Dim(input_h_shape, 2);",
            "      string direction;",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"direction\", &direction));",
            "      string rnn_mode;",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"rnn_mode\", &rnn_mode));",
            "      int dir_count = (direction == \"bidirectional\") ? 2 : 1;",
            "      DimensionHandle output_size;",
            "      TF_RETURN_IF_ERROR(c->Multiply(num_units, dir_count, &output_size));",
            "      auto output_shape = c->MakeShape({seq_length, batch_size, output_size});",
            "      auto output_h_shape = input_h_shape;",
            "      auto output_c_shape TF_ATTRIBUTE_UNUSED =",
            "          (rnn_mode == \"lstm\") ? output_h_shape : c->MakeShape({});",
            "      c->set_output(0, output_shape);"
        ],
        [
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"rnn_mode\", &rnn_mode));",
            "      int dir_count = (direction == \"bidirectional\") ? 2 : 1;",
            "      DimensionHandle output_size;",
            "      TF_RETURN_IF_ERROR(c->Multiply(num_units, dir_count, &output_size));",
            "      auto output_shape =",
            "          c->MakeShape({max_seq_length, batch_size, output_size});",
            "      auto output_h_shape = input_h_shape;",
            "      auto output_c_shape TF_ATTRIBUTE_UNUSED =",
            "          (rnn_mode == \"lstm\") ? input_c_shape : c->MakeShape({});",
            "      c->set_output(0, output_shape);",
            "      c->set_output(1, output_h_shape);",
            "      c->set_output(2, output_c_shape);",
            "      c->set_output(3, c->UnknownShape());",
            "      c->set_output(4, c->UnknownShape());",
            "      return Status::OK();",
            "    });",
            "",
            "REGISTER_OP(\"CudnnRNNBackprop\")",
            "    .Input(\"input: T\")",
            "    .Input(\"input_h: T\")",
            "    .Input(\"input_c: T\")",
            "    .Input(\"params: T\")",
            "    .Input(\"output: T\")",
            "    .Input(\"output_h: T\")",
            "    .Input(\"output_c: T\")",
            "    .Input(\"output_backprop: T\")"
        ]
    ],
    "Clean Code": [
        [
            "    .Attr(\"is_training: bool = true\")",
            "    .SetShapeFn([](InferenceContext* c) {",
            "      ShapeHandle unused;",
            "      auto input_shape = c->input(0);",
            "      auto input_h_shape = c->input(1);",
            "      TF_RETURN_IF_ERROR(c->WithRank(input_shape, 3, &unused));",
            "      TF_RETURN_IF_ERROR(c->WithRank(input_h_shape, 3, &unused));",
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 1, &unused));",
            "",
            "      auto seq_length = c->Dim(input_shape, 0);",
            "      auto batch_size = c->Dim(input_shape, 1);",
            "      auto num_units = c->Dim(input_h_shape, 2);",
            "",
            "      string direction;",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"direction\", &direction));",
            "      string rnn_mode;",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"rnn_mode\", &rnn_mode));"
        ],
        [
            "    .Attr(\"is_training: bool = true\")",
            "    .SetShapeFn([](InferenceContext* c) {",
            "      ShapeHandle unused;",
            "      auto input_shape = c->input(0);",
            "      auto input_h_shape = c->input(1);",
            "      TF_RETURN_IF_ERROR(c->WithRank(input_shape, 3, &unused));",
            "      TF_RETURN_IF_ERROR(c->WithRank(input_h_shape, 3, &unused));",
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 1, &unused));",
            "",
            "      auto seq_length = c->Dim(input_shape, 0);",
            "      auto batch_size = c->Dim(input_shape, 1);",
            "      auto num_units = c->Dim(input_h_shape, 2);",
            "      string direction;"
        ],
        [
            "    .Attr(\"time_major: bool = true\")",
            "    .SetShapeFn([](InferenceContext* c) {",
            "      ShapeHandle unused;",
            "      auto input_shape = c->input(0);",
            "      auto input_h_shape = c->input(1);",
            "      auto input_c_shape = c->input(2);",
            "      TF_RETURN_IF_ERROR(c->WithRank(input_shape, 3, &unused));",
            "      TF_RETURN_IF_ERROR(c->WithRank(input_h_shape, 3, &unused));",
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 1, &unused));",
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(4), 1, &unused));",
            "",
            "      auto max_seq_length = c->Dim(input_shape, 0);",
            "      auto batch_size = c->Dim(input_shape, 1);",
            "      auto num_units = c->Dim(input_h_shape, 2);",
            "",
            "      string direction;",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"direction\", &direction));",
            "      string rnn_mode;",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"rnn_mode\", &rnn_mode));",
            "      if (rnn_mode == \"lstm\") {",
            "        TF_RETURN_IF_ERROR(c->WithRank(input_c_shape, 3, &unused));",
            "      }",
            "      int dir_count = (direction == \"bidirectional\") ? 2 : 1;",
            "      DimensionHandle output_size;",
            "      TF_RETURN_IF_ERROR(c->Multiply(num_units, dir_count, &output_size));",
            "      auto output_shape ="
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cqv6-3phm-hcwx",
    "API Signature": "tf.raw_ops.CudnnRNNV3(\n    input,\n    input_h,\n    input_c,\n    params,\n    sequence_lengths,\n    rnn_mode='lstm',\n    input_mode='linear_input',\n    direction='unidirectional',\n    dropout=0,\n    seed=0,\n    seed2=0,\n    num_proj=0,\n    is_training=True,\n    time_major=True,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "input=[0.1, 0.1],\ninput_h=[0.5],"
},
{
    "Title": "\n        Integer division by 0 in `tf.raw_ops.AllToAll`\n      ",
    "Bug description": "The  shape inference code for   can be made to execute a division by 0:",
    "Sample Code": "@\ndef func():\n  return tf.raw_ops.AllToAll(\n    input=[0.0, 0.1652, 0.6543],\n    group_assignment=[1, -1],\n    concat_dimension=0,\n    split_dimension=0,\n    split_count=0)\n\n)\n\nfunc()",
    "Code change": [
        "@@ -32,6 +32,7 @@ REGISTER_OP(\"AllToAll\")\n     .Attr(\"split_count: int\")\n     .SetShapeFn([](InferenceContext* c) {\n       ShapeHandle input = c->input(0);\n+      ShapeHandle group_assignment = c->input(1);\n       if (!c->RankKnown(input)) {\n         c->set_output(0, c->UnknownShape());\n         return Status::OK();\n@@ -42,6 +43,21 @@ REGISTER_OP(\"AllToAll\")\n       int split_dimension;\n       int split_count;\n       TF_RETURN_IF_ERROR(c->GetAttr(\"split_count\", &split_count));\n+      if (split_count < 1) {\n+        return errors::InvalidArgument(\"split_count \", split_count,\n+                                       \" must at least be one.\");\n+      }\n+      if (c->RankKnown(group_assignment) && c->Rank(group_assignment) != 2) {\n+        return errors::InvalidArgument(\"group_assignment must have rank 2.\");\n+      }\n+      DimensionHandle num_replicas_per_group = c->Dim(group_assignment, 1);\n+      if (c->ValueKnown(num_replicas_per_group) &&\n+          (c->Value(num_replicas_per_group) != split_count)) {\n+        return errors::InvalidArgument(\n+            \"split_count \", split_count,\n+            \" must equal the size of the second dimension of group_assignment \",\n+            c->Value(num_replicas_per_group));\n+      }\n \n       TF_RETURN_IF_ERROR(c->GetAttr(\"concat_dimension\", &concat_dimension));\n \n@@ -65,6 +81,12 @@ REGISTER_OP(\"AllToAll\")\n           dims[i] = c->MakeDim(c->Value(dims[i]) * split_count);\n         }\n         if (i == split_dimension) {\n+          if (c->ValueKnown(dims[i]) &&\n+              (c->Value(dims[i]) % split_count != 0)) {\n+            return errors::InvalidArgument(\n+                \"input dimension \", c->Value(dims[i]),\n+                \" not divisible by split_count \", split_count);\n+          }\n           dims[i] = c->MakeDim(c->Value(dims[i]) / split_count);\n         }\n       }\n",
        "@@ -32,6 +32,7 @@ from tensorflow.python.platform import test\n from tensorflow.python.tpu import tpu\n from tensorflow.python.tpu import tpu_feed\n from tensorflow.python.tpu import training_loop\n+from tensorflow.python.tpu.ops import tpu_ops\n \n \n class TPUContextTest(test.TestCase):\n@@ -165,6 +166,51 @@ class TPUGraphPruneTest(test.TestCase):\n         graph.get_operation_by_name(\"import/y\").get_attr(\n             tpu._TPU_REPLICATE_ATTR)\n \n+\n+class TPUOpsTest(test.TestCase):\n+\n+  def test_all_to_all_zero_split_count(self):\n+    with self.assertRaisesRegex(\n+        ValueError, \"split_count 0 must at least be one\"):\n+      tpu_ops.all_to_all(\n+          x=[0.0, 0.1652, 0.6543],\n+          group_assignment=[1, -1],\n+          concat_dimension=0,\n+          split_dimension=0,\n+          split_count=0)\n+\n+  def test_all_to_all_group_assignment_wrong_shape(self):\n+    with self.assertRaisesRegex(\n+        ValueError, \"group_assignment must have rank 2\"):\n+      tpu_ops.all_to_all(\n+          x=[0.0, 0.1652, 0.6543],\n+          group_assignment=[1, -1],\n+          concat_dimension=0,\n+          split_dimension=0,\n+          split_count=2)\n+\n+  def test_all_to_all_split_count_not_equal_to_group_assignment_shape(self):\n+    with self.assertRaisesRegex(\n+        ValueError, \"split_count 1 must equal the size of the second dimension \"\n+        \"of group_assignment 2\"):\n+      tpu_ops.all_to_all(\n+          x=[0.0, 0.1652, 0.6543],\n+          group_assignment=[[0, 1], [2, 3]],\n+          concat_dimension=0,\n+          split_dimension=0,\n+          split_count=1)\n+\n+  def test_all_to_all_split_count_not_divide_input_shape(self):\n+    with self.assertRaisesRegex(\n+        ValueError, \"input dimension 3 not divisible by split_count 2\"):\n+      tpu_ops.all_to_all(\n+          x=[[0.0], [0.1652], [0.6543]],\n+          group_assignment=[[0, 1], [2, 3]],\n+          concat_dimension=1,\n+          split_dimension=0,\n+          split_count=2)\n+\n+\n def do_einsum():\n   a = array_ops.placeholder(dtype=dtypes.float32, name=\"a\", shape=[2, 3, 4])\n   b = array_ops.placeholder(dtype=dtypes.float32, name=\"b\", shape=[2, 4, 5])\n"
    ],
    "Buggy Code": [
        [
            "    .SetShapeFn([](InferenceContext* c) {",
            "      ShapeHandle input = c->input(0);",
            "      if (!c->RankKnown(input)) {",
            "        c->set_output(0, c->UnknownShape());",
            "        return Status::OK();",
            "      }",
            ""
        ],
        [
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"split_count\", &split_count));",
            "",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"concat_dimension\", &concat_dimension));",
            "",
            "      if (concat_dimension < 0 || concat_dimension >= rank) {",
            "        return errors::InvalidArgument(\"concat_dimension \", concat_dimension,",
            "                                       \" is out of range of input rank \", rank);",
            "      }",
            "",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"split_dimension\", &split_dimension));",
            "      if (split_dimension < 0 || split_dimension >= rank) {",
            "        return errors::InvalidArgument(\"split_dimension \", split_dimension,",
            "                                       \" is out of range of input rank \", rank);",
            "      }",
            "",
            "      std::vector<DimensionHandle> dims;",
            "      dims.resize(rank);",
            "",
            "      for (int32_t i = 0; i < rank; ++i) {",
            "        dims[i] = c->Dim(input, i);",
            "        if (i == concat_dimension) {"
        ],
        [
            "",
            "REGISTER_OP(\"CollectivePermute\")",
            "    .Input(\"input: T\")",
            "    .Input(\"source_target_pairs: int32\")",
            "    .Output(\"output: T\")",
            "    .Attr(\"T: numbertype\")",
            "    .SetShapeFn(shape_inference::UnchangedShape);",
            "}  // namespace tensorflow",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    .SetShapeFn([](InferenceContext* c) {",
            "      ShapeHandle input = c->input(0);",
            "      ShapeHandle group_assignment = c->input(1);",
            "      if (!c->RankKnown(input)) {",
            "        c->set_output(0, c->UnknownShape());",
            "        return Status::OK();",
            "      }"
        ],
        [
            "      int split_count;",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"split_count\", &split_count));",
            "      if (split_count < 1) {",
            "        return errors::InvalidArgument(\"split_count \", split_count,",
            "                                       \" must at least be one.\");",
            "      }",
            "      if (c->RankKnown(group_assignment) && c->Rank(group_assignment) != 2) {",
            "        return errors::InvalidArgument(\"group_assignment must have rank 2.\");",
            "      }",
            "      DimensionHandle num_replicas_per_group = c->Dim(group_assignment, 1);",
            "      if (c->ValueKnown(num_replicas_per_group) &&",
            "          (c->Value(num_replicas_per_group) != split_count)) {",
            "        return errors::InvalidArgument(",
            "            \"split_count \", split_count,",
            "            \" must equal the size of the second dimension of group_assignment \",",
            "            c->Value(num_replicas_per_group));",
            "      }",
            "",
            "      TF_RETURN_IF_ERROR(c->GetAttr(\"concat_dimension\", &concat_dimension));",
            "",
            "      if (concat_dimension < 0 || concat_dimension >= rank) {"
        ],
        [
            "        }",
            "        if (i == split_dimension) {",
            "          if (c->ValueKnown(dims[i]) &&",
            "              (c->Value(dims[i]) % split_count != 0)) {",
            "            return errors::InvalidArgument(",
            "                \"input dimension \", c->Value(dims[i]),",
            "                \" not divisible by split_count \", split_count);",
            "          }",
            "          dims[i] = c->MakeDim(c->Value(dims[i]) / split_count);",
            "        }",
            "      }",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9crf-c6qr-r273",
    "API Signature": "tf.raw_ops.AllToAll(\n    input,\n    group_assignment,\n    concat_dimension,\n    split_dimension,\n    split_count,\n    name=None\n)\n",
    "Score": 0.007194244604316547,
    "Anomaly": "Zero integer argument",
    "Anomaly Description": "A zero integer argument in Python refers to an integer value of zero (0) that is passed as an argument to a function, method, or operation. It represents a numerical value of zero that is used as input for a specific computation or functionality.",
    "Category": "Integer",
    "Argument": "split_count=0"
},
{
    "Title": "\n        Use after free / memory leak in `CollectiveReduceV2`\n      ",
    "Bug description": "The  async implementation  of  CollectiveReduceV2  suffers from a memory leak and a use after free:",
    "Sample Code": "tf.raw_ops.CollectiveReduceV2(\n  input=[],\n  group_size=[-10, -10, -10],\n  group_key=[-10, -10],\n  instance_key=[-10],\n  ordering_token=[],\n  merge_op='Mul',\n  ,\n  final_op='Div')",
    "Code change": [
        "@@ -494,15 +494,17 @@ class CollectiveOpV2Kernel : public AsyncOpKernel {\n                               const Tensor& group_size, const Tensor& group_key,\n                               const Tensor& instance_key) {\n     if (group_size.dims() > 0) {\n-      return errors::Internal(\"Unexpected dimensions on input group_size, got \",\n-                              group_size.shape().DebugString());\n+      return errors::InvalidArgument(\n+          \"Unexpected dimensions on input group_size, got \",\n+          group_size.shape().DebugString());\n     }\n     if (group_key.dims() > 0) {\n-      return errors::Internal(\"Unexpected dimensions on input group_key, got \",\n-                              group_key.shape().DebugString());\n+      return errors::InvalidArgument(\n+          \"Unexpected dimensions on input group_key, got \",\n+          group_key.shape().DebugString());\n     }\n     if (instance_key.dims() > 0) {\n-      return errors::Internal(\n+      return errors::InvalidArgument(\n           \"Unexpected dimensions on input instance_key, got \",\n           instance_key.shape().DebugString());\n     }\n@@ -625,7 +627,7 @@ class CollectiveReduceV2OpKernel : public CollectiveOpV2Kernel {\n                                               /*group_size*/ c->input(1),\n                                               /*group_key*/ c->input(2),\n                                               /*instance_key*/ c->input(3)),\n-                         done);\n+                         done_with_cleanup);\n     col_params->instance.shape = c->input(0).shape();\n     col_params->merge_op = merge_op_.get();\n     col_params->final_op = final_op_.get();\n@@ -855,14 +857,15 @@ class CollectiveInitializeCommunicatorOpKernel : public AsyncOpKernel {\n \n   Status CheckInputs(Tensor group_size_t, Tensor group_key_t) {\n     if (group_size_t.dims() > 0) {\n-      return errors::Internal(\n+      return errors::InvalidArgument(\n           \"Unexpected dimensions on input group_size. \"\n           \"It shoulbe a scalar, got tensor with shape \",\n           group_size_t.shape().DebugString());\n     }\n     if (group_key_t.dims() > 0) {\n-      return errors::Internal(\"Unexpected dimensions on input group_key, got \",\n-                              group_key_t.shape().DebugString());\n+      return errors::InvalidArgument(\n+          \"Unexpected dimensions on input group_key, got \",\n+          group_key_t.shape().DebugString());\n     }\n \n     auto group_size = group_size_t.unaligned_flat<int32>()(0);\n@@ -1084,7 +1087,7 @@ class CollectiveReduceV3OpKernel : public CollectiveOpV3Kernel {\n     };\n     core::RefCountPtr<CollectiveGroupResource> resource;\n     OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n-                         done);\n+                         done_with_cleanup);\n \n     Tensor group_assignment = c->input(2);\n \n@@ -1134,7 +1137,7 @@ class CollectiveAllToAllV3OpKernel : public CollectiveOpV3Kernel {\n     };\n     core::RefCountPtr<CollectiveGroupResource> resource;\n     OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n-                         done);\n+                         done_with_cleanup);\n \n     Tensor group_assignment = c->input(2);\n \n",
        "@@ -1182,6 +1182,69 @@ class InputPipelineTest(test.TestCase):\n     self.assertAllEqual(self.evaluate(f()), [[3.], [3.]])\n \n \n+@combinations.generate(\n+    combinations.times(\n+        combinations.combine(collective_op=[\n+            combinations.NamedObject('all_reduce_v2',\n+                                     CollectiveOpsV2.all_reduce),\n+            combinations.NamedObject('all_gather_v2',\n+                                     CollectiveOpsV2.all_gather)\n+        ]), device_combination))\n+class InvalidInputTest(test.TestCase, parameterized.TestCase):\n+\n+  def setUp(self):\n+    _setup_context()\n+    super().setUp()\n+\n+  def testInvalidGroupKey(self, collective_op, device, communication):\n+    dev0 = '/device:%s:0' % device\n+    group_size = 2\n+    group_key = [100]\n+    instance_key = 100\n+    in_tensor = constant_op.constant([1.])\n+\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      with ops.device(dev0):\n+        collective_op(\n+            in_tensor,\n+            group_size,\n+            group_key,\n+            instance_key,\n+            communication_hint=communication)\n+\n+  def testInvalidGroupSize(self, collective_op, device, communication):\n+    dev0 = '/device:%s:0' % device\n+    group_size = -2\n+    group_key = 100\n+    instance_key = 100\n+    in_tensor = constant_op.constant([1.])\n+\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      with ops.device(dev0):\n+        collective_op(\n+            in_tensor,\n+            group_size,\n+            group_key,\n+            instance_key,\n+            communication_hint=communication)\n+\n+  def testInvalidInstanceKey(self, collective_op, device, communication):\n+    dev0 = '/device:%s:0' % device\n+    group_size = 2\n+    group_key = 100\n+    instance_key = [100]\n+    in_tensor = constant_op.constant([1.])\n+\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      with ops.device(dev0):\n+        collective_op(\n+            in_tensor,\n+            group_size,\n+            group_key,\n+            instance_key,\n+            communication_hint=communication)\n+\n+\n class CollectiveOpsV3Test(test.TestCase, parameterized.TestCase):\n \n   def setUp(self):\n"
    ],
    "Buggy Code": [
        [
            "                              const Tensor& instance_key) {",
            "    if (group_size.dims() > 0) {",
            "      return errors::Internal(\"Unexpected dimensions on input group_size, got \",",
            "                              group_size.shape().DebugString());",
            "    }",
            "    if (group_key.dims() > 0) {",
            "      return errors::Internal(\"Unexpected dimensions on input group_key, got \",",
            "                              group_key.shape().DebugString());",
            "    }",
            "    if (instance_key.dims() > 0) {",
            "      return errors::Internal(",
            "          \"Unexpected dimensions on input instance_key, got \",",
            "          instance_key.shape().DebugString());",
            "    }",
            "    col_params->name = name_;",
            "    col_params->group.device_type = device_type_;",
            "    col_params->group.group_size = group_size.unaligned_flat<int32>()(0);"
        ],
        [
            "                         done);",
            "    col_params->instance.shape = c->input(0).shape();",
            "    col_params->merge_op = merge_op_.get();",
            "    col_params->final_op = final_op_.get();",
            "    VLOG(1) << \"CollectiveReduceV2 group_size \" << col_params->group.group_size",
            "            << \" group_key \" << col_params->group.group_key << \" instance_key \"",
            "            << col_params->instance.instance_key;"
        ],
        [
            "      return errors::Internal(",
            "          \"Unexpected dimensions on input group_size. \"",
            "          \"It shoulbe a scalar, got tensor with shape \",",
            "          group_size_t.shape().DebugString());",
            "    }",
            "    if (group_key_t.dims() > 0) {",
            "      return errors::Internal(\"Unexpected dimensions on input group_key, got \",",
            "                              group_key_t.shape().DebugString());",
            "    }",
            "",
            "    auto group_size = group_size_t.unaligned_flat<int32>()(0);",
            "    if (group_size <= 0) {",
            "      return errors::InvalidArgument(",
            "          \"group_size must be positive integer but got \", group_size);",
            "    }"
        ],
        [
            "",
            "    Tensor group_assignment = c->input(2);",
            "",
            "    OP_REQUIRES_OK_ASYNC(",
            "        c,",
            "        FillCollectiveParams(col_params, group_assignment, REDUCTION_COLLECTIVE,",
            "                             resource.get()),"
        ],
        [
            "",
            "    Tensor group_assignment = c->input(2);",
            "",
            "    OP_REQUIRES_OK_ASYNC(",
            "        c,",
            "        FillCollectiveParams(col_params, group_assignment,",
            "                             ALL_TO_ALL_COLLECTIVE, resource.get()),"
        ]
    ],
    "Clean Code": [
        [
            "                              const Tensor& instance_key) {",
            "    if (group_size.dims() > 0) {",
            "      return errors::InvalidArgument(",
            "          \"Unexpected dimensions on input group_size, got \",",
            "          group_size.shape().DebugString());",
            "    }",
            "    if (group_key.dims() > 0) {",
            "      return errors::InvalidArgument(",
            "          \"Unexpected dimensions on input group_key, got \",",
            "          group_key.shape().DebugString());",
            "    }",
            "    if (instance_key.dims() > 0) {",
            "      return errors::InvalidArgument(",
            "          \"Unexpected dimensions on input instance_key, got \",",
            "          instance_key.shape().DebugString());",
            "    }",
            "    col_params->name = name_;"
        ],
        [
            "                                              /*group_key*/ c->input(2),",
            "                                              /*instance_key*/ c->input(3)),",
            "                         done_with_cleanup);",
            "    col_params->instance.shape = c->input(0).shape();",
            "    col_params->merge_op = merge_op_.get();",
            "    col_params->final_op = final_op_.get();",
            "    VLOG(1) << \"CollectiveReduceV2 group_size \" << col_params->group.group_size"
        ],
        [
            "  Status CheckInputs(Tensor group_size_t, Tensor group_key_t) {",
            "    if (group_size_t.dims() > 0) {",
            "      return errors::InvalidArgument(",
            "          \"Unexpected dimensions on input group_size. \"",
            "          \"It shoulbe a scalar, got tensor with shape \",",
            "          group_size_t.shape().DebugString());",
            "    }",
            "    if (group_key_t.dims() > 0) {",
            "      return errors::InvalidArgument(",
            "          \"Unexpected dimensions on input group_key, got \",",
            "          group_key_t.shape().DebugString());",
            "    }",
            "",
            "    auto group_size = group_size_t.unaligned_flat<int32>()(0);",
            "    if (group_size <= 0) {"
        ],
        [
            "    core::RefCountPtr<CollectiveGroupResource> resource;",
            "    OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),",
            "                         done_with_cleanup);",
            "",
            "    Tensor group_assignment = c->input(2);",
            "",
            "    OP_REQUIRES_OK_ASYNC("
        ],
        [
            "    core::RefCountPtr<CollectiveGroupResource> resource;",
            "    OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),",
            "                         done_with_cleanup);",
            "",
            "    Tensor group_assignment = c->input(2);",
            "",
            "    OP_REQUIRES_OK_ASYNC("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gpfh-jvf9-7wg5",
    "API Signature": "tf.raw_ops.CollectiveReduceV2(\n    input,\n    group_size,\n    group_key,\n    instance_key,\n    ordering_token,\n    merge_op,\n    final_op,\n    communication_hint='auto',\n    timeout_seconds=0,\n    max_subdivs_per_device=-1,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "List",
    "Argument": "group_size=[-10, -10, -10],\ngroup_key=[-10, -10],"
},
{
    "Title": "\n        Undefined behavior via `nullptr` reference binding in sparse matrix multiplication\n      ",
    "Bug description": "The  code for sparse matrix multiplication  is vulnerable to undefined behavior via binding a reference to  nullptr :",
    "Sample Code": "tf.raw_ops.SparseMatMul(\n  a=[[1.0,1.0,1.0]],\n  b=[[],[],[]],\n  transpose_a=False,\n  transpose_b=False,\n  a_is_sparse=False, \n  , \n  b_is_sparse=True)",
    "Code change": [
        "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/fill_functor.h\"\n #include \"tensorflow/core/lib/core/blocking_counter.h\"\n #include \"tensorflow/core/lib/core/threadpool.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/macros.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n@@ -980,9 +981,18 @@ class SparseMatMulOp : public OpKernel {\n                 errors::InvalidArgument(\n                     \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                     \", b: \", b.shape().DebugString()));\n+    OP_REQUIRES(ctx, m >= 0 && n >= 0 && k >= 0,\n+                errors::InvalidArgument(\n+                    \"Matrix dimensions cannot be negative: a: \",\n+                    a.shape().DebugString(), \", b: \", b.shape().DebugString()));\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n \n+    // Return early if at least one of the output dimension size is 0.\n+    if (m == 0 || n == 0) {\n+      return;\n+    }\n+\n     if (k == 0) {\n       // If the inner dimension k in the matrix multiplication is zero, we fill\n       // the output with zeros.\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/lib/core/blocking_counter.h\"",
            "#include \"tensorflow/core/lib/core/threadpool.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/macros.h\"",
            "#include \"tensorflow/core/platform/mutex.h\"",
            "#include \"tensorflow/core/platform/thread_annotations.h\"",
            "#include \"tensorflow/core/platform/types.h\""
        ],
        [
            "                    \", b: \", b.shape().DebugString()));",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));",
            "",
            "    if (k == 0) {",
            "      // If the inner dimension k in the matrix multiplication is zero, we fill",
            "      // the output with zeros.",
            "      functor::SetZeroFunctor<CPUDevice, float> f;",
            "      f(ctx->eigen_device<CPUDevice>(), output->flat<float>());",
            "      return;",
            "    }",
            "",
            "    auto out = output->matrix<float>();",
            "",
            "    std::unique_ptr<Tensor> a_float;",
            "    std::unique_ptr<Tensor> b_float;",
            "    if (!a_is_sparse_ && !b_is_sparse_) {",
            "      auto left = &a;"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/lib/core/blocking_counter.h\"",
            "#include \"tensorflow/core/lib/core/threadpool.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#include \"tensorflow/core/platform/logging.h\"",
            "#include \"tensorflow/core/platform/macros.h\"",
            "#include \"tensorflow/core/platform/mutex.h\"",
            "#include \"tensorflow/core/platform/thread_annotations.h\""
        ],
        [
            "                    \"Matrix size incompatible: a: \", a.shape().DebugString(),",
            "                    \", b: \", b.shape().DebugString()));",
            "    OP_REQUIRES(ctx, m >= 0 && n >= 0 && k >= 0,",
            "                errors::InvalidArgument(",
            "                    \"Matrix dimensions cannot be negative: a: \",",
            "                    a.shape().DebugString(), \", b: \", b.shape().DebugString()));",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));",
            "",
            "    // Return early if at least one of the output dimension size is 0.",
            "    if (m == 0 || n == 0) {",
            "      return;",
            "    }",
            "",
            "    if (k == 0) {",
            "      // If the inner dimension k in the matrix multiplication is zero, we fill",
            "      // the output with zeros.",
            "      functor::SetZeroFunctor<CPUDevice, float> f;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4f99-p9c2-3j8x",
    "API Signature": "tf.raw_ops.SparseMatMul(\n    a,\n    b,\n    transpose_a=False,\n    transpose_b=False,\n    a_is_sparse=False,\n    b_is_sparse=False,\n    name=None\n)\n",
    "Score": 0.03237410071942446,
    "Anomaly": "Zero integer list element",
    "Anomaly Description": "A zero integer list element in Python refers to an element within a list that has a value of zero. It is an integer value of zero (0) that is present as an item in a list.",
    "Category": "List",
    "Argument": "a=[[1.0,1.0,1.0]],\nb=[[],[],[]],"
},
{
    "Title": "\n        Heap buffer overflow in `Transpose`\n      ",
    "Bug description": "The  shape inference function for   is vulnerable to a heap buffer overflow:",
    "Sample Code": "@\ndef test():\n  y = tf.raw_ops.Transpose(x=[1,2,3,4],perm=[-10])\n  return y\n\n\n\ntest()",
    "Code change": [
        "@@ -168,7 +168,7 @@ Status TransposeShapeFn(InferenceContext* c) {\n \n     for (int32_t i = 0; i < rank; ++i) {\n       int64_t in_idx = data[i];\n-      if (in_idx >= rank) {\n+      if (in_idx >= rank || in_idx <= -rank) {\n         return errors::InvalidArgument(\"perm dim \", in_idx,\n                                        \" is out of range of input rank \", rank);\n       }\n"
    ],
    "Buggy Code": [
        [
            "    for (int32_t i = 0; i < rank; ++i) {",
            "      int64_t in_idx = data[i];",
            "      if (in_idx >= rank) {",
            "        return errors::InvalidArgument(\"perm dim \", in_idx,",
            "                                       \" is out of range of input rank \", rank);",
            "      }",
            "      dims[i] = c->Dim(input, in_idx);"
        ]
    ],
    "Clean Code": [
        [
            "    for (int32_t i = 0; i < rank; ++i) {",
            "      int64_t in_idx = data[i];",
            "      if (in_idx >= rank || in_idx <= -rank) {",
            "        return errors::InvalidArgument(\"perm dim \", in_idx,",
            "                                       \" is out of range of input rank \", rank);",
            "      }",
            "      dims[i] = c->Dim(input, in_idx);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-3ff2-r28g-w7h9",
    "API Signature": "tf.raw_ops.Transpose(\n    x, perm, name=None\n)\n",
    "Score": 0.02877697841726619,
    "Anomaly": "Negative integer list element",
    "Anomaly Description": "A negative integer list element in Python refers to an element within a list that has a negative integer value. It means that the element is a negative number represented by an integer data type.",
    "Category": "List",
    "Argument": "perm=[-10]"
},
{
    "Title": "\n        Null pointer exception in `DeserializeSparse`\n      ",
    "Bug description": "The  shape inference code for   can trigger a null pointer dereference:",
    "Sample Code": "dataset = tf.data.Dataset.range(3)\n  \n@                 \ndef test():                  \n  y = tf.raw_ops.DeserializeSparse(\n    serialized_sparse=tf.data.experimental.to_variant(dataset),\n    dtype=tf.int32)\n\n)\n\ntest()",
    "Code change": [
        "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/common_shape_fns.h\"\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/shape_inference.h\"\n+#include \"tensorflow/core/framework/types.pb.h\"\n #include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n@@ -159,6 +160,8 @@ REGISTER_OP(\"DeserializeSparse\")\n     .Attr(\"Tserialized: {string, variant} = DT_STRING\")\n     .SetShapeFn([](InferenceContext* c) {\n       // serialized sparse is [?, ..., ?, 3] vector.\n+      ShapeHandle unused_shape;\n+      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &unused_shape));\n       DimensionHandle unused;\n       TF_RETURN_IF_ERROR(c->WithValue(c->Dim(c->input(0), -1), 3, &unused));\n       c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,\n",
        "@@ -16,10 +16,12 @@\n \n import numpy as np\n \n+from tensorflow.python.eager import def_function\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import sparse_tensor as sparse_tensor_lib\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import gen_resource_variable_ops\n from tensorflow.python.ops import sparse_ops\n from tensorflow.python.platform import test\n \n@@ -460,6 +462,18 @@ class SerializeSparseTest(test.TestCase):\n     self._testDeserializeFailsInvalidProtoHelper(\n         sparse_ops.serialize_sparse, sparse_ops.deserialize_many_sparse)\n \n+  def testDeserializeInvalidVariant(self):\n+    mu = gen_resource_variable_ops.mutex_v2()\n+    mu_lock = gen_resource_variable_ops.mutex_lock(mutex=mu)\n+\n+    @def_function.function\n+    def f():\n+      return sparse_ops.deserialize_sparse(\n+          serialized_sparse=mu_lock, dtype=dtypes.int32)\n+\n+    with self.assertRaisesRegex(ValueError, r\"Shape must be at least rank 1\"):\n+      f()\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/op.h\"",
            "#include \"tensorflow/core/framework/shape_inference.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using shape_inference::DimensionHandle;"
        ],
        [
            "      // serialized sparse is [?, ..., ?, 3] vector.",
            "      DimensionHandle unused;",
            "      TF_RETURN_IF_ERROR(c->WithValue(c->Dim(c->input(0), -1), 3, &unused));",
            "      c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,",
            "                                 InferenceContext::kUnknownDim));",
            "      c->set_output(1, c->Vector(InferenceContext::kUnknownDim));",
            "      c->set_output(2, c->Vector(InferenceContext::kUnknownDim));",
            "      return Status::OK();"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/op.h\"",
            "#include \"tensorflow/core/framework/shape_inference.h\"",
            "#include \"tensorflow/core/framework/types.pb.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "namespace tensorflow {",
            ""
        ],
        [
            "    .SetShapeFn([](InferenceContext* c) {",
            "      // serialized sparse is [?, ..., ?, 3] vector.",
            "      ShapeHandle unused_shape;",
            "      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &unused_shape));",
            "      DimensionHandle unused;",
            "      TF_RETURN_IF_ERROR(c->WithValue(c->Dim(c->input(0), -1), 3, &unused));",
            "      c->set_output(0, c->Matrix(InferenceContext::kUnknownDim,",
            "                                 InferenceContext::kUnknownDim));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x3v8-c8qx-3j3r",
    "API Signature": "tf.raw_ops.DeserializeSparse(\n    serialized_sparse, dtype, name=None\n)\n",
    "Score": 0.02158273381294964,
    "Anomaly": "Scalar input tensor",
    "Anomaly Description": "A scalar input tensor refers to a tensor with a rank of 0, meaning it has zero dimensions. In other words, a scalar input tensor represents a single value without any additional structure or dimensions.",
    "Category": "Tensor",
    "Argument": "dataset = tf.data.Dataset.range(3)"
},
{
    "Title": "\n        Reference binding to `nullptr` in `tf.ragged.cross`\n      ",
    "Bug description": "The  shape inference code for   has an undefined behavior due to binding a reference to  nullptr . In the following scenario, this results in a crash:",
    "Sample Code": "@                 \ndef test():     \n  y = tf.ragged.cross([tf.ragged.constant([['1']]),'2'])\n  return y                   \n                             \n                   \n                             \ntest()        ",
    "Code change": [
        "@@ -99,6 +99,13 @@ REGISTER_OP(\"RaggedCross\")\n       int dense_start = num_ragged * 2 + num_sparse * 3;\n       for (int i = 0; i < dense_types.size(); ++i) {\n         ShapeHandle dense_input = c->input(i + dense_start);\n+        int32 rank = c->Rank(dense_input);\n+        if (rank == InferenceContext::kUnknownRank) {\n+          continue;\n+        } else if (rank != 2) {\n+          return errors::InvalidArgument(\n+              \"tf.ragged.cross only supports inputs with rank=2\");\n+        }\n         int64_t batch_size = c->Value(c->Dim(dense_input, 0));\n         if (batch_size != InferenceContext::kUnknownDim) {\n           ShapeHandle row_splits = c->Vector(batch_size + 1);\n",
        "@@ -18,10 +18,12 @@ from absl.testing import parameterized\n \n import numpy as np\n \n+from tensorflow.python.eager import def_function\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import sparse_tensor\n+from tensorflow.python.framework import tensor_spec\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import sparse_ops\n from tensorflow.python.ops.ragged import ragged_array_ops\n@@ -358,6 +360,16 @@ class RaggedCrossOpTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n                   dense_const([[2], [3]])],\n           exception=(ValueError, errors.InvalidArgumentError),\n           message='inputs must all have the same batch dimension size'),\n+      dict(\n+          testcase_name='3DDenseTensor',\n+          inputs=[dense_const([[[1]]])],\n+          exception=(ValueError, errors.InvalidArgumentError),\n+          message='tf.ragged.cross only supports inputs with rank=2'),\n+      dict(\n+          testcase_name='0DDenseTensor',\n+          inputs=[dense_const(1)],\n+          exception=(ValueError, errors.InvalidArgumentError),\n+          message='tf.ragged.cross only supports inputs with rank=2'),\n   ])\n   def testStaticError(self, inputs, exception=ValueError, message=None):\n     with self.assertRaisesRegex(exception, message):\n@@ -368,17 +380,36 @@ class RaggedCrossOpTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n           testcase_name='3DRaggedTensor',\n           inputs=[ragged_const([[[1]]], ragged_rank=1)],\n           message='tf.ragged.cross only supports inputs with rank=2'),\n+      dict(\n+          testcase_name='0DDenseTensor',\n+          inputs=[dense_const(1)],\n+          signature=[[tensor_spec.TensorSpec(None, dtypes.int32)]],\n+          exception=(ValueError, errors.InvalidArgumentError),\n+          message='tf.ragged.cross only supports inputs with rank=2'),\n+      dict(\n+          testcase_name='1DDenseTensor',\n+          inputs=[dense_const([1])],\n+          signature=[[tensor_spec.TensorSpec(None, dtypes.int32)]],\n+          exception=(ValueError, errors.InvalidArgumentError),\n+          message='tf.ragged.cross only supports inputs with rank=2'),\n       dict(\n           testcase_name='3DDenseTensor',\n           inputs=[dense_const([[[1]]])],\n+          signature=[[tensor_spec.TensorSpec(None, dtypes.int32)]],\n+          exception=(ValueError, errors.InvalidArgumentError),\n           message='tf.ragged.cross only supports inputs with rank=2'),\n   ])\n   def testRuntimeError(self,\n                        inputs,\n                        exception=errors.InvalidArgumentError,\n-                       message=None):\n+                       message=None,\n+                       signature=None):\n+    @def_function.function(input_signature=signature)\n+    def fn(x):\n+      return ragged_array_ops.cross(x)\n+\n     with self.assertRaisesRegex(exception, message):\n-      self.evaluate(ragged_array_ops.cross(inputs))\n+      self.evaluate(fn(inputs))\n \n   def _ragged_to_sparse(self, t):\n     if ragged_tensor.is_ragged(t):\n"
    ],
    "Buggy Code": [
        [
            "      for (int i = 0; i < dense_types.size(); ++i) {",
            "        ShapeHandle dense_input = c->input(i + dense_start);",
            "        int64_t batch_size = c->Value(c->Dim(dense_input, 0));",
            "        if (batch_size != InferenceContext::kUnknownDim) {",
            "          ShapeHandle row_splits = c->Vector(batch_size + 1);",
            "          if (!c->Merge(out_splits, row_splits, &out_splits).ok()) {",
            "            return errors::InvalidArgument(",
            "                \"inputs must all have the same batch dimension size.\");",
            "          }",
            "        }",
            "      }",
            "",
            "      c->set_output(0, out_values);"
        ]
    ],
    "Clean Code": [
        [
            "      for (int i = 0; i < dense_types.size(); ++i) {",
            "        ShapeHandle dense_input = c->input(i + dense_start);",
            "        int32 rank = c->Rank(dense_input);",
            "        if (rank == InferenceContext::kUnknownRank) {",
            "          continue;",
            "        } else if (rank != 2) {",
            "          return errors::InvalidArgument(",
            "              \"tf.ragged.cross only supports inputs with rank=2\");",
            "        }",
            "        int64_t batch_size = c->Value(c->Dim(dense_input, 0));",
            "        if (batch_size != InferenceContext::kUnknownDim) {",
            "          ShapeHandle row_splits = c->Vector(batch_size + 1);",
            "          if (!c->Merge(out_splits, row_splits, &out_splits).ok()) {"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vwhq-49r4-gj9v",
    "API Signature": "tf.ragged.cross(\n    inputs, name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "[tf.ragged.constant([['1']]),'2']"
},
{
    "Title": "\n        Heap OOB in shape inference for `QuantizeV2`\n      ",
    "Bug description": "The  shape inference code for   can trigger a read outside of bounds of heap allocated array:",
    "Sample Code": "@\ndef test():\n  data=tf.raw_ops.QuantizeV2(\n    input=[1.0,1.0],\n    min_range=[1.0,10.0],\n    max_range=[1.0,10.0],\n    T=tf.qint32,\n    mode='MIN_COMBINED',\n    round_mode='HALF_TO_EVEN',\n    narrow_range=False,\n    axis=-100,\n    ensure_minimum_range=10)\n  return data\n\n\n\ntest()",
    "Code change": [
        "@@ -2559,6 +2559,9 @@ Status QuantizeV2Shape(InferenceContext* c) {\n   if (!s.ok() && s.code() != error::NOT_FOUND) {\n     return s;\n   }\n+  if (axis < -1) {\n+    return errors::InvalidArgument(\"axis should be at least -1, got \", axis);\n+  }\n   const int minmax_rank = (axis == -1) ? 0 : 1;\n   TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n   ShapeHandle minmax;\n"
    ],
    "Buggy Code": [
        [
            "    return s;",
            "  }",
            "  const int minmax_rank = (axis == -1) ? 0 : 1;",
            "  TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));",
            "  ShapeHandle minmax;",
            "  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));",
            "  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));",
            "  if (axis != -1) {",
            "    ShapeHandle input;"
        ]
    ],
    "Clean Code": [
        [
            "    return s;",
            "  }",
            "  if (axis < -1) {",
            "    return errors::InvalidArgument(\"axis should be at least -1, got \", axis);",
            "  }",
            "  const int minmax_rank = (axis == -1) ? 0 : 1;",
            "  TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));",
            "  ShapeHandle minmax;",
            "  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cvgx-3v3q-m36c",
    "API Signature": "tf.raw_ops.QuantizeV2(\n    input,\n    min_range,\n    max_range,\n    T,\n    mode='MIN_COMBINED',\n    round_mode='HALF_AWAY_FROM_ZERO',\n    narrow_range=False,\n    axis=-1,\n    ensure_minimum_range=0.01,\n    name=None\n)\n",
    "Score": 0.039568345323741004,
    "Anomaly": "Negative integer argument",
    "Anomaly Description": "A negative integer argument in Python refers to an integer value that is less than zero. It is a numeric value that represents a negative quantity or position in a numerical sequence. In Python, negative integers are denoted by placing a minus sign (-) before the numerical value. For example, -1, -2, -3, and so on.",
    "Category": "Integer",
    "Argument": "axis=-100,"
},
{
    "Title": "\n        Heap OOB read in all `tf.raw_ops.QuantizeAndDequantizeV*` ops\n      ",
    "Bug description": "The  shape inference functions for the   can trigger a read outside of bounds of heap allocated array as illustrated in the following sets of PoCs:",
    "Sample Code": "@\ndef test():\n  data=tf.raw_ops.QuantizeAndDequantizeV2(\n    input=[1.0,1.0],\n    input_min=[1.0,10.0],\n    input_max=[1.0,10.0],\n    signed_input=False,\n    num_bits=10,\n    range_given=False,\n    round_mode='HALF_TO_EVEN',\n    narrow_range=False,\n    axis=-100)\n  return data\n\n\n\ntest()",
    "Code change": [
        "@@ -2863,7 +2863,10 @@ REGISTER_OP(\"QuantizeAndDequantizeV2\")\n       ShapeHandle minmax;\n       TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n       TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n-      if (axis != -1) {\n+      if (axis < -1) {\n+        return errors::InvalidArgument(\"axis should be at least -1, got \",\n+                                       axis);\n+      } else if (axis != -1) {\n         ShapeHandle input;\n         TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n         DimensionHandle depth;\n@@ -2895,7 +2898,10 @@ REGISTER_OP(\"QuantizeAndDequantizeV4\")\n       ShapeHandle minmax;\n       TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n       TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n-      if (axis != -1) {\n+      if (axis < -1) {\n+        return errors::InvalidArgument(\"axis should be at least -1, got \",\n+                                       axis);\n+      } else if (axis != -1) {\n         ShapeHandle input;\n         TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n         DimensionHandle depth;\n@@ -2923,7 +2929,10 @@ REGISTER_OP(\"QuantizeAndDequantizeV4Grad\")\n       ShapeHandle minmax;\n       TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));\n       TF_RETURN_IF_ERROR(c->Merge(c->input(3), minmax, &minmax));\n-      if (axis != -1) {\n+      if (axis < -1) {\n+        return errors::InvalidArgument(\"axis should be at least -1, got \",\n+                                       axis);\n+      } else if (axis != -1) {\n         ShapeHandle input;\n         TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n         DimensionHandle depth;\n@@ -2956,7 +2965,10 @@ REGISTER_OP(\"QuantizeAndDequantizeV3\")\n       ShapeHandle minmax;\n       TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n       TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n-      if (axis != -1) {\n+      if (axis < -1) {\n+        return errors::InvalidArgument(\"axis should be at least -1, got \",\n+                                       axis);\n+      } else if (axis != -1) {\n         ShapeHandle input;\n         TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n         DimensionHandle depth;\n",
        "@@ -1374,6 +1374,8 @@ TEST(ArrayOpsTest, QuantizeAndDequantizeV2_ShapeFn) {\n   INFER_ERROR(\"Shapes must be equal rank, but are 1 and 0\", op,\n               \"[1,2,?,4,5];[];[1]\");\n   INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1,2,?,4,5];[1];[1]\");\n+  (*op.node_def.mutable_attr())[\"axis\"].set_i(-2);\n+  INFER_ERROR(\"axis should be at least -1, got -2\", op, \"?;?;?\");\n }\n \n TEST(ArrayOpsTest, SpaceToBatch_ShapeFn) {\n"
    ],
    "Buggy Code": [
        [
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));",
            "      TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));",
            "      if (axis != -1) {",
            "        ShapeHandle input;",
            "        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));",
            "        DimensionHandle depth;",
            "        TF_RETURN_IF_ERROR(",
            "            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));",
            "      }",
            "      c->set_output(0, c->input(0));"
        ],
        [
            "        ShapeHandle input;",
            "        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));",
            "        DimensionHandle depth;",
            "        TF_RETURN_IF_ERROR(",
            "            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));",
            "      }",
            "      c->set_output(0, c->input(0));",
            "      return Status::OK();",
            "    });",
            ""
        ],
        [
            "        TF_RETURN_IF_ERROR(",
            "            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));",
            "      }",
            "      ShapeHandle inputs;",
            "      TF_RETURN_IF_ERROR(c->Merge(c->input(0), c->input(1), &inputs));",
            "      c->set_output(0, inputs);",
            "      c->set_output(1, minmax);",
            "      c->set_output(2, minmax);",
            "      return Status::OK();",
            "    });"
        ],
        [
            "      ShapeHandle unused;",
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 0, &unused));",
            "      c->set_output(0, c->input(0));",
            "      return Status::OK();",
            "    });",
            "",
            "REGISTER_OP(\"QuantizeV2\")",
            "    .Input(\"input: float\")",
            "    .Input(\"min_range: float\")",
            "    .Input(\"max_range: float\")"
        ]
    ],
    "Clean Code": [
        [
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));",
            "      TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));",
            "      if (axis < -1) {",
            "        return errors::InvalidArgument(\"axis should be at least -1, got \",",
            "                                       axis);",
            "      } else if (axis != -1) {",
            "        ShapeHandle input;",
            "        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));",
            "        DimensionHandle depth;",
            "        TF_RETURN_IF_ERROR("
        ],
        [
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));",
            "      TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));",
            "      if (axis < -1) {",
            "        return errors::InvalidArgument(\"axis should be at least -1, got \",",
            "                                       axis);",
            "      } else if (axis != -1) {",
            "        ShapeHandle input;",
            "        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));",
            "        DimensionHandle depth;",
            "        TF_RETURN_IF_ERROR("
        ],
        [
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));",
            "      TF_RETURN_IF_ERROR(c->Merge(c->input(3), minmax, &minmax));",
            "      if (axis < -1) {",
            "        return errors::InvalidArgument(\"axis should be at least -1, got \",",
            "                                       axis);",
            "      } else if (axis != -1) {",
            "        ShapeHandle input;",
            "        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));",
            "        DimensionHandle depth;",
            "        TF_RETURN_IF_ERROR("
        ],
        [
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));",
            "      TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));",
            "      if (axis < -1) {",
            "        return errors::InvalidArgument(\"axis should be at least -1, got \",",
            "                                       axis);",
            "      } else if (axis != -1) {",
            "        ShapeHandle input;",
            "        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));",
            "        DimensionHandle depth;",
            "        TF_RETURN_IF_ERROR("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-49rx-x2rw-pc6f",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n    gradients, input, input_min, input_max, axis=-1, name=None\n)\n",
    "Score": 0.039568345323741004,
    "Anomaly": "Negative integer argument",
    "Anomaly Description": "A negative integer argument in Python refers to an integer value that is less than zero. It is a numeric value that represents a negative quantity or position in a numerical sequence. In Python, negative integers are denoted by placing a minus sign (-) before the numerical value. For example, -1, -2, -3, and so on.",
    "Category": "Integer",
    "Argument": "axis=-100,"
},
{
    "Title": "\n        FPE in `ParallelConcat`\n      ",
    "Bug description": "The  implementation of   misses some input validation and can produce a division by 0:",
    "Sample Code": "@\ndef test():\n  y = tf.raw_ops.ParallelConcat(values=[['tf']],shape=0)\n  return y\n\n\n\ntest()",
    "Code change": [
        "@@ -71,6 +71,15 @@ class ParallelConcatUpdate : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     auto value = ctx->input(0);\n+    // Value should be at least rank 1. Also the 0th dimension should be\n+    // at least loc_.\n+    OP_REQUIRES(ctx, value.dims() >= 1,\n+                errors::InvalidArgument(\"value should be at least rank 1.\"));\n+    OP_REQUIRES(\n+        ctx, value.dim_size(0) > loc_,\n+        errors::InvalidArgument(\"0th dimension of value = \", value.dim_size(0),\n+                                \" is less than loc_=\", loc_));\n+\n     auto update = ctx->input(1);\n \n     OP_REQUIRES(\n",
        "@@ -16,12 +16,16 @@\n \n import numpy as np\n \n+from tensorflow.python import tf2\n from tensorflow.python.eager import context\n+from tensorflow.python.eager import def_function\n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import gen_array_ops\n from tensorflow.python.ops import gradient_checker_v2\n from tensorflow.python.platform import test\n \n@@ -69,6 +73,19 @@ class StackOpTest(test.TestCase):\n             c = array_ops.parallel_stack(xs)\n             self.assertAllEqual(c, data)\n \n+  def testParallelConcatShapeZero(self):\n+    if not tf2.enabled():\n+      self.skipTest(\"only fails in TF2\")\n+\n+    @def_function.function\n+    def f():\n+      y = gen_array_ops.parallel_concat(values=[[\"tf\"]], shape=0)\n+      return y\n+\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                r\"0th dimension of value .* is less than\"):\n+      f()\n+\n   def testSimpleParallelGPU(self):\n     # tf.parallel_stack is only supported in graph mode.\n     with ops.Graph().as_default():\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    auto value = ctx->input(0);",
            "    auto update = ctx->input(1);",
            "",
            "    OP_REQUIRES(",
            "        ctx, value.dims() == update.dims(),",
            "        errors::InvalidArgument(\"value and update shape doesn't match: \",",
            "                                value.shape().DebugString(), \" vs. \",",
            "                                update.shape().DebugString()));",
            "    for (int i = 1; i < value.dims(); ++i) {",
            "      OP_REQUIRES(",
            "          ctx, value.dim_size(i) == update.dim_size(i),",
            "          errors::InvalidArgument(\"value and update shape doesn't match \",",
            "                                  value.shape().DebugString(), \" vs. \",",
            "                                  update.shape().DebugString()));"
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    auto value = ctx->input(0);",
            "    // Value should be at least rank 1. Also the 0th dimension should be",
            "    // at least loc_.",
            "    OP_REQUIRES(ctx, value.dims() >= 1,",
            "                errors::InvalidArgument(\"value should be at least rank 1.\"));",
            "    OP_REQUIRES(",
            "        ctx, value.dim_size(0) > loc_,",
            "        errors::InvalidArgument(\"0th dimension of value = \", value.dim_size(0),",
            "                                \" is less than loc_=\", loc_));",
            "",
            "    auto update = ctx->input(1);",
            "",
            "    OP_REQUIRES(",
            "        ctx, value.dims() == update.dims(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-7v94-64hj-m82h",
    "API Signature": "tf.raw_ops.ParallelConcat(\n    values, shape, name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "shape=0"
},
{
    "Title": "\n        Heap OOB read in `tf.raw_ops.SparseCountSparseOutput`\n      ",
    "Bug description": "The  shape inference functions for   can trigger a read outside of bounds of heap allocated array:",
    "Sample Code": "@\ndef func():\n  return tf.raw_ops.SparseCountSparseOutput(\n    indices=[1],\n    values=[[1]],\n    dense_shape=[10],\n    weights=[],\n    binary_output= True)\n\n)\n\nfunc()",
    "Code change": [
        "@@ -41,6 +41,8 @@ Status DenseCountSparseOutputShapeFn(InferenceContext *c) {\n }\n \n Status SparseCountSparseOutputShapeFn(InferenceContext *c) {\n+  ShapeHandle unused;\n+  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n   auto rank = c->Dim(c->input(0), 1);\n   auto nvals = c->UnknownDim();\n   c->set_output(0, c->Matrix(nvals, rank));  // out.indices\n",
        "@@ -831,6 +831,25 @@ class TestSparseCountFailureModes(test.TestCase):\n       self.evaluate(bincount_ops.sparse_bincount(x, weights=weights, axis=-1))\n \n \n+class RawOpsHeapOobTest(test.TestCase, parameterized.TestCase):\n+\n+  @test_util.run_v1_only(\"Test security error\")\n+  def testSparseCountSparseOutputBadIndicesShapeTooSmall(self):\n+    indices = [1]\n+    values = [[1]]\n+    weights = []\n+    dense_shape = [10]\n+    with self.assertRaisesRegex(ValueError,\n+                                \"Shape must be rank 2 but is rank 1 for\"):\n+      self.evaluate(\n+          gen_count_ops.SparseCountSparseOutput(\n+              indices=indices,\n+              values=values,\n+              dense_shape=dense_shape,\n+              weights=weights,\n+              binary_output=True))\n+\n+\n @test_util.run_all_in_graph_and_eager_modes\n @test_util.disable_tfrt\n class RawOpsTest(test.TestCase, parameterized.TestCase):\n"
    ],
    "Buggy Code": [
        [
            "",
            "Status SparseCountSparseOutputShapeFn(InferenceContext *c) {",
            "  auto rank = c->Dim(c->input(0), 1);",
            "  auto nvals = c->UnknownDim();",
            "  c->set_output(0, c->Matrix(nvals, rank));  // out.indices",
            "  c->set_output(1, c->Vector(nvals));        // out.values",
            "  c->set_output(2, c->Vector(rank));         // out.dense_shape",
            "  return Status::OK();"
        ]
    ],
    "Clean Code": [
        [
            "",
            "Status SparseCountSparseOutputShapeFn(InferenceContext *c) {",
            "  ShapeHandle unused;",
            "  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));",
            "  auto rank = c->Dim(c->input(0), 1);",
            "  auto nvals = c->UnknownDim();",
            "  c->set_output(0, c->Matrix(nvals, rank));  // out.indices",
            "  c->set_output(1, c->Vector(nvals));        // out.values"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m342-ff57-4jcc",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "indices=[1]"
},
{
    "Title": "\n        Heap OOB in TFLite's `Gather*` implementations\n      ",
    "Bug description": "TFLite's  GatherNd  does not support negative indices but there are no checks for this situation.",
    "Sample Code": "import numpy as np\ntf.compat.v1.disable_v2_behavior()\n\nparams = tf.compat.v1.placeholder(name=\"params\", dtype=tf.int64, shape=(1,))\nindices = tf.compat.v1.placeholder(name=\"indices\", dtype=tf.int64, shape=())\n\nout = tf.gather(params, indices, name='out')\n\nwith tf.compat.v1.Session() as sess:\n   converter = tf.compat.v1.lite.TFLiteConverter.from_session(sess, [params, indices], [out])\n   tflite_model = converter.convert()\n\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nparams_data = np.reshape(np.array([1], dtype=np.int64), newshape=(1,))\nindices_data = np.reshape(np.array(-10, dtype=np.int64), newshape=())\ninterpreter.set_tensor(input_details[0]['index'], params_data)\ninterpreter.set_tensor(input_details[1]['index'], indices_data)\n\n)\n\ninterpreter.invoke()",
    "Code change": [
        "@@ -123,6 +123,17 @@ TfLiteStatus GatherNdString(const TfLiteTensor* params,\n template <typename IndicesT>\n TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                           const TfLiteTensor* indices, TfLiteTensor* output) {\n+  bool indices_has_only_positive_elements = true;\n+  const auto* indices_values = GetTensorData<IndicesT>(indices);\n+  const size_t num_indices = indices->bytes / sizeof(IndicesT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indices_values[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   switch (params->type) {\n     case kTfLiteFloat32:\n       return GatherNd<float, IndicesT>(params, indices, output);\n"
    ],
    "Buggy Code": [
        [
            "TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,",
            "                          const TfLiteTensor* indices, TfLiteTensor* output) {",
            "  switch (params->type) {",
            "    case kTfLiteFloat32:",
            "      return GatherNd<float, IndicesT>(params, indices, output);",
            "    case kTfLiteUInt8:",
            "      return GatherNd<uint8_t, IndicesT>(params, indices, output);",
            "    case kTfLiteInt8:",
            "      return GatherNd<int8_t, IndicesT>(params, indices, output);",
            "    case kTfLiteInt16:",
            "      return GatherNd<int16_t, IndicesT>(params, indices, output);",
            "    case kTfLiteInt32:",
            "      return GatherNd<int32_t, IndicesT>(params, indices, output);",
            "    case kTfLiteInt64:",
            "      return GatherNd<int64_t, IndicesT>(params, indices, output);",
            "    case kTfLiteString:",
            "      return GatherNdString<IndicesT>(params, indices, output);"
        ]
    ],
    "Clean Code": [
        [
            "TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,",
            "                          const TfLiteTensor* indices, TfLiteTensor* output) {",
            "  bool indices_has_only_positive_elements = true;",
            "  const auto* indices_values = GetTensorData<IndicesT>(indices);",
            "  const size_t num_indices = indices->bytes / sizeof(IndicesT);",
            "  for (size_t i = 0; i < num_indices; i++) {",
            "    if (indices_values[i] < 0) {",
            "      indices_has_only_positive_elements = false;",
            "      break;",
            "    }",
            "  }",
            "  TF_LITE_ENSURE(context, indices_has_only_positive_elements);",
            "",
            "  switch (params->type) {",
            "    case kTfLiteFloat32:",
            "      return GatherNd<float, IndicesT>(params, indices, output);",
            "    case kTfLiteUInt8:"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jwf9-w5xm-f437",
    "API Signature": null,
    "Score": 0.025179856115107913,
    "Anomaly": "Negative input tensor",
    "Anomaly Description": "A negative input tensor refers to a tensor that contains negative values. In other words, the elements of the tensor have a value less than zero.",
    "Category": "Tensor",
    "Argument": "indices_data = np.reshape(np.array(-10, dtype=np.int64), newshape=())"
},
{
    "Title": "\n        Missing validation in shape inference for `Dequantize`\n      ",
    "Bug description": "The shape inference code for  tf.raw_ops.Dequantize  has a vulnerability that could trigger a denial of service via a segfault if an attacker provides invalid arguments:",
    "Sample Code": "tf.compat.v1.disable_v2_behavior()\ntf.raw_ops.Dequantize(\n  input_tensor = tf.constant(-10.0, dtype=tf.float32),\n  input_tensor = tf.cast(input_tensor, dtype=tf.quint8),\n  min_range = tf.constant([], shape=[0], dtype=tf.float32),\n  max_range = tf.constant([], shape=[0], dtype=tf.float32),\n  mode  = 'MIN_COMBINED',\n  narrow_range=False,\n  axis=-10,\n  ,\n  dtype=tf.dtypes.float32)",
    "Code change": [
        "@@ -2990,6 +2990,10 @@ REGISTER_OP(\"Dequantize\")\n       if (!s.ok() && s.code() != error::NOT_FOUND) {\n         return s;\n       }\n+      if (axis < -1) {\n+        return errors::InvalidArgument(\"axis should be at least -1, got \",\n+                                       axis);\n+      }\n       const int minmax_rank = (axis == -1) ? 0 : 1;\n       TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n       ShapeHandle minmax;\n"
    ],
    "Buggy Code": [
        [
            "        return s;",
            "      }",
            "      const int minmax_rank = (axis == -1) ? 0 : 1;",
            "      TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));",
            "      ShapeHandle minmax;",
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));",
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));",
            "      if (axis != -1) {",
            "        ShapeHandle input;",
            "        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));"
        ]
    ],
    "Clean Code": [
        [
            "        return s;",
            "      }",
            "      if (axis < -1) {",
            "        return errors::InvalidArgument(\"axis should be at least -1, got \",",
            "                                       axis);",
            "      }",
            "      const int minmax_rank = (axis == -1) ? 0 : 1;",
            "      TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));",
            "      ShapeHandle minmax;",
            "      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qfpc-5pjr-mh26",
    "API Signature": "tf.raw_ops.Dequantize(\n    input,\n    min_range,\n    max_range,\n    mode='MIN_COMBINED',\n    narrow_range=False,\n    axis=-1,\n    dtype=tf.dtypes.float32,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Integer",
    "Argument": "axis=-10,"
},
{
    "Title": "\n        Division by 0 in most convolution operators\n      ",
    "Bug description": "Most implementations of convolution operators in TensorFlow are affected by a division by 0 vulnerability where an attacker can trigger a denial of service via a crash:",
    "Sample Code": "tf.compat.v1.disable_v2_behavior()\ntf.raw_ops.Conv2D(\n  input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),\n  filter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),\n  strides = [1, 1, 1, 1],\n  ],\n  padding = \"SAME\")",
    "Code change": [
        "@@ -672,6 +672,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -681,6 +683,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n       int64_t num_groups = input_depth_value / filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,\n@@ -816,6 +820,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -825,6 +831,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\n       int64_t num_groups = input_depth_value / filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,\n@@ -2456,6 +2464,9 @@ Status SparseReduceShapeFn(InferenceContext* c) {\n \n     int64_t ndims = shape_vec.size();\n     absl::flat_hash_set<int64> axes;\n+    if (ndims == 0)\n+      return errors::InvalidArgument(\n+          \"Number of dims in shape tensor must not be 0\");\n     for (int i = 0; i < axes_vec.size(); i++) {\n       axes.insert((axes_vec(i) + ndims) % ndims);\n     }\n"
    ],
    "Buggy Code": [
        [
            "    int64_t input_depth_value = c->Value(input_depth_dim),",
            "            filter_input_depth_value = c->Value(filter_input_depth_dim);",
            "    if (input_depth_value % filter_input_depth_value != 0)",
            "      return errors::InvalidArgument(",
            "          \"Depth of input (\", input_depth_value,",
            "          \") is not a multiple of input depth of filter (\",",
            "          filter_input_depth_value, \")\");",
            "    if (input_depth_value != filter_input_depth_value) {"
        ],
        [
            "        if (output_depth_value % num_groups != 0)",
            "          return errors::InvalidArgument(",
            "              \"Depth of output (\", output_depth_value,",
            "              \") is not a multiple of the number of groups (\", num_groups, \")\");",
            "      }",
            "    }",
            "  }",
            ""
        ],
        [
            "          \"Depth of input (\", input_depth_value,",
            "          \") is not a multiple of input depth of filter (\",",
            "          filter_input_depth_value, \")\");",
            "    if (input_depth_value != filter_input_depth_value) {",
            "      int64_t num_groups = input_depth_value / filter_input_depth_value;",
            "      if (c->ValueKnown(output_depth_dim)) {",
            "        int64_t output_depth_value = c->Value(output_depth_dim);",
            "        if (output_depth_value % num_groups != 0)"
        ],
        [
            "      }",
            "    }",
            "  }",
            "",
            "  Padding padding;",
            "  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));",
            "  DimensionHandle output_planes, output_rows, output_cols;",
            ""
        ],
        [
            "      dims.reserve(ndims);",
            "      for (int d = 0; d < ndims; ++d) {",
            "        if (axes.find(d) == axes.end()) {",
            "          dims.push_back(c->MakeDim(shape_vec(d)));",
            "        } else {",
            "          dims.push_back(c->MakeDim(1));",
            "        }",
            "      }",
            "    } else {"
        ]
    ],
    "Clean Code": [
        [
            "    int64_t input_depth_value = c->Value(input_depth_dim),",
            "            filter_input_depth_value = c->Value(filter_input_depth_dim);",
            "    if (filter_input_depth_value == 0)",
            "      return errors::InvalidArgument(\"Depth of filter must not be 0\");",
            "    if (input_depth_value % filter_input_depth_value != 0)",
            "      return errors::InvalidArgument(",
            "          \"Depth of input (\", input_depth_value,",
            "          \") is not a multiple of input depth of filter (\","
        ],
        [
            "      if (c->ValueKnown(output_depth_dim)) {",
            "        int64_t output_depth_value = c->Value(output_depth_dim);",
            "        if (num_groups == 0)",
            "          return errors::InvalidArgument(\"Number of groups must not be 0\");",
            "        if (output_depth_value % num_groups != 0)",
            "          return errors::InvalidArgument(",
            "              \"Depth of output (\", output_depth_value,",
            "              \") is not a multiple of the number of groups (\", num_groups, \")\");"
        ],
        [
            "    int64_t input_depth_value = c->Value(input_depth_dim),",
            "            filter_input_depth_value = c->Value(filter_input_depth_dim);",
            "    if (filter_input_depth_value == 0)",
            "      return errors::InvalidArgument(\"Depth of filter must not be 0\");",
            "    if (input_depth_value % filter_input_depth_value != 0)",
            "      return errors::InvalidArgument(",
            "          \"Depth of input (\", input_depth_value,",
            "          \") is not a multiple of input depth of filter (\","
        ],
        [
            "      if (c->ValueKnown(output_depth_dim)) {",
            "        int64_t output_depth_value = c->Value(output_depth_dim);",
            "        if (num_groups == 0)",
            "          return errors::InvalidArgument(\"Number of groups must not be 0\");",
            "        if (output_depth_value % num_groups != 0)",
            "          return errors::InvalidArgument(",
            "              \"Depth of output (\", output_depth_value,",
            "              \") is not a multiple of the number of groups (\", num_groups, \")\");"
        ],
        [
            "    int64_t ndims = shape_vec.size();",
            "    absl::flat_hash_set<int64> axes;",
            "    if (ndims == 0)",
            "      return errors::InvalidArgument(",
            "          \"Number of dims in shape tensor must not be 0\");",
            "    for (int i = 0; i < axes_vec.size(); i++) {",
            "      axes.insert((axes_vec(i) + ndims) % ndims);",
            "    }",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9c8h-2mv3-49ww",
    "API Signature": "tf.raw_ops.Conv2D(\n    input,\n    filter,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "filter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),"
},
{
    "Title": "\n        Division by 0 in most convolution operators\n      ",
    "Bug description": "Most implementations of convolution operators in TensorFlow are affected by a division by 0 vulnerability where an attacker can trigger a denial of service via a crash:",
    "Sample Code": "tf.compat.v1.disable_v2_behavior()\ntf.raw_ops.Conv2D(\n  input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),\n  filter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),\n  strides = [1, 1, 1, 1],\n  ],\n  padding = \"SAME\")",
    "Code change": [
        "@@ -672,6 +672,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -681,6 +683,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n       int64_t num_groups = input_depth_value / filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,\n@@ -816,6 +820,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -825,6 +831,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\n       int64_t num_groups = input_depth_value / filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,\n@@ -2456,6 +2464,9 @@ Status SparseReduceShapeFn(InferenceContext* c) {\n \n     int64_t ndims = shape_vec.size();\n     absl::flat_hash_set<int64> axes;\n+    if (ndims == 0)\n+      return errors::InvalidArgument(\n+          \"Number of dims in shape tensor must not be 0\");\n     for (int i = 0; i < axes_vec.size(); i++) {\n       axes.insert((axes_vec(i) + ndims) % ndims);\n     }\n"
    ],
    "Buggy Code": [
        [
            "    int64_t input_depth_value = c->Value(input_depth_dim),",
            "            filter_input_depth_value = c->Value(filter_input_depth_dim);",
            "    if (input_depth_value % filter_input_depth_value != 0)",
            "      return errors::InvalidArgument(",
            "          \"Depth of input (\", input_depth_value,",
            "          \") is not a multiple of input depth of filter (\",",
            "          filter_input_depth_value, \")\");",
            "    if (input_depth_value != filter_input_depth_value) {"
        ],
        [
            "        if (output_depth_value % num_groups != 0)",
            "          return errors::InvalidArgument(",
            "              \"Depth of output (\", output_depth_value,",
            "              \") is not a multiple of the number of groups (\", num_groups, \")\");",
            "      }",
            "    }",
            "  }",
            ""
        ],
        [
            "          \"Depth of input (\", input_depth_value,",
            "          \") is not a multiple of input depth of filter (\",",
            "          filter_input_depth_value, \")\");",
            "    if (input_depth_value != filter_input_depth_value) {",
            "      int64_t num_groups = input_depth_value / filter_input_depth_value;",
            "      if (c->ValueKnown(output_depth_dim)) {",
            "        int64_t output_depth_value = c->Value(output_depth_dim);",
            "        if (output_depth_value % num_groups != 0)"
        ],
        [
            "      }",
            "    }",
            "  }",
            "",
            "  Padding padding;",
            "  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));",
            "  DimensionHandle output_planes, output_rows, output_cols;",
            ""
        ],
        [
            "      dims.reserve(ndims);",
            "      for (int d = 0; d < ndims; ++d) {",
            "        if (axes.find(d) == axes.end()) {",
            "          dims.push_back(c->MakeDim(shape_vec(d)));",
            "        } else {",
            "          dims.push_back(c->MakeDim(1));",
            "        }",
            "      }",
            "    } else {"
        ]
    ],
    "Clean Code": [
        [
            "    int64_t input_depth_value = c->Value(input_depth_dim),",
            "            filter_input_depth_value = c->Value(filter_input_depth_dim);",
            "    if (filter_input_depth_value == 0)",
            "      return errors::InvalidArgument(\"Depth of filter must not be 0\");",
            "    if (input_depth_value % filter_input_depth_value != 0)",
            "      return errors::InvalidArgument(",
            "          \"Depth of input (\", input_depth_value,",
            "          \") is not a multiple of input depth of filter (\","
        ],
        [
            "      if (c->ValueKnown(output_depth_dim)) {",
            "        int64_t output_depth_value = c->Value(output_depth_dim);",
            "        if (num_groups == 0)",
            "          return errors::InvalidArgument(\"Number of groups must not be 0\");",
            "        if (output_depth_value % num_groups != 0)",
            "          return errors::InvalidArgument(",
            "              \"Depth of output (\", output_depth_value,",
            "              \") is not a multiple of the number of groups (\", num_groups, \")\");"
        ],
        [
            "    int64_t input_depth_value = c->Value(input_depth_dim),",
            "            filter_input_depth_value = c->Value(filter_input_depth_dim);",
            "    if (filter_input_depth_value == 0)",
            "      return errors::InvalidArgument(\"Depth of filter must not be 0\");",
            "    if (input_depth_value % filter_input_depth_value != 0)",
            "      return errors::InvalidArgument(",
            "          \"Depth of input (\", input_depth_value,",
            "          \") is not a multiple of input depth of filter (\","
        ],
        [
            "      if (c->ValueKnown(output_depth_dim)) {",
            "        int64_t output_depth_value = c->Value(output_depth_dim);",
            "        if (num_groups == 0)",
            "          return errors::InvalidArgument(\"Number of groups must not be 0\");",
            "        if (output_depth_value % num_groups != 0)",
            "          return errors::InvalidArgument(",
            "              \"Depth of output (\", output_depth_value,",
            "              \") is not a multiple of the number of groups (\", num_groups, \")\");"
        ],
        [
            "    int64_t ndims = shape_vec.size();",
            "    absl::flat_hash_set<int64> axes;",
            "    if (ndims == 0)",
            "      return errors::InvalidArgument(",
            "          \"Number of dims in shape tensor must not be 0\");",
            "    for (int i = 0; i < axes_vec.size(); i++) {",
            "      axes.insert((axes_vec(i) + ndims) % ndims);",
            "    }",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9c8h-2mv3-49ww",
    "API Signature": "tf.raw_ops.Conv2D(\n    input,\n    filter,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),"
},
{
    "Title": "\n        Reference binding to nullptr in shape inference\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in  tf.raw_ops.SparseFillEmptyRows :",
    "Sample Code": "tf.compat.v1.disable_v2_behavior()\ntf.raw_ops.SparseFillEmptyRows(\n  indices = tf.constant([], shape=[0, 0], dtype=tf.int64),\n  values = tf.constant([], shape=[0], dtype=tf.int64),\n  dense_shape = tf.constant([], shape=[0], dtype=tf.int64),\n  ),\n  default_value = 0)",
    "Code change": [
        "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/common_shape_fns.h\"\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/shape_inference.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -619,6 +620,8 @@ REGISTER_OP(\"SparseFillEmptyRows\")\n       DimensionHandle unused_dim;\n       TF_RETURN_IF_ERROR(c->Merge(c->Dim(input_indices, 1),\n                                   c->Dim(input_shape, 0), &unused_dim));\n+      if (c->Value(c->NumElements(input_shape)) == 0)\n+        return errors::InvalidArgument(\"dense_shape must not be empty\");\n       ShapeHandle output_indices =\n           c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));\n       ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/op.h\"",
            "#include \"tensorflow/core/framework/shape_inference.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using shape_inference::DimensionHandle;",
            "using shape_inference::InferenceContext;"
        ],
        [
            "                                  c->Dim(input_shape, 0), &unused_dim));",
            "      ShapeHandle output_indices =",
            "          c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));",
            "      ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);",
            "      ShapeHandle constant_input_shape;",
            "      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(2, &constant_input_shape));",
            "      ShapeHandle empty_row_indicator =",
            "          c->Vector(c->Dim(constant_input_shape, 0));"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/op.h\"",
            "#include \"tensorflow/core/framework/shape_inference.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using shape_inference::DimensionHandle;"
        ],
        [
            "      TF_RETURN_IF_ERROR(c->Merge(c->Dim(input_indices, 1),",
            "                                  c->Dim(input_shape, 0), &unused_dim));",
            "      if (c->Value(c->NumElements(input_shape)) == 0)",
            "        return errors::InvalidArgument(\"dense_shape must not be empty\");",
            "      ShapeHandle output_indices =",
            "          c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));",
            "      ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);",
            "      ShapeHandle constant_input_shape;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v768-w7m9-2vmm",
    "API Signature": "tf.raw_ops.SparseFillEmptyRows(\n    indices, values, dense_shape, default_value, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "dense_shape = tf.constant([], shape=[0], dtype=tf.int64),"
},
{
    "Title": "\n        Incomplete validation in `MaxPoolGrad`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a segmentation fault in  tf.raw_ops.MaxPoolGrad  caused by missing validation:",
    "Sample Code": "tf.raw_ops.MaxPoolGrad(\n  orig_input = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  orig_output = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  grad = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  ksize = [1, 16, 16, 1],\n  strides = [1, 16, 18, 1],\n  padding = \"EXPLICIT\",\n  ,\n  explicit_paddings = [0, 0, 14, 3, 15, 5, 0, 0])",
    "Code change": [
        "@@ -74,6 +74,7 @@ static void SpatialMaxPoolWithArgMaxHelper(\n         errors::Internal(\"SpatialMaxPoolWithArgMaxHelper requires Targmax \"\n                          \"to be int64 when input_backprop != nullptr\"));\n   }\n+  if (tensor_in.NumElements() == 0 || output->NumElements() == 0) return;\n \n   typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n       ConstEigenMatrixMap;\n@@ -949,6 +950,10 @@ class MaxPoolingWithArgmaxOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& tensor_in = context->input(0);\n+    OP_REQUIRES(context, tensor_in.dims() == 4,\n+                errors::InvalidArgument(\"tensor_in must be 4-dimensional (2)\"));\n+    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n+                errors::InvalidArgument(\"tensor_in must not be empty (2)\"));\n \n     PoolParameters params{context,\n                           ksize_,\n",
        "@@ -171,6 +171,8 @@ PoolParameters::PoolParameters(OpKernelContext* context,\n     pad_depth = 0;\n     out_depth = depth;\n   } else {\n+    OP_REQUIRES(context, depth_window > 0,\n+                errors::InvalidArgument(\"depth_window must not be 0\"));\n     // Our current version of depthwise max pooling does not support\n     // any padding, and expects the depth_window to equal the\n     // depth_stride (no overlapping).\n"
    ],
    "Buggy Code": [
        [
            "                         \"to be int64 when input_backprop != nullptr\"));",
            "  }",
            "",
            "  typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>",
            "      ConstEigenMatrixMap;",
            "  typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>",
            "      EigenMatrixMap;"
        ],
        [
            "    const Tensor& tensor_in = context->input(0);",
            "",
            "    PoolParameters params{context,",
            "                          ksize_,",
            "                          stride_,",
            "                          padding_,",
            "                          /*explicit_paddings=*/{},",
            "                          FORMAT_NHWC,",
            "                          tensor_in.shape()};",
            "    if (!context->status().ok()) {"
        ],
        [
            "    out_depth = depth;",
            "  } else {",
            "    // Our current version of depthwise max pooling does not support",
            "    // any padding, and expects the depth_window to equal the",
            "    // depth_stride (no overlapping).",
            "    OP_REQUIRES(",
            "        context, depth % depth_window == 0,",
            "        errors::Unimplemented(\"Depthwise max pooling requires the depth \""
        ]
    ],
    "Clean Code": [
        [
            "                         \"to be int64 when input_backprop != nullptr\"));",
            "  }",
            "  if (tensor_in.NumElements() == 0 || output->NumElements() == 0) return;",
            "",
            "  typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>",
            "      ConstEigenMatrixMap;",
            "  typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>"
        ],
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& tensor_in = context->input(0);",
            "    OP_REQUIRES(context, tensor_in.dims() == 4,",
            "                errors::InvalidArgument(\"tensor_in must be 4-dimensional (2)\"));",
            "    OP_REQUIRES(context, tensor_in.NumElements() > 0,",
            "                errors::InvalidArgument(\"tensor_in must not be empty (2)\"));",
            "",
            "    PoolParameters params{context,",
            "                          ksize_,",
            "                          stride_,"
        ],
        [
            "    out_depth = depth;",
            "  } else {",
            "    OP_REQUIRES(context, depth_window > 0,",
            "                errors::InvalidArgument(\"depth_window must not be 0\"));",
            "    // Our current version of depthwise max pooling does not support",
            "    // any padding, and expects the depth_window to equal the",
            "    // depth_stride (no overlapping).",
            "    OP_REQUIRES("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-7ghq-fvr3-pj2x",
    "API Signature": "tf.raw_ops.MaxPoolGrad(\n    orig_input,\n    orig_output,\n    grad,\n    ksize,\n    strides,\n    padding,\n    explicit_paddings=[],\n    data_format='NHWC',\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "orig_input = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),"
},
{
    "Title": "\n        Incomplete validation in `MaxPoolGrad`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a segmentation fault in  tf.raw_ops.MaxPoolGrad  caused by missing validation:",
    "Sample Code": "tf.raw_ops.MaxPoolGrad(\n  orig_input = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  orig_output = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  grad = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),\n  ksize = [1, 16, 16, 1],\n  strides = [1, 16, 18, 1],\n  padding = \"EXPLICIT\",\n  ,\n  explicit_paddings = [0, 0, 14, 3, 15, 5, 0, 0])",
    "Code change": [
        "@@ -74,6 +74,7 @@ static void SpatialMaxPoolWithArgMaxHelper(\n         errors::Internal(\"SpatialMaxPoolWithArgMaxHelper requires Targmax \"\n                          \"to be int64 when input_backprop != nullptr\"));\n   }\n+  if (tensor_in.NumElements() == 0 || output->NumElements() == 0) return;\n \n   typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n       ConstEigenMatrixMap;\n@@ -949,6 +950,10 @@ class MaxPoolingWithArgmaxOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& tensor_in = context->input(0);\n+    OP_REQUIRES(context, tensor_in.dims() == 4,\n+                errors::InvalidArgument(\"tensor_in must be 4-dimensional (2)\"));\n+    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n+                errors::InvalidArgument(\"tensor_in must not be empty (2)\"));\n \n     PoolParameters params{context,\n                           ksize_,\n",
        "@@ -171,6 +171,8 @@ PoolParameters::PoolParameters(OpKernelContext* context,\n     pad_depth = 0;\n     out_depth = depth;\n   } else {\n+    OP_REQUIRES(context, depth_window > 0,\n+                errors::InvalidArgument(\"depth_window must not be 0\"));\n     // Our current version of depthwise max pooling does not support\n     // any padding, and expects the depth_window to equal the\n     // depth_stride (no overlapping).\n"
    ],
    "Buggy Code": [
        [
            "                         \"to be int64 when input_backprop != nullptr\"));",
            "  }",
            "",
            "  typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>",
            "      ConstEigenMatrixMap;",
            "  typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>",
            "      EigenMatrixMap;"
        ],
        [
            "    const Tensor& tensor_in = context->input(0);",
            "",
            "    PoolParameters params{context,",
            "                          ksize_,",
            "                          stride_,",
            "                          padding_,",
            "                          /*explicit_paddings=*/{},",
            "                          FORMAT_NHWC,",
            "                          tensor_in.shape()};",
            "    if (!context->status().ok()) {"
        ],
        [
            "    out_depth = depth;",
            "  } else {",
            "    // Our current version of depthwise max pooling does not support",
            "    // any padding, and expects the depth_window to equal the",
            "    // depth_stride (no overlapping).",
            "    OP_REQUIRES(",
            "        context, depth % depth_window == 0,",
            "        errors::Unimplemented(\"Depthwise max pooling requires the depth \""
        ]
    ],
    "Clean Code": [
        [
            "                         \"to be int64 when input_backprop != nullptr\"));",
            "  }",
            "  if (tensor_in.NumElements() == 0 || output->NumElements() == 0) return;",
            "",
            "  typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>",
            "      ConstEigenMatrixMap;",
            "  typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>"
        ],
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& tensor_in = context->input(0);",
            "    OP_REQUIRES(context, tensor_in.dims() == 4,",
            "                errors::InvalidArgument(\"tensor_in must be 4-dimensional (2)\"));",
            "    OP_REQUIRES(context, tensor_in.NumElements() > 0,",
            "                errors::InvalidArgument(\"tensor_in must not be empty (2)\"));",
            "",
            "    PoolParameters params{context,",
            "                          ksize_,",
            "                          stride_,"
        ],
        [
            "    out_depth = depth;",
            "  } else {",
            "    OP_REQUIRES(context, depth_window > 0,",
            "                errors::InvalidArgument(\"depth_window must not be 0\"));",
            "    // Our current version of depthwise max pooling does not support",
            "    // any padding, and expects the depth_window to equal the",
            "    // depth_stride (no overlapping).",
            "    OP_REQUIRES("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-7ghq-fvr3-pj2x",
    "API Signature": "tf.raw_ops.MaxPoolGrad(\n    orig_input,\n    orig_output,\n    grad,\n    ksize,\n    strides,\n    padding,\n    explicit_paddings=[],\n    data_format='NHWC',\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "orig_input = tf.constant([], shape=[3, 0, 0, 2], dtype=tf.float32),"
},
{
    "Title": "\n        `CHECK`-fail in `MapStage`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in  tf.raw_ops.MapStage :",
    "Sample Code": "tf.raw_ops.MapStage(\n  key=tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64),\n  indices=tf.constant((0), dtype=tf.int32),\n  values=[tf.constant((0), dtype=tf.int32)],\n  dtypes=[tf.int32,\n  tf.int64],\n  capacity=0,\n  memory_limit=0,\n  container='',\n  ,\n  shared_name='')",
    "Code change": [
        "@@ -527,6 +527,8 @@ class MapStageOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->input(\"key\", &key_tensor));\n     OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));\n     OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));\n+    OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\n+                errors::InvalidArgument(\"key must not be empty\"));\n \n     // Create copy for insertion into Staging Area\n     Tensor key(*key_tensor);\n"
    ],
    "Buggy Code": [
        [
            "    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));",
            "    OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));",
            "",
            "    // Create copy for insertion into Staging Area",
            "    Tensor key(*key_tensor);",
            "",
            "    // Create the tuple to store",
            "    for (std::size_t i = 0; i < values_tensor.size(); ++i) {"
        ]
    ],
    "Clean Code": [
        [
            "    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));",
            "    OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));",
            "    OP_REQUIRES(ctx, key_tensor->NumElements() > 0,",
            "                errors::InvalidArgument(\"key must not be empty\"));",
            "",
            "    // Create copy for insertion into Staging Area",
            "    Tensor key(*key_tensor);",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-278g-rq84-9hmg",
    "API Signature": "tf.raw_ops.MapStage(\n    key,\n    indices,\n    values,\n    dtypes,\n    capacity=0,\n    memory_limit=0,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "key=tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64),"
},
{
    "Title": "\n        Heap OOB in `SdcaOptimizerV2`\n      ",
    "Bug description": "An attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to  tf.raw_ops.SdcaOptimizerV2 :",
    "Sample Code": "tf.raw_ops.SdcaOptimizerV2(\n  sparse_example_indices=[[1]],\n  sparse_feature_indices=[[1]],\n  sparse_feature_values=[[1.0,2.0]],\n  dense_features=[[1.0]],\n  example_weights=[1.0],\n  example_labels=[],\n  sparse_indices=[1],\n  sparse_weights=[1.0],\n  dense_weights=[[1.0]],\n  example_state_data=[[100.0,100.0,100.0,100.0]],\n  loss_type='logistic_loss',\n  l1=100.0,\n  l2=100.0,\n  num_loss_partitions=1,\n  num_inner_iterations=1,\n  ,\n  adaptive=True)       ",
    "Code change": [
        "@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\n   const Tensor* example_labels_t;\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n   auto example_labels = example_labels_t->flat<float>();\n+  if (example_labels.size() != num_examples) {\n+    return errors::InvalidArgument(\"Expected \", num_examples,\n+                                   \" example labels but got \",\n+                                   example_labels.size());\n+  }\n \n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR(\n"
    ],
    "Buggy Code": [
        [
            "  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));",
            "  auto example_labels = example_labels_t->flat<float>();",
            "",
            "  OpInputList dense_features_inputs;",
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"dense_features\", &dense_features_inputs));",
            "",
            "  examples_.clear();",
            "  examples_.resize(num_examples);",
            "  probabilities_.resize(num_examples);",
            "  sampled_index_.resize(num_examples);"
        ]
    ],
    "Clean Code": [
        [
            "  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));",
            "  auto example_labels = example_labels_t->flat<float>();",
            "  if (example_labels.size() != num_examples) {",
            "    return errors::InvalidArgument(\"Expected \", num_examples,",
            "                                   \" example labels but got \",",
            "                                   example_labels.size());",
            "  }",
            "",
            "  OpInputList dense_features_inputs;",
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"dense_features\", &dense_features_inputs));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5hj3-vjjf-f5m7",
    "API Signature": "tf.raw_ops.SdcaOptimizerV2(\n    sparse_example_indices,\n    sparse_feature_indices,\n    sparse_feature_values,\n    dense_features,\n    example_weights,\n    example_labels,\n    sparse_indices,\n    sparse_weights,\n    dense_weights,\n    example_state_data,\n    loss_type,\n    l1,\n    l2,\n    num_loss_partitions,\n    num_inner_iterations,\n    adaptive=True,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "example_labels=[],"
},
{
    "Title": "\n        Reference binding to nullptr in map operations\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in  tf.raw_ops.Map*  and  tf.raw_ops.OrderedMap*  operations:",
    "Sample Code": "tf.raw_ops.MapPeek(\n  key=tf.constant([8],dtype=tf.int64),\n  indices=[],\n  dtypes=[tf.int32],\n  capacity=8,\n  ,\n  memory_limit=128)",
    "Code change": [
        "@@ -210,9 +210,9 @@ class StagingMap : public ResourceBase {\n                                    const OptionalTuple& tuple)\n       TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {\n     if (tuple[index].has_value()) {\n-      return Status(errors::InvalidArgument(\n+      return errors::InvalidArgument(\n           \"The tensor for index '\", index, \"' for key '\", key.scalar<int64>()(),\n-          \"' was already initialized '\", dtypes_.size(), \"'.\"));\n+          \"' was already initialized '\", dtypes_.size(), \"'.\");\n     }\n \n     return Status::OK();\n@@ -220,6 +220,10 @@ class StagingMap : public ResourceBase {\n \n   // Check that the indices are strictly ordered\n   Status check_index_ordering(const Tensor& indices) {\n+    if (indices.NumElements() == 0) {\n+      return errors::InvalidArgument(\"Indices are empty\");\n+    }\n+\n     auto findices = indices.flat<int>();\n \n     for (std::size_t i = 0; i < findices.dimension(0) - 1; ++i) {\n@@ -227,8 +231,7 @@ class StagingMap : public ResourceBase {\n         continue;\n       }\n \n-      return Status(\n-          errors::InvalidArgument(\"Indices are not strictly ordered\"));\n+      return errors::InvalidArgument(\"Indices are not strictly ordered\");\n     }\n \n     return Status::OK();\n@@ -238,10 +241,10 @@ class StagingMap : public ResourceBase {\n   Status check_memory_limit(std::size_t bytes)\n       TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {\n     if (has_memory_limit() && bytes > memory_limit_) {\n-      return Status(errors::ResourceExhausted(\n+      return errors::ResourceExhausted(\n           \"Attempted to insert tensors with combined size of '\", bytes,\n           \"' bytes into Staging Area with a memory limit of '\", memory_limit_,\n-          \"'.\"));\n+          \"'.\");\n     }\n \n     return Status::OK();\n"
    ],
    "Buggy Code": [
        [
            "      TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {",
            "    if (tuple[index].has_value()) {",
            "      return Status(errors::InvalidArgument(",
            "          \"The tensor for index '\", index, \"' for key '\", key.scalar<int64>()(),",
            "          \"' was already initialized '\", dtypes_.size(), \"'.\"));",
            "    }",
            "",
            "    return Status::OK();",
            "  }"
        ],
        [
            "  // Check that the indices are strictly ordered",
            "  Status check_index_ordering(const Tensor& indices) {",
            "    auto findices = indices.flat<int>();",
            "",
            "    for (std::size_t i = 0; i < findices.dimension(0) - 1; ++i) {",
            "      if (findices(i) < findices(i + 1)) {",
            "        continue;",
            "      }",
            "",
            "      return Status("
        ],
        [
            "    }",
            "",
            "    return Status::OK();",
            "  }",
            "",
            "  // Check bytes are within memory limits memory limits",
            "  Status check_memory_limit(std::size_t bytes)"
        ],
        [
            "          \"Attempted to insert tensors with combined size of '\", bytes,",
            "          \"' bytes into Staging Area with a memory limit of '\", memory_limit_,",
            "          \"'.\"));",
            "    }",
            "",
            "    return Status::OK();",
            "  }",
            "",
            "  // Insert incomplete data into the Barrier",
            "  Status put_incomplete(const KeyType& key, const Tensor& indices,"
        ]
    ],
    "Clean Code": [
        [
            "      TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {",
            "    if (tuple[index].has_value()) {",
            "      return errors::InvalidArgument(",
            "          \"The tensor for index '\", index, \"' for key '\", key.scalar<int64>()(),",
            "          \"' was already initialized '\", dtypes_.size(), \"'.\");",
            "    }",
            "",
            "    return Status::OK();",
            "  }"
        ],
        [
            "  // Check that the indices are strictly ordered",
            "  Status check_index_ordering(const Tensor& indices) {",
            "    if (indices.NumElements() == 0) {",
            "      return errors::InvalidArgument(\"Indices are empty\");",
            "    }",
            "",
            "    auto findices = indices.flat<int>();",
            "",
            "    for (std::size_t i = 0; i < findices.dimension(0) - 1; ++i) {",
            "      if (findices(i) < findices(i + 1)) {"
        ],
        [
            "      }",
            "",
            "      return errors::InvalidArgument(\"Indices are not strictly ordered\");",
            "    }",
            "",
            "    return Status::OK();",
            "  }"
        ],
        [
            "      TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {",
            "    if (has_memory_limit() && bytes > memory_limit_) {",
            "      return errors::ResourceExhausted(",
            "          \"Attempted to insert tensors with combined size of '\", bytes,",
            "          \"' bytes into Staging Area with a memory limit of '\", memory_limit_,",
            "          \"'.\");",
            "    }",
            "",
            "    return Status::OK();",
            "  }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qr82-2c78-4m8h",
    "API Signature": "tf.raw_ops.MapPeek(\n    key,\n    indices,\n    dtypes,\n    capacity=0,\n    memory_limit=0,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Empty list argument",
    "Anomaly Description": "An empty list argument in Python refers to a list parameter or value that contains no elements. It is a list object passed as an argument to a function, method, or operation, but it does not have any items or content.",
    "Category": "List",
    "Argument": "indices=[],"
},
{
    "Title": "\n        Heap OOB in `UpperBound` and `LowerBound`\n      ",
    "Bug description": "An attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to  tf.raw_ops.UpperBound :",
    "Sample Code": "tf.raw_ops.UpperBound(\n  sorted_input=[1,2,3],\n  values=tf.constant(value=[[0,0,0],[1,1,1],[2,2,2]],dtype=tf.int64),\n  ),\n  out_type=tf.int64)",
    "Code change": [
        "@@ -86,6 +86,10 @@ class UpperBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    // inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     // must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n@@ -127,6 +131,10 @@ class LowerBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    // inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     // must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor& values_t = ctx->input(1);",
            "",
            "    // must have same batch dim_size for both",
            "    OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),",
            "                Status(error::INVALID_ARGUMENT,",
            "                       \"Leading dim_size of both tensors must match.\"));",
            "",
            "    // this is required because we do indexing in int32 on the GPU",
            "    OP_REQUIRES(ctx, values_t.NumElements() < std::numeric_limits<int>::max(),",
            "                Status(error::INVALID_ARGUMENT,"
        ],
        [
            "                Status(error::INVALID_ARGUMENT,",
            "                       \"Leading dim_size of both tensors must match.\"));",
            "",
            "    // this is required because we do indexing in int32 on the GPU",
            "    OP_REQUIRES(ctx, values_t.NumElements() < std::numeric_limits<int>::max(),",
            "                Status(error::INVALID_ARGUMENT,",
            "                       \"values tensor size must less than INT_MAX\"));",
            "",
            "    Tensor* output_t;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, values_t.shape(), &output_t));"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor& values_t = ctx->input(1);",
            "",
            "    // inputs must be at least a matrix",
            "    OP_REQUIRES(",
            "        ctx, sorted_inputs_t.shape().dims() >= 2,",
            "        errors::InvalidArgument(\"sorted input argument must be a matrix\"));",
            "    // must have same batch dim_size for both",
            "    OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),",
            "                Status(error::INVALID_ARGUMENT,",
            "                       \"Leading dim_size of both tensors must match.\"));"
        ],
        [
            "    const Tensor& values_t = ctx->input(1);",
            "",
            "    // inputs must be at least a matrix",
            "    OP_REQUIRES(",
            "        ctx, sorted_inputs_t.shape().dims() >= 2,",
            "        errors::InvalidArgument(\"sorted input argument must be a matrix\"));",
            "    // must have same batch dim_size for both",
            "    OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),",
            "                Status(error::INVALID_ARGUMENT,",
            "                       \"Leading dim_size of both tensors must match.\"));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9697-98pf-4rw7",
    "API Signature": "tf.raw_ops.UpperBound(\n    sorted_inputs,\n    values,\n    out_type=tf.dtypes.int32,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "sorted_input=[1,2,3],"
},
{
    "Title": "\n        Heap OOB in `UpperBound` and `LowerBound`\n      ",
    "Bug description": "An attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to  tf.raw_ops.UpperBound :",
    "Sample Code": "tf.raw_ops.UpperBound(\n  sorted_input=[1,2,3],\n  values=tf.constant(value=[[0,0,0],[1,1,1],[2,2,2]],dtype=tf.int64),\n  ),\n  out_type=tf.int64)",
    "Code change": [
        "@@ -86,6 +86,10 @@ class UpperBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    // inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     // must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n@@ -127,6 +131,10 @@ class LowerBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    // inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     // must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor& values_t = ctx->input(1);",
            "",
            "    // must have same batch dim_size for both",
            "    OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),",
            "                Status(error::INVALID_ARGUMENT,",
            "                       \"Leading dim_size of both tensors must match.\"));",
            "",
            "    // this is required because we do indexing in int32 on the GPU",
            "    OP_REQUIRES(ctx, values_t.NumElements() < std::numeric_limits<int>::max(),",
            "                Status(error::INVALID_ARGUMENT,"
        ],
        [
            "                Status(error::INVALID_ARGUMENT,",
            "                       \"Leading dim_size of both tensors must match.\"));",
            "",
            "    // this is required because we do indexing in int32 on the GPU",
            "    OP_REQUIRES(ctx, values_t.NumElements() < std::numeric_limits<int>::max(),",
            "                Status(error::INVALID_ARGUMENT,",
            "                       \"values tensor size must less than INT_MAX\"));",
            "",
            "    Tensor* output_t;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, values_t.shape(), &output_t));"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor& values_t = ctx->input(1);",
            "",
            "    // inputs must be at least a matrix",
            "    OP_REQUIRES(",
            "        ctx, sorted_inputs_t.shape().dims() >= 2,",
            "        errors::InvalidArgument(\"sorted input argument must be a matrix\"));",
            "    // must have same batch dim_size for both",
            "    OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),",
            "                Status(error::INVALID_ARGUMENT,",
            "                       \"Leading dim_size of both tensors must match.\"));"
        ],
        [
            "    const Tensor& values_t = ctx->input(1);",
            "",
            "    // inputs must be at least a matrix",
            "    OP_REQUIRES(",
            "        ctx, sorted_inputs_t.shape().dims() >= 2,",
            "        errors::InvalidArgument(\"sorted input argument must be a matrix\"));",
            "    // must have same batch dim_size for both",
            "    OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),",
            "                Status(error::INVALID_ARGUMENT,",
            "                       \"Leading dim_size of both tensors must match.\"));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9697-98pf-4rw7",
    "API Signature": "tf.raw_ops.LowerBound(\n    sorted_inputs,\n    values,\n    out_type=tf.dtypes.int32,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "sorted_input=[1,2,3],"
},
{
    "Title": "\n        Crash in NMS ops caused by integer conversion to unsigned\n      ",
    "Bug description": "An attacker can cause denial of service in applications serving models using  tf.raw_ops.NonMaxSuppressionV5  by triggering a division by 0:",
    "Sample Code": "tf.raw_ops.NonMaxSuppressionV5(\n  boxes=[[[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]],[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]],[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]]]],\n  scores=[[[1.0,2.0,3.0],[1.0,2.0,3.0],[1.0,2.0,3.0]]],\n  max_output_size_per_class=-1,\n  max_total_size=10,\n  iou_threshold=score_threshold=0.5,\n  pad_per_class=True,\n  ,\n  clip_boxes=True)",
    "Code change": [
        "@@ -169,6 +169,8 @@ void DoNonMaxSuppressionOp(OpKernelContext* context, const Tensor& scores,\n                            bool pad_to_max_output_size = false,\n                            int* ptr_num_valid_outputs = nullptr) {\n   const int output_size = max_output_size.scalar<int>()();\n+  OP_REQUIRES(context, output_size >= 0,\n+              errors::InvalidArgument(\"output size must be non-negative\"));\n \n   std::vector<T> scores_data(num_boxes);\n   std::copy_n(scores.flat<T>().data(), num_boxes, scores_data.begin());\n@@ -768,6 +770,9 @@ class NonMaxSuppressionV4Op : public OpKernel {\n         context, scores, num_boxes, max_output_size, iou_threshold_val,\n         score_threshold_val, dummy_soft_nms_sigma, similarity_fn,\n         return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);\n+    if (!context->status().ok()) {\n+      return;\n+    }\n \n     // Allocate scalar output tensor for number of indices computed.\n     Tensor* num_outputs_t = nullptr;\n@@ -845,6 +850,9 @@ class NonMaxSuppressionV5Op : public OpKernel {\n         context, scores, num_boxes, max_output_size, iou_threshold_val,\n         score_threshold_val, soft_nms_sigma_val, similarity_fn,\n         return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);\n+    if (!context->status().ok()) {\n+      return;\n+    }\n \n     // Allocate scalar output tensor for number of indices computed.\n     Tensor* num_outputs_t = nullptr;\n"
    ],
    "Buggy Code": [
        [
            "                           int* ptr_num_valid_outputs = nullptr) {",
            "  const int output_size = max_output_size.scalar<int>()();",
            "",
            "  std::vector<T> scores_data(num_boxes);",
            "  std::copy_n(scores.flat<T>().data(), num_boxes, scores_data.begin());",
            "",
            "  // Data structure for a selection candidate in NMS.",
            "  struct Candidate {"
        ],
        [
            "",
            "    // Allocate scalar output tensor for number of indices computed.",
            "    Tensor* num_outputs_t = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(",
            "                                1, tensorflow::TensorShape{}, &num_outputs_t));",
            "    num_outputs_t->scalar<int32>().setConstant(num_valid_outputs);",
            "  }",
            "",
            " private:"
        ],
        [
            "    OP_REQUIRES_OK(context, context->allocate_output(",
            "                                2, tensorflow::TensorShape{}, &num_outputs_t));",
            "    num_outputs_t->scalar<int32>().setConstant(num_valid_outputs);",
            "  }",
            "",
            " private:",
            "  bool pad_to_max_output_size_;",
            "};",
            ""
        ]
    ],
    "Clean Code": [
        [
            "                           int* ptr_num_valid_outputs = nullptr) {",
            "  const int output_size = max_output_size.scalar<int>()();",
            "  OP_REQUIRES(context, output_size >= 0,",
            "              errors::InvalidArgument(\"output size must be non-negative\"));",
            "",
            "  std::vector<T> scores_data(num_boxes);",
            "  std::copy_n(scores.flat<T>().data(), num_boxes, scores_data.begin());",
            ""
        ],
        [
            "        score_threshold_val, dummy_soft_nms_sigma, similarity_fn,",
            "        return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);",
            "    if (!context->status().ok()) {",
            "      return;",
            "    }",
            "",
            "    // Allocate scalar output tensor for number of indices computed.",
            "    Tensor* num_outputs_t = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output("
        ],
        [
            "        score_threshold_val, soft_nms_sigma_val, similarity_fn,",
            "        return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);",
            "    if (!context->status().ok()) {",
            "      return;",
            "    }",
            "",
            "    // Allocate scalar output tensor for number of indices computed.",
            "    Tensor* num_outputs_t = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vmjw-c2vp-p33c",
    "API Signature": "tf.raw_ops.NonMaxSuppressionV5(\n    boxes,\n    scores,\n    max_output_size,\n    iou_threshold,\n    score_threshold,\n    soft_nms_sigma,\n    pad_to_max_output_size=False,\n    name=None\n)\n",
    "Score": 0.039568345323741004,
    "Anomaly": "Negative integer argument",
    "Anomaly Description": "A negative integer argument in Python refers to an integer value that is less than zero. It is a numeric value that represents a negative quantity or position in a numerical sequence. In Python, negative integers are denoted by placing a minus sign (-) before the numerical value. For example, -1, -2, -3, and so on.",
    "Category": "Integer",
    "Argument": "max_output_size=-1,"
},
{
    "Title": "\n        Crash in NMS ops caused by integer conversion to unsigned\n      ",
    "Bug description": "An attacker can cause denial of service in applications serving models using  tf.raw_ops.NonMaxSuppressionV5  by triggering a division by 0:",
    "Sample Code": "tf.raw_ops.NonMaxSuppressionV5(\n  boxes=[[[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]],[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]],[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]]]],\n  scores=[[[1.0,2.0,3.0],[1.0,2.0,3.0],[1.0,2.0,3.0]]],\n  max_output_size_per_class=-1,\n  max_total_size=10,\n  iou_threshold=score_threshold=0.5,\n  pad_per_class=True,\n  ,\n  clip_boxes=True)",
    "Code change": [
        "@@ -169,6 +169,8 @@ void DoNonMaxSuppressionOp(OpKernelContext* context, const Tensor& scores,\n                            bool pad_to_max_output_size = false,\n                            int* ptr_num_valid_outputs = nullptr) {\n   const int output_size = max_output_size.scalar<int>()();\n+  OP_REQUIRES(context, output_size >= 0,\n+              errors::InvalidArgument(\"output size must be non-negative\"));\n \n   std::vector<T> scores_data(num_boxes);\n   std::copy_n(scores.flat<T>().data(), num_boxes, scores_data.begin());\n@@ -768,6 +770,9 @@ class NonMaxSuppressionV4Op : public OpKernel {\n         context, scores, num_boxes, max_output_size, iou_threshold_val,\n         score_threshold_val, dummy_soft_nms_sigma, similarity_fn,\n         return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);\n+    if (!context->status().ok()) {\n+      return;\n+    }\n \n     // Allocate scalar output tensor for number of indices computed.\n     Tensor* num_outputs_t = nullptr;\n@@ -845,6 +850,9 @@ class NonMaxSuppressionV5Op : public OpKernel {\n         context, scores, num_boxes, max_output_size, iou_threshold_val,\n         score_threshold_val, soft_nms_sigma_val, similarity_fn,\n         return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);\n+    if (!context->status().ok()) {\n+      return;\n+    }\n \n     // Allocate scalar output tensor for number of indices computed.\n     Tensor* num_outputs_t = nullptr;\n"
    ],
    "Buggy Code": [
        [
            "                           int* ptr_num_valid_outputs = nullptr) {",
            "  const int output_size = max_output_size.scalar<int>()();",
            "",
            "  std::vector<T> scores_data(num_boxes);",
            "  std::copy_n(scores.flat<T>().data(), num_boxes, scores_data.begin());",
            "",
            "  // Data structure for a selection candidate in NMS.",
            "  struct Candidate {"
        ],
        [
            "",
            "    // Allocate scalar output tensor for number of indices computed.",
            "    Tensor* num_outputs_t = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output(",
            "                                1, tensorflow::TensorShape{}, &num_outputs_t));",
            "    num_outputs_t->scalar<int32>().setConstant(num_valid_outputs);",
            "  }",
            "",
            " private:"
        ],
        [
            "    OP_REQUIRES_OK(context, context->allocate_output(",
            "                                2, tensorflow::TensorShape{}, &num_outputs_t));",
            "    num_outputs_t->scalar<int32>().setConstant(num_valid_outputs);",
            "  }",
            "",
            " private:",
            "  bool pad_to_max_output_size_;",
            "};",
            ""
        ]
    ],
    "Clean Code": [
        [
            "                           int* ptr_num_valid_outputs = nullptr) {",
            "  const int output_size = max_output_size.scalar<int>()();",
            "  OP_REQUIRES(context, output_size >= 0,",
            "              errors::InvalidArgument(\"output size must be non-negative\"));",
            "",
            "  std::vector<T> scores_data(num_boxes);",
            "  std::copy_n(scores.flat<T>().data(), num_boxes, scores_data.begin());",
            ""
        ],
        [
            "        score_threshold_val, dummy_soft_nms_sigma, similarity_fn,",
            "        return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);",
            "    if (!context->status().ok()) {",
            "      return;",
            "    }",
            "",
            "    // Allocate scalar output tensor for number of indices computed.",
            "    Tensor* num_outputs_t = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output("
        ],
        [
            "        score_threshold_val, soft_nms_sigma_val, similarity_fn,",
            "        return_scores_tensor_, pad_to_max_output_size_, &num_valid_outputs);",
            "    if (!context->status().ok()) {",
            "      return;",
            "    }",
            "",
            "    // Allocate scalar output tensor for number of indices computed.",
            "    Tensor* num_outputs_t = nullptr;",
            "    OP_REQUIRES_OK(context, context->allocate_output("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vmjw-c2vp-p33c",
    "API Signature": "tf.raw_ops.CombinedNonMaxSuppression(\n    boxes,\n    scores,\n    max_output_size_per_class,\n    max_total_size,\n    iou_threshold,\n    score_threshold,\n    pad_per_class=False,\n    clip_boxes=True,\n    name=None\n)\n",
    "Score": 0.039568345323741004,
    "Anomaly": "Negative integer argument",
    "Anomaly Description": "A negative integer argument in Python refers to an integer value that is less than zero. It is a numeric value that represents a negative quantity or position in a numerical sequence. In Python, negative integers are denoted by placing a minus sign (-) before the numerical value. For example, -1, -2, -3, and so on.",
    "Category": "Integer",
    "Argument": "max_output_size=-1,"
},
{
    "Title": "\n        FPE in `tf.raw_ops.UnravelIndex`\n      ",
    "Bug description": "An attacker can cause denial of service in applications serving models using  tf.raw_ops.UnravelIndex  by triggering a division by 0:",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.UnravelIndex(indices=-1, dims=[1,0,2])",
    "Code change": [
        "@@ -53,6 +53,14 @@ class UnravelIndexOp : public OpKernel {\n                                 dims_tensor.shape().DebugString(), \"\\\"\"));\n \n     auto dims = dims_tensor.vec<Tidx>();\n+    // Make sure dims does not contain a zero\n+    for (int i = 0; i < dims.size(); i++) {\n+      OP_REQUIRES(\n+          ctx, dims(i) != 0,\n+          errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"\n+                                  \"but dims contains zero at index \",\n+                                  i));\n+    }\n \n     // Chek to make sure indices is not out of boundary\n     Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();\n",
        "@@ -1575,7 +1575,7 @@ class UnravelIndexTest(test_util.TensorFlowTestCase):\n     with self.cached_session():\n       for dtype in [dtypes.int32, dtypes.int64]:\n         with self.assertRaisesRegex(errors.InvalidArgumentError,\n-                                    \"index is out of bound as with dims\"):\n+                                    \"dims cannot contain a dim of zero\"):\n           indices = constant_op.constant([2, 5, 7], dtype=dtype)\n           dims = constant_op.constant([3, 0], dtype=dtype)\n           self.evaluate(array_ops.unravel_index(indices=indices, dims=dims))\n"
    ],
    "Buggy Code": [
        [
            "",
            "    auto dims = dims_tensor.vec<Tidx>();",
            "",
            "    // Chek to make sure indices is not out of boundary",
            "    Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();",
            "    Tidx dims_prod = dims_prod_eigen();",
            "    const Tidx* indices = indices_tensor.flat<Tidx>().data();",
            "    int64 size = indices_tensor.NumElements();",
            "    bool check = std::all_of(indices, indices + size,",
            "                             [&](Tidx index) { return index < dims_prod; });",
            "    OP_REQUIRES(ctx, check,",
            "                errors::InvalidArgument(\"index is out of bound as with dims\"));",
            "",
            "    Eigen::array<bool, 1> reverse({true});"
        ]
    ],
    "Clean Code": [
        [
            "",
            "    auto dims = dims_tensor.vec<Tidx>();",
            "    // Make sure dims does not contain a zero",
            "    for (int i = 0; i < dims.size(); i++) {",
            "      OP_REQUIRES(",
            "          ctx, dims(i) != 0,",
            "          errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"",
            "                                  \"but dims contains zero at index \",",
            "                                  i));",
            "    }",
            "",
            "    // Chek to make sure indices is not out of boundary",
            "    Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();",
            "    Tidx dims_prod = dims_prod_eigen();"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2wmv-37vq-52g5",
    "API Signature": "tf.raw_ops.UnravelIndex(\n    indices, dims, name=None\n)\n",
    "Score": 0.03237410071942446,
    "Anomaly": "Zero integer list element",
    "Anomaly Description": "A zero integer list element in Python refers to an element within a list that has a value of zero. It is an integer value of zero (0) that is present as an item in a list.",
    "Category": "List",
    "Argument": "dims=[1,0,2]"
},
{
    "Title": "\n        Reference binding to nullptr in unicode encoding\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in  tf.raw_ops.UnicodeEncode :",
    "Sample Code": "from tensorflow.python.ops import gen_string_ops\n\ngen_string_ops.unicode_encode(\n  input_values=[],\n  input_splits=[],\n  output_encoding='UTF-8',\n  errors='ignore',\n  ,\n  replacement_char='a')",
    "Code change": [
        "@@ -533,6 +533,10 @@ class UnicodeEncodeOp : public OpKernel {\n     const Tensor& input_splits = context->input(1);\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n \n+    OP_REQUIRES(\n+        context, input_splits.NumElements() > 0,\n+        errors::InvalidArgument(\"Input_splits should contain elements, but \"\n+                                \"given input_values has 0 elements\"));\n     // Operation will treat first argument in input_splits as if it were zero\n     // regardless of its actual value since splits should begin with zero and\n     // end with the length of the input values vector.\n"
    ],
    "Buggy Code": [
        [
            "    const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();",
            "",
            "    // Operation will treat first argument in input_splits as if it were zero",
            "    // regardless of its actual value since splits should begin with zero and",
            "    // end with the length of the input values vector.",
            "    OP_REQUIRES(",
            "        context, input_splits_flat(0) == 0,",
            "        errors::InvalidArgument(\"First value in input_splits must be zero.\"));",
            "    OP_REQUIRES(context,",
            "                input_splits_flat(input_splits_flat.size() - 1) =="
        ]
    ],
    "Clean Code": [
        [
            "    const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();",
            "",
            "    OP_REQUIRES(",
            "        context, input_splits.NumElements() > 0,",
            "        errors::InvalidArgument(\"Input_splits should contain elements, but \"",
            "                                \"given input_values has 0 elements\"));",
            "    // Operation will treat first argument in input_splits as if it were zero",
            "    // regardless of its actual value since splits should begin with zero and",
            "    // end with the length of the input values vector.",
            "    OP_REQUIRES("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-w74j-v8xh-3w5h",
    "API Signature": null,
    "Score": 0.025179856115107913,
    "Anomaly": "Empty list argument",
    "Anomaly Description": "An empty list argument in Python refers to a list parameter or value that contains no elements. It is a list object passed as an argument to a function, method, or operation, but it does not have any items or content.",
    "Category": "List",
    "Argument": "input_splits=[],"
},
{
    "Title": "\n        Reference binding to nullptr in `RaggedTensorToVariant`\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in  tf.raw_ops.RaggedTensorToVariant :",
    "Sample Code": "tf.raw_ops.RaggedTensorToVariant(\n  rt_nested_splits=[],\n  rt_dense_values=[1,2,3],\n  ],\n  batched_input=True)",
    "Code change": [
        "@@ -157,6 +157,12 @@ class RaggedTensorToVariantOp : public OpKernel {\n       return;\n     }\n \n+    // Checked here instead of at input in case batched_input_ is false\n+    OP_REQUIRES(context, ragged_nested_splits_len > 0,\n+                errors::InvalidArgument(\n+                    \"rt_nested_splits must be a list of one or more, but \"\n+                    \"received rt_nested_splits of length 0.\"));\n+\n     // Unbatch the Ragged Tensor and encode the components.\n     std::vector<RaggedTensorVariant> unbatched_ragged_input;\n     auto batched_splits_top_vec =\n"
    ],
    "Buggy Code": [
        [
            "    }",
            "",
            "    // Unbatch the Ragged Tensor and encode the components.",
            "    std::vector<RaggedTensorVariant> unbatched_ragged_input;",
            "    auto batched_splits_top_vec =",
            "        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();",
            "    int num_components = batched_splits_top_vec.size() - 1;",
            "    OP_REQUIRES(context, num_components >= 0,",
            "                errors::Internal(\"Invalid split argument.\"));",
            "    OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(",
            "                                batched_ragged_input, &unbatched_ragged_input));",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    }",
            "",
            "    // Checked here instead of at input in case batched_input_ is false",
            "    OP_REQUIRES(context, ragged_nested_splits_len > 0,",
            "                errors::InvalidArgument(",
            "                    \"rt_nested_splits must be a list of one or more, but \"",
            "                    \"received rt_nested_splits of length 0.\"));",
            "",
            "    // Unbatch the Ragged Tensor and encode the components.",
            "    std::vector<RaggedTensorVariant> unbatched_ragged_input;",
            "    auto batched_splits_top_vec =",
            "        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-w4xf-2pqw-5mq7",
    "API Signature": "tf.raw_ops.RaggedTensorToVariant(\n    rt_nested_splits, rt_dense_values, batched_input, name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Empty list argument",
    "Anomaly Description": "An empty list argument in Python refers to a list parameter or value that contains no elements. It is a list object passed as an argument to a function, method, or operation, but it does not have any items or content.",
    "Category": "List",
    "Argument": "rt_nested_splits=[],"
},
{
    "Title": "\n        Incomplete validation in MKL requantization\n      ",
    "Bug description": "Due to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "from tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  [],\n  out_type=tf.int)",
    "Code change": [
        "@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n"
    ],
    "Buggy Code": [
        [
            "        errors::InvalidArgument(\"input_max has incorrect size, expected \",",
            "                                depth, \" was \", input_max.dim_size(0)));",
            "",
            "    const float* input_min_data = input_min.flat<float>().data();",
            "    const float* input_max_data = input_max.flat<float>().data();",
            "    std::vector<float> ranges(depth);",
            "    bool is_non_negative = true;",
            "    Eigen::array<int, 2> shuffling({1, 0});",
            "    auto input_matrix = input.flat_inner_dims<qint32>();",
            "",
            "    // TODO: verify performance of not transposing and finding the min max",
            "    // directly from input_matrix vs the one presented below of transposing and",
            "    // using the transposed matrix as the transposing operation in itself might",
            "    // be more costly.",
            "    // Note that this operation is a calibration step for quantization and will",
            "    // cease to exist in the final inference graph(will exist as a const node).",
            "    auto transposed_input = input_matrix.shuffle(shuffling);",
            "",
            "    // Find the ranges of each channel in parallel.",
            "    float out_min_max = std::numeric_limits<float>::min();"
        ]
    ],
    "Clean Code": [
        [
            "        errors::InvalidArgument(\"input_max has incorrect size, expected \",",
            "                                depth, \" was \", input_max.dim_size(0)));",
            "    OP_REQUIRES(",
            "        ctx, input_min.NumElements() == depth,",
            "        errors::InvalidArgument(\"input_min must have the same number of \"",
            "                                \"elements as input_max, got \",",
            "                                input_min.NumElements(), \" and \", depth));",
            "    OP_REQUIRES(ctx, input.NumElements() > 0,",
            "                errors::InvalidArgument(\"input must not be empty\"));",
            "    OP_REQUIRES(ctx, input.dims() == 4,",
            "                errors::InvalidArgument(\"input must be in NHWC format\"));",
            "    OP_REQUIRES(",
            "        ctx, input.dim_size(3) == depth,",
            "        errors::InvalidArgument(",
            "            \"input must have same number of channels as length of input_min: \",",
            "            input.dim_size(3), \" vs \", depth));",
            "",
            "    const float* input_min_data = input_min.flat<float>().data();",
            "    const float* input_max_data = input_max.flat<float>().data();",
            "    std::vector<float> ranges(depth);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v82p-hv3v-p6qp",
    "API Signature": "tf.raw_ops.RequantizationRangePerChannel(\n    input, input_min, input_max, clip_value_max, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "input=[],"
},
{
    "Title": "\n        Incomplete validation in MKL requantization\n      ",
    "Bug description": "Due to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "from tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  [],\n  out_type=tf.int)",
    "Code change": [
        "@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n"
    ],
    "Buggy Code": [
        [
            "        errors::InvalidArgument(\"input_max has incorrect size, expected \",",
            "                                depth, \" was \", input_max.dim_size(0)));",
            "",
            "    const float* input_min_data = input_min.flat<float>().data();",
            "    const float* input_max_data = input_max.flat<float>().data();",
            "    std::vector<float> ranges(depth);",
            "    bool is_non_negative = true;",
            "    Eigen::array<int, 2> shuffling({1, 0});",
            "    auto input_matrix = input.flat_inner_dims<qint32>();",
            "",
            "    // TODO: verify performance of not transposing and finding the min max",
            "    // directly from input_matrix vs the one presented below of transposing and",
            "    // using the transposed matrix as the transposing operation in itself might",
            "    // be more costly.",
            "    // Note that this operation is a calibration step for quantization and will",
            "    // cease to exist in the final inference graph(will exist as a const node).",
            "    auto transposed_input = input_matrix.shuffle(shuffling);",
            "",
            "    // Find the ranges of each channel in parallel.",
            "    float out_min_max = std::numeric_limits<float>::min();"
        ]
    ],
    "Clean Code": [
        [
            "        errors::InvalidArgument(\"input_max has incorrect size, expected \",",
            "                                depth, \" was \", input_max.dim_size(0)));",
            "    OP_REQUIRES(",
            "        ctx, input_min.NumElements() == depth,",
            "        errors::InvalidArgument(\"input_min must have the same number of \"",
            "                                \"elements as input_max, got \",",
            "                                input_min.NumElements(), \" and \", depth));",
            "    OP_REQUIRES(ctx, input.NumElements() > 0,",
            "                errors::InvalidArgument(\"input must not be empty\"));",
            "    OP_REQUIRES(ctx, input.dims() == 4,",
            "                errors::InvalidArgument(\"input must be in NHWC format\"));",
            "    OP_REQUIRES(",
            "        ctx, input.dim_size(3) == depth,",
            "        errors::InvalidArgument(",
            "            \"input must have same number of channels as length of input_min: \",",
            "            input.dim_size(3), \" vs \", depth));",
            "",
            "    const float* input_min_data = input_min.flat<float>().data();",
            "    const float* input_max_data = input_max.flat<float>().data();",
            "    std::vector<float> ranges(depth);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v82p-hv3v-p6qp",
    "API Signature": "tf.raw_ops.RequantizationRangePerChannel(\n    input, input_min, input_max, clip_value_max, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "List",
    "Argument": "input_min=[-100,-100,-100,-100,-100],\ninput_max=[-100,-100,-100],"
},
{
    "Title": "\n        Incomplete validation in MKL requantization\n      ",
    "Bug description": "Due to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "from tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  [],\n  out_type=tf.int)",
    "Code change": [
        "@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n"
    ],
    "Buggy Code": [
        [
            "        errors::InvalidArgument(\"input_max has incorrect size, expected \",",
            "                                depth, \" was \", input_max.dim_size(0)));",
            "",
            "    const float* input_min_data = input_min.flat<float>().data();",
            "    const float* input_max_data = input_max.flat<float>().data();",
            "    std::vector<float> ranges(depth);",
            "    bool is_non_negative = true;",
            "    Eigen::array<int, 2> shuffling({1, 0});",
            "    auto input_matrix = input.flat_inner_dims<qint32>();",
            "",
            "    // TODO: verify performance of not transposing and finding the min max",
            "    // directly from input_matrix vs the one presented below of transposing and",
            "    // using the transposed matrix as the transposing operation in itself might",
            "    // be more costly.",
            "    // Note that this operation is a calibration step for quantization and will",
            "    // cease to exist in the final inference graph(will exist as a const node).",
            "    auto transposed_input = input_matrix.shuffle(shuffling);",
            "",
            "    // Find the ranges of each channel in parallel.",
            "    float out_min_max = std::numeric_limits<float>::min();"
        ]
    ],
    "Clean Code": [
        [
            "        errors::InvalidArgument(\"input_max has incorrect size, expected \",",
            "                                depth, \" was \", input_max.dim_size(0)));",
            "    OP_REQUIRES(",
            "        ctx, input_min.NumElements() == depth,",
            "        errors::InvalidArgument(\"input_min must have the same number of \"",
            "                                \"elements as input_max, got \",",
            "                                input_min.NumElements(), \" and \", depth));",
            "    OP_REQUIRES(ctx, input.NumElements() > 0,",
            "                errors::InvalidArgument(\"input must not be empty\"));",
            "    OP_REQUIRES(ctx, input.dims() == 4,",
            "                errors::InvalidArgument(\"input must be in NHWC format\"));",
            "    OP_REQUIRES(",
            "        ctx, input.dim_size(3) == depth,",
            "        errors::InvalidArgument(",
            "            \"input must have same number of channels as length of input_min: \",",
            "            input.dim_size(3), \" vs \", depth));",
            "",
            "    const float* input_min_data = input_min.flat<float>().data();",
            "    const float* input_max_data = input_max.flat<float>().data();",
            "    std::vector<float> ranges(depth);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v82p-hv3v-p6qp",
    "API Signature": "tf.raw_ops.RequantizationRangePerChannel(\n    input, input_min, input_max, clip_value_max, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "input=[],\ninput_min=[-100,-100,-100,-100,-100],"
},
{
    "Title": "\n        Incomplete validation in MKL requantization\n      ",
    "Bug description": "Due to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "from tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  [],\n  out_type=tf.int)",
    "Code change": [
        "@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n"
    ],
    "Buggy Code": [
        [
            "        errors::InvalidArgument(\"input_max has incorrect size, expected \",",
            "                                depth, \" was \", input_max.dim_size(0)));",
            "",
            "    const float* input_min_data = input_min.flat<float>().data();",
            "    const float* input_max_data = input_max.flat<float>().data();",
            "    std::vector<float> ranges(depth);",
            "    bool is_non_negative = true;",
            "    Eigen::array<int, 2> shuffling({1, 0});",
            "    auto input_matrix = input.flat_inner_dims<qint32>();",
            "",
            "    // TODO: verify performance of not transposing and finding the min max",
            "    // directly from input_matrix vs the one presented below of transposing and",
            "    // using the transposed matrix as the transposing operation in itself might",
            "    // be more costly.",
            "    // Note that this operation is a calibration step for quantization and will",
            "    // cease to exist in the final inference graph(will exist as a const node).",
            "    auto transposed_input = input_matrix.shuffle(shuffling);",
            "",
            "    // Find the ranges of each channel in parallel.",
            "    float out_min_max = std::numeric_limits<float>::min();"
        ]
    ],
    "Clean Code": [
        [
            "        errors::InvalidArgument(\"input_max has incorrect size, expected \",",
            "                                depth, \" was \", input_max.dim_size(0)));",
            "    OP_REQUIRES(",
            "        ctx, input_min.NumElements() == depth,",
            "        errors::InvalidArgument(\"input_min must have the same number of \"",
            "                                \"elements as input_max, got \",",
            "                                input_min.NumElements(), \" and \", depth));",
            "    OP_REQUIRES(ctx, input.NumElements() > 0,",
            "                errors::InvalidArgument(\"input must not be empty\"));",
            "    OP_REQUIRES(ctx, input.dims() == 4,",
            "                errors::InvalidArgument(\"input must be in NHWC format\"));",
            "    OP_REQUIRES(",
            "        ctx, input.dim_size(3) == depth,",
            "        errors::InvalidArgument(",
            "            \"input must have same number of channels as length of input_min: \",",
            "            input.dim_size(3), \" vs \", depth));",
            "",
            "    const float* input_min_data = input_min.flat<float>().data();",
            "    const float* input_max_data = input_max.flat<float>().data();",
            "    std::vector<float> ranges(depth);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v82p-hv3v-p6qp",
    "API Signature": null,
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "List",
    "Argument": "input_min=[-100,-100,-100,-100,-100],\ninput_max=[-100,-100,-100],"
},
{
    "Title": "\n        Incomplete validation in MKL requantization\n      ",
    "Bug description": "Due to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "from tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  [],\n  out_type=tf.int)",
    "Code change": [
        "@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n"
    ],
    "Buggy Code": [
        [
            "        errors::InvalidArgument(\"input_max has incorrect size, expected \",",
            "                                depth, \" was \", input_max.dim_size(0)));",
            "",
            "    const float* input_min_data = input_min.flat<float>().data();",
            "    const float* input_max_data = input_max.flat<float>().data();",
            "    std::vector<float> ranges(depth);",
            "    bool is_non_negative = true;",
            "    Eigen::array<int, 2> shuffling({1, 0});",
            "    auto input_matrix = input.flat_inner_dims<qint32>();",
            "",
            "    // TODO: verify performance of not transposing and finding the min max",
            "    // directly from input_matrix vs the one presented below of transposing and",
            "    // using the transposed matrix as the transposing operation in itself might",
            "    // be more costly.",
            "    // Note that this operation is a calibration step for quantization and will",
            "    // cease to exist in the final inference graph(will exist as a const node).",
            "    auto transposed_input = input_matrix.shuffle(shuffling);",
            "",
            "    // Find the ranges of each channel in parallel.",
            "    float out_min_max = std::numeric_limits<float>::min();"
        ]
    ],
    "Clean Code": [
        [
            "        errors::InvalidArgument(\"input_max has incorrect size, expected \",",
            "                                depth, \" was \", input_max.dim_size(0)));",
            "    OP_REQUIRES(",
            "        ctx, input_min.NumElements() == depth,",
            "        errors::InvalidArgument(\"input_min must have the same number of \"",
            "                                \"elements as input_max, got \",",
            "                                input_min.NumElements(), \" and \", depth));",
            "    OP_REQUIRES(ctx, input.NumElements() > 0,",
            "                errors::InvalidArgument(\"input must not be empty\"));",
            "    OP_REQUIRES(ctx, input.dims() == 4,",
            "                errors::InvalidArgument(\"input must be in NHWC format\"));",
            "    OP_REQUIRES(",
            "        ctx, input.dim_size(3) == depth,",
            "        errors::InvalidArgument(",
            "            \"input must have same number of channels as length of input_min: \",",
            "            input.dim_size(3), \" vs \", depth));",
            "",
            "    const float* input_min_data = input_min.flat<float>().data();",
            "    const float* input_max_data = input_max.flat<float>().data();",
            "    std::vector<float> ranges(depth);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v82p-hv3v-p6qp",
    "API Signature": null,
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "input=[],"
},
{
    "Title": "\n        Incomplete validation in `QuantizeV2`\n      ",
    "Bug description": "Due to incomplete validation in  tf.raw_ops.QuantizeV2 , an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:",
    "Sample Code": "tf.raw_ops.QuantizeV2(\n  input=[1,2,3],\n  min_range=[1,2],\n  max_range=[],\n  T=tf.qint32,\n  mode='SCALED',\n  round_mode='HALF_AWAY_FROM_ZERO',\n  narrow_range=False,\n  axis=1,\n  ,\n  ensure_minimum_range=3)",
    "Code change": [
        "@@ -113,7 +113,50 @@ class QuantizeV2Op : public OpKernel {\n \n     int num_slices = 1;\n     if (axis_ > -1) {\n+      OP_REQUIRES(\n+          ctx, input.dims() > axis_,\n+          errors::InvalidArgument(\n+              \"Axis is on a zero-based index, so its value must always be less \"\n+              \"than number of input's dims, but given axis value was \",\n+              axis_, \" and input's dims was \", input.dims()));\n       num_slices = input.dim_size(axis_);\n+      OP_REQUIRES(ctx, input_min_range.dims() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but min_range dims are \",\n+                      input_min_range.dims()));\n+      OP_REQUIRES(ctx, input_min_range.dim_size(0) == num_slices,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but min_range is a 1-D tensor of size \",\n+                      input_min_range.dim_size(0),\n+                      \" and input's axis dimension is of size \", num_slices));\n+      OP_REQUIRES(ctx, input_max_range.dims() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but max_range dims are \",\n+                      input_max_range.dims()));\n+      OP_REQUIRES(ctx, input_max_range.dim_size(0) == num_slices,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but max_range is a 1-D tensor of size \",\n+                      input_max_range.dim_size(0),\n+                      \" and input's axis dimension is of size \", num_slices));\n+    } else {\n+      OP_REQUIRES(ctx, input_min_range.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is not specified, min_range must contain a \"\n+                      \"single float element, but it contains \",\n+                      input_min_range.NumElements(), \" elements\"));\n+      OP_REQUIRES(ctx, input_max_range.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is not specified, max_range must contain a \"\n+                      \"single float element, but it contains \",\n+                      input_max_range.NumElements(), \" elements\"));\n     }\n \n     const TensorShape& minmax_shape = ctx->input(1).shape();\n"
    ],
    "Buggy Code": [
        [
            "    int num_slices = 1;",
            "    if (axis_ > -1) {",
            "      num_slices = input.dim_size(axis_);",
            "    }",
            "",
            "    const TensorShape& minmax_shape = ctx->input(1).shape();",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
            "",
            "    Tensor* output_min_tensor = nullptr;",
            "    Tensor* output_max_tensor = nullptr;",
            "",
            "    if (num_slices == 1) {",
            "      OP_REQUIRES_OK(ctx, ctx->allocate_output(1, {}, &output_min_tensor));",
            "      OP_REQUIRES_OK(ctx, ctx->allocate_output(2, {}, &output_max_tensor));",
            "      const float min_range = input_min_range.template flat<float>()(0);",
            "      const float max_range = input_max_range.template flat<float>()(0);",
            "      QuantizeTensor(ctx, input, min_range, max_range, output,",
            "                     output_min_tensor, output_max_tensor);",
            "      return;",
            "    }",
            "",
            "    OP_REQUIRES(ctx, mode_ != QUANTIZE_MODE_MIN_FIRST,",
            "                errors::Unimplemented(\"MIN_FIRST mode is not implemented for \"",
            "                                      \"Quantize with axis != -1.\"));",
            "    OP_REQUIRES_OK(ctx,",
            "                   ctx->allocate_output(1, minmax_shape, &output_min_tensor));",
            "    OP_REQUIRES_OK(ctx,",
            "                   ctx->allocate_output(2, minmax_shape, &output_max_tensor));",
            "",
            "    auto input_tensor =",
            "        input.template flat_inner_outer_dims<float, 3>(axis_ - 1);",
            "    int64_t pre_dim = 1, post_dim = 1;",
            "    for (int i = 0; i < axis_; ++i) {",
            "      pre_dim *= output->dim_size(i);",
            "    }",
            "    for (int i = axis_ + 1; i < output->dims(); ++i) {",
            "      post_dim *= output->dim_size(i);",
            "    }",
            "    auto output_tensor = output->template bit_casted_shaped<T, 3>(",
            "        {pre_dim, num_slices, post_dim});",
            "    auto min_ranges = input_min_range.template vec<float>();",
            "    auto max_ranges = input_max_range.template vec<float>();",
            "    for (int i = 0; i < num_slices; ++i) {",
            "      QuantizeSlice(ctx->eigen_device<Device>(), ctx,",
            "                    input_tensor.template chip<1>(i), min_ranges(i),",
            "                    max_ranges(i), output_tensor.template chip<1>(i),",
            "                    &output_min_tensor->flat<float>()(i),",
            "                    &output_max_tensor->flat<float>()(i));",
            "    }"
        ]
    ],
    "Clean Code": [
        [
            "    int num_slices = 1;",
            "    if (axis_ > -1) {",
            "      OP_REQUIRES(",
            "          ctx, input.dims() > axis_,",
            "          errors::InvalidArgument(",
            "              \"Axis is on a zero-based index, so its value must always be less \"",
            "              \"than number of input's dims, but given axis value was \",",
            "              axis_, \" and input's dims was \", input.dims()));",
            "      num_slices = input.dim_size(axis_);",
            "      OP_REQUIRES(ctx, input_min_range.dims() == 1,",
            "                  errors::InvalidArgument(",
            "                      \"If axis is specified, min_range must be a 1-D tensor \"",
            "                      \"whose size matches the axis dimension of the input and \"",
            "                      \"output tensors, but min_range dims are \",",
            "                      input_min_range.dims()));",
            "      OP_REQUIRES(ctx, input_min_range.dim_size(0) == num_slices,",
            "                  errors::InvalidArgument(",
            "                      \"If axis is specified, min_range must be a 1-D tensor \"",
            "                      \"whose size matches the axis dimension of the input and \"",
            "                      \"output tensors, but min_range is a 1-D tensor of size \",",
            "                      input_min_range.dim_size(0),",
            "                      \" and input's axis dimension is of size \", num_slices));",
            "      OP_REQUIRES(ctx, input_max_range.dims() == 1,",
            "                  errors::InvalidArgument(",
            "                      \"If axis is specified, max_range must be a 1-D tensor \"",
            "                      \"whose size matches the axis dimension of the input and \"",
            "                      \"output tensors, but max_range dims are \",",
            "                      input_max_range.dims()));",
            "      OP_REQUIRES(ctx, input_max_range.dim_size(0) == num_slices,",
            "                  errors::InvalidArgument(",
            "                      \"If axis is specified, max_range must be a 1-D tensor \"",
            "                      \"whose size matches the axis dimension of the input and \"",
            "                      \"output tensors, but max_range is a 1-D tensor of size \",",
            "                      input_max_range.dim_size(0),",
            "                      \" and input's axis dimension is of size \", num_slices));",
            "    } else {",
            "      OP_REQUIRES(ctx, input_min_range.NumElements() == 1,",
            "                  errors::InvalidArgument(",
            "                      \"If axis is not specified, min_range must contain a \"",
            "                      \"single float element, but it contains \",",
            "                      input_min_range.NumElements(), \" elements\"));",
            "      OP_REQUIRES(ctx, input_max_range.NumElements() == 1,",
            "                  errors::InvalidArgument(",
            "                      \"If axis is not specified, max_range must contain a \"",
            "                      \"single float element, but it contains \",",
            "                      input_max_range.NumElements(), \" elements\"));",
            "    }",
            "",
            "    const TensorShape& minmax_shape = ctx->input(1).shape();",
            "    Tensor* output = nullptr;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-g25h-jr74-qp5j",
    "API Signature": "tf.raw_ops.QuantizeV2(\n    input,\n    min_range,\n    max_range,\n    T,\n    mode='MIN_COMBINED',\n    round_mode='HALF_AWAY_FROM_ZERO',\n    narrow_range=False,\n    axis=-1,\n    ensure_minimum_range=0.01,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "List",
    "Argument": "min_range=[1,2], \nmax_range=[],"
},
{
    "Title": "\n        Heap OOB in boosted trees\n      ",
    "Bug description": "An attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to  BoostedTreesSparseCalculateBestFeatureSplit :",
    "Sample Code": "tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit(\n  node_id_range=[0,10],\n  stats_summary_indices=[[1, 2, 3, 0x1000000]],\n  stats_summary_values=[1.0],\n  stats_summary_shape=[1,1,1,1],\n  l1=l2=[1.0],\n  tree_complexity=[0.5],\n  min_node_weight=[1.0],\n  logits_dimension=3,\n  ,\n  split_type='inequality')                                                                                                                                                                                                                                                                ",
    "Code change": [
        "@@ -1050,6 +1050,13 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\n       const int32_t feature_dim = stats_summary_indices(idx, 1);\n       const int32_t bucket_id = stats_summary_indices(idx, 2);\n       const int32_t stat_dim = stats_summary_indices(idx, 3);\n+      OP_REQUIRES(context, stat_dim < stats_dims,\n+                  errors::InvalidArgument(\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\n+                      \"stats_summary_indices, cannot be greater than stats \"\n+                      \"dims, the last value in stats_summary_shape, which was \",\n+                      stats_dims, \". At index (\", idx,\n+                      \", 4), stats_summary_indices contains value \", stat_dim));\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\n       auto& b_map = f_insert_result.first->second;\n"
    ],
    "Buggy Code": [
        [
            "      const int32_t bucket_id = stats_summary_indices(idx, 2);",
            "      const int32_t stat_dim = stats_summary_indices(idx, 3);",
            "      std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(",
            "          FeatureMapIterator::value_type(feature_dim, BucketMap()));",
            "      auto& b_map = f_insert_result.first->second;",
            "      std::pair<BucketMapIterator, bool> const& b_insert_result =",
            "          b_map.insert(BucketMapIterator::value_type(",
            "              bucket_id, std::vector<float>(stats_dims)));",
            "      auto& stats = b_insert_result.first->second;",
            "      stats[stat_dim] = stats_summary_values(idx);",
            "    }  // for node_id",
            "    // process the last node id",
            "    process_node(f_map, &output_node_ids, &output_gains,"
        ]
    ],
    "Clean Code": [
        [
            "      const int32_t bucket_id = stats_summary_indices(idx, 2);",
            "      const int32_t stat_dim = stats_summary_indices(idx, 3);",
            "      OP_REQUIRES(context, stat_dim < stats_dims,",
            "                  errors::InvalidArgument(",
            "                      \"Stat dim, the sum of logits dim and hessian dim in \"",
            "                      \"stats_summary_indices, cannot be greater than stats \"",
            "                      \"dims, the last value in stats_summary_shape, which was \",",
            "                      stats_dims, \". At index (\", idx,",
            "                      \", 4), stats_summary_indices contains value \", stat_dim));",
            "      std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(",
            "          FeatureMapIterator::value_type(feature_dim, BucketMap()));",
            "      auto& b_map = f_insert_result.first->second;",
            "      std::pair<BucketMapIterator, bool> const& b_insert_result ="
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-r4c4-5fpq-56wg",
    "API Signature": "tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit(\n    node_id_range,\n    stats_summary_indices,\n    stats_summary_values,\n    stats_summary_shape,\n    l1,\n    l2,\n    tree_complexity,\n    min_node_weight,\n    logits_dimension,\n    split_type='inequality',\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "List",
    "Argument": "stats_summary_indices=[[1, 2, 3, 0x1000000]],\nstats_summary_values=[1.0],\nstats_summary_shape=[1,1,1,1],"
},
{
    "Title": "\n        Crash caused by integer conversion to unsigned\n      ",
    "Bug description": "An attacker can cause a denial of service in  boosted_trees_create_quantile_stream_resource  by using negative arguments:",
    "Sample Code": "from tensorflow.python.ops import gen_boosted_trees_ops\nimport numpy as np\n\nv= tf.Variable([0.0, 0.0, 0.0, 0.0, 0.0])\ngen_boosted_trees_ops.boosted_trees_create_quantile_stream_resource(\n  quantile_stream_resource_handle = v.handle,\n  epsilon = [74.82224],\n  num_streams = [-49], \n  ], \n  max_elements = np.int32(586))",
    "Code change": [
        "@@ -116,6 +116,9 @@ class BoostedTreesCreateQuantileStreamResourceOp : public OpKernel {\n     const Tensor* num_streams_t;\n     OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\n     int64_t num_streams = num_streams_t->scalar<int64>()();\n+    OP_REQUIRES(context, num_streams >= 0,\n+                errors::InvalidArgument(\n+                    \"Num_streams input cannot be a negative integer\"));\n \n     auto result =\n         new QuantileStreamResource(epsilon, max_elements_, num_streams);\n"
    ],
    "Buggy Code": [
        [
            "    OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));",
            "    int64_t num_streams = num_streams_t->scalar<int64>()();",
            "",
            "    auto result =",
            "        new QuantileStreamResource(epsilon, max_elements_, num_streams);",
            "    auto status = CreateResource(context, HandleFromInput(context, 0), result);",
            "    if (!status.ok() && status.code() != tensorflow::error::ALREADY_EXISTS) {",
            "      OP_REQUIRES(context, false, status);",
            "    }"
        ]
    ],
    "Clean Code": [
        [
            "    OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));",
            "    int64_t num_streams = num_streams_t->scalar<int64>()();",
            "    OP_REQUIRES(context, num_streams >= 0,",
            "                errors::InvalidArgument(",
            "                    \"Num_streams input cannot be a negative integer\"));",
            "",
            "    auto result =",
            "        new QuantileStreamResource(epsilon, max_elements_, num_streams);",
            "    auto status = CreateResource(context, HandleFromInput(context, 0), result);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gf88-j2mg-cc82",
    "API Signature": null,
    "Score": 0.02877697841726619,
    "Anomaly": "Negative integer list element",
    "Anomaly Description": "A negative integer list element in Python refers to an element within a list that has a negative integer value. It means that the element is a negative number represented by an integer data type.",
    "Category": "List",
    "Argument": "num_streams = [-49],"
},
{
    "Title": "\n        Division by 0 in inplace operations\n      ",
    "Bug description": "An attacker can cause a floating point exception by calling inplace operations with crafted arguments that would result in a division by 0:",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.InplaceSub(x=[],i=[-99,-1,-1],v=[1,1,1])",
    "Code change": [
        "@@ -225,7 +225,7 @@ class InplaceOpBase : public OpKernel {\n \n     Tensor y = x;  // This creates an alias intentionally.\n     // Skip processing if tensors are empty.\n-    if (x.NumElements() > 0 || v.NumElements() > 0) {\n+    if (x.NumElements() > 0 && v.NumElements() > 0) {\n       OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));\n     }\n     ctx->set_output(0, y);\n"
    ],
    "Buggy Code": [
        [
            "    Tensor y = x;  // This creates an alias intentionally.",
            "    // Skip processing if tensors are empty.",
            "    if (x.NumElements() > 0 || v.NumElements() > 0) {",
            "      OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));",
            "    }",
            "    ctx->set_output(0, y);",
            "  }"
        ]
    ],
    "Clean Code": [
        [
            "    Tensor y = x;  // This creates an alias intentionally.",
            "    // Skip processing if tensors are empty.",
            "    if (x.NumElements() > 0 && v.NumElements() > 0) {",
            "      OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));",
            "    }",
            "    ctx->set_output(0, y);",
            "  }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cm5x-837x-jf3c",
    "API Signature": "tf.raw_ops.InplaceSub(\n    x, i, v, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "x=[]"
},
{
    "Title": "\n        Reference binding to nullptr and heap OOB in binary cwise ops\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in all binary cwise operations that don't require broadcasting (e.g., gradients of binary cwise operations):",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.SqrtGrad(y=[4, 16],dy=[])",
    "Code change": [
        "@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& in0 = ctx->input(0);\n     const Tensor& in1 = ctx->input(1);\n+    OP_REQUIRES(\n+        ctx, in0.NumElements() == in1.NumElements(),\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\n+                                \"same number of elements, got \",\n+                                in0.NumElements(), \" and \", in1.NumElements()));\n     auto in0_flat = in0.flat<Tin>();\n     auto in1_flat = in1.flat<Tin>();\n     const Device& eigen_device = ctx->eigen_device<Device>();\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor& in0 = ctx->input(0);",
            "    const Tensor& in1 = ctx->input(1);",
            "    auto in0_flat = in0.flat<Tin>();",
            "    auto in1_flat = in1.flat<Tin>();",
            "    const Device& eigen_device = ctx->eigen_device<Device>();",
            "",
            "    Tensor* out = nullptr;",
            "    if (std::is_same<Tin, Tout>::value) {",
            "      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(",
            "                              {0, 1}, 0, in0.shape(), &out));",
            "    } else {"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor& in0 = ctx->input(0);",
            "    const Tensor& in1 = ctx->input(1);",
            "    OP_REQUIRES(",
            "        ctx, in0.NumElements() == in1.NumElements(),",
            "        errors::InvalidArgument(\"The two arguments to a cwise op must have \"",
            "                                \"same number of elements, got \",",
            "                                in0.NumElements(), \" and \", in1.NumElements()));",
            "    auto in0_flat = in0.flat<Tin>();",
            "    auto in1_flat = in1.flat<Tin>();",
            "    const Device& eigen_device = ctx->eigen_device<Device>();",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-q3g3-h9r4-prrc",
    "API Signature": "tf.raw_ops.SqrtGrad(\n    y, dy, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "List",
    "Argument": "y=[4, 16] \ndy=[]"
},
{
    "Title": "\n        Reference binding to nullptr in `MatrixSetDiagV*` ops\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in all operations of type  tf.raw_ops.MatrixSetDiagV* :",
    "Sample Code": "tf.raw_ops.MatrixSetDiagV3(\n  input=[1,2,3],\n  diagonal=[1,1],\n  k=[],\n  [],\n  align='RIGHT_LEFT')",
    "Code change": [
        "@@ -70,6 +70,9 @@ class MatrixSetDiagOp : public OpKernel {\n                   errors::InvalidArgument(\n                       \"diag_index must be a scalar or vector, received shape: \",\n                       diag_index.shape().DebugString()));\n+      OP_REQUIRES(\n+          context, diag_index.NumElements() > 0,\n+          errors::InvalidArgument(\"diag_index must have at least one element\"));\n       lower_diag_index = diag_index.flat<int32>()(0);\n       upper_diag_index = lower_diag_index;\n       if (TensorShapeUtils::IsVector(diag_index.shape())) {\n"
    ],
    "Buggy Code": [
        [
            "                      \"diag_index must be a scalar or vector, received shape: \",",
            "                      diag_index.shape().DebugString()));",
            "      lower_diag_index = diag_index.flat<int32>()(0);",
            "      upper_diag_index = lower_diag_index;",
            "      if (TensorShapeUtils::IsVector(diag_index.shape())) {",
            "        auto diag_index_size = diag_index.dim_size(0);",
            "        OP_REQUIRES(",
            "            context, 0 < diag_index_size && diag_index_size <= 2,",
            "            errors::InvalidArgument("
        ]
    ],
    "Clean Code": [
        [
            "                      \"diag_index must be a scalar or vector, received shape: \",",
            "                      diag_index.shape().DebugString()));",
            "      OP_REQUIRES(",
            "          context, diag_index.NumElements() > 0,",
            "          errors::InvalidArgument(\"diag_index must have at least one element\"));",
            "      lower_diag_index = diag_index.flat<int32>()(0);",
            "      upper_diag_index = lower_diag_index;",
            "      if (TensorShapeUtils::IsVector(diag_index.shape())) {",
            "        auto diag_index_size = diag_index.dim_size(0);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6p5r-g9mq-ggh2",
    "API Signature": "tf.raw_ops.MatrixSetDiagV3(\n    input, diagonal, k, align='RIGHT_LEFT', name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "k=[],"
},
{
    "Title": "\n        Reference binding to nullptr in `MatrixDiagV*` ops\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in all operations of type  tf.raw_ops.MatrixDiagV* :",
    "Sample Code": "tf.raw_ops.MatrixDiagV3(\n  diagonal=[1,0],\n  k=[],\n  num_rows=[1,2,3],\n  num_cols=[4,5],\n  padding_value=[],\n  [],\n  align='RIGHT_RIGHT')",
    "Code change": [
        "@@ -73,6 +73,9 @@ class MatrixDiagPartOp : public OpKernel {\n                   errors::InvalidArgument(\n                       \"diag_index must be a scalar or vector, received shape: \",\n                       diag_index.shape().DebugString()));\n+      OP_REQUIRES(context, diag_index.NumElements() > 0,\n+                  errors::InvalidArgument(\n+                      \"Expected diag_index to have at least 1 element\"));\n       lower_diag_index = diag_index.flat<int32>()(0);\n       upper_diag_index = lower_diag_index;\n       if (TensorShapeUtils::IsVector(diag_index.shape())) {\n@@ -179,6 +182,9 @@ class MatrixDiagOp : public OpKernel {\n                   errors::InvalidArgument(\n                       \"diag_index must be a scalar or vector, received shape: \",\n                       diag_index.shape().DebugString()));\n+      OP_REQUIRES(context, diag_index.NumElements() > 0,\n+                  errors::InvalidArgument(\n+                      \"Expected diag_index to have at least 1 element\"));\n       lower_diag_index = diag_index.flat<int32>()(0);\n       upper_diag_index = lower_diag_index;\n       if (TensorShapeUtils::IsVector(diag_index.shape())) {\n"
    ],
    "Buggy Code": [
        [
            "                      \"diag_index must be a scalar or vector, received shape: \",",
            "                      diag_index.shape().DebugString()));",
            "      lower_diag_index = diag_index.flat<int32>()(0);",
            "      upper_diag_index = lower_diag_index;",
            "      if (TensorShapeUtils::IsVector(diag_index.shape())) {",
            "        auto diag_index_size = diag_index.dim_size(0);",
            "        OP_REQUIRES(",
            "            context, 0 < diag_index_size && diag_index_size <= 2,",
            "            errors::InvalidArgument("
        ],
        [
            "      upper_diag_index = lower_diag_index;",
            "      if (TensorShapeUtils::IsVector(diag_index.shape())) {",
            "        auto diag_index_size = diag_index.dim_size(0);",
            "        OP_REQUIRES(",
            "            context, 0 < diag_index_size && diag_index_size <= 2,",
            "            errors::InvalidArgument(",
            "                \"diag_index must have only one or two elements, received \",",
            "                diag_index_size, \" elements.\"));",
            "        if (diag_index_size > 1) {"
        ]
    ],
    "Clean Code": [
        [
            "                      \"diag_index must be a scalar or vector, received shape: \",",
            "                      diag_index.shape().DebugString()));",
            "      OP_REQUIRES(context, diag_index.NumElements() > 0,",
            "                  errors::InvalidArgument(",
            "                      \"Expected diag_index to have at least 1 element\"));",
            "      lower_diag_index = diag_index.flat<int32>()(0);",
            "      upper_diag_index = lower_diag_index;",
            "      if (TensorShapeUtils::IsVector(diag_index.shape())) {",
            "        auto diag_index_size = diag_index.dim_size(0);"
        ],
        [
            "                      \"diag_index must be a scalar or vector, received shape: \",",
            "                      diag_index.shape().DebugString()));",
            "      OP_REQUIRES(context, diag_index.NumElements() > 0,",
            "                  errors::InvalidArgument(",
            "                      \"Expected diag_index to have at least 1 element\"));",
            "      lower_diag_index = diag_index.flat<int32>()(0);",
            "      upper_diag_index = lower_diag_index;",
            "      if (TensorShapeUtils::IsVector(diag_index.shape())) {",
            "        auto diag_index_size = diag_index.dim_size(0);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5xwc-mrhx-5g3m",
    "API Signature": "tf.raw_ops.MatrixDiagV3(\n    diagonal,\n    k,\n    num_rows,\n    num_cols,\n    padding_value,\n    align='RIGHT_LEFT',\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "k=[],"
},
{
    "Title": "\n        Reference binding to nullptr in `RaggedTensorToSparse`\n      ",
    "Bug description": "An attacker can cause undefined behavior via binding a reference to null pointer in  tf.raw_ops.RaggedTensorToSparse :",
    "Sample Code": "tf.raw_ops.RaggedTensorToSparse(\n  rt_nested_splits=[[0, 38, 0]],\n  ]],\n  rt_dense_values=[])",
    "Code change": [
        "@@ -21,6 +21,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -38,7 +39,8 @@ class RaggedTensorToSparseOp : public OpKernel {\n     OP_REQUIRES_OK(\n         context, context->input_list(\"rt_nested_splits\", &rt_nested_splits_in));\n     const int rt_nested_splits_len = rt_nested_splits_in.size();\n-    DCHECK_GT(rt_nested_splits_len, 0);  // Enforced by REGISTER_OP.\n+    OP_REQUIRES(context, rt_nested_splits_len > 0,\n+                errors::InvalidArgument(\"rt_nested_splits must be non empty\"));\n     std::vector<ConstFlatSplits> rt_nested_splits;\n     rt_nested_splits.reserve(rt_nested_splits_len);\n     for (int i = 0; i < rt_nested_splits_len; ++i) {\n@@ -162,6 +164,14 @@ class RaggedTensorToSparseOp : public OpKernel {\n       if (rt_nested_splits[i](0) != 0) {\n         return InvalidArgument(\"First value of ragged splits must be 0.\");\n       }\n+      for (int j = 1; j < rt_nested_splits[i].size(); ++j) {\n+        if (rt_nested_splits[i](j) < rt_nested_splits[i](j - 1)) {\n+          return InvalidArgument(\n+              \"Ragged splits should be non decreasing, but we got \",\n+              rt_nested_splits[i](j - 1), \" followed by \",\n+              rt_nested_splits[i](j));\n+        }\n+      }\n       if (i > 0) {\n         SPLITS_TYPE last_split =\n             rt_nested_splits[i - 1](rt_nested_splits[i - 1].size() - 1);\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using errors::InvalidArgument;",
            ""
        ],
        [
            "    const int rt_nested_splits_len = rt_nested_splits_in.size();",
            "    DCHECK_GT(rt_nested_splits_len, 0);  // Enforced by REGISTER_OP.",
            "    std::vector<ConstFlatSplits> rt_nested_splits;",
            "    rt_nested_splits.reserve(rt_nested_splits_len);",
            "    for (int i = 0; i < rt_nested_splits_len; ++i) {",
            "      rt_nested_splits.push_back(rt_nested_splits_in[i].flat<SPLITS_TYPE>());",
            "    }",
            ""
        ],
        [
            "      if (i > 0) {",
            "        SPLITS_TYPE last_split =",
            "            rt_nested_splits[i - 1](rt_nested_splits[i - 1].size() - 1);",
            "        if (rt_nested_splits[i].size() != last_split + 1) {",
            "          return InvalidArgument(",
            "              \"Final value of ragged splits must match the length \"",
            "              \"the corresponding ragged values.\");",
            "        }",
            "      }",
            "    }",
            "    if (rt_dense_values_in.dim_size(0) !=",
            "        rt_nested_splits.back()(rt_nested_splits.back().size() - 1)) {",
            "      return InvalidArgument(",
            "          \"Final value of ragged splits must match the length \""
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using errors::InvalidArgument;"
        ],
        [
            "        context, context->input_list(\"rt_nested_splits\", &rt_nested_splits_in));",
            "    const int rt_nested_splits_len = rt_nested_splits_in.size();",
            "    OP_REQUIRES(context, rt_nested_splits_len > 0,",
            "                errors::InvalidArgument(\"rt_nested_splits must be non empty\"));",
            "    std::vector<ConstFlatSplits> rt_nested_splits;",
            "    rt_nested_splits.reserve(rt_nested_splits_len);",
            "    for (int i = 0; i < rt_nested_splits_len; ++i) {",
            "      rt_nested_splits.push_back(rt_nested_splits_in[i].flat<SPLITS_TYPE>());"
        ],
        [
            "        return InvalidArgument(\"First value of ragged splits must be 0.\");",
            "      }",
            "      for (int j = 1; j < rt_nested_splits[i].size(); ++j) {",
            "        if (rt_nested_splits[i](j) < rt_nested_splits[i](j - 1)) {",
            "          return InvalidArgument(",
            "              \"Ragged splits should be non decreasing, but we got \",",
            "              rt_nested_splits[i](j - 1), \" followed by \",",
            "              rt_nested_splits[i](j));",
            "        }",
            "      }",
            "      if (i > 0) {",
            "        SPLITS_TYPE last_split =",
            "            rt_nested_splits[i - 1](rt_nested_splits[i - 1].size() - 1);",
            "        if (rt_nested_splits[i].size() != last_split + 1) {"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4xfp-4pfp-89wg",
    "API Signature": "tf.raw_ops.RaggedTensorToSparse(\n    rt_nested_splits, rt_dense_values, name=None\n)\n",
    "Score": 0.0035971223021582736,
    "Anomaly": "Non increasing order of elements",
    "Anomaly Description": "Non increasing order of elements",
    "Category": "List",
    "Argument": "rt_nested_splits=[[0, 38, 0]],"
},
{
    "Title": "\n        Heap OOB in `ResourceScatterUpdate`\n      ",
    "Bug description": "An attacker can trigger a read from outside of bounds of heap allocated data by sending invalid arguments to  tf.raw_ops.ResourceScatterUpdate :",
    "Sample Code": "v = tf.Variable([b'vvv'])\ntf.raw_ops.ResourceScatterUpdate(\n  resource=v.handle,\n  indices=[0],\n  ],\n  updates=['1', '2', '3', '4', '5'])",
    "Code change": [
        "@@ -955,11 +955,12 @@ class ResourceScatterUpdateOp : public OpKernel {\n                         params->dim_size(0), \")\"));\n       } else {\n         int64_t num_updates = updates.NumElements();\n-        OP_REQUIRES(c, num_updates % N == 0,\n-                    errors::InvalidArgument(\n-                        \"shape of indices (\", indices.shape().DebugString(),\n-                        \") is not compatible with the shape of updates (\",\n-                        updates.shape().DebugString(), \")\"));\n+        OP_REQUIRES(\n+            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n+            errors::InvalidArgument(\n+                \"The shape of indices (\", indices.shape().DebugString(),\n+                \") must be a prefix of the shape of updates (\",\n+                updates.shape().DebugString(), \")\"));\n         auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n \n         functor::ScatterFunctor<Device, T, Index, op> functor;\n"
    ],
    "Buggy Code": [
        [
            "      } else {",
            "        int64_t num_updates = updates.NumElements();",
            "        OP_REQUIRES(c, num_updates % N == 0,",
            "                    errors::InvalidArgument(",
            "                        \"shape of indices (\", indices.shape().DebugString(),",
            "                        \") is not compatible with the shape of updates (\",",
            "                        updates.shape().DebugString(), \")\"));",
            "        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});",
            "",
            "        functor::ScatterFunctor<Device, T, Index, op> functor;",
            "        const Index bad_i = functor(c, c->template eigen_device<Device>(),",
            "                                    params_flat, updates_flat, indices_flat);"
        ]
    ],
    "Clean Code": [
        [
            "      } else {",
            "        int64_t num_updates = updates.NumElements();",
            "        OP_REQUIRES(",
            "            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),",
            "            errors::InvalidArgument(",
            "                \"The shape of indices (\", indices.shape().DebugString(),",
            "                \") must be a prefix of the shape of updates (\",",
            "                updates.shape().DebugString(), \")\"));",
            "        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});",
            "",
            "        functor::ScatterFunctor<Device, T, Index, op> functor;",
            "        const Index bad_i = functor(c, c->template eigen_device<Device>(),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-7fvx-3jfc-2cpc",
    "API Signature": "tf.raw_ops.ResourceScatterUpdate(\n    resource, indices, updates, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "List",
    "Argument": "indices=[0], \nupdates=['1', '2', '3', '4', '5']"
},
{
    "Title": "\n        Heap OOB and CHECK fail in `ResourceGather`\n      ",
    "Bug description": "An attacker can trigger a crash via a  CHECK -fail in debug builds of TensorFlow using  tf.raw_ops.ResourceGather  or a read from outside the bounds of heap allocated data in the same API in a release build:",
    "Sample Code": "tensor = tf.constant(value=[[1,2],[3,4],[5,6]],shape=(3,2),dtype=tf.uint32)\nv = tf.Variable(tensor)\ntf.raw_ops.ResourceGather(\n  resource=v.handle,\n  indices=[0],\n  dtype=tf.uint32,\n  batch_dims=10,\n  ,\n  validate_indices=False)",
    "Code change": [
        "@@ -660,6 +660,11 @@ class ResourceGatherOp : public OpKernel {\n     OP_REQUIRES(\n         c, TensorShapeUtils::IsVectorOrHigher(params.shape()),\n         errors::InvalidArgument(\"params must be at least 1 dimensional\"));\n+    OP_REQUIRES(\n+        c, params.shape().dims() >= batch_dims_,\n+        errors::InvalidArgument(\"params must have at least \", batch_dims_,\n+                                \" (batch_dims) dimensions but it has shape \",\n+                                params.shape().DebugString()));\n \n     // Check that we have enough index space\n     const int64_t N = indices.NumElements();\n"
    ],
    "Buggy Code": [
        [
            "        c, TensorShapeUtils::IsVectorOrHigher(params.shape()),",
            "        errors::InvalidArgument(\"params must be at least 1 dimensional\"));",
            "",
            "    // Check that we have enough index space",
            "    const int64_t N = indices.NumElements();",
            "    OP_REQUIRES(",
            "        c, params.dim_size(0) <= std::numeric_limits<Index>::max(),",
            "        errors::InvalidArgument(\"params.shape[0] too large for \",",
            "                                DataTypeString(DataTypeToEnum<Index>::v()),",
            "                                \" indexing: \", params.dim_size(0), \" > \",",
            "                                std::numeric_limits<Index>::max()));"
        ]
    ],
    "Clean Code": [
        [
            "        c, TensorShapeUtils::IsVectorOrHigher(params.shape()),",
            "        errors::InvalidArgument(\"params must be at least 1 dimensional\"));",
            "    OP_REQUIRES(",
            "        c, params.shape().dims() >= batch_dims_,",
            "        errors::InvalidArgument(\"params must have at least \", batch_dims_,",
            "                                \" (batch_dims) dimensions but it has shape \",",
            "                                params.shape().DebugString()));",
            "",
            "    // Check that we have enough index space",
            "    const int64_t N = indices.NumElements();",
            "    OP_REQUIRES("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2r8p-fg3c-wcj4",
    "API Signature": "tf.raw_ops.ResourceGather(\n    resource, indices, dtype, batch_dims=0, validate_indices=True, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Integer",
    "Argument": "batch_dims=10,"
},
{
    "Title": "\n        Division by 0 in `ResourceGather`\n      ",
    "Bug description": "An attacker can trigger a crash via a floating point exception in  tf.raw_ops.ResourceGather :",
    "Sample Code": "tensor = tf.constant(value=[[]],shape=(0,1),dtype=tf.uint32)\nv = tf.Variable(tensor)\ntf.raw_ops.ResourceGather(\n  resource=v.handle,\n  indices=[0],\n  dtype=tf.uint32,\n  batch_dims=1,\n  ,\n  validate_indices=False)",
    "Code change": [
        "@@ -710,7 +710,8 @@ class ResourceGatherOp : public OpKernel {\n         copy_functor(c->eigen_device<Device>(), tmp_indices.flat<Index>(),\n                      indices.flat<Index>());\n \n-        AddBatchOffsets(&tmp_indices, params);\n+        AddBatchOffsets(c, &tmp_indices, params);\n+        if (!c->status().ok()) return;\n         op_indices = &tmp_indices;\n       }\n \n@@ -742,11 +743,17 @@ class ResourceGatherOp : public OpKernel {\n   // Example: batch_dims = 1, indices = [[0, 1, 2], [0, 1, 2]]\n   // If indexing into a params dimension of size 4, then the indices will become\n   // [0, 1, 2, 4, 5, 6]\n-  void AddBatchOffsets(Tensor* indices, const Tensor& params) {\n+  void AddBatchOffsets(OpKernelContext* ctx, Tensor* indices,\n+                       const Tensor& params) {\n     int64_t batch_size = 1;  // The size of all batch dimensions.\n     for (int idx = 0; idx < batch_dims_; ++idx) {\n       batch_size *= params.dim_size(idx);\n     }\n+    OP_REQUIRES(\n+        ctx, batch_size != 0,\n+        errors::InvalidArgument(\n+            \"Inner size of indices would result in batch_size of 0 and a \",\n+            \"division by 0 in the implementation. This is illegal\"));\n \n     auto indices_flat = indices->flat<Index>();\n     int64_t const index_inner_size = indices->NumElements() / batch_size;\n"
    ],
    "Buggy Code": [
        [
            "                     indices.flat<Index>());",
            "",
            "        AddBatchOffsets(&tmp_indices, params);",
            "        op_indices = &tmp_indices;",
            "      }",
            "",
            "      int64_t gather_dim_size = 1;",
            "      for (int idx = 0; idx <= batch_dims_; ++idx) {"
        ],
        [
            "  // [0, 1, 2, 4, 5, 6]",
            "  void AddBatchOffsets(Tensor* indices, const Tensor& params) {",
            "    int64_t batch_size = 1;  // The size of all batch dimensions.",
            "    for (int idx = 0; idx < batch_dims_; ++idx) {",
            "      batch_size *= params.dim_size(idx);",
            "    }",
            "",
            "    auto indices_flat = indices->flat<Index>();",
            "    int64_t const index_inner_size = indices->NumElements() / batch_size;",
            "    int64_t const batch_offset = params.dim_size(batch_dims_);",
            "    for (int64_t batch_idx = 0, dest_idx = 0; batch_idx < batch_size;",
            "         ++batch_idx) {",
            "      for (int64_t idx = 0; idx < index_inner_size; ++idx) {",
            "        indices_flat(dest_idx++) += batch_offset * batch_idx;",
            "      }",
            "    }",
            "  }"
        ]
    ],
    "Clean Code": [
        [
            "                     indices.flat<Index>());",
            "",
            "        AddBatchOffsets(c, &tmp_indices, params);",
            "        if (!c->status().ok()) return;",
            "        op_indices = &tmp_indices;",
            "      }",
            "",
            "      int64_t gather_dim_size = 1;"
        ],
        [
            "  // If indexing into a params dimension of size 4, then the indices will become",
            "  // [0, 1, 2, 4, 5, 6]",
            "  void AddBatchOffsets(OpKernelContext* ctx, Tensor* indices,",
            "                       const Tensor& params) {",
            "    int64_t batch_size = 1;  // The size of all batch dimensions.",
            "    for (int idx = 0; idx < batch_dims_; ++idx) {",
            "      batch_size *= params.dim_size(idx);",
            "    }",
            "    OP_REQUIRES(",
            "        ctx, batch_size != 0,",
            "        errors::InvalidArgument(",
            "            \"Inner size of indices would result in batch_size of 0 and a \",",
            "            \"division by 0 in the implementation. This is illegal\"));",
            "",
            "    auto indices_flat = indices->flat<Index>();",
            "    int64_t const index_inner_size = indices->NumElements() / batch_size;",
            "    int64_t const batch_offset = params.dim_size(batch_dims_);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qjj8-32p7-h289",
    "API Signature": "tf.raw_ops.ResourceGather(\n    resource, indices, dtype, batch_dims=0, validate_indices=True, name=None\n)\n",
    "Score": 0.03237410071942446,
    "Anomaly": "Zero integer list element",
    "Anomaly Description": "A zero integer list element in Python refers to an element within a list that has a value of zero. It is an integer value of zero (0) that is present as an item in a list.",
    "Category": "List",
    "Argument": "indices=[0],"
},
{
    "Title": "\n        Heap buffer overflow in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation for  tf.raw_ops.FractionalAvgPoolGrad  can be tricked into accessing data outside of bounds of heap allocated buffers:",
    "Sample Code": "tf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=[0,1,2,3],\n  out_backprop = np.array([[[[541],[541]],[[541],[541]]]]),\n  row_pooling_sequence=[0, 0, 0, 0, 0],\n  col_pooling_sequence=[-2, 0, 0, 2, 0],\n  ],\n  overlapping=True)",
    "Code change": [
        "@@ -271,6 +271,18 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64_t in_rows = orig_input_tensor_shape_flat(1);\n     const int64_t in_cols = orig_input_tensor_shape_flat(2);\n     const int64_t in_depth = orig_input_tensor_shape_flat(3);\n+    OP_REQUIRES(\n+        context, in_batch != 0,\n+        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_rows != 0,\n+        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_cols != 0,\n+        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_depth != 0,\n+        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n \n     constexpr int tensor_in_and_out_dims = 4;\n     // Transform orig_input_tensor_shape into TensorShape\n"
    ],
    "Buggy Code": [
        [
            "    const int64_t in_cols = orig_input_tensor_shape_flat(2);",
            "    const int64_t in_depth = orig_input_tensor_shape_flat(3);",
            "",
            "    constexpr int tensor_in_and_out_dims = 4;",
            "    // Transform orig_input_tensor_shape into TensorShape",
            "    TensorShape in_shape;",
            "    for (auto i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      in_shape.AddDim(orig_input_tensor_shape_flat(i));",
            "    }",
            "",
            "    // Create intermediate in_backprop.",
            "    Tensor in_backprop_tensor_temp;",
            "    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(",
            "                                {0}, DataTypeToEnum<double>::v(), in_shape,",
            "                                &in_backprop_tensor_temp));",
            "    in_backprop_tensor_temp.flat<double>().setZero();",
            "    // Transform 4D tensor to 2D matrix.",
            "    EigenDoubleMatrixMap in_backprop_tensor_temp_mat("
        ]
    ],
    "Clean Code": [
        [
            "    const int64_t in_cols = orig_input_tensor_shape_flat(2);",
            "    const int64_t in_depth = orig_input_tensor_shape_flat(3);",
            "    OP_REQUIRES(",
            "        context, in_batch != 0,",
            "        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));",
            "    OP_REQUIRES(",
            "        context, in_rows != 0,",
            "        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));",
            "    OP_REQUIRES(",
            "        context, in_cols != 0,",
            "        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));",
            "    OP_REQUIRES(",
            "        context, in_depth != 0,",
            "        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));",
            "",
            "    constexpr int tensor_in_and_out_dims = 4;",
            "    // Transform orig_input_tensor_shape into TensorShape",
            "    TensorShape in_shape;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hpv4-7p9c-mvfr",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.03237410071942446,
    "Anomaly": "Zero integer list element",
    "Anomaly Description": "A zero integer list element in Python refers to an element within a list that has a value of zero. It is an integer value of zero (0) that is present as an item in a list.",
    "Category": "List",
    "Argument": "orig_input_tensor_shape=[0,1,2,3],"
},
{
    "Title": "\n        Heap buffer overflow in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation for  tf.raw_ops.FractionalAvgPoolGrad  can be tricked into accessing data outside of bounds of heap allocated buffers:",
    "Sample Code": "tf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=[0,1,2,3],\n  out_backprop = np.array([[[[541],[541]],[[541],[541]]]]),\n  row_pooling_sequence=[0, 0, 0, 0, 0],\n  col_pooling_sequence=[-2, 0, 0, 2, 0],\n  ],\n  overlapping=True)",
    "Code change": [
        "@@ -271,6 +271,18 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64_t in_rows = orig_input_tensor_shape_flat(1);\n     const int64_t in_cols = orig_input_tensor_shape_flat(2);\n     const int64_t in_depth = orig_input_tensor_shape_flat(3);\n+    OP_REQUIRES(\n+        context, in_batch != 0,\n+        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_rows != 0,\n+        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_cols != 0,\n+        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_depth != 0,\n+        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n \n     constexpr int tensor_in_and_out_dims = 4;\n     // Transform orig_input_tensor_shape into TensorShape\n"
    ],
    "Buggy Code": [
        [
            "    const int64_t in_cols = orig_input_tensor_shape_flat(2);",
            "    const int64_t in_depth = orig_input_tensor_shape_flat(3);",
            "",
            "    constexpr int tensor_in_and_out_dims = 4;",
            "    // Transform orig_input_tensor_shape into TensorShape",
            "    TensorShape in_shape;",
            "    for (auto i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      in_shape.AddDim(orig_input_tensor_shape_flat(i));",
            "    }",
            "",
            "    // Create intermediate in_backprop.",
            "    Tensor in_backprop_tensor_temp;",
            "    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(",
            "                                {0}, DataTypeToEnum<double>::v(), in_shape,",
            "                                &in_backprop_tensor_temp));",
            "    in_backprop_tensor_temp.flat<double>().setZero();",
            "    // Transform 4D tensor to 2D matrix.",
            "    EigenDoubleMatrixMap in_backprop_tensor_temp_mat("
        ]
    ],
    "Clean Code": [
        [
            "    const int64_t in_cols = orig_input_tensor_shape_flat(2);",
            "    const int64_t in_depth = orig_input_tensor_shape_flat(3);",
            "    OP_REQUIRES(",
            "        context, in_batch != 0,",
            "        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));",
            "    OP_REQUIRES(",
            "        context, in_rows != 0,",
            "        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));",
            "    OP_REQUIRES(",
            "        context, in_cols != 0,",
            "        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));",
            "    OP_REQUIRES(",
            "        context, in_depth != 0,",
            "        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));",
            "",
            "    constexpr int tensor_in_and_out_dims = 4;",
            "    // Transform orig_input_tensor_shape into TensorShape",
            "    TensorShape in_shape;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hpv4-7p9c-mvfr",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.03237410071942446,
    "Anomaly": "Zero integer list element",
    "Anomaly Description": "A zero integer list element in Python refers to an element within a list that has a value of zero. It is an integer value of zero (0) that is present as an item in a list.",
    "Category": "List",
    "Argument": "row_pooling_sequence=[0, 0, 0, 0, 0],"
},
{
    "Title": "\n        Heap buffer overflow in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation for  tf.raw_ops.FractionalAvgPoolGrad  can be tricked into accessing data outside of bounds of heap allocated buffers:",
    "Sample Code": "tf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=[0,1,2,3],\n  out_backprop = np.array([[[[541],[541]],[[541],[541]]]]),\n  row_pooling_sequence=[0, 0, 0, 0, 0],\n  col_pooling_sequence=[-2, 0, 0, 2, 0],\n  ],\n  overlapping=True)",
    "Code change": [
        "@@ -271,6 +271,18 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64_t in_rows = orig_input_tensor_shape_flat(1);\n     const int64_t in_cols = orig_input_tensor_shape_flat(2);\n     const int64_t in_depth = orig_input_tensor_shape_flat(3);\n+    OP_REQUIRES(\n+        context, in_batch != 0,\n+        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_rows != 0,\n+        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_cols != 0,\n+        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_depth != 0,\n+        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n \n     constexpr int tensor_in_and_out_dims = 4;\n     // Transform orig_input_tensor_shape into TensorShape\n"
    ],
    "Buggy Code": [
        [
            "    const int64_t in_cols = orig_input_tensor_shape_flat(2);",
            "    const int64_t in_depth = orig_input_tensor_shape_flat(3);",
            "",
            "    constexpr int tensor_in_and_out_dims = 4;",
            "    // Transform orig_input_tensor_shape into TensorShape",
            "    TensorShape in_shape;",
            "    for (auto i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      in_shape.AddDim(orig_input_tensor_shape_flat(i));",
            "    }",
            "",
            "    // Create intermediate in_backprop.",
            "    Tensor in_backprop_tensor_temp;",
            "    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(",
            "                                {0}, DataTypeToEnum<double>::v(), in_shape,",
            "                                &in_backprop_tensor_temp));",
            "    in_backprop_tensor_temp.flat<double>().setZero();",
            "    // Transform 4D tensor to 2D matrix.",
            "    EigenDoubleMatrixMap in_backprop_tensor_temp_mat("
        ]
    ],
    "Clean Code": [
        [
            "    const int64_t in_cols = orig_input_tensor_shape_flat(2);",
            "    const int64_t in_depth = orig_input_tensor_shape_flat(3);",
            "    OP_REQUIRES(",
            "        context, in_batch != 0,",
            "        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));",
            "    OP_REQUIRES(",
            "        context, in_rows != 0,",
            "        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));",
            "    OP_REQUIRES(",
            "        context, in_cols != 0,",
            "        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));",
            "    OP_REQUIRES(",
            "        context, in_depth != 0,",
            "        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));",
            "",
            "    constexpr int tensor_in_and_out_dims = 4;",
            "    // Transform orig_input_tensor_shape into TensorShape",
            "    TensorShape in_shape;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hpv4-7p9c-mvfr",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.02877697841726619,
    "Anomaly": "Negative integer list element",
    "Anomaly Description": "A negative integer list element in Python refers to an element within a list that has a negative integer value. It means that the element is a negative number represented by an integer data type.",
    "Category": "List",
    "Argument": "col_pooling_sequence=[-2, 0, 0, 2, 0],"
},
{
    "Title": "\n        Null pointer dereference in `SparseTensorSliceDataset`\n      ",
    "Bug description": "When a user does not supply arguments that determine a valid sparse tensor,  tf.raw_ops.SparseTensorSliceDataset  implementation can be made to dereference a null pointer:",
    "Sample Code": "tf.raw_ops.SparseTensorSliceDataset(\n  indices=[[],[],[]],\n  values=[1,2,3],\n  ],\n  dense_shape=[3,3])",
    "Code change": [
        "@@ -241,6 +241,17 @@ class SparseTensorSliceDatasetOp : public DatasetOpKernel {\n                 errors::InvalidArgument(\n                     \"Input indices should be a matrix but received shape \",\n                     indices->shape().DebugString()));\n+\n+    const auto num_indices = indices->NumElements();\n+    const auto num_values = values->NumElements();\n+    if (num_indices == 0 || num_values == 0) {\n+      OP_REQUIRES(ctx, num_indices == num_values,\n+                  errors::InvalidArgument(\n+                      \"If indices or values are empty, the other one must also \"\n+                      \"be. Got indices of shape \",\n+                      indices->shape().DebugString(), \" and values of shape \",\n+                      values->shape().DebugString()));\n+    }\n     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                 errors::InvalidArgument(\n                     \"Input values should be a vector but received shape \",\n",
        "@@ -118,6 +118,26 @@ class FromSparseTensorSlicesTest(test_base.DatasetTestBase,\n       with self.assertRaises(errors.OutOfRangeError):\n         sess.run(get_next)\n \n+  @combinations.generate(combinations.combine(tf_api_version=1, mode=[\"graph\"]))\n+  def testEmptySparseTensorSlicesInvalid(self):\n+    \"\"\"Test a dataset based on invalid `tf.sparse.SparseTensor`.\"\"\"\n+    st = array_ops.sparse_placeholder(dtypes.float64)\n+    iterator = dataset_ops.make_initializable_iterator(\n+        dataset_ops.Dataset.from_sparse_tensor_slices(st))\n+    init_op = iterator.initializer\n+\n+    with self.cached_session() as sess:\n+      # Test with an empty sparse tensor but with non empty values.\n+      empty_indices = np.empty((0, 4), dtype=np.int64)\n+      non_empty_values = [1, 2, 3, 4]\n+      empty_dense_shape = [0, 4, 37, 9]\n+      sparse_feed = sparse_tensor.SparseTensorValue(empty_indices,\n+                                                    non_empty_values,\n+                                                    empty_dense_shape)\n+      # Here, we expect the test to fail when running the feed.\n+      with self.assertRaises(errors.InvalidArgumentError):\n+        sess.run(init_op, feed_dict={st: sparse_feed})\n+\n   @combinations.generate(combinations.combine(tf_api_version=2, mode=[\"eager\"]))\n   def testFromSparseTensorSlicesError(self):\n     with self.assertRaises(AttributeError):\n"
    ],
    "Buggy Code": [
        [
            "                    \"Input indices should be a matrix but received shape \",",
            "                    indices->shape().DebugString()));",
            "    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),",
            "                errors::InvalidArgument(",
            "                    \"Input values should be a vector but received shape \",",
            "                    indices->shape().DebugString()));",
            "    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),",
            "                errors::InvalidArgument(",
            "                    \"Input shape should be a vector but received shape \",",
            "                    dense_shape->shape().DebugString()));",
            "",
            "    // We currently ensure that `sparse_tensor` is ordered in the",
            "    // batch dimension.",
            "    // TODO(mrry): Investigate ways to avoid this unconditional check",
            "    // if we can be sure that the sparse tensor was produced in an",
            "    // appropriate order (e.g. by `tf.parse_example()` or a Dataset",
            "    // that batches elements into rows of a SparseTensor)."
        ]
    ],
    "Clean Code": [
        [
            "                    \"Input indices should be a matrix but received shape \",",
            "                    indices->shape().DebugString()));",
            "",
            "    const auto num_indices = indices->NumElements();",
            "    const auto num_values = values->NumElements();",
            "    if (num_indices == 0 || num_values == 0) {",
            "      OP_REQUIRES(ctx, num_indices == num_values,",
            "                  errors::InvalidArgument(",
            "                      \"If indices or values are empty, the other one must also \"",
            "                      \"be. Got indices of shape \",",
            "                      indices->shape().DebugString(), \" and values of shape \",",
            "                      values->shape().DebugString()));",
            "    }",
            "    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),",
            "                errors::InvalidArgument(",
            "                    \"Input values should be a vector but received shape \",",
            "                    indices->shape().DebugString()));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c5x2-p679-95wc",
    "API Signature": "tf.raw_ops.SparseTensorSliceDataset(\n    indices, values, dense_shape, name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Empty list argument",
    "Anomaly Description": "An empty list argument in Python refers to a list parameter or value that contains no elements. It is a list object passed as an argument to a function, method, or operation, but it does not have any items or content.",
    "Category": "List",
    "Argument": "indices=[[],[],[]],"
},
{
    "Title": "\n        Bad alloc in `StringNGrams` caused by integer conversion\n      ",
    "Bug description": "The implementation of  tf.raw_ops.StringNGrams  is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value.",
    "Sample Code": "tf.raw_ops.StringNGrams(\n  data=['',''],\n  data_splits=[0,2],\n  separator=' '*100,\n  ngram_widths=[-80,0,0,-60],\n  left_pad=' ',\n  right_pad=' ',\n  pad_width=100,\n  ,\n  preserve_short_sequences=False)",
    "Code change": [
        "@@ -53,6 +53,12 @@ class StringNGramsOp : public tensorflow::OpKernel {\n   }\n \n   void Compute(tensorflow::OpKernelContext* context) override {\n+    for (int ngram_width : ngram_widths_) {\n+      OP_REQUIRES(\n+          context, ngram_width > 0,\n+          errors::InvalidArgument(\"ngram_widths must contain positive values\"));\n+    }\n+\n     const tensorflow::Tensor* data;\n     OP_REQUIRES_OK(context, context->input(\"data\", &data));\n     const auto& input_data = data->flat<tstring>().data();\n"
    ],
    "Buggy Code": [
        [
            "",
            "  void Compute(tensorflow::OpKernelContext* context) override {",
            "    const tensorflow::Tensor* data;",
            "    OP_REQUIRES_OK(context, context->input(\"data\", &data));",
            "    const auto& input_data = data->flat<tstring>().data();",
            "",
            "    const tensorflow::Tensor* splits;",
            "    OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));",
            "    const auto& splits_vec = splits->flat<SPLITS_TYPE>();",
            "",
            "    // Validate that the splits are valid indices into data, only if there are",
            "    // splits specified."
        ]
    ],
    "Clean Code": [
        [
            "",
            "  void Compute(tensorflow::OpKernelContext* context) override {",
            "    for (int ngram_width : ngram_widths_) {",
            "      OP_REQUIRES(",
            "          context, ngram_width > 0,",
            "          errors::InvalidArgument(\"ngram_widths must contain positive values\"));",
            "    }",
            "",
            "    const tensorflow::Tensor* data;",
            "    OP_REQUIRES_OK(context, context->input(\"data\", &data));",
            "    const auto& input_data = data->flat<tstring>().data();",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h6jh-7gv5-28vg",
    "API Signature": "tf.raw_ops.StringNGrams(\n    data,\n    data_splits,\n    separator,\n    ngram_widths,\n    left_pad,\n    right_pad,\n    pad_width,\n    preserve_short_sequences,\n    name=None\n)\n",
    "Score": 0.02877697841726619,
    "Anomaly": "Negative integer list element",
    "Anomaly Description": "A negative integer list element in Python refers to an element within a list that has a negative integer value. It means that the element is a negative number represented by an integer data type.",
    "Category": "List",
    "Argument": "ngram_widths=[-80,0,0,-60],"
},
{
    "Title": "\n        Integer overflow due to conversion to unsigned\n      ",
    "Bug description": "The implementation of  tf.raw_ops.QuantizeAndDequantizeV4Grad  is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value.",
    "Sample Code": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n  gradients=[1.0,2.0],\n  input=[1.0,1.0],\n  input_min=[0.0],\n  input_max=[10.0],\n  ],\n  axis=-100)",
    "Code change": [
        "@@ -158,6 +158,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n     Tensor* input_backprop = nullptr;\n     OP_REQUIRES_OK(ctx,\n                    ctx->allocate_output(0, input.shape(), &input_backprop));\n+    OP_REQUIRES(\n+        ctx, axis_ >= -1,\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n+    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n+                errors::InvalidArgument(\n+                    \"Axis should be -1 or 0 or a positive value less than \",\n+                    input.shape().dims(), \"but given axis value was \", axis_));\n \n     OP_REQUIRES(\n         ctx, input.IsSameSize(gradient),\n"
    ],
    "Buggy Code": [
        [
            "    OP_REQUIRES_OK(ctx,",
            "                   ctx->allocate_output(0, input.shape(), &input_backprop));",
            "",
            "    OP_REQUIRES(",
            "        ctx, input.IsSameSize(gradient),",
            "        errors::InvalidArgument(\"gradient and input must be the same size\"));",
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    const Tensor& input_min_tensor = ctx->input(2);",
            "    OP_REQUIRES(ctx,",
            "                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,",
            "                errors::InvalidArgument(",
            "                    \"Input min tensor must have dimension 1. Recieved \",",
            "                    input_min_tensor.dims(), \".\"));"
        ]
    ],
    "Clean Code": [
        [
            "    OP_REQUIRES_OK(ctx,",
            "                   ctx->allocate_output(0, input.shape(), &input_backprop));",
            "    OP_REQUIRES(",
            "        ctx, axis_ >= -1,",
            "        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
            "    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
            "                errors::InvalidArgument(",
            "                    \"Axis should be -1 or 0 or a positive value less than \",",
            "                    input.shape().dims(), \"but given axis value was \", axis_));",
            "",
            "    OP_REQUIRES(",
            "        ctx, input.IsSameSize(gradient),",
            "        errors::InvalidArgument(\"gradient and input must be the same size\"));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9w2p-5mgw-p94c",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n    gradients, input, input_min, input_max, axis=-1, name=None\n)\n",
    "Score": 0.039568345323741004,
    "Anomaly": "Negative integer argument",
    "Anomaly Description": "A negative integer argument in Python refers to an integer value that is less than zero. It is a numeric value that represents a negative quantity or position in a numerical sequence. In Python, negative integers are denoted by placing a minus sign (-) before the numerical value. For example, -1, -2, -3, and so on.",
    "Category": "Integer",
    "Argument": "axis=-100,"
},
{
    "Title": "\n        Null pointer dereference in `MatrixDiagPartOp`\n      ",
    "Bug description": "If a user does not provide a valid padding value to  tf.raw_ops.MatrixDiagPartOp , then the code triggers a null pointer dereference (if input is empty) or produces invalid behavior, ignoring all values after the first:",
    "Sample Code": "tf.raw_ops.MatrixDiagPartV2(\n  input=tf.ones(2,dtype=tf.int32),\n  k=tf.ones(2,dtype=tf.int32),\n  ),\n  padding_value=[])",
    "Code change": [
        "@@ -89,7 +89,10 @@ class MatrixDiagPartOp : public OpKernel {\n           upper_diag_index = diag_index.flat<int32>()(1);\n         }\n       }\n-      padding_value = context->input(2).flat<T>()(0);\n+      const Tensor& padding_in = context->input(2);\n+      OP_REQUIRES(context, padding_in.NumElements() == 1,\n+                  errors::InvalidArgument(\"Padding must be scalar.\"));\n+      padding_value = padding_in.flat<T>()(0);\n     }\n     const TensorShape& input_shape = input.shape();\n \n"
    ],
    "Buggy Code": [
        [
            "        }",
            "      }",
            "      padding_value = context->input(2).flat<T>()(0);",
            "    }",
            "    const TensorShape& input_shape = input.shape();",
            "",
            "    // Preliminary validation of sizes.",
            "    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input_shape),",
            "                errors::InvalidArgument(",
            "                    \"input must be at least 2-dim, received shape: \","
        ]
    ],
    "Clean Code": [
        [
            "        }",
            "      }",
            "      const Tensor& padding_in = context->input(2);",
            "      OP_REQUIRES(context, padding_in.NumElements() == 1,",
            "                  errors::InvalidArgument(\"Padding must be scalar.\"));",
            "      padding_value = padding_in.flat<T>()(0);",
            "    }",
            "    const TensorShape& input_shape = input.shape();",
            "",
            "    // Preliminary validation of sizes."
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fcwc-p4fc-c5cc",
    "API Signature": "tf.raw_ops.MatrixDiagPartV2(\n    input, k, padding_value, name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "padding_value=[]"
},
{
    "Title": "\n        `std::abort` raised from `TensorListReserve`\n      ",
    "Bug description": "Providing a negative element to  num_elements  list argument of   tf.raw_ops.TensorListReserve  causes the runtime to abort the process due to reallocating a  std::vector  to have a negative number of elements:",
    "Sample Code": "tf.raw_ops.TensorListReserve(\n  element_shape = tf.constant([1]),\n  num_elements=tf.constant([-1]),\n  ]),\n  element_dtype = tf.int32)",
    "Code change": [
        "@@ -302,6 +302,10 @@ class TensorListReserve : public OpKernel {\n     PartialTensorShape element_shape;\n     OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(0), &element_shape));\n     int32 num_elements = c->input(1).scalar<int32>()();\n+    OP_REQUIRES(c, num_elements >= 0,\n+                errors::InvalidArgument(\"The num_elements to reserve must be a \"\n+                                        \"non negative number, but got \",\n+                                        num_elements));\n     TensorList output;\n     output.element_shape = element_shape;\n     output.element_dtype = element_dtype_;\n"
    ],
    "Buggy Code": [
        [
            "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(0), &element_shape));",
            "    int32 num_elements = c->input(1).scalar<int32>()();",
            "    TensorList output;",
            "    output.element_shape = element_shape;",
            "    output.element_dtype = element_dtype_;",
            "    output.tensors().resize(num_elements, Tensor(DT_INVALID));",
            "    Tensor* result;",
            "    AllocatorAttributes attr;",
            "    attr.set_on_host(true);",
            "    OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape{}, &result, attr));"
        ]
    ],
    "Clean Code": [
        [
            "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(0), &element_shape));",
            "    int32 num_elements = c->input(1).scalar<int32>()();",
            "    OP_REQUIRES(c, num_elements >= 0,",
            "                errors::InvalidArgument(\"The num_elements to reserve must be a \"",
            "                                        \"non negative number, but got \",",
            "                                        num_elements));",
            "    TensorList output;",
            "    output.element_shape = element_shape;",
            "    output.element_dtype = element_dtype_;",
            "    output.tensors().resize(num_elements, Tensor(DT_INVALID));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-27j5-4p9v-pp67",
    "API Signature": "tf.raw_ops.TensorListReserve(\n    element_shape, num_elements, element_dtype, name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Negative input tensor",
    "Anomaly Description": "A negative input tensor refers to a tensor that contains negative values. In other words, the elements of the tensor have a value less than zero.",
    "Category": "Tensor",
    "Argument": "num_elements=tf.constant([-1]"
},
{
    "Title": "\n        Heap OOB in `RaggedGather`\n      ",
    "Bug description": "If the arguments to  tf.raw_ops.RaggedGather  don't determine a valid ragged tensor code can trigger a read from outside of bounds of heap allocated buffers.",
    "Sample Code": "tf.raw_ops.RaggedGather(\n  params_nested_splits = [0,0,0],\n  params_dense_values = [1,1],\n  indices = [0,0,9,0,0],\n  ],\n  OUTPUT_RAGGED_RANK=0)",
    "Code change": [
        "@@ -58,15 +58,21 @@ class RaggedGatherOpBase : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     // Get the input Tensors.\n+\n     OpInputList params_nested_splits_in;\n     OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",\n                                                 &params_nested_splits_in));\n+    OP_REQUIRES(\n+        context, params_nested_splits_in.size() > 0,\n+        errors::InvalidArgument(\"params_nested_splits must be non empty\"));\n+\n     const Tensor& params_dense_values_in =\n         context->input(params_nested_splits_in.size());\n     const Tensor& indices_in =\n         context->input(params_nested_splits_in.size() + 1);\n \n-    DCHECK_GT(params_nested_splits_in.size(), 0);  // Enforced by REGISTER_OP.\n+    OP_REQUIRES(context, params_nested_splits_in[0].dims() > 0,\n+                errors::InvalidArgument(\"Split tensors must not be scalars\"));\n     SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;\n     OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));\n \n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    // Get the input Tensors.",
            "    OpInputList params_nested_splits_in;",
            "    OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",",
            "                                                &params_nested_splits_in));",
            "    const Tensor& params_dense_values_in =",
            "        context->input(params_nested_splits_in.size());",
            "    const Tensor& indices_in =",
            "        context->input(params_nested_splits_in.size() + 1);",
            "",
            "    DCHECK_GT(params_nested_splits_in.size(), 0);  // Enforced by REGISTER_OP.",
            "    SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;",
            "    OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));",
            "",
            "    OP_REQUIRES(context, params_dense_values_in.dims() > 0,",
            "                errors::InvalidArgument(\"params.rank must be nonzero\"));",
            "    SPLITS_TYPE num_params_dense_values = params_dense_values_in.dim_size(0);",
            "",
            "    // Calculate the `splits`, and store the value slices that we need to",
            "    // copy in `value_slices`.",
            "    std::vector<std::pair<SPLITS_TYPE, SPLITS_TYPE>> value_slices;"
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    // Get the input Tensors.",
            "",
            "    OpInputList params_nested_splits_in;",
            "    OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",",
            "                                                &params_nested_splits_in));",
            "    OP_REQUIRES(",
            "        context, params_nested_splits_in.size() > 0,",
            "        errors::InvalidArgument(\"params_nested_splits must be non empty\"));",
            "",
            "    const Tensor& params_dense_values_in =",
            "        context->input(params_nested_splits_in.size());",
            "    const Tensor& indices_in =",
            "        context->input(params_nested_splits_in.size() + 1);",
            "",
            "    OP_REQUIRES(context, params_nested_splits_in[0].dims() > 0,",
            "                errors::InvalidArgument(\"Split tensors must not be scalars\"));",
            "    SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;",
            "    OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));",
            "",
            "    OP_REQUIRES(context, params_dense_values_in.dims() > 0,"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9c8h-vvrj-w2p8",
    "API Signature": "tf.raw_ops.RaggedGather(\n    params_nested_splits,\n    params_dense_values,\n    indices,\n    OUTPUT_RAGGED_RANK,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "List",
    "Argument": "params_nested_splits = [0,0,0],\nparams_dense_values = [1,1],\nindices = [0,0,9,0,0],"
},
{
    "Title": "\n        Division by 0 in `ResourceScatterDiv`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.ResourceScatterDiv  is vulnerable to a division by 0 error:",
    "Sample Code": "v= tf.Variable([1,2,3])\ntf.raw_ops.ResourceScatterDiv(\n  resource=v.handle,\n  indices=[1],\n  ],\n  updates=[0])",
    "Code change": [
        "@@ -873,6 +873,35 @@ TF_CALL_GPU_NUMBER_TYPES(REGISTER_GATHER_ND_GPU);\n #undef REGISTER_GATHER_ND_ALL_INDICES\n #undef REGISTER_GATHER_ND_FULL\n \n+namespace {\n+\n+template <typename Device>\n+bool isCPUDevice() {\n+  return false;\n+}\n+\n+template <>\n+bool isCPUDevice<CPUDevice>() {\n+  return true;\n+}\n+\n+template <typename T>\n+bool ValidateInput(const Tensor& updates) {\n+  const auto updates_flat = updates.flat<T>();\n+  const T zero(0);\n+  for (int i = 0; i < updates.NumElements(); i++) {\n+    if (updates_flat(i) == zero) return false;\n+  }\n+  return true;\n+}\n+\n+template <>\n+bool ValidateInput<Variant>(const Tensor& updates) {\n+  return true;\n+}\n+\n+}  // namespace\n+\n template <typename Device, typename T, typename Index, scatter_op::UpdateOp op>\n class ResourceScatterUpdateOp : public OpKernel {\n  public:\n@@ -939,6 +968,12 @@ class ResourceScatterUpdateOp : public OpKernel {\n                                 \" indexing: \", params->dim_size(0), \" > \",\n                                 std::numeric_limits<Index>::max()));\n \n+    // Prevent division by 0\n+    if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {\n+      OP_REQUIRES(c, ValidateInput<T>(updates),\n+                  errors::InvalidArgument(\"updates must not contain 0\"));\n+    }\n+\n     if (N > 0) {\n       auto indices_flat = indices.flat<Index>();\n       auto params_flat = params->flat_outer_dims<T>();\n",
        "@@ -175,8 +175,9 @@ class ShardedVariableTest(test.TestCase, parameterized.TestCase):\n                             'scatter_update')\n   def test_scatter_ops_even_partition(self, op):\n     v = variables_lib.Variable(array_ops.zeros((30, 1)))\n+    # Make sure values does not contain 0 due to testing `scatter_div`!\n     sparse_delta = ops.IndexedSlices(\n-        values=constant_op.constant([[0.], [1.], [2.], [3.], [4.]]),\n+        values=constant_op.constant([[1.], [2.], [3.], [4.], [5.]]),\n         indices=constant_op.constant([0, 10, 12, 21, 22]))\n \n     v0 = variables_lib.Variable(array_ops.zeros((10, 1)))\n"
    ],
    "Buggy Code": [
        [
            "#undef REGISTER_GATHER_ND_FULL",
            "",
            "template <typename Device, typename T, typename Index, scatter_op::UpdateOp op>",
            "class ResourceScatterUpdateOp : public OpKernel {",
            " public:",
            "  explicit ResourceScatterUpdateOp(OpKernelConstruction* c) : OpKernel(c) {",
            "    // We use the same kernel for many operations.",
            "    // Each operation has a different set of attributes defined in its nodes.",
            "    Status s = c->GetAttr(\"use_locking\", &use_exclusive_lock_);",
            "    if (!s.ok()) {",
            "      use_exclusive_lock_ = false;",
            "    }",
            "  }",
            "",
            "  void Compute(OpKernelContext* c) override {",
            "    core::RefCountPtr<Var> v;",
            "    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));",
            "    OP_REQUIRES_OK(c, EnsureSparseVariableAccess<Device, T>(c, v.get()));",
            "    const bool is_non_pod_dtype = c->input_dtype(0) == DT_RESOURCE ||",
            "                                  c->input_dtype(0) == DT_STRING ||",
            "                                  c->input_dtype(0) == DT_VARIANT;",
            "    if (is_non_pod_dtype || use_exclusive_lock_) {",
            "      mutex_lock ml(*v->mu());",
            "      DoCompute(c);",
            "    } else {",
            "      // For POD dtypes, we can safely run the update without the mutex.",
            "      tf_shared_lock ml(*v->mu());",
            "      DoCompute(c);",
            "    }",
            "  }",
            "",
            " private:",
            "  bool use_exclusive_lock_;",
            "",
            "  void DoCompute(OpKernelContext* c) {"
        ],
        [
            "        OP_REQUIRES(c, bad_i < 0,",
            "                    errors::InvalidArgument(",
            "                        \"indices\", SliceDebugString(indices.shape(), bad_i),",
            "                        \" = \", indices_flat(bad_i), \" is not in [0, \",",
            "                        params->dim_size(0), \")\"));",
            "      }",
            "    }",
            "  }",
            "};",
            "",
            "#define REGISTER_SCATTER_KERNEL_INDEX(type, index_type, dev, name, op) \\",
            "  REGISTER_KERNEL_BUILDER(                                             \\"
        ]
    ],
    "Clean Code": [
        [
            "#undef REGISTER_GATHER_ND_FULL",
            "",
            "namespace {",
            "",
            "template <typename Device>",
            "bool isCPUDevice() {",
            "  return false;",
            "}",
            "",
            "template <>",
            "bool isCPUDevice<CPUDevice>() {",
            "  return true;",
            "}",
            "",
            "template <typename T>",
            "bool ValidateInput(const Tensor& updates) {",
            "  const auto updates_flat = updates.flat<T>();",
            "  const T zero(0);",
            "  for (int i = 0; i < updates.NumElements(); i++) {",
            "    if (updates_flat(i) == zero) return false;",
            "  }",
            "  return true;",
            "}",
            "",
            "template <>",
            "bool ValidateInput<Variant>(const Tensor& updates) {",
            "  return true;",
            "}",
            "",
            "}  // namespace",
            "",
            "template <typename Device, typename T, typename Index, scatter_op::UpdateOp op>",
            "class ResourceScatterUpdateOp : public OpKernel {",
            " public:",
            "  explicit ResourceScatterUpdateOp(OpKernelConstruction* c) : OpKernel(c) {"
        ],
        [
            "                                std::numeric_limits<Index>::max()));",
            "",
            "    // Prevent division by 0",
            "    if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {",
            "      OP_REQUIRES(c, ValidateInput<T>(updates),",
            "                  errors::InvalidArgument(\"updates must not contain 0\"));",
            "    }",
            "",
            "    if (N > 0) {",
            "      auto indices_flat = indices.flat<Index>();",
            "      auto params_flat = params->flat_outer_dims<T>();",
            "      if (TensorShapeUtils::IsScalar(updates.shape())) {"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-ch4f-829c-v5pw",
    "API Signature": "tf.raw_ops.ResourceScatterDiv(\n    resource, indices, updates, name=None\n)\n",
    "Score": 0.03237410071942446,
    "Anomaly": "Zero integer list element",
    "Anomaly Description": "A zero integer list element in Python refers to an element within a list that has a value of zero. It is an integer value of zero (0) that is present as an item in a list.",
    "Category": "List",
    "Argument": "updates=[0]"
},
{
    "Title": "\n        Integer division by 0 in sparse reshaping\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SparseReshape  can be made to trigger an integral division by 0 exception:",
    "Sample Code": "tf.raw_ops.SparseReshape(\n  input_indices = np.ones((1,3)),\n  input_shape = np.array([1,1,0]),\n  ]),\n  new_shape = np.array([1,0]))",
    "Code change": [
        "@@ -174,6 +174,12 @@ void ReshapeSparseTensor(OpKernelContext *context,\n                                           TensorShape({nnz, output_rank}),\n                                           &result_indices));\n   if (nnz > 0) {\n+    OP_REQUIRES(\n+        context, dense_size > 0 && product > 0,\n+        errors::InvalidArgument(\n+            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\n+            input_shape.DebugString(), \") or output shape (\",\n+            output_shape.DebugString(), \") is empty\"));\n     OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                 context, input_shape, output_shape,\n                                 input_indices_in.matrix<int64>(),\n"
    ],
    "Buggy Code": [
        [
            "                                          &result_indices));",
            "  if (nnz > 0) {",
            "    OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(",
            "                                context, input_shape, output_shape,",
            "                                input_indices_in.matrix<int64>(),",
            "                                result_indices->matrix<int64>()));",
            "  }",
            "}",
            "",
            "#define EXPLICITLY_INSTANTIATE_FUNCTION(Device)                    \\",
            "  template void ReshapeSparseTensor<Device>(                       \\",
            "      OpKernelContext * context, const Tensor &input_indices_in,   \\"
        ]
    ],
    "Clean Code": [
        [
            "                                          &result_indices));",
            "  if (nnz > 0) {",
            "    OP_REQUIRES(",
            "        context, dense_size > 0 && product > 0,",
            "        errors::InvalidArgument(",
            "            \"Input tensor has \", nnz, \" non zero elements but input shape (\",",
            "            input_shape.DebugString(), \") or output shape (\",",
            "            output_shape.DebugString(), \") is empty\"));",
            "    OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(",
            "                                context, input_shape, output_shape,",
            "                                input_indices_in.matrix<int64>(),",
            "                                result_indices->matrix<int64>()));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-95xm-g58g-3p88",
    "API Signature": "tf.raw_ops.SparseReshape(\n    input_indices, input_shape, new_shape, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "List",
    "Argument": "input_shape = np.array([1,1,0]),\nnew_shape = np.array([1,0])"
},
{
    "Title": "\n        Null pointer dereference and heap OOB read in operations restoring tensors\n      ",
    "Bug description": "When restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer:",
    "Sample Code": "tf.raw_ops.Restore(\n  file_pattern=['/tmp'],\n  tensor_name=['x'], \n  default_value=21,\n  dt=tf.int,\n  ,\n  preferred_shard=42)",
    "Code change": [
        "@@ -151,11 +151,18 @@ void RestoreTensor(OpKernelContext* context,\n         context, size == 1,\n         errors::InvalidArgument(\n             \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n-            size, \"elements\"));\n+            size, \" elements\"));\n   }\n   const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n \n   const Tensor& tensor_name_t = context->input(1);\n+  {\n+    const int64_t size = tensor_name_t.NumElements();\n+    OP_REQUIRES(context, size > restore_index,\n+                errors::InvalidArgument(\n+                    \"Input 1 (file_pattern) must be a have at least \",\n+                    restore_index + 1, \" elements\"));\n+  }\n   const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n \n   // If we cannot find a cached reader we will allocate our own.\n"
    ],
    "Buggy Code": [
        [
            "        errors::InvalidArgument(",
            "            \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",",
            "            size, \"elements\"));",
            "  }",
            "  const string& file_pattern = file_pattern_t.flat<tstring>()(0);",
            "",
            "  const Tensor& tensor_name_t = context->input(1);",
            "  const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);",
            "",
            "  // If we cannot find a cached reader we will allocate our own.",
            "  std::unique_ptr<checkpoint::TensorSliceReader> allocated_reader;",
            "",
            "  const checkpoint::TensorSliceReader* reader = nullptr;",
            "",
            "  if (context->slice_reader_cache()) {",
            "    reader = context->slice_reader_cache()->GetReader(file_pattern, open_func,",
            "                                                      preferred_shard);",
            "  }"
        ]
    ],
    "Clean Code": [
        [
            "        errors::InvalidArgument(",
            "            \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",",
            "            size, \" elements\"));",
            "  }",
            "  const string& file_pattern = file_pattern_t.flat<tstring>()(0);",
            "",
            "  const Tensor& tensor_name_t = context->input(1);",
            "  {",
            "    const int64_t size = tensor_name_t.NumElements();",
            "    OP_REQUIRES(context, size > restore_index,",
            "                errors::InvalidArgument(",
            "                    \"Input 1 (file_pattern) must be a have at least \",",
            "                    restore_index + 1, \" elements\"));",
            "  }",
            "  const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);",
            "",
            "  // If we cannot find a cached reader we will allocate our own.",
            "  std::unique_ptr<checkpoint::TensorSliceReader> allocated_reader;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gh6x-4whr-2qv4",
    "API Signature": "tf.raw_ops.Restore(\n    file_pattern, tensor_name, dt, preferred_shard=-1, name=None\n)\n",
    "Score": 0.01079136690647482,
    "Anomaly": "Empty string argument",
    "Anomaly Description": "An empty string argument in Python refers to a string parameter or value that has no characters or content. It is a string value passed as an argument to a function, method, or operation, but it does not contain any meaningful data.\n\nIn Python, an empty string can be denoted as \"\" or ''. It represents a string literal with zero characters between the quotation marks.",
    "Category": "String",
    "Argument": "tensor_name=[]"
},
{
    "Title": "\n        Null pointer dereference and heap OOB read in operations restoring tensors\n      ",
    "Bug description": "When restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer:",
    "Sample Code": "tf.raw_ops.Restore(\n  file_pattern=['/tmp'],\n  tensor_name=['x'], \n  default_value=21,\n  dt=tf.int,\n  ,\n  preferred_shard=42)",
    "Code change": [
        "@@ -151,11 +151,18 @@ void RestoreTensor(OpKernelContext* context,\n         context, size == 1,\n         errors::InvalidArgument(\n             \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n-            size, \"elements\"));\n+            size, \" elements\"));\n   }\n   const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n \n   const Tensor& tensor_name_t = context->input(1);\n+  {\n+    const int64_t size = tensor_name_t.NumElements();\n+    OP_REQUIRES(context, size > restore_index,\n+                errors::InvalidArgument(\n+                    \"Input 1 (file_pattern) must be a have at least \",\n+                    restore_index + 1, \" elements\"));\n+  }\n   const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n \n   // If we cannot find a cached reader we will allocate our own.\n"
    ],
    "Buggy Code": [
        [
            "        errors::InvalidArgument(",
            "            \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",",
            "            size, \"elements\"));",
            "  }",
            "  const string& file_pattern = file_pattern_t.flat<tstring>()(0);",
            "",
            "  const Tensor& tensor_name_t = context->input(1);",
            "  const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);",
            "",
            "  // If we cannot find a cached reader we will allocate our own.",
            "  std::unique_ptr<checkpoint::TensorSliceReader> allocated_reader;",
            "",
            "  const checkpoint::TensorSliceReader* reader = nullptr;",
            "",
            "  if (context->slice_reader_cache()) {",
            "    reader = context->slice_reader_cache()->GetReader(file_pattern, open_func,",
            "                                                      preferred_shard);",
            "  }"
        ]
    ],
    "Clean Code": [
        [
            "        errors::InvalidArgument(",
            "            \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",",
            "            size, \" elements\"));",
            "  }",
            "  const string& file_pattern = file_pattern_t.flat<tstring>()(0);",
            "",
            "  const Tensor& tensor_name_t = context->input(1);",
            "  {",
            "    const int64_t size = tensor_name_t.NumElements();",
            "    OP_REQUIRES(context, size > restore_index,",
            "                errors::InvalidArgument(",
            "                    \"Input 1 (file_pattern) must be a have at least \",",
            "                    restore_index + 1, \" elements\"));",
            "  }",
            "  const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);",
            "",
            "  // If we cannot find a cached reader we will allocate our own.",
            "  std::unique_ptr<checkpoint::TensorSliceReader> allocated_reader;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gh6x-4whr-2qv4",
    "API Signature": "tf.raw_ops.RestoreSlice(\n    file_pattern,\n    tensor_name,\n    shape_and_slice,\n    dt,\n    preferred_shard=-1,\n    name=None\n)\n",
    "Score": 0.01079136690647482,
    "Anomaly": "Empty string argument",
    "Anomaly Description": "An empty string argument in Python refers to a string parameter or value that has no characters or content. It is a string value passed as an argument to a function, method, or operation, but it does not contain any meaningful data.\n\nIn Python, an empty string can be denoted as \"\" or ''. It represents a string literal with zero characters between the quotation marks.",
    "Category": "String",
    "Argument": "tensor_name=[]"
},
{
    "Title": "\n        Null pointer dereference in `RaggedTensorToTensor`\n      ",
    "Bug description": "Sending invalid argument for  row_partition_types  of  tf.raw_ops.RaggedTensorToTensor  API results in a null pointer dereference and undefined behavior:",
    "Sample Code": "tf.raw_ops.RaggedTensorToTensor(\n  shape=1,\n  values=10,\n  default_value=21,\n  row_partition_tensors=tf.constant([0,0,0,0]),\n  ]),\n  row_partition_types=[])",
    "Code change": [
        "@@ -348,6 +348,9 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n   Status GetFirstDimensionSize(OpKernelContext* context, INDEX_TYPE* result) {\n     const Tensor first_partition_tensor =\n         context->input(kFirstPartitionInputIndex);\n+    if (row_partition_types_.empty()) {\n+      return errors::InvalidArgument(\"No row_partition_types given.\");\n+    }\n     const RowPartitionType first_partition_type = row_partition_types_[0];\n     switch (first_partition_type) {\n       case RowPartitionType::FIRST_DIM_SIZE:\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor first_partition_tensor =",
            "        context->input(kFirstPartitionInputIndex);",
            "    const RowPartitionType first_partition_type = row_partition_types_[0];",
            "    switch (first_partition_type) {",
            "      case RowPartitionType::FIRST_DIM_SIZE:",
            "        *result = first_partition_tensor.scalar<INDEX_TYPE>()();",
            "        return Status::OK();",
            "      case RowPartitionType::VALUE_ROWIDS:",
            "        return errors::InvalidArgument("
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor first_partition_tensor =",
            "        context->input(kFirstPartitionInputIndex);",
            "    if (row_partition_types_.empty()) {",
            "      return errors::InvalidArgument(\"No row_partition_types given.\");",
            "    }",
            "    const RowPartitionType first_partition_type = row_partition_types_[0];",
            "    switch (first_partition_type) {",
            "      case RowPartitionType::FIRST_DIM_SIZE:",
            "        *result = first_partition_tensor.scalar<INDEX_TYPE>()();"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hwr7-8gxx-fj5p",
    "API Signature": "tf.raw_ops.RaggedTensorToTensor(\n    shape,\n    values,\n    default_value,\n    row_partition_tensors,\n    row_partition_types,\n    name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Empty list argument",
    "Anomaly Description": "An empty list argument in Python refers to a list parameter or value that contains no elements. It is a list object passed as an argument to a function, method, or operation, but it does not have any items or content.",
    "Category": "List",
    "Argument": "row_partition_types=[]"
},
{
    "Title": "\n        Null pointer dereference in `CompressElement`\n      ",
    "Bug description": "It is possible to trigger a null pointer dereference in TensorFlow by passing an invalid input to  tf.raw_ops.CompressElement :",
    "Sample Code": " tensorflow as tf\n\ntf.raw_ops.CompressElement(components=[[]])",
    "Code change": [
        "@@ -29,9 +29,10 @@ Status CompressElement(const std::vector<Tensor>& element,\n   int64 total_size = 0;\n   for (auto& component : element) {\n     if (DataTypeCanUseMemcpy(component.dtype())) {\n-      // Some datatypes can be memcopied, allowing us to save two copies\n-      // (AsProtoTensorContent and SerializeToArray).\n-      total_size += DMAHelper::buffer(&component)->size();\n+      const TensorBuffer* buffer = DMAHelper::buffer(&component);\n+      if (buffer) {\n+        total_size += buffer->size();\n+      }\n     } else {\n       non_memcpy_components.emplace_back();\n       component.AsProtoTensorContent(&non_memcpy_components.back());\n@@ -53,8 +54,10 @@ Status CompressElement(const std::vector<Tensor>& element,\n     component.shape().AsProto(metadata->mutable_tensor_shape());\n     if (DataTypeCanUseMemcpy(component.dtype())) {\n       const TensorBuffer* buffer = DMAHelper::buffer(&component);\n-      memcpy(position, buffer->data(), buffer->size());\n-      metadata->set_tensor_size_bytes(buffer->size());\n+      if (buffer) {\n+        memcpy(position, buffer->data(), buffer->size());\n+        metadata->set_tensor_size_bytes(buffer->size());\n+      }\n     } else {\n       TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];\n       proto.SerializeToArray(position, proto.ByteSizeLong());\n@@ -94,8 +97,13 @@ Status UncompressElement(const CompressedElement& compressed,\n     if (DataTypeCanUseMemcpy(metadata.dtype())) {\n       out->emplace_back(metadata.dtype(), metadata.tensor_shape());\n       TensorBuffer* buffer = DMAHelper::buffer(&out->back());\n-      iov[i].iov_base = buffer->data();\n-      iov[i].iov_len = buffer->size();\n+      if (buffer) {\n+        iov[i].iov_base = buffer->data();\n+        iov[i].iov_len = buffer->size();\n+      } else {\n+        iov[i].iov_base = nullptr;\n+        iov[i].iov_len = 0;\n+      }\n     } else {\n       // Allocate an empty Tensor. We will fill it out later after\n       // uncompressing into the tensor_proto_str.\n"
    ],
    "Buggy Code": [
        [
            "  for (auto& component : element) {",
            "    if (DataTypeCanUseMemcpy(component.dtype())) {",
            "      // Some datatypes can be memcopied, allowing us to save two copies",
            "      // (AsProtoTensorContent and SerializeToArray).",
            "      total_size += DMAHelper::buffer(&component)->size();",
            "    } else {",
            "      non_memcpy_components.emplace_back();",
            "      component.AsProtoTensorContent(&non_memcpy_components.back());",
            "      total_size += non_memcpy_components.back().ByteSizeLong();",
            "    }"
        ],
        [
            "      const TensorBuffer* buffer = DMAHelper::buffer(&component);",
            "      memcpy(position, buffer->data(), buffer->size());",
            "      metadata->set_tensor_size_bytes(buffer->size());",
            "    } else {",
            "      TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];",
            "      proto.SerializeToArray(position, proto.ByteSizeLong());",
            "      metadata->set_tensor_size_bytes(proto.ByteSizeLong());",
            "    }",
            "    position += metadata->tensor_size_bytes();",
            "  }"
        ],
        [
            "      iov[i].iov_len = buffer->size();",
            "    } else {",
            "      // Allocate an empty Tensor. We will fill it out later after",
            "      // uncompressing into the tensor_proto_str.",
            "      out->emplace_back();",
            "      tensor_proto_strs.emplace_back();",
            "      tstring& tensor_proto_str = tensor_proto_strs.back();",
            "      tensor_proto_str.resize_uninitialized(metadata.tensor_size_bytes());",
            "      iov[i].iov_base = tensor_proto_str.mdata();",
            "      iov[i].iov_len = tensor_proto_str.size();",
            "    }",
            "    total_size += iov[i].iov_len;",
            "  }"
        ]
    ],
    "Clean Code": [
        [
            "  for (auto& component : element) {",
            "    if (DataTypeCanUseMemcpy(component.dtype())) {",
            "      const TensorBuffer* buffer = DMAHelper::buffer(&component);",
            "      if (buffer) {",
            "        total_size += buffer->size();",
            "      }",
            "    } else {",
            "      non_memcpy_components.emplace_back();",
            "      component.AsProtoTensorContent(&non_memcpy_components.back());",
            "      total_size += non_memcpy_components.back().ByteSizeLong();"
        ],
        [
            "    if (DataTypeCanUseMemcpy(component.dtype())) {",
            "      const TensorBuffer* buffer = DMAHelper::buffer(&component);",
            "      if (buffer) {",
            "        memcpy(position, buffer->data(), buffer->size());",
            "        metadata->set_tensor_size_bytes(buffer->size());",
            "      }",
            "    } else {",
            "      TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];",
            "      proto.SerializeToArray(position, proto.ByteSizeLong());",
            "      metadata->set_tensor_size_bytes(proto.ByteSizeLong());"
        ],
        [
            "      out->emplace_back(metadata.dtype(), metadata.tensor_shape());",
            "      TensorBuffer* buffer = DMAHelper::buffer(&out->back());",
            "      if (buffer) {",
            "        iov[i].iov_base = buffer->data();",
            "        iov[i].iov_len = buffer->size();",
            "      } else {",
            "        iov[i].iov_base = nullptr;",
            "        iov[i].iov_len = 0;",
            "      }",
            "    } else {",
            "      // Allocate an empty Tensor. We will fill it out later after",
            "      // uncompressing into the tensor_proto_str.",
            "      out->emplace_back();"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c9qf-r67m-p7cg",
    "API Signature": "tf.raw_ops.CompressElement(\n    components, name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Empty list argument",
    "Anomaly Description": "An empty list argument in Python refers to a list parameter or value that contains no elements. It is a list object passed as an argument to a function, method, or operation, but it does not have any items or content.",
    "Category": "List",
    "Argument": "components=[[]]"
},
{
    "Title": "\n        Floating point exception in `SparseDenseCwiseDiv`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SparseDenseCwiseDiv  is vulnerable to a division by 0 error:",
    "Sample Code": "import numpy as np\n\ntf.raw_ops.SparseDenseCwiseDiv( \n  sp_indices=np.array([[4]]),\n  sp_values=np.array([-400]),\n  sp_shape=np.array([647.]),\n  ]),\n  dense=np.array([0]))",
    "Code change": [
        "@@ -114,7 +114,10 @@ class SparseDenseBinaryOpShared : public OpKernel {\n     OP_REQUIRES_OK(\n         ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                 &dense_gathered));\n-\n+    bool op_is_div = false;\n+    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {\n+      op_is_div = true;\n+    }\n     // Pulls relevant entries from the dense side, with reshape and broadcasting\n     // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n     // up memory.\n@@ -143,6 +146,12 @@ class SparseDenseBinaryOpShared : public OpKernel {\n           errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                   \"dense side with broadcasted shape\"));       \\\n       dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n+      if (op_is_div) {                                                         \\\n+        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\\n+                    errors::InvalidArgument(                                   \\\n+                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\\n+                        \"but input dense tensor contains zero \"));             \\\n+      }                                                                        \\\n     }                                                                          \\\n     break;                                                                     \\\n   }\n"
    ],
    "Buggy Code": [
        [
            "        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),",
            "                                &dense_gathered));",
            "",
            "    // Pulls relevant entries from the dense side, with reshape and broadcasting",
            "    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing",
            "    // up memory.",
            "    //",
            "    // We can directly use the sparse indices to look up dense side, because",
            "    // \"b.y_reshape()\" and \"b.y_bcast()\" are guaranteed to have rank \"ndims\".",
            "    auto dense_gathered_flat = dense_gathered.flat<T>();"
        ],
        [
            "    break;                                                                     \\",
            "  }",
            "",
            "      CASE(1);",
            "      CASE(2);",
            "      CASE(3);",
            "      CASE(4);",
            "      CASE(5);",
            "      default:",
            "        OP_REQUIRES(",
            "            ctx, false,",
            "            errors::InvalidArgument(\"Only tensors with ranks between 1 and 5 \""
        ]
    ],
    "Clean Code": [
        [
            "        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),",
            "                                &dense_gathered));",
            "    bool op_is_div = false;",
            "    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {",
            "      op_is_div = true;",
            "    }",
            "    // Pulls relevant entries from the dense side, with reshape and broadcasting",
            "    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing",
            "    // up memory.",
            "    //"
        ],
        [
            "                                  \"dense side with broadcasted shape\"));       \\",
            "      dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\",
            "      if (op_is_div) {                                                         \\",
            "        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\",
            "                    errors::InvalidArgument(                                   \\",
            "                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\",
            "                        \"but input dense tensor contains zero \"));             \\",
            "      }                                                                        \\",
            "    }                                                                          \\",
            "    break;                                                                     \\",
            "  }",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hp4c-x6r7-6555",
    "API Signature": "tf.raw_ops.SparseDenseCwiseDiv(\n    sp_indices, sp_values, sp_shape, dense, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "dense=np.array([0])"
},
{
    "Title": "\n        Segfault in `tf.raw_ops.SparseCountSparseOutput`\n      ",
    "Bug description": "Passing invalid arguments (e.g., discovered via fuzzing) to  tf.raw_ops.SparseCountSparseOutput  results in segfault.",
    "Sample Code": "",
    "Code change": [
        "@@ -192,6 +192,10 @@ class SparseCount : public OpKernel {\n               \"; values shape: \", values.shape().DebugString()));\n     }\n \n+    OP_REQUIRES(context, shape.NumElements() != 0,\n+                errors::InvalidArgument(\n+                    \"The shape argument requires at least one element.\"));\n+\n     bool is_1d = shape.NumElements() == 1;\n     int num_batches = is_1d ? 1 : shape.flat<int64>()(0);\n     int num_values = values.NumElements();\n@@ -212,6 +216,14 @@ class SparseCount : public OpKernel {\n \n     for (int idx = 0; idx < num_values; ++idx) {\n       int batch = is_1d ? 0 : indices_values(idx, 0);\n+      if (batch >= num_batches) {\n+        OP_REQUIRES(context, batch < num_batches,\n+                    errors::InvalidArgument(\n+                        \"Indices value along the first dimension must be \",\n+                        \"lower than the first index of the shape.\", \"Got \",\n+                        batch, \" as batch and \", num_batches,\n+                        \" as the first dimension of the shape.\"));\n+      }\n       const auto& value = values_values(idx);\n       if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\n         if (binary_output_) {\n"
    ],
    "Buggy Code": [
        [
            "    }",
            "",
            "    bool is_1d = shape.NumElements() == 1;",
            "    int num_batches = is_1d ? 1 : shape.flat<int64>()(0);",
            "    int num_values = values.NumElements();",
            "",
            "    OP_REQUIRES(context, num_values == indices.shape().dim_size(0),",
            "                errors::InvalidArgument(",
            "                    \"Number of values must match first dimension of indices.\",",
            "                    \"Got \", num_values,"
        ],
        [
            "        if (binary_output_) {",
            "          per_batch_counts[batch][value] = 1;",
            "        } else if (use_weights) {",
            "          per_batch_counts[batch][value] += weight_values(idx);",
            "        } else {",
            "          per_batch_counts[batch][value]++;",
            "        }",
            "        if (value > max_value) {",
            "          max_value = value;",
            "        }",
            "      }",
            "    }",
            "",
            "    int num_output_values = GetOutputSize(max_value, maxlength_, minlength_);"
        ]
    ],
    "Clean Code": [
        [
            "    }",
            "",
            "    OP_REQUIRES(context, shape.NumElements() != 0,",
            "                errors::InvalidArgument(",
            "                    \"The shape argument requires at least one element.\"));",
            "",
            "    bool is_1d = shape.NumElements() == 1;",
            "    int num_batches = is_1d ? 1 : shape.flat<int64>()(0);",
            "    int num_values = values.NumElements();",
            ""
        ],
        [
            "    for (int idx = 0; idx < num_values; ++idx) {",
            "      int batch = is_1d ? 0 : indices_values(idx, 0);",
            "      if (batch >= num_batches) {",
            "        OP_REQUIRES(context, batch < num_batches,",
            "                    errors::InvalidArgument(",
            "                        \"Indices value along the first dimension must be \",",
            "                        \"lower than the first index of the shape.\", \"Got \",",
            "                        batch, \" as batch and \", num_batches,",
            "                        \" as the first dimension of the shape.\"));",
            "      }",
            "      const auto& value = values_values(idx);",
            "      if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {",
            "        if (binary_output_) {",
            "          per_batch_counts[batch][value] = 1;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wvjw-p9f5-vq28",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Empty list argument",
    "Anomaly Description": "An empty list argument in Python refers to a list parameter or value that contains no elements. It is a list object passed as an argument to a function, method, or operation, but it does not have any items or content.",
    "Category": "List",
    "Argument": "dense_shape=[]"
},
{
    "Title": "\n        Interpreter crash from `tf.io.decode_raw`\n      ",
    "Bug description": "The implementation of  tf.io.decode_raw  produces incorrect results and crashes the Python interpreter when combining  fixed_length  and wider datatypes.",
    "Sample Code": " tensorflow as tf\n\ntf.io.decode_raw(tf.constant([\"1\",\"2\",\"3\",\"4\"]), tf.uint16, fixed_length=4)",
    "Code change": [
        "@@ -19,6 +19,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/common_shape_fns.h\"\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/shape_inference.h\"\n \n namespace tensorflow {\n@@ -83,14 +84,13 @@ class DecodePaddedRawOp : public OpKernel {\n     // can copy the memory directly.\n     if (!convert_data_endianness_ || sizeof(T) == 1) {\n       for (int64 i = 0; i < flat_in.size(); ++i) {\n-        const T* in_data = reinterpret_cast<const T*>(flat_in(i).data());\n-\n-        if (flat_in(i).size() > fixed_length) {\n-          memcpy(out_data, in_data, fixed_length);\n-        } else {\n-          memcpy(out_data, in_data, flat_in(i).size());\n-        }\n-        out_data += fixed_length;\n+        const auto to_copy =\n+            std::min(flat_in(i).size(), static_cast<size_t>(fixed_length));\n+        memcpy(out_data, flat_in(i).data(), to_copy);\n+        // Note: increase out_data by width since it's already of type T* so\n+        // each shift amount is implicitly multiplied by sizeof(T) according to\n+        // pointer arithmetic rules.\n+        out_data += width;\n       }\n     } else {\n       // Otherwise, the data is not in the host's byte order, and rather than a\n@@ -105,7 +105,10 @@ class DecodePaddedRawOp : public OpKernel {\n              p_in += sizeof(T), p_out += sizeof(T)) {\n           std::reverse_copy(p_in, p_in + sizeof(T), p_out);\n         }\n-        out_data += fixed_length;\n+        // Note: increase out_data by width since it's already of type T* so\n+        // each shift amount is implicitly multiplied by sizeof(T) according to\n+        // pointer arithmetic rules.\n+        out_data += width;\n       }\n     }\n   }\n",
        "@@ -850,8 +850,8 @@ def decode_raw(input_bytes,\n                name=None):\n   r\"\"\"Convert raw bytes from input tensor into numeric tensors.\n \n-  The input tensor is interpreted as a sequence of bytes. These bytes are then\n-  decoded as numbers in the format specified by `out_type`.\n+  Every component of the input tensor is interpreted as a sequence of bytes.\n+  These bytes are then decoded as numbers in the format specified by `out_type`.\n \n   >>> tf.io.decode_raw(tf.constant(\"1\"), tf.uint8)\n   <tf.Tensor: shape=(1,), dtype=uint8, numpy=array([49], dtype=uint8)>\n@@ -909,22 +909,35 @@ def decode_raw(input_bytes,\n   >>> tf.io.decode_raw(tf.constant([\"1212\"]), tf.uint16, fixed_length=4)\n   <tf.Tensor: shape=(1, 2), dtype=uint16, numpy=array([[12849, 12849]], ...\n \n-  Note: There is currently a bug in `fixed_length` that can result in data loss:\n-\n-  >>> # truncated to length of type as it matches fixed_length\n-  >>> tf.io.decode_raw(tf.constant([\"1212\"]), tf.uint16, fixed_length=2)\n-  <tf.Tensor: shape=(1, 1), dtype=uint16, numpy=array([[12849]], dtype=uint16)>\n-  >>> # ignores the second component\n-  >>> tf.io.decode_raw(tf.constant([\"12\",\"34\"]), tf.uint16, fixed_length=2)\n-  <tf.Tensor: shape=(2, 1), dtype=uint16, numpy=\n-  array([[12849],\n-         [    0]], dtype=uint16)>\n-  >>> tf.io.decode_raw(tf.constant([\"12\",\"34\"]), tf.uint16, fixed_length=4)\n-  <tf.Tensor: shape=(2, 2), dtype=uint16, numpy=\n-  array([[12849,     0],\n-         [    0,     0]], dtype=uint16)>\n-\n-  This will be fixed on a future release of TensorFlow.\n+  If the input value is larger than `fixed_length`, it is truncated:\n+\n+  >>> x=''.join([chr(1), chr(2), chr(3), chr(4)])\n+  >>> tf.io.decode_raw(x, tf.uint16, fixed_length=2)\n+  <tf.Tensor: shape=(1,), dtype=uint16, numpy=array([513], dtype=uint16)>\n+  >>> hex(513)\n+  '0x201'\n+\n+  If `little_endian` and `fixed_length` are specified, truncation to the fixed\n+  length occurs before endianness conversion:\n+\n+  >>> x=''.join([chr(1), chr(2), chr(3), chr(4)])\n+  >>> tf.io.decode_raw(x, tf.uint16, fixed_length=2, little_endian=False)\n+  <tf.Tensor: shape=(1,), dtype=uint16, numpy=array([258], dtype=uint16)>\n+  >>> hex(258)\n+  '0x102'\n+\n+  If input values all have the same length, then specifying `fixed_length`\n+  equal to the size of the strings should not change output:\n+\n+  >>> x = [\"12345678\", \"87654321\"]\n+  >>> tf.io.decode_raw(x, tf.int16)\n+  <tf.Tensor: shape=(2, 4), dtype=int16, numpy=\n+  array([[12849, 13363, 13877, 14391],\n+         [14136, 13622, 13108, 12594]], dtype=int16)>\n+  >>> tf.io.decode_raw(x, tf.int16, fixed_length=len(x[0]))\n+  <tf.Tensor: shape=(2, 4), dtype=int16, numpy=\n+  array([[12849, 13363, 13877, 14391],\n+         [14136, 13622, 13108, 12594]], dtype=int16)>\n \n   Args:\n     input_bytes:\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/shape_inference.h\"",
            "",
            "namespace tensorflow {",
            "",
            "template <typename T>"
        ],
        [
            "      for (int64 i = 0; i < flat_in.size(); ++i) {",
            "        const T* in_data = reinterpret_cast<const T*>(flat_in(i).data());",
            "",
            "        if (flat_in(i).size() > fixed_length) {",
            "          memcpy(out_data, in_data, fixed_length);",
            "        } else {",
            "          memcpy(out_data, in_data, flat_in(i).size());",
            "        }",
            "        out_data += fixed_length;",
            "      }",
            "    } else {",
            "      // Otherwise, the data is not in the host's byte order, and rather than a",
            "      // direct copy, we need to reverse the byte ordering of each element."
        ],
        [
            "          std::reverse_copy(p_in, p_in + sizeof(T), p_out);",
            "        }",
            "        out_data += fixed_length;",
            "      }",
            "    }",
            "  }",
            "",
            " private:",
            "  // True if the endianness of the data and the endianness of the host are",
            "  // different, and the data needs conversion."
        ],
        [
            "  r\"\"\"Convert raw bytes from input tensor into numeric tensors.",
            "",
            "  The input tensor is interpreted as a sequence of bytes. These bytes are then",
            "  decoded as numbers in the format specified by `out_type`.",
            "",
            "  >>> tf.io.decode_raw(tf.constant(\"1\"), tf.uint8)",
            "  <tf.Tensor: shape=(1,), dtype=uint8, numpy=array([49], dtype=uint8)>",
            "  >>> tf.io.decode_raw(tf.constant(\"1,2\"), tf.uint8)"
        ],
        [
            "  <tf.Tensor: shape=(1, 2), dtype=uint16, numpy=array([[12849, 12849]], ...",
            "",
            "  Note: There is currently a bug in `fixed_length` that can result in data loss:",
            "",
            "  >>> # truncated to length of type as it matches fixed_length",
            "  >>> tf.io.decode_raw(tf.constant([\"1212\"]), tf.uint16, fixed_length=2)",
            "  <tf.Tensor: shape=(1, 1), dtype=uint16, numpy=array([[12849]], dtype=uint16)>",
            "  >>> # ignores the second component",
            "  >>> tf.io.decode_raw(tf.constant([\"12\",\"34\"]), tf.uint16, fixed_length=2)",
            "  <tf.Tensor: shape=(2, 1), dtype=uint16, numpy=",
            "  array([[12849],",
            "         [    0]], dtype=uint16)>",
            "  >>> tf.io.decode_raw(tf.constant([\"12\",\"34\"]), tf.uint16, fixed_length=4)",
            "  <tf.Tensor: shape=(2, 2), dtype=uint16, numpy=",
            "  array([[12849,     0],",
            "         [    0,     0]], dtype=uint16)>",
            "",
            "  This will be fixed on a future release of TensorFlow.",
            "",
            "  Args:",
            "    input_bytes:",
            "      Each element of the input Tensor is converted to an array of bytes.",
            "",
            "      Currently, this must be a tensor of strings (bytes), although semantically",
            "      the operation should support any input.",
            "    out_type:",
            "      `DType` of the output. Acceptable types are `half`, `float`, `double`,",
            "      `int32`, `uint16`, `uint8`, `int16`, `int8`, `int64`.",
            "    little_endian:",
            "      Whether the `input_bytes` data is in little-endian format. Data will be",
            "      converted into host byte order if necessary.",
            "    fixed_length:",
            "      If set, the first `fixed_length` bytes of each element will be converted.",
            "      Data will be zero-padded or truncated to the specified length.",
            ""
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/op.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/framework/shape_inference.h\"",
            "",
            "namespace tensorflow {",
            ""
        ],
        [
            "    if (!convert_data_endianness_ || sizeof(T) == 1) {",
            "      for (int64 i = 0; i < flat_in.size(); ++i) {",
            "        const auto to_copy =",
            "            std::min(flat_in(i).size(), static_cast<size_t>(fixed_length));",
            "        memcpy(out_data, flat_in(i).data(), to_copy);",
            "        // Note: increase out_data by width since it's already of type T* so",
            "        // each shift amount is implicitly multiplied by sizeof(T) according to",
            "        // pointer arithmetic rules.",
            "        out_data += width;",
            "      }",
            "    } else {",
            "      // Otherwise, the data is not in the host's byte order, and rather than a",
            "      // direct copy, we need to reverse the byte ordering of each element."
        ],
        [
            "          std::reverse_copy(p_in, p_in + sizeof(T), p_out);",
            "        }",
            "        // Note: increase out_data by width since it's already of type T* so",
            "        // each shift amount is implicitly multiplied by sizeof(T) according to",
            "        // pointer arithmetic rules.",
            "        out_data += width;",
            "      }",
            "    }",
            "  }",
            ""
        ],
        [
            "  r\"\"\"Convert raw bytes from input tensor into numeric tensors.",
            "",
            "  Every component of the input tensor is interpreted as a sequence of bytes.",
            "  These bytes are then decoded as numbers in the format specified by `out_type`.",
            "",
            "  >>> tf.io.decode_raw(tf.constant(\"1\"), tf.uint8)",
            "  <tf.Tensor: shape=(1,), dtype=uint8, numpy=array([49], dtype=uint8)>",
            "  >>> tf.io.decode_raw(tf.constant(\"1,2\"), tf.uint8)"
        ],
        [
            "  <tf.Tensor: shape=(1, 2), dtype=uint16, numpy=array([[12849, 12849]], ...",
            "",
            "  If the input value is larger than `fixed_length`, it is truncated:",
            "",
            "  >>> x=''.join([chr(1), chr(2), chr(3), chr(4)])",
            "  >>> tf.io.decode_raw(x, tf.uint16, fixed_length=2)",
            "  <tf.Tensor: shape=(1,), dtype=uint16, numpy=array([513], dtype=uint16)>",
            "  >>> hex(513)",
            "  '0x201'",
            "",
            "  If `little_endian` and `fixed_length` are specified, truncation to the fixed",
            "  length occurs before endianness conversion:",
            "",
            "  >>> x=''.join([chr(1), chr(2), chr(3), chr(4)])",
            "  >>> tf.io.decode_raw(x, tf.uint16, fixed_length=2, little_endian=False)",
            "  <tf.Tensor: shape=(1,), dtype=uint16, numpy=array([258], dtype=uint16)>",
            "  >>> hex(258)",
            "  '0x102'",
            "",
            "  If input values all have the same length, then specifying `fixed_length`",
            "  equal to the size of the strings should not change output:",
            "",
            "  >>> x = [\"12345678\", \"87654321\"]",
            "  >>> tf.io.decode_raw(x, tf.int16)",
            "  <tf.Tensor: shape=(2, 4), dtype=int16, numpy=",
            "  array([[12849, 13363, 13877, 14391],",
            "         [14136, 13622, 13108, 12594]], dtype=int16)>",
            "  >>> tf.io.decode_raw(x, tf.int16, fixed_length=len(x[0]))",
            "  <tf.Tensor: shape=(2, 4), dtype=int16, numpy=",
            "  array([[12849, 13363, 13877, 14391],",
            "         [14136, 13622, 13108, 12594]], dtype=int16)>",
            "",
            "  Args:",
            "    input_bytes:",
            "      Each element of the input Tensor is converted to an array of bytes."
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-8pmx-p244-g88h",
    "API Signature": "tf.io.decode_raw(\n    input_bytes, out_type, little_endian=True, fixed_length=None, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "tf.io.decode_raw(tf.constant([\"1\",\"2\",\"3\",\"4\"]), tf.uint16, fixed_length=4)"
},
{
    "Title": "\n        Incomplete validation in `tf.raw_ops.CTCLoss`\n      ",
    "Bug description": "Incomplete validation in  tf.raw_ops.CTCLoss  allows an attacker to trigger an OOB read from heap:",
    "Sample Code": "inputs = tf.constant([], shape=[0, 2, 11], dtype=tf.float32)\nlabels_indices = tf.constant([], shape=[0, 2], dtype=tf.int64)\nlabels_values = tf.constant([], shape=[0], dtype=tf.int32)\nsequence_length = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\n\ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=False, ctc_merge_repeated=False,\n                   ,\n                   ignore_longer_outputs_than_inputs=False)",
    "Code change": [
        "@@ -109,6 +109,9 @@ class CTCLossOp : public OpKernel {\n \n     const TensorShape& inputs_shape = inputs->shape();\n     const int64 max_time = inputs_shape.dim_size(0);\n+    OP_REQUIRES(ctx, max_time != 0,\n+                errors::InvalidArgument(\n+                    \"Max time or first dimension of input cannot be 0.\"));\n     const int64 batch_size = inputs_shape.dim_size(1);\n     const int64 num_classes_raw = inputs_shape.dim_size(2);\n     OP_REQUIRES(\n"
    ],
    "Buggy Code": [
        [
            "    const TensorShape& inputs_shape = inputs->shape();",
            "    const int64 max_time = inputs_shape.dim_size(0);",
            "    const int64 batch_size = inputs_shape.dim_size(1);",
            "    const int64 num_classes_raw = inputs_shape.dim_size(2);",
            "    OP_REQUIRES(",
            "        ctx, FastBoundsCheck(num_classes_raw, std::numeric_limits<int>::max()),",
            "        errors::InvalidArgument(\"num_classes cannot exceed max int\"));",
            "    const int num_classes = static_cast<const int>(num_classes_raw);",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    const TensorShape& inputs_shape = inputs->shape();",
            "    const int64 max_time = inputs_shape.dim_size(0);",
            "    OP_REQUIRES(ctx, max_time != 0,",
            "                errors::InvalidArgument(",
            "                    \"Max time or first dimension of input cannot be 0.\"));",
            "    const int64 batch_size = inputs_shape.dim_size(1);",
            "    const int64 num_classes_raw = inputs_shape.dim_size(2);",
            "    OP_REQUIRES(",
            "        ctx, FastBoundsCheck(num_classes_raw, std::numeric_limits<int>::max()),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vvg4-vgrv-xfr7",
    "API Signature": "tf.raw_ops.CTCLoss(\n    inputs,\n    labels_indices,\n    labels_values,\n    sequence_length,\n    preprocess_collapse_repeated=False,\n    ctc_merge_repeated=True,\n    ignore_longer_outputs_than_inputs=False,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "inputs = tf.constant([], shape=[10, 16, 0], dtype=tf.float32)"
},
{
    "Title": "\n        Incomplete validation in `tf.raw_ops.CTCLoss`\n      ",
    "Bug description": "Incomplete validation in  tf.raw_ops.CTCLoss  allows an attacker to trigger an OOB read from heap:",
    "Sample Code": "inputs = tf.constant([], shape=[0, 2, 11], dtype=tf.float32)\nlabels_indices = tf.constant([], shape=[0, 2], dtype=tf.int64)\nlabels_values = tf.constant([], shape=[0], dtype=tf.int32)\nsequence_length = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\n\ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=False, ctc_merge_repeated=False,\n                   ,\n                   ignore_longer_outputs_than_inputs=False)",
    "Code change": [
        "@@ -109,6 +109,9 @@ class CTCLossOp : public OpKernel {\n \n     const TensorShape& inputs_shape = inputs->shape();\n     const int64 max_time = inputs_shape.dim_size(0);\n+    OP_REQUIRES(ctx, max_time != 0,\n+                errors::InvalidArgument(\n+                    \"Max time or first dimension of input cannot be 0.\"));\n     const int64 batch_size = inputs_shape.dim_size(1);\n     const int64 num_classes_raw = inputs_shape.dim_size(2);\n     OP_REQUIRES(\n"
    ],
    "Buggy Code": [
        [
            "    const TensorShape& inputs_shape = inputs->shape();",
            "    const int64 max_time = inputs_shape.dim_size(0);",
            "    const int64 batch_size = inputs_shape.dim_size(1);",
            "    const int64 num_classes_raw = inputs_shape.dim_size(2);",
            "    OP_REQUIRES(",
            "        ctx, FastBoundsCheck(num_classes_raw, std::numeric_limits<int>::max()),",
            "        errors::InvalidArgument(\"num_classes cannot exceed max int\"));",
            "    const int num_classes = static_cast<const int>(num_classes_raw);",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    const TensorShape& inputs_shape = inputs->shape();",
            "    const int64 max_time = inputs_shape.dim_size(0);",
            "    OP_REQUIRES(ctx, max_time != 0,",
            "                errors::InvalidArgument(",
            "                    \"Max time or first dimension of input cannot be 0.\"));",
            "    const int64 batch_size = inputs_shape.dim_size(1);",
            "    const int64 num_classes_raw = inputs_shape.dim_size(2);",
            "    OP_REQUIRES(",
            "        ctx, FastBoundsCheck(num_classes_raw, std::numeric_limits<int>::max()),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vvg4-vgrv-xfr7",
    "API Signature": "tf.raw_ops.CTCLoss(\n    inputs,\n    labels_indices,\n    labels_values,\n    sequence_length,\n    preprocess_collapse_repeated=False,\n    ctc_merge_repeated=True,\n    ignore_longer_outputs_than_inputs=False,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "labels_indices = tf.constant([], shape=[8, 0], dtype=tf.int64)"
},
{
    "Title": "\n        Incomplete validation in `tf.raw_ops.CTCLoss`\n      ",
    "Bug description": "Incomplete validation in  tf.raw_ops.CTCLoss  allows an attacker to trigger an OOB read from heap:",
    "Sample Code": "inputs = tf.constant([], shape=[0, 2, 11], dtype=tf.float32)\nlabels_indices = tf.constant([], shape=[0, 2], dtype=tf.int64)\nlabels_values = tf.constant([], shape=[0], dtype=tf.int32)\nsequence_length = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\n\ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=False, ctc_merge_repeated=False,\n                   ,\n                   ignore_longer_outputs_than_inputs=False)",
    "Code change": [
        "@@ -109,6 +109,9 @@ class CTCLossOp : public OpKernel {\n \n     const TensorShape& inputs_shape = inputs->shape();\n     const int64 max_time = inputs_shape.dim_size(0);\n+    OP_REQUIRES(ctx, max_time != 0,\n+                errors::InvalidArgument(\n+                    \"Max time or first dimension of input cannot be 0.\"));\n     const int64 batch_size = inputs_shape.dim_size(1);\n     const int64 num_classes_raw = inputs_shape.dim_size(2);\n     OP_REQUIRES(\n"
    ],
    "Buggy Code": [
        [
            "    const TensorShape& inputs_shape = inputs->shape();",
            "    const int64 max_time = inputs_shape.dim_size(0);",
            "    const int64 batch_size = inputs_shape.dim_size(1);",
            "    const int64 num_classes_raw = inputs_shape.dim_size(2);",
            "    OP_REQUIRES(",
            "        ctx, FastBoundsCheck(num_classes_raw, std::numeric_limits<int>::max()),",
            "        errors::InvalidArgument(\"num_classes cannot exceed max int\"));",
            "    const int num_classes = static_cast<const int>(num_classes_raw);",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    const TensorShape& inputs_shape = inputs->shape();",
            "    const int64 max_time = inputs_shape.dim_size(0);",
            "    OP_REQUIRES(ctx, max_time != 0,",
            "                errors::InvalidArgument(",
            "                    \"Max time or first dimension of input cannot be 0.\"));",
            "    const int64 batch_size = inputs_shape.dim_size(1);",
            "    const int64 num_classes_raw = inputs_shape.dim_size(2);",
            "    OP_REQUIRES(",
            "        ctx, FastBoundsCheck(num_classes_raw, std::numeric_limits<int>::max()),"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vvg4-vgrv-xfr7",
    "API Signature": "tf.raw_ops.CTCLoss(\n    inputs,\n    labels_indices,\n    labels_values,\n    sequence_length,\n    preprocess_collapse_repeated=False,\n    ctc_merge_repeated=True,\n    ignore_longer_outputs_than_inputs=False,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "labels_indices = tf.constant([], shape=[0, 2], dtype=tf.int64)\nlabels_values = tf.constant([], shape=[0], dtype=tf.int32)"
},
{
    "Title": "\n        Heap buffer overflow in `BandedTriangularSolve`\n      ",
    "Bug description": "An attacker can trigger a heap buffer overflow in Eigen implementation of  tf.raw_ops.BandedTriangularSolve :",
    "Sample Code": "import numpy as np\n  \nmatrix_array = np.array([])\nmatrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(0,1)),dtype=tf.float32)\nrhs_array = np.array([1,1])\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(1,2)),dtype=tf.float32)\n)\ntf.raw_ops.BandedTriangularSolve(matrix=matrix_tensor,rhs=rhs_tensor)",
    "Code change": [
        "@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\n                                           \" for dimension \", i));\n     }\n \n+    OP_REQUIRES(\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\n+        errors::InvalidArgument(\n+            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\n     const int num_dims = a_indices_t->dim_size(1);\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\n     const auto b_indices_mat = b_indices_t->matrix<int64>();\n"
    ],
    "Buggy Code": [
        [
            "    }",
            "",
            "    const int num_dims = a_indices_t->dim_size(1);",
            "    const auto a_indices_mat = a_indices_t->matrix<int64>();",
            "    const auto b_indices_mat = b_indices_t->matrix<int64>();",
            "    std::vector<T> a_augmented_values, b_augmented_values;",
            "    std::vector<std::pair<bool, int64>> entries_to_copy;  // from_a?, idx",
            "    UnionSparseIndicesAndValues(a_indices_mat, a_values, a_nnz, b_indices_mat,",
            "                                b_values, b_nnz, num_dims, &a_augmented_values,",
            "                                &b_augmented_values, &entries_to_copy);",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    }",
            "",
            "    OP_REQUIRES(",
            "        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),",
            "        errors::InvalidArgument(",
            "            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),",
            "            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));",
            "    const int num_dims = a_indices_t->dim_size(1);",
            "    const auto a_indices_mat = a_indices_t->matrix<int64>();",
            "    const auto b_indices_mat = b_indices_t->matrix<int64>();",
            "    std::vector<T> a_augmented_values, b_augmented_values;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2xgj-xhgf-ggjv",
    "API Signature": "tf.raw_ops.BandedTriangularSolve(\n    matrix, rhs, lower=True, adjoint=False, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "matrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(0,1)),dtype=tf.float32)\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(1,2)),dtype=tf.float32)"
},
{
    "Title": "\n        Invalid validation in `QuantizeAndDequantizeV2`\n      ",
    "Bug description": "The validation in  tf.raw_ops.QuantizeAndDequantizeV2  allows invalid values for  axis  argument:",
    "Sample Code": "input_tensor = tf.constant([0.0], shape=[1], dtype=float)\ninput_min = tf.constant(-10.0)\ninput_max = tf.constant(-10.0)\n\ntf.raw_ops.QuantizeAndDequantizeV2(\n  input=input_tensor, input_min=input_min, input_max=input_max,\n  signed_input=False, num_bits=1, range_given=False, round_mode='HALF_TO_EVEN',\n  ,\n  narrow_range=False, axis=-2)",
    "Code change": [
        "@@ -72,6 +72,9 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(\n+        ctx, axis_ >= -1,\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n     OP_REQUIRES(\n         ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n         errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& input = ctx->input(0);",
            "    OP_REQUIRES(",
            "        ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
            "        errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,",
            "                                \" but is rank \", input.shape().dims()));",
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    Tensor input_min_tensor;",
            "    Tensor input_max_tensor;"
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& input = ctx->input(0);",
            "    OP_REQUIRES(",
            "        ctx, axis_ >= -1,",
            "        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
            "    OP_REQUIRES(",
            "        ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
            "        errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,",
            "                                \" but is rank \", input.shape().dims()));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mq5c-prh3-3f3h",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV2(\n    input,\n    input_min,\n    input_max,\n    signed_input=True,\n    num_bits=8,\n    range_given=False,\n    round_mode='HALF_TO_EVEN',\n    narrow_range=False,\n    axis=-1,\n    name=None\n)\n",
    "Score": 0.14028776978417265,
    "Anomaly": "Tensor Rank Confusion",
    "Anomaly Description": "Tensor Rank Confusion",
    "Category": "Tensor",
    "Argument": "axis=-2"
},
{
    "Title": "\n        Incomplete validation in `SparseReshape`\n      ",
    "Bug description": "Incomplete validation in  SparseReshape  results in a denial of service based on a  CHECK -failure.",
    "Sample Code": "input_indices = tf.constant(41, shape=[1, 1], dtype=tf.int64)\ninput_shape = tf.zeros([11], dtype=tf.int64)\nnew_shape = tf.zeros([1], dtype=tf.int64)\n\ntf.raw_ops.SparseReshape(input_indices=input_indices,\n    input_shape=input_shape,\n    ,\n    new_shape=new_shape)",
    "Code change": [
        "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/reshape_util.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -38,6 +39,17 @@ class SparseReshapeOp : public OpKernel {\n   explicit SparseReshapeOp(OpKernelConstruction* context) : OpKernel(context) {}\n \n   void Compute(OpKernelContext* context) override {\n+    const Tensor& input_indices_in = context->input(0);\n+    const Tensor& input_shape_in = context->input(1);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n+                errors::InvalidArgument(\"Input must be a matrix.\"));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n+                errors::InvalidArgument(\"Input shape must be a vector.\"));\n+    OP_REQUIRES(context,\n+                input_indices_in.dim_size(1) == input_shape_in.dim_size(0),\n+                errors::InvalidArgument(\n+                    \"Input tensor rank must match input shape length.\"));\n     ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),\n                                 context->input(2), 0 /* output indices index */,\n                                 1 /* output shape index */);\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/kernels/reshape_util.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using CPUDevice = Eigen::ThreadPoolDevice;",
            "using GPUDevice = Eigen::GpuDevice;"
        ],
        [
            "  void Compute(OpKernelContext* context) override {",
            "    ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),",
            "                                context->input(2), 0 /* output indices index */,",
            "                                1 /* output shape index */);",
            "  }",
            "};",
            "",
            "REGISTER_KERNEL_BUILDER(Name(\"SparseReshape\").Device(DEVICE_CPU),",
            "                        SparseReshapeOp<CPUDevice>)",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "REGISTER_KERNEL_BUILDER(Name(\"SparseReshape\")",
            "                            .Device(DEVICE_GPU)",
            "                            .HostMemory(\"input_shape\")",
            "                            .HostMemory(\"new_shape\")",
            "                            .HostMemory(\"output_shape\"),",
            "                        SparseReshapeOp<GPUDevice>)"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/kernels/reshape_util.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using CPUDevice = Eigen::ThreadPoolDevice;"
        ],
        [
            "",
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input_indices_in = context->input(0);",
            "    const Tensor& input_shape_in = context->input(1);",
            "",
            "    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),",
            "                errors::InvalidArgument(\"Input must be a matrix.\"));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),",
            "                errors::InvalidArgument(\"Input shape must be a vector.\"));",
            "    OP_REQUIRES(context,",
            "                input_indices_in.dim_size(1) == input_shape_in.dim_size(0),",
            "                errors::InvalidArgument(",
            "                    \"Input tensor rank must match input shape length.\"));",
            "    ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),",
            "                                context->input(2), 0 /* output indices index */,",
            "                                1 /* output shape index */);",
            "  }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9rpc-5v9q-5r7f",
    "API Signature": "tf.raw_ops.SparseReshape(\n    input_indices, input_shape, new_shape, name=None\n)\n",
    "Score": 0.02158273381294964,
    "Anomaly": "Scalar input tensor",
    "Anomaly Description": "A scalar input tensor refers to a tensor with a rank of 0, meaning it has zero dimensions. In other words, a scalar input tensor represents a single value without any additional structure or dimensions.",
    "Category": "Tensor",
    "Argument": "input_indices = tf.constant(41, shape=[1, 1], dtype=tf.int64)"
},
{
    "Title": "\n        Incomplete validation in `SparseReshape`\n      ",
    "Bug description": "Incomplete validation in  SparseReshape  results in a denial of service based on a  CHECK -failure.",
    "Sample Code": "input_indices = tf.constant(41, shape=[1, 1], dtype=tf.int64)\ninput_shape = tf.zeros([11], dtype=tf.int64)\nnew_shape = tf.zeros([1], dtype=tf.int64)\n\ntf.raw_ops.SparseReshape(input_indices=input_indices,\n    input_shape=input_shape,\n    ,\n    new_shape=new_shape)",
    "Code change": [
        "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/reshape_util.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -38,6 +39,17 @@ class SparseReshapeOp : public OpKernel {\n   explicit SparseReshapeOp(OpKernelConstruction* context) : OpKernel(context) {}\n \n   void Compute(OpKernelContext* context) override {\n+    const Tensor& input_indices_in = context->input(0);\n+    const Tensor& input_shape_in = context->input(1);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n+                errors::InvalidArgument(\"Input must be a matrix.\"));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n+                errors::InvalidArgument(\"Input shape must be a vector.\"));\n+    OP_REQUIRES(context,\n+                input_indices_in.dim_size(1) == input_shape_in.dim_size(0),\n+                errors::InvalidArgument(\n+                    \"Input tensor rank must match input shape length.\"));\n     ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),\n                                 context->input(2), 0 /* output indices index */,\n                                 1 /* output shape index */);\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/kernels/reshape_util.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using CPUDevice = Eigen::ThreadPoolDevice;",
            "using GPUDevice = Eigen::GpuDevice;"
        ],
        [
            "  void Compute(OpKernelContext* context) override {",
            "    ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),",
            "                                context->input(2), 0 /* output indices index */,",
            "                                1 /* output shape index */);",
            "  }",
            "};",
            "",
            "REGISTER_KERNEL_BUILDER(Name(\"SparseReshape\").Device(DEVICE_CPU),",
            "                        SparseReshapeOp<CPUDevice>)",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "REGISTER_KERNEL_BUILDER(Name(\"SparseReshape\")",
            "                            .Device(DEVICE_GPU)",
            "                            .HostMemory(\"input_shape\")",
            "                            .HostMemory(\"new_shape\")",
            "                            .HostMemory(\"output_shape\"),",
            "                        SparseReshapeOp<GPUDevice>)"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/kernels/reshape_util.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using CPUDevice = Eigen::ThreadPoolDevice;"
        ],
        [
            "",
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input_indices_in = context->input(0);",
            "    const Tensor& input_shape_in = context->input(1);",
            "",
            "    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),",
            "                errors::InvalidArgument(\"Input must be a matrix.\"));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),",
            "                errors::InvalidArgument(\"Input shape must be a vector.\"));",
            "    OP_REQUIRES(context,",
            "                input_indices_in.dim_size(1) == input_shape_in.dim_size(0),",
            "                errors::InvalidArgument(",
            "                    \"Input tensor rank must match input shape length.\"));",
            "    ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),",
            "                                context->input(2), 0 /* output indices index */,",
            "                                1 /* output shape index */);",
            "  }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9rpc-5v9q-5r7f",
    "API Signature": "tf.raw_ops.SparseReshape(\n    input_indices, input_shape, new_shape, name=None\n)\n",
    "Score": 0.02158273381294964,
    "Anomaly": "Scalar input tensor",
    "Anomaly Description": "A scalar input tensor refers to a tensor with a rank of 0, meaning it has zero dimensions. In other words, a scalar input tensor represents a single value without any additional structure or dimensions.",
    "Category": "Tensor",
    "Argument": "input_shape = tf.zeros([11], dtype=tf.int64)"
},
{
    "Title": "\n        Incomplete validation in `SparseReshape`\n      ",
    "Bug description": "Incomplete validation in  SparseReshape  results in a denial of service based on a  CHECK -failure.",
    "Sample Code": "input_indices = tf.constant(41, shape=[1, 1], dtype=tf.int64)\ninput_shape = tf.zeros([11], dtype=tf.int64)\nnew_shape = tf.zeros([1], dtype=tf.int64)\n\ntf.raw_ops.SparseReshape(input_indices=input_indices,\n    input_shape=input_shape,\n    ,\n    new_shape=new_shape)",
    "Code change": [
        "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/reshape_util.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -38,6 +39,17 @@ class SparseReshapeOp : public OpKernel {\n   explicit SparseReshapeOp(OpKernelConstruction* context) : OpKernel(context) {}\n \n   void Compute(OpKernelContext* context) override {\n+    const Tensor& input_indices_in = context->input(0);\n+    const Tensor& input_shape_in = context->input(1);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n+                errors::InvalidArgument(\"Input must be a matrix.\"));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n+                errors::InvalidArgument(\"Input shape must be a vector.\"));\n+    OP_REQUIRES(context,\n+                input_indices_in.dim_size(1) == input_shape_in.dim_size(0),\n+                errors::InvalidArgument(\n+                    \"Input tensor rank must match input shape length.\"));\n     ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),\n                                 context->input(2), 0 /* output indices index */,\n                                 1 /* output shape index */);\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/kernels/reshape_util.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using CPUDevice = Eigen::ThreadPoolDevice;",
            "using GPUDevice = Eigen::GpuDevice;"
        ],
        [
            "  void Compute(OpKernelContext* context) override {",
            "    ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),",
            "                                context->input(2), 0 /* output indices index */,",
            "                                1 /* output shape index */);",
            "  }",
            "};",
            "",
            "REGISTER_KERNEL_BUILDER(Name(\"SparseReshape\").Device(DEVICE_CPU),",
            "                        SparseReshapeOp<CPUDevice>)",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "REGISTER_KERNEL_BUILDER(Name(\"SparseReshape\")",
            "                            .Device(DEVICE_GPU)",
            "                            .HostMemory(\"input_shape\")",
            "                            .HostMemory(\"new_shape\")",
            "                            .HostMemory(\"output_shape\"),",
            "                        SparseReshapeOp<GPUDevice>)"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/kernels/reshape_util.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "namespace tensorflow {",
            "",
            "using CPUDevice = Eigen::ThreadPoolDevice;"
        ],
        [
            "",
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input_indices_in = context->input(0);",
            "    const Tensor& input_shape_in = context->input(1);",
            "",
            "    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),",
            "                errors::InvalidArgument(\"Input must be a matrix.\"));",
            "    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),",
            "                errors::InvalidArgument(\"Input shape must be a vector.\"));",
            "    OP_REQUIRES(context,",
            "                input_indices_in.dim_size(1) == input_shape_in.dim_size(0),",
            "                errors::InvalidArgument(",
            "                    \"Input tensor rank must match input shape length.\"));",
            "    ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),",
            "                                context->input(2), 0 /* output indices index */,",
            "                                1 /* output shape index */);",
            "  }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9rpc-5v9q-5r7f",
    "API Signature": "tf.raw_ops.SparseReshape(\n    input_indices, input_shape, new_shape, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "new_shape = tf.zeros([1], dtype=tf.int64)"
},
{
    "Title": "\n        Incomplete validation in `SparseSparseMinimum`\n      ",
    "Bug description": "Incomplete validation in  SparseAdd  results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:",
    "Sample Code": "a_indices = tf.ones([45, 92], dtype=tf.int64)\na_values = tf.ones([45], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)\nb_values = tf.ones([1], dtype=tf.int64)\nb_shape = tf.ones([1], dtype=tf.int64)\n                    \ntf.raw_ops.SparseSparseMinimum(a_indices=a_indices,\n    a_values=a_values,\n    a_shape=a_shape,\n    b_indices=b_indices,\n    b_values=b_values,\n    ,\n    b_shape=b_shape)",
    "Code change": [
        "@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\n                                           \" for dimension \", i));\n     }\n \n+    OP_REQUIRES(\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\n+        errors::InvalidArgument(\n+            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\n     const int num_dims = a_indices_t->dim_size(1);\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\n     const auto b_indices_mat = b_indices_t->matrix<int64>();\n"
    ],
    "Buggy Code": [
        [
            "    }",
            "",
            "    const int num_dims = a_indices_t->dim_size(1);",
            "    const auto a_indices_mat = a_indices_t->matrix<int64>();",
            "    const auto b_indices_mat = b_indices_t->matrix<int64>();",
            "    std::vector<T> a_augmented_values, b_augmented_values;",
            "    std::vector<std::pair<bool, int64>> entries_to_copy;  // from_a?, idx",
            "    UnionSparseIndicesAndValues(a_indices_mat, a_values, a_nnz, b_indices_mat,",
            "                                b_values, b_nnz, num_dims, &a_augmented_values,",
            "                                &b_augmented_values, &entries_to_copy);",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    }",
            "",
            "    OP_REQUIRES(",
            "        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),",
            "        errors::InvalidArgument(",
            "            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),",
            "            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));",
            "    const int num_dims = a_indices_t->dim_size(1);",
            "    const auto a_indices_mat = a_indices_t->matrix<int64>();",
            "    const auto b_indices_mat = b_indices_t->matrix<int64>();",
            "    std::vector<T> a_augmented_values, b_augmented_values;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gv26-jpj9-c8gq",
    "API Signature": "tf.raw_ops.SparseSparseMinimum(\n    a_indices, a_values, a_shape, b_indices, b_values, b_shape, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "a_indices = tf.ones([45, 92], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)"
},
{
    "Title": "\n        Incomplete validation in `SparseSparseMinimum`\n      ",
    "Bug description": "Incomplete validation in  SparseAdd  results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:",
    "Sample Code": "a_indices = tf.ones([45, 92], dtype=tf.int64)\na_values = tf.ones([45], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)\nb_values = tf.ones([1], dtype=tf.int64)\nb_shape = tf.ones([1], dtype=tf.int64)\n                    \ntf.raw_ops.SparseSparseMinimum(a_indices=a_indices,\n    a_values=a_values,\n    a_shape=a_shape,\n    b_indices=b_indices,\n    b_values=b_values,\n    ,\n    b_shape=b_shape)",
    "Code change": [
        "@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\n                                           \" for dimension \", i));\n     }\n \n+    OP_REQUIRES(\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\n+        errors::InvalidArgument(\n+            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\n     const int num_dims = a_indices_t->dim_size(1);\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\n     const auto b_indices_mat = b_indices_t->matrix<int64>();\n"
    ],
    "Buggy Code": [
        [
            "    }",
            "",
            "    const int num_dims = a_indices_t->dim_size(1);",
            "    const auto a_indices_mat = a_indices_t->matrix<int64>();",
            "    const auto b_indices_mat = b_indices_t->matrix<int64>();",
            "    std::vector<T> a_augmented_values, b_augmented_values;",
            "    std::vector<std::pair<bool, int64>> entries_to_copy;  // from_a?, idx",
            "    UnionSparseIndicesAndValues(a_indices_mat, a_values, a_nnz, b_indices_mat,",
            "                                b_values, b_nnz, num_dims, &a_augmented_values,",
            "                                &b_augmented_values, &entries_to_copy);",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    }",
            "",
            "    OP_REQUIRES(",
            "        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),",
            "        errors::InvalidArgument(",
            "            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),",
            "            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));",
            "    const int num_dims = a_indices_t->dim_size(1);",
            "    const auto a_indices_mat = a_indices_t->matrix<int64>();",
            "    const auto b_indices_mat = b_indices_t->matrix<int64>();",
            "    std::vector<T> a_augmented_values, b_augmented_values;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gv26-jpj9-c8gq",
    "API Signature": "tf.raw_ops.SparseSparseMinimum(\n    a_indices, a_values, a_shape, b_indices, b_values, b_shape, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "a_indices = tf.ones([45, 92], dtype=tf.int64) \na_shape = tf.ones([1], dtype=tf.int64)"
},
{
    "Title": "\n        Incomplete validation in `SparseSparseMinimum`\n      ",
    "Bug description": "Incomplete validation in  SparseAdd  results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:",
    "Sample Code": "a_indices = tf.ones([45, 92], dtype=tf.int64)\na_values = tf.ones([45], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)\nb_values = tf.ones([1], dtype=tf.int64)\nb_shape = tf.ones([1], dtype=tf.int64)\n                    \ntf.raw_ops.SparseSparseMinimum(a_indices=a_indices,\n    a_values=a_values,\n    a_shape=a_shape,\n    b_indices=b_indices,\n    b_values=b_values,\n    ,\n    b_shape=b_shape)",
    "Code change": [
        "@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\n                                           \" for dimension \", i));\n     }\n \n+    OP_REQUIRES(\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\n+        errors::InvalidArgument(\n+            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\n     const int num_dims = a_indices_t->dim_size(1);\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\n     const auto b_indices_mat = b_indices_t->matrix<int64>();\n"
    ],
    "Buggy Code": [
        [
            "    }",
            "",
            "    const int num_dims = a_indices_t->dim_size(1);",
            "    const auto a_indices_mat = a_indices_t->matrix<int64>();",
            "    const auto b_indices_mat = b_indices_t->matrix<int64>();",
            "    std::vector<T> a_augmented_values, b_augmented_values;",
            "    std::vector<std::pair<bool, int64>> entries_to_copy;  // from_a?, idx",
            "    UnionSparseIndicesAndValues(a_indices_mat, a_values, a_nnz, b_indices_mat,",
            "                                b_values, b_nnz, num_dims, &a_augmented_values,",
            "                                &b_augmented_values, &entries_to_copy);",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    }",
            "",
            "    OP_REQUIRES(",
            "        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),",
            "        errors::InvalidArgument(",
            "            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),",
            "            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));",
            "    const int num_dims = a_indices_t->dim_size(1);",
            "    const auto a_indices_mat = a_indices_t->matrix<int64>();",
            "    const auto b_indices_mat = b_indices_t->matrix<int64>();",
            "    std::vector<T> a_augmented_values, b_augmented_values;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gv26-jpj9-c8gq",
    "API Signature": "tf.raw_ops.SparseSparseMinimum(\n    a_indices, a_values, a_shape, b_indices, b_values, b_shape, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "a_indices = tf.ones([45, 92], dtype=tf.int64)\na_values = tf.ones([45], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)\nb_values = tf.ones([1], dtype=tf.int64)\nb_shape = tf.ones([1], dtype=tf.int64)"
},
{
    "Title": "\n        Incomplete validation in `SparseAdd`\n      ",
    "Bug description": "Incomplete validation in  SparseAdd  results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:",
    "Sample Code": "a_indices = tf.zeros([10, 97], dtype=tf.int64)\na_values = tf.zeros([10], dtype=tf.int64)\na_shape = tf.zeros([0], dtype=tf.int64)\n\nb_indices = tf.zeros([0, 0], dtype=tf.int64)\nb_values = tf.zeros([0], dtype=tf.int64)\nb_shape = tf.zeros([0], dtype=tf.int64)\n  \nthresh = 0\n\ntf.raw_ops.SparseAdd(a_indices=a_indices,\n                    a_values=a_values,\n                    a_shape=a_shape,\n                    b_indices=b_indices,\n                    b_values=b_values,\n                    b_shape=b_shape,\n                    ,\n                    thresh=thresh)",
    "Code change": [
        "@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n@@ -101,6 +102,10 @@ class SparseAddOp : public OpKernel {\n     std::vector<T> out_values;\n     const int num_dims = a_shape->dim_size(0);\n \n+    OP_REQUIRES(ctx, num_dims > 0,\n+                errors::InvalidArgument(\"Invalid input_a shape. Received: \",\n+                                        a_shape->DebugString()));\n+\n     // The input and output sparse tensors are assumed to be ordered along\n     // increasing dimension number.\n     int64 i = 0, j = 0;\n"
    ],
    "Buggy Code": [
        [
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/util/sparse/sparse_tensor.h\""
        ],
        [
            "",
            "    // The input and output sparse tensors are assumed to be ordered along",
            "    // increasing dimension number.",
            "    int64 i = 0, j = 0;",
            "    T s;",
            "    while (i < a_nnz && j < b_nnz) {",
            "      switch (sparse::DimComparator::cmp(a_indices_mat, b_indices_mat, i, j,",
            "                                         num_dims)) {",
            "        case -1:",
            "          entries_to_copy.emplace_back(true, i);"
        ]
    ],
    "Clean Code": [
        [
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\""
        ],
        [
            "    const int num_dims = a_shape->dim_size(0);",
            "",
            "    OP_REQUIRES(ctx, num_dims > 0,",
            "                errors::InvalidArgument(\"Invalid input_a shape. Received: \",",
            "                                        a_shape->DebugString()));",
            "",
            "    // The input and output sparse tensors are assumed to be ordered along",
            "    // increasing dimension number.",
            "    int64 i = 0, j = 0;",
            "    T s;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cjc7-49v2-jp64",
    "API Signature": "tf.raw_ops.SparseAdd(\n    a_indices,\n    a_values,\n    a_shape,\n    b_indices,\n    b_values,\n    b_shape,\n    thresh,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "a_indices = tf.zeros([10, 97], dtype=tf.int64) \na_values = tf.zeros([10], dtype=tf.int64)"
},
{
    "Title": "\n        Incomplete validation in `SparseAdd`\n      ",
    "Bug description": "Incomplete validation in  SparseAdd  results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:",
    "Sample Code": "a_indices = tf.zeros([10, 97], dtype=tf.int64)\na_values = tf.zeros([10], dtype=tf.int64)\na_shape = tf.zeros([0], dtype=tf.int64)\n\nb_indices = tf.zeros([0, 0], dtype=tf.int64)\nb_values = tf.zeros([0], dtype=tf.int64)\nb_shape = tf.zeros([0], dtype=tf.int64)\n  \nthresh = 0\n\ntf.raw_ops.SparseAdd(a_indices=a_indices,\n                    a_values=a_values,\n                    a_shape=a_shape,\n                    b_indices=b_indices,\n                    b_values=b_values,\n                    b_shape=b_shape,\n                    ,\n                    thresh=thresh)",
    "Code change": [
        "@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n@@ -101,6 +102,10 @@ class SparseAddOp : public OpKernel {\n     std::vector<T> out_values;\n     const int num_dims = a_shape->dim_size(0);\n \n+    OP_REQUIRES(ctx, num_dims > 0,\n+                errors::InvalidArgument(\"Invalid input_a shape. Received: \",\n+                                        a_shape->DebugString()));\n+\n     // The input and output sparse tensors are assumed to be ordered along\n     // increasing dimension number.\n     int64 i = 0, j = 0;\n"
    ],
    "Buggy Code": [
        [
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/util/sparse/sparse_tensor.h\""
        ],
        [
            "",
            "    // The input and output sparse tensors are assumed to be ordered along",
            "    // increasing dimension number.",
            "    int64 i = 0, j = 0;",
            "    T s;",
            "    while (i < a_nnz && j < b_nnz) {",
            "      switch (sparse::DimComparator::cmp(a_indices_mat, b_indices_mat, i, j,",
            "                                         num_dims)) {",
            "        case -1:",
            "          entries_to_copy.emplace_back(true, i);"
        ]
    ],
    "Clean Code": [
        [
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\""
        ],
        [
            "    const int num_dims = a_shape->dim_size(0);",
            "",
            "    OP_REQUIRES(ctx, num_dims > 0,",
            "                errors::InvalidArgument(\"Invalid input_a shape. Received: \",",
            "                                        a_shape->DebugString()));",
            "",
            "    // The input and output sparse tensors are assumed to be ordered along",
            "    // increasing dimension number.",
            "    int64 i = 0, j = 0;",
            "    T s;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cjc7-49v2-jp64",
    "API Signature": "tf.raw_ops.SparseAdd(\n    a_indices,\n    a_values,\n    a_shape,\n    b_indices,\n    b_values,\n    b_shape,\n    thresh,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "a_shape = tf.zeros([0], dtype=tf.int64)\nb_indices = tf.zeros([0, 0], dtype=tf.int64)\nb_values = tf.zeros([0], dtype=tf.int64)\nb_shape = tf.zeros([0], dtype=tf.int64)"
},
{
    "Title": "\n        Heap OOB and null pointer dereference in `RaggedTensorToTensor`\n      ",
    "Bug description": "Due to lack of validation in  tf.raw_ops.RaggedTensorToTensor , an attacker can exploit an undefined behavior if input arguments are empty:",
    "Sample Code": "shape = tf.constant([-1, -1], shape=[2], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\ndefault_value = tf.constant(404, dtype=tf.int64)\nrow = tf.constant([269, 404, 0, 0, 0, 0, 0], shape=[7], dtype=tf.int64)\nrows = [row]\ntypes = ['ROW_SPLITS']\n\ntf.raw_ops.RaggedTensorToTensor(\n  shape=shape, values=values, default_value=default_value, \n  , \n  row_partition_tensors=rows, row_partition_types=types)",
    "Code change": [
        "@@ -208,7 +208,7 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n   }\n \n   void CalculateOutputIndexRowSplit(\n-      const RowPartitionTensor& row_split,\n+      OpKernelContext* context, const RowPartitionTensor& row_split,\n       const vector<INDEX_TYPE>& parent_output_index,\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n       vector<INDEX_TYPE>* result) {\n@@ -233,7 +233,8 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n       }\n     }\n     if (row_split_size > 0) {\n-      DCHECK_EQ(result->size(), row_split(row_split_size - 1));\n+      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),\n+                  errors::InvalidArgument(\"Invalid row split size.\"));\n     }\n   }\n \n@@ -259,7 +260,7 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n   // result[7] = -1 because parent_output_index[value_rowids[6]] == -1\n   // result[8] = parent_output_index[value_rowids[7]]\n   void CalculateOutputIndexValueRowID(\n-      const RowPartitionTensor& value_rowids,\n+      OpKernelContext* context, const RowPartitionTensor& value_rowids,\n       const vector<INDEX_TYPE>& parent_output_index,\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n       vector<INDEX_TYPE>* result) {\n@@ -293,7 +294,8 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n       }\n       result->push_back(current_output_index);\n     }\n-    DCHECK_EQ(result->size(), value_rowids.size());\n+    OP_REQUIRES(context, result->size() == value_rowids.size(),\n+                errors::InvalidArgument(\"Invalid row ids.\"));\n   }\n \n   Status CalculateOutputIndex(OpKernelContext* context, int dimension,\n@@ -307,13 +309,13 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n     switch (partition_type) {\n       case RowPartitionType::VALUE_ROWIDS:\n         CalculateOutputIndexValueRowID(\n-            row_partition_tensor, parent_output_index, output_index_multiplier,\n-            output_size, result);\n+            context, row_partition_tensor, parent_output_index,\n+            output_index_multiplier, output_size, result);\n         return tensorflow::Status::OK();\n       case RowPartitionType::ROW_SPLITS:\n-        CalculateOutputIndexRowSplit(row_partition_tensor, parent_output_index,\n-                                     output_index_multiplier, output_size,\n-                                     result);\n+        CalculateOutputIndexRowSplit(\n+            context, row_partition_tensor, parent_output_index,\n+            output_index_multiplier, output_size, result);\n         return tensorflow::Status::OK();\n       default:\n         return errors::InvalidArgument(\n"
    ],
    "Buggy Code": [
        [
            "",
            "  void CalculateOutputIndexRowSplit(",
            "      const RowPartitionTensor& row_split,",
            "      const vector<INDEX_TYPE>& parent_output_index,",
            "      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,",
            "      vector<INDEX_TYPE>* result) {",
            "    INDEX_TYPE row_split_size = row_split.size();"
        ],
        [
            "    }",
            "    if (row_split_size > 0) {",
            "      DCHECK_EQ(result->size(), row_split(row_split_size - 1));",
            "    }",
            "  }",
            "",
            "  // Calculate the output index of the first element of a list.",
            "  // The parent_output_index is the same computation for the previous list."
        ],
        [
            "  void CalculateOutputIndexValueRowID(",
            "      const RowPartitionTensor& value_rowids,",
            "      const vector<INDEX_TYPE>& parent_output_index,",
            "      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,",
            "      vector<INDEX_TYPE>* result) {",
            "    const INDEX_TYPE index_size = value_rowids.size();",
            "    result->reserve(index_size);"
        ],
        [
            "    }",
            "    DCHECK_EQ(result->size(), value_rowids.size());",
            "  }",
            "",
            "  Status CalculateOutputIndex(OpKernelContext* context, int dimension,",
            "                              const vector<INDEX_TYPE>& parent_output_index,",
            "                              INDEX_TYPE output_index_multiplier,",
            "                              INDEX_TYPE output_size,"
        ],
        [
            "            row_partition_tensor, parent_output_index, output_index_multiplier,",
            "            output_size, result);",
            "        return tensorflow::Status::OK();",
            "      case RowPartitionType::ROW_SPLITS:",
            "        CalculateOutputIndexRowSplit(row_partition_tensor, parent_output_index,",
            "                                     output_index_multiplier, output_size,",
            "                                     result);",
            "        return tensorflow::Status::OK();",
            "      default:",
            "        return errors::InvalidArgument(",
            "            \"Unsupported partition type:\",",
            "            RowPartitionTypeToString(partition_type));",
            "    }"
        ]
    ],
    "Clean Code": [
        [
            "",
            "  void CalculateOutputIndexRowSplit(",
            "      OpKernelContext* context, const RowPartitionTensor& row_split,",
            "      const vector<INDEX_TYPE>& parent_output_index,",
            "      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,",
            "      vector<INDEX_TYPE>* result) {",
            "    INDEX_TYPE row_split_size = row_split.size();"
        ],
        [
            "    }",
            "    if (row_split_size > 0) {",
            "      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),",
            "                  errors::InvalidArgument(\"Invalid row split size.\"));",
            "    }",
            "  }",
            "",
            "  // Calculate the output index of the first element of a list."
        ],
        [
            "  // result[8] = parent_output_index[value_rowids[7]]",
            "  void CalculateOutputIndexValueRowID(",
            "      OpKernelContext* context, const RowPartitionTensor& value_rowids,",
            "      const vector<INDEX_TYPE>& parent_output_index,",
            "      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,",
            "      vector<INDEX_TYPE>* result) {",
            "    const INDEX_TYPE index_size = value_rowids.size();"
        ],
        [
            "      result->push_back(current_output_index);",
            "    }",
            "    OP_REQUIRES(context, result->size() == value_rowids.size(),",
            "                errors::InvalidArgument(\"Invalid row ids.\"));",
            "  }",
            "",
            "  Status CalculateOutputIndex(OpKernelContext* context, int dimension,",
            "                              const vector<INDEX_TYPE>& parent_output_index,"
        ],
        [
            "      case RowPartitionType::VALUE_ROWIDS:",
            "        CalculateOutputIndexValueRowID(",
            "            context, row_partition_tensor, parent_output_index,",
            "            output_index_multiplier, output_size, result);",
            "        return tensorflow::Status::OK();",
            "      case RowPartitionType::ROW_SPLITS:",
            "        CalculateOutputIndexRowSplit(",
            "            context, row_partition_tensor, parent_output_index,",
            "            output_index_multiplier, output_size, result);",
            "        return tensorflow::Status::OK();",
            "      default:",
            "        return errors::InvalidArgument(",
            "            \"Unsupported partition type:\","
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rgvq-pcvf-hx75",
    "API Signature": "tf.raw_ops.RaggedTensorToTensor(\n    shape,\n    values,\n    default_value,\n    row_partition_tensors,\n    row_partition_types,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "values = tf.constant([], shape=[0], dtype=tf.int64)"
},
{
    "Title": "\n        Division by zero in TFLite's implementation of `BatchToSpaceNd`\n      ",
    "Bug description": "The implementation of the  BatchToSpaceNd  TFLite operator is  vulnerable to a division by zero error :",
    "Sample Code": "",
    "Code change": [
        "@@ -78,6 +78,7 @@ TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n   int output_batch_size = input_size->data[0];\n   for (int dim = 0; dim < spatial_dims_num; ++dim) {\n     // Number of batch must be multiple of (block_shape[dim]).\n+    TF_LITE_ENSURE(context, block_shape[dim] != 0);\n     TF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);\n     output_batch_size = output_batch_size / block_shape[dim];\n     output_size->data[dim + 1] = input_size->data[dim + 1] * block_shape[dim] -\n"
    ],
    "Buggy Code": [
        [
            "  for (int dim = 0; dim < spatial_dims_num; ++dim) {",
            "    // Number of batch must be multiple of (block_shape[dim]).",
            "    TF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);",
            "    output_batch_size = output_batch_size / block_shape[dim];",
            "    output_size->data[dim + 1] = input_size->data[dim + 1] * block_shape[dim] -",
            "                                 crops[dim * 2] - crops[dim * 2 + 1];",
            "  }"
        ]
    ],
    "Clean Code": [
        [
            "  for (int dim = 0; dim < spatial_dims_num; ++dim) {",
            "    // Number of batch must be multiple of (block_shape[dim]).",
            "    TF_LITE_ENSURE(context, block_shape[dim] != 0);",
            "    TF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);",
            "    output_batch_size = output_batch_size / block_shape[dim];",
            "    output_size->data[dim + 1] = input_size->data[dim + 1] * block_shape[dim] -",
            "                                 crops[dim * 2] - crops[dim * 2 + 1];"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cfx7-2xpc-8w4h",
    "API Signature": null,
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "N.A"
},
{
    "Title": "\n        Division by zero in TFLite's implementation of `SpaceToBatchNd`\n      ",
    "Bug description": "The implementation of the  SpaceToBatchNd  TFLite operator is  vulnerable to a division by zero error :",
    "Sample Code": "",
    "Code change": [
        "@@ -79,6 +79,7 @@ TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n   for (int dim = 0; dim < spatial_dims_num; ++dim) {\n     int final_dim_size = (input_size->data[dim + 1] + paddings_data[dim * 2] +\n                           paddings_data[dim * 2 + 1]);\n+    TF_LITE_ENSURE(context, block_shape[dim] != 0);\n     TF_LITE_ENSURE_EQ(context, final_dim_size % block_shape[dim], 0);\n     output_size->data[dim + 1] = final_dim_size / block_shape[dim];\n     output_batch_size *= block_shape[dim];\n"
    ],
    "Buggy Code": [
        [
            "    int final_dim_size = (input_size->data[dim + 1] + paddings_data[dim * 2] +",
            "                          paddings_data[dim * 2 + 1]);",
            "    TF_LITE_ENSURE_EQ(context, final_dim_size % block_shape[dim], 0);",
            "    output_size->data[dim + 1] = final_dim_size / block_shape[dim];",
            "    output_batch_size *= block_shape[dim];",
            "  }",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    int final_dim_size = (input_size->data[dim + 1] + paddings_data[dim * 2] +",
            "                          paddings_data[dim * 2 + 1]);",
            "    TF_LITE_ENSURE(context, block_shape[dim] != 0);",
            "    TF_LITE_ENSURE_EQ(context, final_dim_size % block_shape[dim], 0);",
            "    output_size->data[dim + 1] = final_dim_size / block_shape[dim];",
            "    output_batch_size *= block_shape[dim];",
            "  }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v52p-hfjf-wg88",
    "API Signature": "tf.raw_ops.SpaceToBatchND(\n    input, block_shape, paddings, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "N.A"
},
{
    "Title": "\n        Division by zero in TFLite's implementation of `Split`\n      ",
    "Bug description": "The implementation of the  Split  TFLite operator is  vulnerable to a division by zero error :",
    "Sample Code": "",
    "Code change": [
        "@@ -60,6 +60,7 @@ TfLiteStatus ResizeOutputTensors(TfLiteContext* context, TfLiteNode* node,\n   TF_LITE_ENSURE(context, axis_value < NumDimensions(input));\n \n   const int input_size = SizeOfDimension(input, axis_value);\n+  TF_LITE_ENSURE(context, num_splits != 0);\n   TF_LITE_ENSURE_MSG(context, input_size % num_splits == 0,\n                      \"Not an even split\");\n   const int slice_size = input_size / num_splits;\n"
    ],
    "Buggy Code": [
        [
            "",
            "  const int input_size = SizeOfDimension(input, axis_value);",
            "  TF_LITE_ENSURE_MSG(context, input_size % num_splits == 0,",
            "                     \"Not an even split\");",
            "  const int slice_size = input_size / num_splits;",
            "",
            "  for (int i = 0; i < NumOutputs(node); ++i) {"
        ]
    ],
    "Clean Code": [
        [
            "",
            "  const int input_size = SizeOfDimension(input, axis_value);",
            "  TF_LITE_ENSURE(context, num_splits != 0);",
            "  TF_LITE_ENSURE_MSG(context, input_size % num_splits == 0,",
            "                     \"Not an even split\");",
            "  const int slice_size = input_size / num_splits;",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-97wf-p777-86jq",
    "API Signature": "tf.split(\n    value, num_or_size_splits, axis=0, num=None, name='split'\n)\n",
    "Score": 0.007194244604316547,
    "Anomaly": "Zero integer argument",
    "Anomaly Description": "A zero integer argument in Python refers to an integer value of zero (0) that is passed as an argument to a function, method, or operation. It represents a numerical value of zero that is used as input for a specific computation or functionality.",
    "Category": "Integer",
    "Argument": "num_or_size_splits=0"
},
{
    "Title": "\n        Division by zero in TFLite's implementation of `OneHot`\n      ",
    "Bug description": "The implementation of the  OneHot  TFLite operator is  vulnerable to a division by zero error :",
    "Sample Code": "",
    "Code change": [
        "@@ -69,6 +69,11 @@ void OneHotComputeImpl(const OneHotContext& op_context) {\n   for (int i = 0; i < op_context.axis; ++i) {\n     prefix_dim_size *= op_context.indices->dims->data[i];\n   }\n+  if (prefix_dim_size == 0) {\n+    // If indices tensor is degenerate, return a degenerate tensor, just like\n+    // TensorFlow does.\n+    return;\n+  }\n   const int suffix_dim_size = NumElements(op_context.indices) / prefix_dim_size;\n   const int depth = *op_context.depth->data.i32;\n \n"
    ],
    "Buggy Code": [
        [
            "    prefix_dim_size *= op_context.indices->dims->data[i];",
            "  }",
            "  const int suffix_dim_size = NumElements(op_context.indices) / prefix_dim_size;",
            "  const int depth = *op_context.depth->data.i32;",
            "",
            "  const T on_value = *GetTensorData<T>(op_context.on_value);",
            "  const T off_value = *GetTensorData<T>(op_context.off_value);",
            "",
            "  // View the indices as a matrix of size:",
            "  //     prefix_dim_size x suffix_dim_size",
            "  // View the output as a matrix of size:"
        ]
    ],
    "Clean Code": [
        [
            "    prefix_dim_size *= op_context.indices->dims->data[i];",
            "  }",
            "  if (prefix_dim_size == 0) {",
            "    // If indices tensor is degenerate, return a degenerate tensor, just like",
            "    // TensorFlow does.",
            "    return;",
            "  }",
            "  const int suffix_dim_size = NumElements(op_context.indices) / prefix_dim_size;",
            "  const int depth = *op_context.depth->data.i32;",
            "",
            "  const T on_value = *GetTensorData<T>(op_context.on_value);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-j8qh-3xrq-c825",
    "API Signature": "tf.one_hot(\n    indices,\n    depth,\n    on_value=None,\n    off_value=None,\n    axis=None,\n    dtype=None,\n    name=None\n)\n",
    "Score": 0.03237410071942446,
    "Anomaly": "Zero integer list element",
    "Anomaly Description": "A zero integer list element in Python refers to an element within a list that has a value of zero. It is an integer value of zero (0) that is present as an item in a list.",
    "Category": "List",
    "Argument": "indices=[1,1,0,1],"
},
{
    "Title": "\n        Heap buffer overflow and undefined behavior in `FusedBatchNorm`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.FusedBatchNorm  is vulnerable to a heap buffer overflow:",
    "Sample Code": "import numpy as np\n\nx = tf.zeros([10, 10, 10, 1], dtype=tf.float32)\nscale = tf.constant([], shape=[0], dtype=tf.float32)\noffset = tf.constant([], shape=[0], dtype=tf.float32)\nmean = tf.constant([], shape=[0], dtype=tf.float32)\nvariance = tf.constant([], shape=[0], dtype=tf.float32)\nepsilon = 0.0\nexponential_avg_factor = 0.0\ndata_format = \"NHWC\"\nis_training = False\n\ntf.raw_ops.FusedBatchNorm(\n  x=x, scale=scale, offset=offset, mean=mean, variance=variance, \n  epsilon=epsilon, exponential_avg_factor=exponential_avg_factor,\n  ,\n  data_format=data_format, is_training=is_training)",
    "Code change": [
        "@@ -1282,6 +1282,32 @@ class FusedBatchNormOpBase : public OpKernel {\n                   errors::InvalidArgument(\"Error during tensor copy.\"));\n     }\n \n+    const auto num_channels = GetTensorDim(x, tensor_format_, 'C');\n+    OP_REQUIRES(\n+        context, scale.NumElements() == num_channels,\n+        errors::InvalidArgument(\"scale must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                scale.NumElements(), \" and \", num_channels));\n+    OP_REQUIRES(\n+        context, offset.NumElements() == num_channels,\n+        errors::InvalidArgument(\"offset must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                offset.NumElements(), \" and \", num_channels));\n+    if (estimated_mean.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"mean must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_mean.NumElements(), \" and \", num_channels));\n+    }\n+    if (estimated_variance.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"variance must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_variance.NumElements(), \" and \", num_channels));\n+    }\n+\n     if (has_side_input_) {\n       OP_REQUIRES(context, side_input->shape() == x.shape(),\n                   errors::InvalidArgument(\n@@ -1294,7 +1320,7 @@ class FusedBatchNormOpBase : public OpKernel {\n       // NOTE(ezhulenev): This requirement is coming from implementation\n       // details of cudnnBatchNormalizationForwardTrainingEx.\n       OP_REQUIRES(\n-          context, !is_training_ || x.dim_size(3) % 4 == 0,\n+          context, !is_training_ || num_channels % 4 == 0,\n           errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\n                                   \"channel dimension to be a multiple of 4.\"));\n     }\n"
    ],
    "Buggy Code": [
        [
            "    }",
            "",
            "    if (has_side_input_) {",
            "      OP_REQUIRES(context, side_input->shape() == x.shape(),",
            "                  errors::InvalidArgument(",
            "                      \"side_input shape must be equal to input shape: \",",
            "                      side_input->shape().DebugString(),",
            "                      \" != \", x.shape().DebugString()));",
            "    }",
            "",
            "    if (activation_mode_ != FbnActivationMode::kIdentity) {",
            "      // NOTE(ezhulenev): This requirement is coming from implementation",
            "      // details of cudnnBatchNormalizationForwardTrainingEx.",
            "      OP_REQUIRES(",
            "          context, !is_training_ || x.dim_size(3) % 4 == 0,",
            "          errors::InvalidArgument(\"FusedBatchNorm with activation requires \"",
            "                                  \"channel dimension to be a multiple of 4.\"));",
            "    }",
            "",
            "    Tensor* y = nullptr;",
            "    auto alloc_shape = use_reshape ? dest_shape : x_shape;",
            "    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(",
            "                                {0}, 0, alloc_shape, &y));",
            "",
            "    Tensor* batch_mean = nullptr;",
            "    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(",
            "                                {3}, 1, scale.shape(), &batch_mean));",
            "    Tensor* batch_var = nullptr;",
            "    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(",
            "                                {4}, 2, scale.shape(), &batch_var));",
            "    Tensor* saved_mean = nullptr;",
            "    OP_REQUIRES_OK(context,"
        ],
        [
            "      functor::FusedBatchNorm<Device, T, U, true>()(",
            "          context, x, scale, offset, estimated_mean, estimated_variance,",
            "          side_input, epsilon_, exponential_avg_factor_, activation_mode_, y,",
            "          batch_mean, batch_var, saved_mean, saved_maybe_inv_var,",
            "          tensor_format_, use_reserved_space);",
            "    } else {",
            "      functor::FusedBatchNorm<Device, T, U, false>()("
        ]
    ],
    "Clean Code": [
        [
            "    }",
            "",
            "    const auto num_channels = GetTensorDim(x, tensor_format_, 'C');",
            "    OP_REQUIRES(",
            "        context, scale.NumElements() == num_channels,",
            "        errors::InvalidArgument(\"scale must have the same number of elements \"",
            "                                \"as the channels of x, got \",",
            "                                scale.NumElements(), \" and \", num_channels));",
            "    OP_REQUIRES(",
            "        context, offset.NumElements() == num_channels,",
            "        errors::InvalidArgument(\"offset must have the same number of elements \"",
            "                                \"as the channels of x, got \",",
            "                                offset.NumElements(), \" and \", num_channels));",
            "    if (estimated_mean.NumElements() != 0) {",
            "      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,",
            "                  errors::InvalidArgument(",
            "                      \"mean must be empty or have the same number of \"",
            "                      \"elements as the channels of x, got \",",
            "                      estimated_mean.NumElements(), \" and \", num_channels));",
            "    }",
            "    if (estimated_variance.NumElements() != 0) {",
            "      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,",
            "                  errors::InvalidArgument(",
            "                      \"variance must be empty or have the same number of \"",
            "                      \"elements as the channels of x, got \",",
            "                      estimated_variance.NumElements(), \" and \", num_channels));",
            "    }",
            "",
            "    if (has_side_input_) {",
            "      OP_REQUIRES(context, side_input->shape() == x.shape(),",
            "                  errors::InvalidArgument(",
            "                      \"side_input shape must be equal to input shape: \","
        ],
        [
            "      // details of cudnnBatchNormalizationForwardTrainingEx.",
            "      OP_REQUIRES(",
            "          context, !is_training_ || num_channels % 4 == 0,",
            "          errors::InvalidArgument(\"FusedBatchNorm with activation requires \"",
            "                                  \"channel dimension to be a multiple of 4.\"));",
            "    }",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9xh4-23q4-v6wr",
    "API Signature": "tf.raw_ops.FusedBatchNorm(\n    x,\n    scale,\n    offset,\n    mean,\n    variance,\n    epsilon=0.0001,\n    exponential_avg_factor=1,\n    data_format='NHWC',\n    is_training=True,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "scale = tf.constant([0.0], shape=[1], dtype=tf.float32)\noffset = tf.constant([0.0], shape=[1], dtype=tf.float32)\nmean = tf.constant([0.0], shape=[1], dtype=tf.float32)\nvariance = tf.constant([0.0], shape=[1], dtype=tf.float32)"
},
{
    "Title": "\n        `CHECK`-fail due to integer overflow\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in  caused by an integer overflow in constructing a new tensor shape:",
    "Sample Code": "input_layer = 2**60-1\nsparse_data = tf.raw_ops.SparseSplit(\n    split_dim=1, \n    indices=[(0, 0), (0, 1), (0, 2), \n    (4, 3), (5, 0), (5, 1)],\n    values=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n    shape=(input_layer, input_layer),\n    num_split=2,\n    name=None\n    )\n    )",
    "Code change": [
        "@@ -63,11 +63,18 @@ class SparseSplitOp : public OpKernel {\n                                         input_shape.vec<int64>()(axis),\n                                         \"), got \", num_split_));\n \n+    // Prevent overflow by constructing the dense shape separately\n+    TensorShape dense_shape;\n+    const auto input_shape_flat = input_shape.flat<int64>();\n+    for (int i = 0; i < input_shape.NumElements(); i++) {\n+      OP_REQUIRES_OK(context,\n+                     dense_shape.AddDimWithStatus(input_shape_flat(i)));\n+    }\n+\n     sparse::SparseTensor sparse_tensor;\n     OP_REQUIRES_OK(context,\n-                   sparse::SparseTensor::Create(\n-                       input_indices, input_values,\n-                       TensorShape(input_shape.vec<int64>()), &sparse_tensor));\n+                   sparse::SparseTensor::Create(input_indices, input_values,\n+                                                dense_shape, &sparse_tensor));\n \n     std::vector<sparse::SparseTensor> outputs;\n     OP_REQUIRES_OK(context, sparse::SparseTensor::Split<T>(\n"
    ],
    "Buggy Code": [
        [
            "                                        \"), got \", num_split_));",
            "",
            "    sparse::SparseTensor sparse_tensor;",
            "    OP_REQUIRES_OK(context,",
            "                   sparse::SparseTensor::Create(",
            "                       input_indices, input_values,",
            "                       TensorShape(input_shape.vec<int64>()), &sparse_tensor));",
            "",
            "    std::vector<sparse::SparseTensor> outputs;",
            "    OP_REQUIRES_OK(context, sparse::SparseTensor::Split<T>(",
            "                                sparse_tensor, axis, num_split_, &outputs));",
            "",
            "    for (int slice_index = 0; slice_index < num_split_; ++slice_index) {",
            "      context->set_output(slice_index, outputs[slice_index].indices());",
            "      context->set_output(slice_index + num_split_,",
            "                          outputs[slice_index].values());",
            "      Tensor* shape = nullptr;",
            "      OP_REQUIRES_OK(context, context->allocate_output("
        ]
    ],
    "Clean Code": [
        [
            "                                        \"), got \", num_split_));",
            "",
            "    // Prevent overflow by constructing the dense shape separately",
            "    TensorShape dense_shape;",
            "    const auto input_shape_flat = input_shape.flat<int64>();",
            "    for (int i = 0; i < input_shape.NumElements(); i++) {",
            "      OP_REQUIRES_OK(context,",
            "                     dense_shape.AddDimWithStatus(input_shape_flat(i)));",
            "    }",
            "",
            "    sparse::SparseTensor sparse_tensor;",
            "    OP_REQUIRES_OK(context,",
            "                   sparse::SparseTensor::Create(input_indices, input_values,",
            "                                                dense_shape, &sparse_tensor));",
            "",
            "    std::vector<sparse::SparseTensor> outputs;",
            "    OP_REQUIRES_OK(context, sparse::SparseTensor::Split<T>(",
            "                                sparse_tensor, axis, num_split_, &outputs));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xvjm-fvxx-q3hv",
    "API Signature": "tf.raw_ops.SparseSplit(\n    split_dim, indices, values, shape, num_split, name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Large integer argument",
    "Anomaly Description": "A large integer argument refers to an argument passed to a function or operation that represents a large integer value. It means that the argument is an integer value that exceeds the typical range of integer values supported by the underlying programming language or system.\n\nThe specific definition of a \"large\" integer may vary depending on the context and the limitations of the programming language or system being used. For example, in Python, integers have arbitrary precision, allowing you to work with integers of any size. However, other programming languages may have predefined limits on the range of integer values they can handle.\n\nIn the context of function arguments, a large integer argument can be used to represent various concepts or quantities. It may be used to specify an index, a count, a value, or any other numerical parameter required by the function or operation.",
    "Category": "Integer",
    "Argument": "import tensorflow as tf\n\ninput_layer = 2**60-1\nsparse_data = tf.raw_ops.SparseSplit(\nsplit_dim=1, \nindices=[(0, 0), (0, 1), (0, 2), \n(4, 3), (5, 0), (5, 1)],\nvalues=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\nshape=(input_layer, input_layer),\nnum_split=2,\nname=None\n)"
},
{
    "Title": "\n        Heap OOB read in `tf.raw_ops.Dequantize`\n      ",
    "Bug description": "Due to lack of validation in  tf.raw_ops.Dequantize , an attacker can trigger a read from outside of bounds of heap allocated data:",
    "Sample Code": "input_tensor=tf.constant(\n  [75, 75, 75, 75, -6, -9, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10], shape=[5, 10], dtype=tf.int32)\ninput_tensor=tf.cast(input_tensor, dtype=tf.quint8)\nmin_range = tf.constant([-10], shape=[1], dtype=tf.float32)\nmax_range = tf.constant([24, 758, 758, 758, 758], shape=[5], dtype=tf.float32)\n  \ntf.raw_ops.Dequantize( \n  input=input_tensor, min_range=min_range, max_range=max_range, mode='SCALED',\n  ,\n  narrow_range=True, axis=0, dtype=tf.dtypes.float32)",
    "Code change": [
        "@@ -98,6 +98,18 @@ class DequantizeOp : public OpKernel {\n     if (axis_ > -1) {\n       num_slices = input.dim_size(axis_);\n     }\n+    OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,\n+                errors::InvalidArgument(\n+                    \"input_min_tensor must have as many elements as input on \"\n+                    \"the dequantization axis (\",\n+                    axis_, \"), got \", input_min_tensor.NumElements(),\n+                    \", expected \", num_slices));\n+    OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,\n+                errors::InvalidArgument(\n+                    \"input_max_tensor must have as many elements as input on \"\n+                    \"the dequantization axis (\",\n+                    axis_, \"), got \", input_max_tensor.NumElements(),\n+                    \", expected \", num_slices));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n"
    ],
    "Buggy Code": [
        [
            "      num_slices = input.dim_size(axis_);",
            "    }",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
            "    Tensor float_output =",
            "        need_cast_ ? tensorflow::Tensor(DT_FLOAT, input.shape()) : *output;",
            "    if (num_slices == 1) {",
            "      const float min_range = input_min_tensor.flat<float>()(0);",
            "      const float max_range = input_max_tensor.flat<float>()(0);",
            "      DequantizeTensor(ctx, input, min_range, max_range, &float_output);",
            "    } else {",
            "      OP_REQUIRES(ctx, mode_ != QUANTIZE_MODE_MIN_FIRST,",
            "                  errors::Unimplemented(\"MIN_FIRST mode is not implemented for \"",
            "                                        \"Dequantize with axis != -1.\"));",
            "",
            "      int64 pre_dim = 1, post_dim = 1;",
            "      for (int i = 0; i < axis_; ++i) {"
        ]
    ],
    "Clean Code": [
        [
            "      num_slices = input.dim_size(axis_);",
            "    }",
            "    OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,",
            "                errors::InvalidArgument(",
            "                    \"input_min_tensor must have as many elements as input on \"",
            "                    \"the dequantization axis (\",",
            "                    axis_, \"), got \", input_min_tensor.NumElements(),",
            "                    \", expected \", num_slices));",
            "    OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,",
            "                errors::InvalidArgument(",
            "                    \"input_max_tensor must have as many elements as input on \"",
            "                    \"the dequantization axis (\",",
            "                    axis_, \"), got \", input_max_tensor.NumElements(),",
            "                    \", expected \", num_slices));",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
            "    Tensor float_output ="
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c45w-2wxr-pp53",
    "API Signature": "tf.raw_ops.Dequantize(\n    input,\n    min_range,\n    max_range,\n    mode='MIN_COMBINED',\n    narrow_range=False,\n    axis=-1,\n    dtype=tf.dtypes.float32,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "min_range = tf.constant([-10], shape=[1], dtype=tf.float32)\nmax_range = tf.constant([24, 758, 758, 758, 758], shape=[5], dtype=tf.float32)"
},
{
    "Title": "\n        Segfault in `CTCBeamSearchDecoder`\n      ",
    "Bug description": "Due to lack of validation in  tf.raw_ops.CTCBeamSearchDecoder , an attacker can trigger denial of service via segmentation faults:",
    "Sample Code": "inputs = tf.constant([], shape=[18, 8, 0], dtype=tf.float32)\nsequence_length = tf.constant([11, -43, -92, 11, -89, -83, -35, -100],\nshape=[8], dtype=tf.int32)\nbeam_width = 10\ntop_paths = 3\nmerge_repeated = True\n\ntf.raw_ops.CTCBeamSearchDecoder(\n  inputs=inputs, sequence_length=sequence_length, beam_width=beam_width,\n  ,\n  top_paths=top_paths, merge_repeated=merge_repeated)",
    "Code change": [
        "@@ -70,6 +70,9 @@ class CTCDecodeHelper {\n     if (inputs_shape.dims() != 3) {\n       return errors::InvalidArgument(\"inputs is not a 3-Tensor\");\n     }\n+    if (inputs_shape.num_elements() == 0) {\n+      return errors::InvalidArgument(\"inputs must not be empty\");\n+    }\n \n     const int64 max_time = inputs_shape.dim_size(0);\n     const int64 batch_size = inputs_shape.dim_size(1);\n"
    ],
    "Buggy Code": [
        [
            "      return errors::InvalidArgument(\"inputs is not a 3-Tensor\");",
            "    }",
            "",
            "    const int64 max_time = inputs_shape.dim_size(0);",
            "    const int64 batch_size = inputs_shape.dim_size(1);",
            "",
            "    if (max_time == 0) {",
            "      return errors::InvalidArgument(\"max_time is 0\");",
            "    }"
        ]
    ],
    "Clean Code": [
        [
            "      return errors::InvalidArgument(\"inputs is not a 3-Tensor\");",
            "    }",
            "    if (inputs_shape.num_elements() == 0) {",
            "      return errors::InvalidArgument(\"inputs must not be empty\");",
            "    }",
            "",
            "    const int64 max_time = inputs_shape.dim_size(0);",
            "    const int64 batch_size = inputs_shape.dim_size(1);",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vq2r-5xvm-3hc3",
    "API Signature": "tf.raw_ops.CTCBeamSearchDecoder(\n    inputs,\n    sequence_length,\n    beam_width,\n    top_paths,\n    merge_repeated=True,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "inputs = tf.constant([], shape=[18, 8, 0], dtype=tf.float32)"
},
{
    "Title": "\n        Heap buffer overflow in `FractionalAvgPoolGrad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.FractionalAvgPoolGrad  is vulnerable to a heap buffer overflow:",
    "Sample Code": "orig_input_tensor_shape = tf.constant([1, 3, 2, 3], shape=[4], dtype=tf.int64)\nout_backprop = tf.constant([2], shape=[1, 1, 1, 1], dtype=tf.int64)\nrow_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\ncol_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\n\n\ntf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=orig_input_tensor_shape, out_backprop=out_backprop,\n  row_pooling_sequence=row_pooling_sequence,\n  ,\n  col_pooling_sequence=col_pooling_sequence, overlapping=False)",
    "Code change": [
        "@@ -250,6 +250,19 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64 out_cols = out_backprop.dim_size(2);\n     const int64 out_depth = out_backprop.dim_size(3);\n \n+    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,\n+                errors::InvalidArgument(\"Given out_backprop shape \",\n+                                        out_backprop.shape().DebugString(),\n+                                        \", row_seq_tensor must have at least \",\n+                                        out_rows + 1, \" elements, but got \",\n+                                        row_seq_tensor.NumElements()));\n+    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,\n+                errors::InvalidArgument(\"Given out_backprop shape \",\n+                                        out_backprop.shape().DebugString(),\n+                                        \", col_seq_tensor must have at least \",\n+                                        out_cols + 1, \" elements, but got \",\n+                                        col_seq_tensor.NumElements()));\n+\n     auto row_seq_tensor_flat = row_seq_tensor.flat<int64>();\n     auto col_seq_tensor_flat = col_seq_tensor.flat<int64>();\n     auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64>();\n"
    ],
    "Buggy Code": [
        [
            "    const int64 out_depth = out_backprop.dim_size(3);",
            "",
            "    auto row_seq_tensor_flat = row_seq_tensor.flat<int64>();",
            "    auto col_seq_tensor_flat = col_seq_tensor.flat<int64>();",
            "    auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64>();",
            "",
            "    const int64 in_batch = orig_input_tensor_shape_flat(0);",
            "    const int64 in_rows = orig_input_tensor_shape_flat(1);",
            "    const int64 in_cols = orig_input_tensor_shape_flat(2);",
            "    const int64 in_depth = orig_input_tensor_shape_flat(3);",
            "",
            "    constexpr int tensor_in_and_out_dims = 4;",
            "    // Transform orig_input_tensor_shape into TensorShape",
            "    TensorShape in_shape;",
            "    for (auto i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      in_shape.AddDim(orig_input_tensor_shape_flat(i));",
            "    }",
            "",
            "    // Create intermediate in_backprop."
        ]
    ],
    "Clean Code": [
        [
            "    const int64 out_depth = out_backprop.dim_size(3);",
            "",
            "    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,",
            "                errors::InvalidArgument(\"Given out_backprop shape \",",
            "                                        out_backprop.shape().DebugString(),",
            "                                        \", row_seq_tensor must have at least \",",
            "                                        out_rows + 1, \" elements, but got \",",
            "                                        row_seq_tensor.NumElements()));",
            "    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,",
            "                errors::InvalidArgument(\"Given out_backprop shape \",",
            "                                        out_backprop.shape().DebugString(),",
            "                                        \", col_seq_tensor must have at least \",",
            "                                        out_cols + 1, \" elements, but got \",",
            "                                        col_seq_tensor.NumElements()));",
            "",
            "    auto row_seq_tensor_flat = row_seq_tensor.flat<int64>();",
            "    auto col_seq_tensor_flat = col_seq_tensor.flat<int64>();",
            "    auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64>();",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6f89-8j54-29xf",
    "API Signature": "tf.raw_ops.FractionalAvgPoolGrad(\n    orig_input_tensor_shape,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.02158273381294964,
    "Anomaly": "Scalar input tensor",
    "Anomaly Description": "A scalar input tensor refers to a tensor with a rank of 0, meaning it has zero dimensions. In other words, a scalar input tensor represents a single value without any additional structure or dimensions.",
    "Category": "Tensor",
    "Argument": "row_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\ncol_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)"
},
{
    "Title": "\n        Undefined behavior and `CHECK`-fail in `FractionalMaxPoolGrad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.FractionalMaxPoolGrad  triggers an undefined behavior if one of the input tensors is empty:",
    "Sample Code": "orig_input = tf.constant([1], shape=[1], dtype=tf.int64)\norig_output = tf.constant([1], shape=[1], dtype=tf.int64)\nout_backprop = tf.constant([1, 1], shape=[2, 1, 1, 1], dtype=tf.int64)\nrow_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64) \ncol_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\n\ntf.raw_ops.FractionalMaxPoolGrad(\n  orig_input=orig_input, orig_output=orig_output, out_backprop=out_backprop,\n  row_pooling_sequence=row_pooling_sequence,\n  ,\n  col_pooling_sequence=col_pooling_sequence, overlapping=False)",
    "Code change": [
        "@@ -235,6 +235,20 @@ class FractionalMaxPoolGradOp : public OpKernel {\n \n     // Just to make it similar to FractionalMaxPoolOp.\n     constexpr int tensor_in_and_out_dims = 4;\n+    OP_REQUIRES(\n+        context, tensor_in.dims() == tensor_in_and_out_dims,\n+        errors::InvalidArgument(\"orig_input should be a tensor of rank 4, got \",\n+                                tensor_in.DebugString()));\n+    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n+                errors::InvalidArgument(\"orig_input must not be empty, got \",\n+                                        tensor_in.DebugString()));\n+    OP_REQUIRES(context, tensor_out.dims() == tensor_in_and_out_dims,\n+                errors::InvalidArgument(\n+                    \"orig_output should be a tensor of rank 4, got \",\n+                    tensor_out.DebugString()));\n+    OP_REQUIRES(context, tensor_out.NumElements() > 0,\n+                errors::InvalidArgument(\"orig_output must not be empty, got \",\n+                                        tensor_out.DebugString()));\n     std::vector<int64> input_size(tensor_in_and_out_dims);\n     std::vector<int64> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n"
    ],
    "Buggy Code": [
        [
            "    // Just to make it similar to FractionalMaxPoolOp.",
            "    constexpr int tensor_in_and_out_dims = 4;",
            "    std::vector<int64> input_size(tensor_in_and_out_dims);",
            "    std::vector<int64> output_size(tensor_in_and_out_dims);",
            "    for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      input_size[i] = tensor_in.dim_size(i);",
            "    }",
            "    for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      output_size[i] = tensor_out.dim_size(i);",
            "    }",
            "",
            "    // ---------",
            "    // Step 1",
            "    // ---------",
            "    Tensor tensor_out_dup;",
            "    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(",
            "                                {1}, DataTypeToEnum<T>::v(), tensor_out.shape(),",
            "                                &tensor_out_dup));",
            "    Tensor tensor_out_arg_max;",
            "    OP_REQUIRES_OK(context, context->allocate_temp(DataTypeToEnum<int64>::v(),"
        ]
    ],
    "Clean Code": [
        [
            "    // Just to make it similar to FractionalMaxPoolOp.",
            "    constexpr int tensor_in_and_out_dims = 4;",
            "    OP_REQUIRES(",
            "        context, tensor_in.dims() == tensor_in_and_out_dims,",
            "        errors::InvalidArgument(\"orig_input should be a tensor of rank 4, got \",",
            "                                tensor_in.DebugString()));",
            "    OP_REQUIRES(context, tensor_in.NumElements() > 0,",
            "                errors::InvalidArgument(\"orig_input must not be empty, got \",",
            "                                        tensor_in.DebugString()));",
            "    OP_REQUIRES(context, tensor_out.dims() == tensor_in_and_out_dims,",
            "                errors::InvalidArgument(",
            "                    \"orig_output should be a tensor of rank 4, got \",",
            "                    tensor_out.DebugString()));",
            "    OP_REQUIRES(context, tensor_out.NumElements() > 0,",
            "                errors::InvalidArgument(\"orig_output must not be empty, got \",",
            "                                        tensor_out.DebugString()));",
            "    std::vector<int64> input_size(tensor_in_and_out_dims);",
            "    std::vector<int64> output_size(tensor_in_and_out_dims);",
            "    for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      input_size[i] = tensor_in.dim_size(i);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x8h6-xgqx-jqgp",
    "API Signature": "tf.raw_ops.FractionalMaxPoolGrad(\n    orig_input,\n    orig_output,\n    out_backprop,\n    row_pooling_sequence,\n    col_pooling_sequence,\n    overlapping=False,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "orig_output = tf.constant([], dtype=tf.int64) "
},
{
    "Title": "\n        Heap buffer overflow in `AvgPool3DGrad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.AvgPool3DGrad  is vulnerable to a heap buffer overflow:",
    "Sample Code": "orig_input_shape = tf.constant([10, 6, 3, 7, 7], shape=[5], dtype=tf.int32)\ngrad = tf.constant([0.01, 0, 0], shape=[3, 1, 1, 1, 1], dtype=tf.float32)\nksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\n\ntf.raw_ops.AvgPool3DGrad(\n  orig_input_shape=orig_input_shape, grad=grad, ksize=ksize, strides=strides,\n  ,\n  padding=padding)",
    "Code change": [
        "@@ -383,6 +383,19 @@ struct LaunchAvgPooling3dGradOp<CPUDevice, T> {\n                      const std::array<int64, 3>& output_shape,\n                      const std::array<int64, 3>& padding,\n                      TensorFormat data_format, Tensor* output) {\n+    OP_REQUIRES(\n+        context, tensor_in_shape.dim_size(0) == out_backprop.dim_size(0),\n+        errors::InvalidArgument(\n+            \"Expected first dimension of tensor_in_shape and \"\n+            \"out_backprop to match, got \",\n+            tensor_in_shape.dim_size(0), \" and \", out_backprop.dim_size(0)));\n+    OP_REQUIRES(\n+        context, tensor_in_shape.dim_size(4) == out_backprop.dim_size(4),\n+        errors::InvalidArgument(\n+            \"Expected last dimension of tensor_in_shape and \"\n+            \"out_backprop to match, got \",\n+            tensor_in_shape.dim_size(4), \" and \", out_backprop.dim_size(4)));\n+\n     output->flat<T>().setZero();\n     std::array<int64, 3> input_size = {{tensor_in_shape.dim_size(3),\n                                         tensor_in_shape.dim_size(2),\n"
    ],
    "Buggy Code": [
        [
            "                     const std::array<int64, 3>& padding,",
            "                     TensorFormat data_format, Tensor* output) {",
            "    output->flat<T>().setZero();",
            "    std::array<int64, 3> input_size = {{tensor_in_shape.dim_size(3),",
            "                                        tensor_in_shape.dim_size(2),",
            "                                        tensor_in_shape.dim_size(1)}};",
            "    for (int64 p = 0; p < out_backprop.dim_size(3); ++p) {",
            "      // Calculate broadcast size for planes/rows/cols. For SAME padding,",
            "      // current index could be in the padding area, and",
            "      //   p * stride_planes + window_planes",
            "      // could be beyond the input tensor's boundary. In such cases, change",
            "      // the starting index and reduce the broadcast size.",
            "      //",
            "      // The same procedure is repeated for every spatial dimension in the",
            "      // nested loops below.",
            "      int pindex, psize;",
            "      OP_REQUIRES_OK(context,",
            "                     GetBroadcastSize(p, input_size[0], window[0], stride[0],",
            "                                      padding[0], &pindex, &psize));"
        ]
    ],
    "Clean Code": [
        [
            "                     const std::array<int64, 3>& padding,",
            "                     TensorFormat data_format, Tensor* output) {",
            "    OP_REQUIRES(",
            "        context, tensor_in_shape.dim_size(0) == out_backprop.dim_size(0),",
            "        errors::InvalidArgument(",
            "            \"Expected first dimension of tensor_in_shape and \"",
            "            \"out_backprop to match, got \",",
            "            tensor_in_shape.dim_size(0), \" and \", out_backprop.dim_size(0)));",
            "    OP_REQUIRES(",
            "        context, tensor_in_shape.dim_size(4) == out_backprop.dim_size(4),",
            "        errors::InvalidArgument(",
            "            \"Expected last dimension of tensor_in_shape and \"",
            "            \"out_backprop to match, got \",",
            "            tensor_in_shape.dim_size(4), \" and \", out_backprop.dim_size(4)));",
            "",
            "    output->flat<T>().setZero();",
            "    std::array<int64, 3> input_size = {{tensor_in_shape.dim_size(3),",
            "                                        tensor_in_shape.dim_size(2),",
            "                                        tensor_in_shape.dim_size(1)}};"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v6r6-84gr-92rm",
    "API Signature": "tf.raw_ops.AvgPool3DGrad(\n    orig_input_shape,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NDHWC',\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "orig_input_shape = tf.constant([10, 6, 3, 7, 7], shape=[5], dtype=tf.int32)\ngrad = tf.constant([0.01, 0, 0], shape=[3, 1, 1, 1, 1], dtype=tf.float32)"
},
{
    "Title": "\n        Heap buffer overflow in `MaxPool3DGradGrad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPool3DGradGrad  is vulnerable to a heap buffer overflow:",
    "Sample Code": "values = [0.01] * 11\norig_input = tf.constant(values, shape=[11, 1, 1, 1, 1], dtype=tf.float32)\norig_output = tf.constant([0.01], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\ngrad = tf.constant([0.01], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\nksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\n\ntf.raw_ops.MaxPool3DGradGrad(\n    orig_input=orig_input, orig_output=orig_output, grad=grad, ksize=ksize,\n    ,\n    strides=strides, padding=padding)",
    "Code change": [
        "@@ -693,6 +693,7 @@ class MaxPooling3dGradGradOp : public OpKernel {\n \n     Pool3dParameters params{context,  ksize_,       stride_,\n                             padding_, data_format_, tensor_in.shape()};\n+    if (!context->status().ok()) return;  // params is invalid\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n@@ -710,6 +711,17 @@ class MaxPooling3dGradGradOp : public OpKernel {\n         context, out_grad_backprop.NumElements() > 0,\n         errors::InvalidArgument(\"received empty tensor out_grad_backprop: \",\n                                 out_grad_backprop.DebugString()));\n+    OP_REQUIRES(context,\n+                tensor_in.NumElements() == out_grad_backprop.NumElements(),\n+                errors::InvalidArgument(\"tensor_in and out_grad_backprop must \"\n+                                        \"have same number of elements, got <\",\n+                                        tensor_in.DebugString(), \"> and <\",\n+                                        out_grad_backprop.DebugString(), \">\"));\n+    OP_REQUIRES(\n+        context, tensor_out.NumElements() == output->NumElements(),\n+        errors::InvalidArgument(\n+            \"tensor_out and output must have same number of elements, got <\",\n+            tensor_out.DebugString(), \"> and <\", output->DebugString(), \">\"));\n \n     LaunchMaxPooling3dGradGradOp<Device, T>::launch(\n         context, params, tensor_in, tensor_out, out_grad_backprop, output);\n"
    ],
    "Buggy Code": [
        [
            "    Pool3dParameters params{context,  ksize_,       stride_,",
            "                            padding_, data_format_, tensor_in.shape()};",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(",
            "                                {2}, 0, tensor_out.shape(), &output));",
            ""
        ],
        [
            "                                out_grad_backprop.DebugString()));",
            "",
            "    LaunchMaxPooling3dGradGradOp<Device, T>::launch(",
            "        context, params, tensor_in, tensor_out, out_grad_backprop, output);",
            "  }",
            "",
            " private:",
            "  std::vector<int32> ksize_;",
            "  std::vector<int32> stride_;",
            "  Padding padding_;",
            "  TensorFormat data_format_;",
            "};",
            "",
            "#define REGISTER_KERNELS(D, T)                                             \\",
            "  REGISTER_KERNEL_BUILDER(                                                 \\",
            "      Name(\"MaxPool3D\").Device(DEVICE_##D).TypeConstraint<T>(\"T\"),         \\",
            "      Pooling3DOp<D##Device, T, MAX>);                                     \\"
        ]
    ],
    "Clean Code": [
        [
            "    Pool3dParameters params{context,  ksize_,       stride_,",
            "                            padding_, data_format_, tensor_in.shape()};",
            "    if (!context->status().ok()) return;  // params is invalid",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(",
            "                                {2}, 0, tensor_out.shape(), &output));"
        ],
        [
            "        errors::InvalidArgument(\"received empty tensor out_grad_backprop: \",",
            "                                out_grad_backprop.DebugString()));",
            "    OP_REQUIRES(context,",
            "                tensor_in.NumElements() == out_grad_backprop.NumElements(),",
            "                errors::InvalidArgument(\"tensor_in and out_grad_backprop must \"",
            "                                        \"have same number of elements, got <\",",
            "                                        tensor_in.DebugString(), \"> and <\",",
            "                                        out_grad_backprop.DebugString(), \">\"));",
            "    OP_REQUIRES(",
            "        context, tensor_out.NumElements() == output->NumElements(),",
            "        errors::InvalidArgument(",
            "            \"tensor_out and output must have same number of elements, got <\",",
            "            tensor_out.DebugString(), \"> and <\", output->DebugString(), \">\"));",
            "",
            "    LaunchMaxPooling3dGradGradOp<Device, T>::launch(",
            "        context, params, tensor_in, tensor_out, out_grad_backprop, output);",
            "  }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-7cqx-92hp-x6wh",
    "API Signature": "tf.raw_ops.MaxPool3DGradGrad(\n    orig_input,\n    orig_output,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NDHWC',\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "orig_input = tf.constant(values, shape=[11, 1, 1, 1, 1], dtype=tf.float32)\ngrad = tf.constant([0.01], shape=[1, 1, 1, 1, 1], dtype=tf.float32)"
},
{
    "Title": "\n        Undefined behavior in `MaxPool3DGradGrad`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPool3DGradGrad  exhibits undefined behavior by dereferencing null pointers backing attacker-supplied empty tensors:",
    "Sample Code": "orig_input = tf.constant([0.0], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\norig_output = tf.constant([0.0], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\ngrad = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)\nksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\n\ntf.raw_ops.MaxPool3DGradGrad(\n    orig_input=orig_input, orig_output=orig_output, grad=grad, ksize=ksize,\n    ,\n    strides=strides, padding=padding)",
    "Code change": [
        "@@ -698,6 +698,19 @@ class MaxPooling3dGradGradOp : public OpKernel {\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                 {2}, 0, tensor_out.shape(), &output));\n \n+    // Given access patterns in LaunchMaxPooling3dGradGradOp, these tensors must\n+    // have elements.\n+    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n+                errors::InvalidArgument(\"received empty tensor tensor_in: \",\n+                                        tensor_in.DebugString()));\n+    OP_REQUIRES(context, tensor_out.NumElements() > 0,\n+                errors::InvalidArgument(\"received empty tensor tensor_out: \",\n+                                        tensor_out.DebugString()));\n+    OP_REQUIRES(\n+        context, out_grad_backprop.NumElements() > 0,\n+        errors::InvalidArgument(\"received empty tensor out_grad_backprop: \",\n+                                out_grad_backprop.DebugString()));\n+\n     LaunchMaxPooling3dGradGradOp<Device, T>::launch(\n         context, params, tensor_in, tensor_out, out_grad_backprop, output);\n   }\n"
    ],
    "Buggy Code": [
        [
            "                                {2}, 0, tensor_out.shape(), &output));",
            "",
            "    LaunchMaxPooling3dGradGradOp<Device, T>::launch(",
            "        context, params, tensor_in, tensor_out, out_grad_backprop, output);",
            "  }",
            "",
            " private:",
            "  std::vector<int32> ksize_;",
            "  std::vector<int32> stride_;",
            "  Padding padding_;",
            "  TensorFormat data_format_;",
            "};",
            "",
            "#define REGISTER_KERNELS(D, T)                                             \\",
            "  REGISTER_KERNEL_BUILDER(                                                 \\",
            "      Name(\"MaxPool3D\").Device(DEVICE_##D).TypeConstraint<T>(\"T\"),         \\",
            "      Pooling3DOp<D##Device, T, MAX>);                                     \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"MaxPool3DGrad\")                            \\",
            "                              .Device(DEVICE_##D)                          \\"
        ]
    ],
    "Clean Code": [
        [
            "                                {2}, 0, tensor_out.shape(), &output));",
            "",
            "    // Given access patterns in LaunchMaxPooling3dGradGradOp, these tensors must",
            "    // have elements.",
            "    OP_REQUIRES(context, tensor_in.NumElements() > 0,",
            "                errors::InvalidArgument(\"received empty tensor tensor_in: \",",
            "                                        tensor_in.DebugString()));",
            "    OP_REQUIRES(context, tensor_out.NumElements() > 0,",
            "                errors::InvalidArgument(\"received empty tensor tensor_out: \",",
            "                                        tensor_out.DebugString()));",
            "    OP_REQUIRES(",
            "        context, out_grad_backprop.NumElements() > 0,",
            "        errors::InvalidArgument(\"received empty tensor out_grad_backprop: \",",
            "                                out_grad_backprop.DebugString()));",
            "",
            "    LaunchMaxPooling3dGradGradOp<Device, T>::launch(",
            "        context, params, tensor_in, tensor_out, out_grad_backprop, output);",
            "  }",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-828x-qc2p-wprq",
    "API Signature": "tf.raw_ops.MaxPool3DGradGrad(\n    orig_input,\n    orig_output,\n    grad,\n    ksize,\n    strides,\n    padding,\n    data_format='NDHWC',\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "grad = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)"
},
{
    "Title": "\n        Division by 0 in `MaxPoolGradWithArgmax`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPoolGradWithArgmax  is vulnerable to a division by 0:",
    "Sample Code": "input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\ngrad = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\nargmax = tf.constant([], shape=[0], dtype=tf.int64)\nksize = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\n\ntf.raw_ops.MaxPoolGradWithArgmax(\n  input=input, grad=grad, argmax=argmax, ksize=ksize, strides=strides,\n  ,\n  padding='SAME', include_batch_in_index=False)",
    "Code change": [
        "@@ -1088,6 +1088,8 @@ class MaxPoolingGradWithArgmaxOp : public OpKernel {\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                 {0}, 0, out_shape, &grad_out));\n \n+    if (out_shape.num_elements() == 0) return;  // nothing to be done\n+\n     LaunchMaxPoolingGradWithArgmax<Device, T>::launch(\n         context, params, grad_in, argmax, grad_out, include_batch_in_index_);\n   }\n"
    ],
    "Buggy Code": [
        [
            "                                {0}, 0, out_shape, &grad_out));",
            "",
            "    LaunchMaxPoolingGradWithArgmax<Device, T>::launch(",
            "        context, params, grad_in, argmax, grad_out, include_batch_in_index_);",
            "  }",
            "",
            " private:",
            "  std::vector<int32> ksize_;"
        ]
    ],
    "Clean Code": [
        [
            "                                {0}, 0, out_shape, &grad_out));",
            "",
            "    if (out_shape.num_elements() == 0) return;  // nothing to be done",
            "",
            "    LaunchMaxPoolingGradWithArgmax<Device, T>::launch(",
            "        context, params, grad_in, argmax, grad_out, include_batch_in_index_);",
            "  }",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9vpm-rcf4-9wqw",
    "API Signature": "tf.raw_ops.MaxPoolGradWithArgmax(\n    input,\n    grad,\n    argmax,\n    ksize,\n    strides,\n    padding,\n    include_batch_in_index=False,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\ngrad = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\nargmax = tf.constant([], shape=[0], dtype=tf.int64)"
},
{
    "Title": "\n        Overflow/denial of service in `tf.raw_ops.ReverseSequence`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.ReverseSequence  allows for stack overflow and/or  CHECK -fail based denial of service.",
    "Sample Code": "input = tf.zeros([1, 1, 1], dtype=tf.int32)\nseq_lengths = tf.constant([0], shape=[1], dtype=tf.int32)\n\ntf.raw_ops.ReverseSequence(\n    (\n    input=input, seq_lengths=seq_lengths, seq_dim=-2, batch_dim=0)",
    "Code change": [
        "@@ -115,6 +115,10 @@ class ReverseSequenceOp : public OpKernel {\n       : OpKernel(context) {\n     OP_REQUIRES_OK(context, context->GetAttr(\"batch_dim\", &batch_dim_));\n     OP_REQUIRES_OK(context, context->GetAttr(\"seq_dim\", &seq_dim_));\n+    OP_REQUIRES(context, batch_dim_ >= 0,\n+                errors::InvalidArgument(\"Invalid batch_dim \", batch_dim_));\n+    OP_REQUIRES(context, seq_dim_ >= 0,\n+                errors::InvalidArgument(\"Invalid seq_dim \", seq_dim_));\n   }\n \n   void Compute(OpKernelContext* context) override {\n"
    ],
    "Buggy Code": [
        [
            "    OP_REQUIRES_OK(context, context->GetAttr(\"batch_dim\", &batch_dim_));",
            "    OP_REQUIRES_OK(context, context->GetAttr(\"seq_dim\", &seq_dim_));",
            "  }",
            "",
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const Tensor& seq_lengths = context->input(1);",
            "",
            "    // Preliminary validation of sizes.",
            "    OP_REQUIRES(context, TensorShapeUtils::IsVector(seq_lengths.shape()),"
        ]
    ],
    "Clean Code": [
        [
            "    OP_REQUIRES_OK(context, context->GetAttr(\"batch_dim\", &batch_dim_));",
            "    OP_REQUIRES_OK(context, context->GetAttr(\"seq_dim\", &seq_dim_));",
            "    OP_REQUIRES(context, batch_dim_ >= 0,",
            "                errors::InvalidArgument(\"Invalid batch_dim \", batch_dim_));",
            "    OP_REQUIRES(context, seq_dim_ >= 0,",
            "                errors::InvalidArgument(\"Invalid seq_dim \", seq_dim_));",
            "  }",
            "",
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6qgm-fv6v-rfpv",
    "API Signature": "tf.raw_ops.ReverseSequence(\n    input, seq_lengths, seq_dim, batch_dim=0, name=None\n)\n",
    "Score": 0.039568345323741004,
    "Anomaly": "Negative integer argument",
    "Anomaly Description": "A negative integer argument in Python refers to an integer value that is less than zero. It is a numeric value that represents a negative quantity or position in a numerical sequence. In Python, negative integers are denoted by placing a minus sign (-) before the numerical value. For example, -1, -2, -3, and so on.",
    "Category": "Integer",
    "Argument": "seq_dim=-2"
},
{
    "Title": "\n        Reference binding to nullptr in `SdcaOptimizer`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SdcaOptimizer  triggers undefined behavior due to dereferencing a null pointer:",
    "Sample Code": "sparse_example_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_indices = [tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_values = []\n\ndense_features = []\ndense_weights = []\n\nexample_weights = tf.constant((0.0), dtype=tf.float32)\nexample_labels = tf.constant((0.0), dtype=tf.float32)\n\nsparse_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_weights = [tf.constant((0.0), dtype=tf.float32), tf.constant((0.0), dtype=tf.float32)]\n  \nexample_state_data = tf.constant([0.0, 0.0, 0.0, 0.0], shape=[1, 4], dtype=tf.float32)\n  \ntf.raw_ops.SdcaOptimizer(\n  sparse_example_indices=sparse_example_indices,\n  sparse_feature_indices=sparse_feature_indices,\n  sparse_feature_values=sparse_feature_values, dense_features=dense_features,\n  example_weights=example_weights, example_labels=example_labels, \n  sparse_indices=sparse_indices, sparse_weights=sparse_weights, \n  dense_weights=dense_weights, example_state_data=example_state_data,\n  loss_type=\"logistic_loss\", l1=0.0, l2=0.0, num_loss_partitions=1,\n  ,\n  num_inner_iterations=1, adaptative=False)",
    "Code change": [
        "@@ -99,6 +99,10 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {\n   OpInputList sparse_weights_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(\"sparse_weights\", &sparse_weights_inputs));\n+  if (sparse_indices_inputs.size() != sparse_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"sparse_indices and sparse_weights must have the same length, got \",\n+        sparse_indices_inputs.size(), \" and \", sparse_weights_inputs.size());\n   OpInputList dense_weights_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(\"dense_weights\", &dense_weights_inputs));\n@@ -106,10 +110,20 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {\n   OpOutputList sparse_weights_outputs;\n   TF_RETURN_IF_ERROR(context->output_list(\"out_delta_sparse_weights\",\n                                           &sparse_weights_outputs));\n+  if (sparse_weights_outputs.size() != sparse_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"out_delta_sparse_weights and sparse_weights must have the same \"\n+        \"length, got \",\n+        sparse_weights_outputs.size(), \" and \", sparse_weights_inputs.size());\n \n   OpOutputList dense_weights_outputs;\n   TF_RETURN_IF_ERROR(\n       context->output_list(\"out_delta_dense_weights\", &dense_weights_outputs));\n+  if (dense_weights_outputs.size() != dense_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"out_delta_dense_weights and dense_weights must have the same length, \"\n+        \"got \",\n+        dense_weights_outputs.size(), \" and \", dense_weights_inputs.size());\n \n   for (int i = 0; i < sparse_weights_inputs.size(); ++i) {\n     Tensor* delta_t;\n@@ -327,13 +341,28 @@ Status Examples::Initialize(OpKernelContext* const context,\n   OpInputList sparse_example_indices_inputs;\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                          &sparse_example_indices_inputs));\n+  if (sparse_example_indices_inputs.size() != num_sparse_features)\n+    return errors::InvalidArgument(\n+        \"Expected \", num_sparse_features,\n+        \" tensors in sparse_example_indices but got \",\n+        sparse_example_indices_inputs.size());\n   OpInputList sparse_feature_indices_inputs;\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                          &sparse_feature_indices_inputs));\n+  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n+    return errors::InvalidArgument(\n+        \"Expected \", num_sparse_features,\n+        \" tensors in sparse_feature_indices but got \",\n+        sparse_feature_indices_inputs.size());\n   OpInputList sparse_feature_values_inputs;\n   if (num_sparse_features_with_values > 0) {\n     TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                            &sparse_feature_values_inputs));\n+    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n+      return errors::InvalidArgument(\n+          \"Expected \", num_sparse_features_with_values,\n+          \" tensors in sparse_feature_values but got \",\n+          sparse_feature_values_inputs.size());\n   }\n \n   const Tensor* example_weights_t;\n@@ -400,6 +429,13 @@ Status Examples::CreateSparseFeatureRepresentation(\n           sparse_example_indices_inputs[i].template flat<int64>();\n       auto feature_indices =\n           sparse_feature_indices_inputs[i].template flat<int64>();\n+      if (example_indices.size() != feature_indices.size()) {\n+        mutex_lock l(mu);\n+        result = errors::InvalidArgument(\n+            \"Found mismatched example_indices and feature_indices [\",\n+            example_indices, \"] vs [\", feature_indices, \"]\");\n+        return;\n+      }\n \n       // Parse features for each example. Features for a particular example\n       // are at the offsets (start_id, end_id]\n"
    ],
    "Buggy Code": [
        [
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"sparse_weights\", &sparse_weights_inputs));",
            "  OpInputList dense_weights_inputs;",
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"dense_weights\", &dense_weights_inputs));",
            "",
            "  OpOutputList sparse_weights_outputs;",
            "  TF_RETURN_IF_ERROR(context->output_list(\"out_delta_sparse_weights\",",
            "                                          &sparse_weights_outputs));",
            ""
        ],
        [
            "  TF_RETURN_IF_ERROR(",
            "      context->output_list(\"out_delta_dense_weights\", &dense_weights_outputs));",
            "",
            "  for (int i = 0; i < sparse_weights_inputs.size(); ++i) {",
            "    Tensor* delta_t;",
            "    TF_RETURN_IF_ERROR(sparse_weights_outputs.allocate(",
            "        i, sparse_weights_inputs[i].shape(), &delta_t));",
            "    // Convert the input vector to a row matrix in internal representation.",
            "    auto deltas = delta_t->shaped<float, 2>({1, delta_t->NumElements()});",
            "    deltas.setZero();",
            "    sparse_weights_.emplace_back(FeatureWeightsSparseStorage{",
            "        sparse_indices_inputs[i].flat<int64>(),",
            "        sparse_weights_inputs[i].shaped<float, 2>(",
            "            {1, sparse_weights_inputs[i].NumElements()}),",
            "        deltas});",
            "  }",
            "",
            "  // Reads in the weights, and allocates and initializes the delta weights.",
            "  const auto initialize_weights =",
            "      [&](const OpInputList& weight_inputs, OpOutputList* const weight_outputs,"
        ],
        [
            "",
            "  if (example_weights.size() >= std::numeric_limits<int>::max()) {",
            "    return errors::InvalidArgument(strings::Printf(",
            "        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),",
            "        std::numeric_limits<int>::max()));",
            "  }",
            "",
            "  // The static_cast here is safe since num_examples can be at max an int.",
            "  const int num_examples = static_cast<int>(example_weights.size());",
            "  const Tensor* example_labels_t;",
            "  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));",
            "  auto example_labels = example_labels_t->flat<float>();",
            "",
            "  OpInputList dense_features_inputs;",
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"dense_features\", &dense_features_inputs));",
            "",
            "  examples_.clear();",
            "  examples_.resize(num_examples);",
            "  probabilities_.resize(num_examples);",
            "  sampled_index_.resize(num_examples);",
            "  sampled_count_.resize(num_examples);",
            "  for (int example_id = 0; example_id < num_examples; ++example_id) {",
            "    Example* const example = &examples_[example_id];",
            "    example->sparse_features_.resize(num_sparse_features);",
            "    example->dense_vectors_.resize(num_dense_features);",
            "    example->example_weight_ = example_weights(example_id);",
            "    example->example_label_ = example_labels(example_id);"
        ],
        [
            "            for (int64 k = 0; k < sparse_features->indices->size(); ++k) {",
            "              const int64 feature_index = (*sparse_features->indices)(k);",
            "              if (!weights.SparseIndexValid(i, feature_index)) {",
            "                mutex_lock l(mu);",
            "                result = errors::InvalidArgument(",
            "                    \"Found sparse feature indices out of valid range: \",",
            "                    (*sparse_features->indices)(k));",
            "                return;",
            "              }",
            "            }",
            "          }",
            "        } else {",
            "          // Add a Tensor that has size 0."
        ]
    ],
    "Clean Code": [
        [
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"sparse_weights\", &sparse_weights_inputs));",
            "  if (sparse_indices_inputs.size() != sparse_weights_inputs.size())",
            "    return errors::InvalidArgument(",
            "        \"sparse_indices and sparse_weights must have the same length, got \",",
            "        sparse_indices_inputs.size(), \" and \", sparse_weights_inputs.size());",
            "  OpInputList dense_weights_inputs;",
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"dense_weights\", &dense_weights_inputs));",
            ""
        ],
        [
            "  TF_RETURN_IF_ERROR(context->output_list(\"out_delta_sparse_weights\",",
            "                                          &sparse_weights_outputs));",
            "  if (sparse_weights_outputs.size() != sparse_weights_inputs.size())",
            "    return errors::InvalidArgument(",
            "        \"out_delta_sparse_weights and sparse_weights must have the same \"",
            "        \"length, got \",",
            "        sparse_weights_outputs.size(), \" and \", sparse_weights_inputs.size());",
            "",
            "  OpOutputList dense_weights_outputs;",
            "  TF_RETURN_IF_ERROR(",
            "      context->output_list(\"out_delta_dense_weights\", &dense_weights_outputs));",
            "  if (dense_weights_outputs.size() != dense_weights_inputs.size())",
            "    return errors::InvalidArgument(",
            "        \"out_delta_dense_weights and dense_weights must have the same length, \"",
            "        \"got \",",
            "        dense_weights_outputs.size(), \" and \", dense_weights_inputs.size());",
            "",
            "  for (int i = 0; i < sparse_weights_inputs.size(); ++i) {",
            "    Tensor* delta_t;",
            "    TF_RETURN_IF_ERROR(sparse_weights_outputs.allocate("
        ],
        [
            "  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",",
            "                                         &sparse_example_indices_inputs));",
            "  if (sparse_example_indices_inputs.size() != num_sparse_features)",
            "    return errors::InvalidArgument(",
            "        \"Expected \", num_sparse_features,",
            "        \" tensors in sparse_example_indices but got \",",
            "        sparse_example_indices_inputs.size());",
            "  OpInputList sparse_feature_indices_inputs;",
            "  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",",
            "                                         &sparse_feature_indices_inputs));",
            "  if (sparse_feature_indices_inputs.size() != num_sparse_features)",
            "    return errors::InvalidArgument(",
            "        \"Expected \", num_sparse_features,",
            "        \" tensors in sparse_feature_indices but got \",",
            "        sparse_feature_indices_inputs.size());",
            "  OpInputList sparse_feature_values_inputs;",
            "  if (num_sparse_features_with_values > 0) {",
            "    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",",
            "                                           &sparse_feature_values_inputs));",
            "    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)",
            "      return errors::InvalidArgument(",
            "          \"Expected \", num_sparse_features_with_values,",
            "          \" tensors in sparse_feature_values but got \",",
            "          sparse_feature_values_inputs.size());",
            "  }",
            "",
            "  const Tensor* example_weights_t;",
            "  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));"
        ],
        [
            "      auto feature_indices =",
            "          sparse_feature_indices_inputs[i].template flat<int64>();",
            "      if (example_indices.size() != feature_indices.size()) {",
            "        mutex_lock l(mu);",
            "        result = errors::InvalidArgument(",
            "            \"Found mismatched example_indices and feature_indices [\",",
            "            example_indices, \"] vs [\", feature_indices, \"]\");",
            "        return;",
            "      }",
            "",
            "      // Parse features for each example. Features for a particular example",
            "      // are at the offsets (start_id, end_id]",
            "      int start_id = -1;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5gqf-456p-4836",
    "API Signature": "tf.raw_ops.SdcaOptimizer(\n    sparse_example_indices,\n    sparse_feature_indices,\n    sparse_feature_values,\n    dense_features,\n    example_weights,\n    example_labels,\n    sparse_indices,\n    sparse_weights,\n    dense_weights,\n    example_state_data,\n    loss_type,\n    l1,\n    l2,\n    num_loss_partitions,\n    num_inner_iterations,\n    adaptative=True,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "sparse_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)] \nsparse_weights = [tf.constant((0.0), dtype=tf.float32), tf.constant((0.0), dtype=tf.float32)]"
},
{
    "Title": "\n        Reference binding to nullptr in `SdcaOptimizer`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.SdcaOptimizer  triggers undefined behavior due to dereferencing a null pointer:",
    "Sample Code": "sparse_example_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_indices = [tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_values = []\n\ndense_features = []\ndense_weights = []\n\nexample_weights = tf.constant((0.0), dtype=tf.float32)\nexample_labels = tf.constant((0.0), dtype=tf.float32)\n\nsparse_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_weights = [tf.constant((0.0), dtype=tf.float32), tf.constant((0.0), dtype=tf.float32)]\n  \nexample_state_data = tf.constant([0.0, 0.0, 0.0, 0.0], shape=[1, 4], dtype=tf.float32)\n  \ntf.raw_ops.SdcaOptimizer(\n  sparse_example_indices=sparse_example_indices,\n  sparse_feature_indices=sparse_feature_indices,\n  sparse_feature_values=sparse_feature_values, dense_features=dense_features,\n  example_weights=example_weights, example_labels=example_labels, \n  sparse_indices=sparse_indices, sparse_weights=sparse_weights, \n  dense_weights=dense_weights, example_state_data=example_state_data,\n  loss_type=\"logistic_loss\", l1=0.0, l2=0.0, num_loss_partitions=1,\n  ,\n  num_inner_iterations=1, adaptative=False)",
    "Code change": [
        "@@ -99,6 +99,10 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {\n   OpInputList sparse_weights_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(\"sparse_weights\", &sparse_weights_inputs));\n+  if (sparse_indices_inputs.size() != sparse_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"sparse_indices and sparse_weights must have the same length, got \",\n+        sparse_indices_inputs.size(), \" and \", sparse_weights_inputs.size());\n   OpInputList dense_weights_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(\"dense_weights\", &dense_weights_inputs));\n@@ -106,10 +110,20 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {\n   OpOutputList sparse_weights_outputs;\n   TF_RETURN_IF_ERROR(context->output_list(\"out_delta_sparse_weights\",\n                                           &sparse_weights_outputs));\n+  if (sparse_weights_outputs.size() != sparse_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"out_delta_sparse_weights and sparse_weights must have the same \"\n+        \"length, got \",\n+        sparse_weights_outputs.size(), \" and \", sparse_weights_inputs.size());\n \n   OpOutputList dense_weights_outputs;\n   TF_RETURN_IF_ERROR(\n       context->output_list(\"out_delta_dense_weights\", &dense_weights_outputs));\n+  if (dense_weights_outputs.size() != dense_weights_inputs.size())\n+    return errors::InvalidArgument(\n+        \"out_delta_dense_weights and dense_weights must have the same length, \"\n+        \"got \",\n+        dense_weights_outputs.size(), \" and \", dense_weights_inputs.size());\n \n   for (int i = 0; i < sparse_weights_inputs.size(); ++i) {\n     Tensor* delta_t;\n@@ -327,13 +341,28 @@ Status Examples::Initialize(OpKernelContext* const context,\n   OpInputList sparse_example_indices_inputs;\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                          &sparse_example_indices_inputs));\n+  if (sparse_example_indices_inputs.size() != num_sparse_features)\n+    return errors::InvalidArgument(\n+        \"Expected \", num_sparse_features,\n+        \" tensors in sparse_example_indices but got \",\n+        sparse_example_indices_inputs.size());\n   OpInputList sparse_feature_indices_inputs;\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                          &sparse_feature_indices_inputs));\n+  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n+    return errors::InvalidArgument(\n+        \"Expected \", num_sparse_features,\n+        \" tensors in sparse_feature_indices but got \",\n+        sparse_feature_indices_inputs.size());\n   OpInputList sparse_feature_values_inputs;\n   if (num_sparse_features_with_values > 0) {\n     TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                            &sparse_feature_values_inputs));\n+    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n+      return errors::InvalidArgument(\n+          \"Expected \", num_sparse_features_with_values,\n+          \" tensors in sparse_feature_values but got \",\n+          sparse_feature_values_inputs.size());\n   }\n \n   const Tensor* example_weights_t;\n@@ -400,6 +429,13 @@ Status Examples::CreateSparseFeatureRepresentation(\n           sparse_example_indices_inputs[i].template flat<int64>();\n       auto feature_indices =\n           sparse_feature_indices_inputs[i].template flat<int64>();\n+      if (example_indices.size() != feature_indices.size()) {\n+        mutex_lock l(mu);\n+        result = errors::InvalidArgument(\n+            \"Found mismatched example_indices and feature_indices [\",\n+            example_indices, \"] vs [\", feature_indices, \"]\");\n+        return;\n+      }\n \n       // Parse features for each example. Features for a particular example\n       // are at the offsets (start_id, end_id]\n"
    ],
    "Buggy Code": [
        [
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"sparse_weights\", &sparse_weights_inputs));",
            "  OpInputList dense_weights_inputs;",
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"dense_weights\", &dense_weights_inputs));",
            "",
            "  OpOutputList sparse_weights_outputs;",
            "  TF_RETURN_IF_ERROR(context->output_list(\"out_delta_sparse_weights\",",
            "                                          &sparse_weights_outputs));",
            ""
        ],
        [
            "  TF_RETURN_IF_ERROR(",
            "      context->output_list(\"out_delta_dense_weights\", &dense_weights_outputs));",
            "",
            "  for (int i = 0; i < sparse_weights_inputs.size(); ++i) {",
            "    Tensor* delta_t;",
            "    TF_RETURN_IF_ERROR(sparse_weights_outputs.allocate(",
            "        i, sparse_weights_inputs[i].shape(), &delta_t));",
            "    // Convert the input vector to a row matrix in internal representation.",
            "    auto deltas = delta_t->shaped<float, 2>({1, delta_t->NumElements()});",
            "    deltas.setZero();",
            "    sparse_weights_.emplace_back(FeatureWeightsSparseStorage{",
            "        sparse_indices_inputs[i].flat<int64>(),",
            "        sparse_weights_inputs[i].shaped<float, 2>(",
            "            {1, sparse_weights_inputs[i].NumElements()}),",
            "        deltas});",
            "  }",
            "",
            "  // Reads in the weights, and allocates and initializes the delta weights.",
            "  const auto initialize_weights =",
            "      [&](const OpInputList& weight_inputs, OpOutputList* const weight_outputs,"
        ],
        [
            "",
            "  if (example_weights.size() >= std::numeric_limits<int>::max()) {",
            "    return errors::InvalidArgument(strings::Printf(",
            "        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),",
            "        std::numeric_limits<int>::max()));",
            "  }",
            "",
            "  // The static_cast here is safe since num_examples can be at max an int.",
            "  const int num_examples = static_cast<int>(example_weights.size());",
            "  const Tensor* example_labels_t;",
            "  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));",
            "  auto example_labels = example_labels_t->flat<float>();",
            "",
            "  OpInputList dense_features_inputs;",
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"dense_features\", &dense_features_inputs));",
            "",
            "  examples_.clear();",
            "  examples_.resize(num_examples);",
            "  probabilities_.resize(num_examples);",
            "  sampled_index_.resize(num_examples);",
            "  sampled_count_.resize(num_examples);",
            "  for (int example_id = 0; example_id < num_examples; ++example_id) {",
            "    Example* const example = &examples_[example_id];",
            "    example->sparse_features_.resize(num_sparse_features);",
            "    example->dense_vectors_.resize(num_dense_features);",
            "    example->example_weight_ = example_weights(example_id);",
            "    example->example_label_ = example_labels(example_id);"
        ],
        [
            "            for (int64 k = 0; k < sparse_features->indices->size(); ++k) {",
            "              const int64 feature_index = (*sparse_features->indices)(k);",
            "              if (!weights.SparseIndexValid(i, feature_index)) {",
            "                mutex_lock l(mu);",
            "                result = errors::InvalidArgument(",
            "                    \"Found sparse feature indices out of valid range: \",",
            "                    (*sparse_features->indices)(k));",
            "                return;",
            "              }",
            "            }",
            "          }",
            "        } else {",
            "          // Add a Tensor that has size 0."
        ]
    ],
    "Clean Code": [
        [
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"sparse_weights\", &sparse_weights_inputs));",
            "  if (sparse_indices_inputs.size() != sparse_weights_inputs.size())",
            "    return errors::InvalidArgument(",
            "        \"sparse_indices and sparse_weights must have the same length, got \",",
            "        sparse_indices_inputs.size(), \" and \", sparse_weights_inputs.size());",
            "  OpInputList dense_weights_inputs;",
            "  TF_RETURN_IF_ERROR(",
            "      context->input_list(\"dense_weights\", &dense_weights_inputs));",
            ""
        ],
        [
            "  TF_RETURN_IF_ERROR(context->output_list(\"out_delta_sparse_weights\",",
            "                                          &sparse_weights_outputs));",
            "  if (sparse_weights_outputs.size() != sparse_weights_inputs.size())",
            "    return errors::InvalidArgument(",
            "        \"out_delta_sparse_weights and sparse_weights must have the same \"",
            "        \"length, got \",",
            "        sparse_weights_outputs.size(), \" and \", sparse_weights_inputs.size());",
            "",
            "  OpOutputList dense_weights_outputs;",
            "  TF_RETURN_IF_ERROR(",
            "      context->output_list(\"out_delta_dense_weights\", &dense_weights_outputs));",
            "  if (dense_weights_outputs.size() != dense_weights_inputs.size())",
            "    return errors::InvalidArgument(",
            "        \"out_delta_dense_weights and dense_weights must have the same length, \"",
            "        \"got \",",
            "        dense_weights_outputs.size(), \" and \", dense_weights_inputs.size());",
            "",
            "  for (int i = 0; i < sparse_weights_inputs.size(); ++i) {",
            "    Tensor* delta_t;",
            "    TF_RETURN_IF_ERROR(sparse_weights_outputs.allocate("
        ],
        [
            "  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",",
            "                                         &sparse_example_indices_inputs));",
            "  if (sparse_example_indices_inputs.size() != num_sparse_features)",
            "    return errors::InvalidArgument(",
            "        \"Expected \", num_sparse_features,",
            "        \" tensors in sparse_example_indices but got \",",
            "        sparse_example_indices_inputs.size());",
            "  OpInputList sparse_feature_indices_inputs;",
            "  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",",
            "                                         &sparse_feature_indices_inputs));",
            "  if (sparse_feature_indices_inputs.size() != num_sparse_features)",
            "    return errors::InvalidArgument(",
            "        \"Expected \", num_sparse_features,",
            "        \" tensors in sparse_feature_indices but got \",",
            "        sparse_feature_indices_inputs.size());",
            "  OpInputList sparse_feature_values_inputs;",
            "  if (num_sparse_features_with_values > 0) {",
            "    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",",
            "                                           &sparse_feature_values_inputs));",
            "    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)",
            "      return errors::InvalidArgument(",
            "          \"Expected \", num_sparse_features_with_values,",
            "          \" tensors in sparse_feature_values but got \",",
            "          sparse_feature_values_inputs.size());",
            "  }",
            "",
            "  const Tensor* example_weights_t;",
            "  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));"
        ],
        [
            "      auto feature_indices =",
            "          sparse_feature_indices_inputs[i].template flat<int64>();",
            "      if (example_indices.size() != feature_indices.size()) {",
            "        mutex_lock l(mu);",
            "        result = errors::InvalidArgument(",
            "            \"Found mismatched example_indices and feature_indices [\",",
            "            example_indices, \"] vs [\", feature_indices, \"]\");",
            "        return;",
            "      }",
            "",
            "      // Parse features for each example. Features for a particular example",
            "      // are at the offsets (start_id, end_id]",
            "      int start_id = -1;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-5gqf-456p-4836",
    "API Signature": "tf.raw_ops.SdcaOptimizer(\n    sparse_example_indices,\n    sparse_feature_indices,\n    sparse_feature_values,\n    dense_features,\n    example_weights,\n    example_labels,\n    sparse_indices,\n    sparse_weights,\n    dense_weights,\n    example_state_data,\n    loss_type,\n    l1,\n    l2,\n    num_loss_partitions,\n    num_inner_iterations,\n    adaptative=True,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "sparse_example_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_indices = [tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64), tf.constant((0), dtype=tf.int64)]"
},
{
    "Title": "\n        Memory corruption in `DrawBoundingBoxesV2`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPoolGradWithArgmax  can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:",
    "Sample Code": "images = tf.fill([10, 96, 0, 1], 0.)\nboxes = tf.fill([10, 53, 0], 0.)\ncolors = tf.fill([0, 1], 0.)\n\n)\n\ntf.raw_ops.DrawBoundingBoxesV2(images=images, boxes=boxes, colors=colors)",
    "Code change": [
        "@@ -73,6 +73,12 @@ class DrawBoundingBoxesOp : public OpKernel {\n         errors::InvalidArgument(\"Channel depth should be either 1 (GRY), \"\n                                 \"3 (RGB), or 4 (RGBA)\"));\n \n+    OP_REQUIRES(\n+        context, boxes.dim_size(2) == 4,\n+        errors::InvalidArgument(\n+            \"The size of the third dimension of the box must be 4. Received: \",\n+            boxes.dim_size(2)));\n+\n     const int64 batch_size = images.dim_size(0);\n     const int64 height = images.dim_size(1);\n     const int64 width = images.dim_size(2);\n"
    ],
    "Buggy Code": [
        [
            "                                \"3 (RGB), or 4 (RGBA)\"));",
            "",
            "    const int64 batch_size = images.dim_size(0);",
            "    const int64 height = images.dim_size(1);",
            "    const int64 width = images.dim_size(2);",
            "    std::vector<std::vector<float>> color_table;",
            "    if (context->num_inputs() == 3) {",
            "      const Tensor& colors_tensor = context->input(2);",
            "      OP_REQUIRES(context, colors_tensor.shape().dims() == 2,",
            "                  errors::InvalidArgument(\"colors must be a 2-D matrix\",",
            "                                          colors_tensor.shape().DebugString()));",
            "      OP_REQUIRES(context, colors_tensor.shape().dim_size(1) >= depth,"
        ]
    ],
    "Clean Code": [
        [
            "                                \"3 (RGB), or 4 (RGBA)\"));",
            "",
            "    OP_REQUIRES(",
            "        context, boxes.dim_size(2) == 4,",
            "        errors::InvalidArgument(",
            "            \"The size of the third dimension of the box must be 4. Received: \",",
            "            boxes.dim_size(2)));",
            "",
            "    const int64 batch_size = images.dim_size(0);",
            "    const int64 height = images.dim_size(1);",
            "    const int64 width = images.dim_size(2);",
            "    std::vector<std::vector<float>> color_table;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-whr9-vfh2-7hm6",
    "API Signature": "tf.raw_ops.DrawBoundingBoxesV2(\n    images, boxes, colors, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "boxes = tf.fill([10, 53, 0], 0.)"
},
{
    "Title": "\n        Heap out of bounds read in `RequantizationRange`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPoolGradWithArgmax  can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:",
    "Sample Code": "input = tf.constant([1], shape=[1], dtype=tf.qint32) \ninput_max = tf.constant([], dtype=tf.float32)\ninput_min = tf.constant([], dtype=tf.float32)\n\n)\n\ntf.raw_ops.RequantizationRange(input=input, input_min=input_min, input_max=input_max)",
    "Code change": [
        "@@ -46,6 +46,10 @@ class RequantizationRangeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(ctx, ctx->input(1).NumElements() > 0,\n+                errors::InvalidArgument(\"Input min must not be empty.\"));\n+    OP_REQUIRES(ctx, ctx->input(2).NumElements() > 0,\n+                errors::InvalidArgument(\"Input max must not be empty.\"));\n     const float input_min_float = ctx->input(1).flat<float>()(0);\n     const float input_max_float = ctx->input(2).flat<float>()(0);\n     Tensor* output_min = nullptr;\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& input = ctx->input(0);",
            "    const float input_min_float = ctx->input(1).flat<float>()(0);",
            "    const float input_max_float = ctx->input(2).flat<float>()(0);",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &output_min));",
            "    Tensor* output_max = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_max));",
            "",
            "    qint32 used_min_quantized;"
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& input = ctx->input(0);",
            "    OP_REQUIRES(ctx, ctx->input(1).NumElements() > 0,",
            "                errors::InvalidArgument(\"Input min must not be empty.\"));",
            "    OP_REQUIRES(ctx, ctx->input(2).NumElements() > 0,",
            "                errors::InvalidArgument(\"Input max must not be empty.\"));",
            "    const float input_min_float = ctx->input(1).flat<float>()(0);",
            "    const float input_max_float = ctx->input(2).flat<float>()(0);",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &output_min));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-3h8m-483j-7xxm",
    "API Signature": "tf.raw_ops.RequantizationRange(\n    input, input_min, input_max, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "input_max = tf.constant([], dtype=tf.float32) \ninput_min = tf.constant([], dtype=tf.float32)"
},
{
    "Title": "\n        Heap out of bounds read in `MaxPoolGradWithArgmax`\n      ",
    "Bug description": "The implementation of  tf.raw_ops.MaxPoolGradWithArgmax  can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:",
    "Sample Code": "input = tf.constant([10.0, 10.0, 10.0], shape=[1, 1, 3, 1], dtype=tf.float32)\ngrad = tf.constant([10.0, 10.0, 10.0, 10.0], shape=[1, 1, 1, 4], dtype=tf.float32)\nargmax = tf.constant([1], shape=[1], dtype=tf.int64)\nksize = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\n  \ntf.raw_ops.MaxPoolGradWithArgmax(\n  input=input, grad=grad, argmax=argmax, ksize=ksize, strides=strides,\n  ,\n  padding='SAME', include_batch_in_index=False)",
    "Code change": [
        "@@ -1014,6 +1014,9 @@ struct LaunchMaxPoolingGradWithArgmax<CPUDevice, T> {\n         const int input_start = start * input_size_per_batch;\n         const int input_end = limit * input_size_per_batch;\n         for (int64 index = input_start; index < input_end; index++) {\n+          if (index >= argmax.NumElements()) {\n+            break;\n+          }\n           int64 grad_out_index = argmax_flat(index);\n           if (!include_batch_in_index) {\n             const int64 cur_batch = index / input_size_per_batch;\n"
    ],
    "Buggy Code": [
        [
            "        const int input_end = limit * input_size_per_batch;",
            "        for (int64 index = input_start; index < input_end; index++) {",
            "          int64 grad_out_index = argmax_flat(index);",
            "          if (!include_batch_in_index) {",
            "            const int64 cur_batch = index / input_size_per_batch;",
            "            grad_out_index += cur_batch * output_size_per_batch;",
            "          }",
            "          CHECK(grad_out_index >= output_start && grad_out_index < output_end)",
            "              << \"Invalid output gradient index: \" << grad_out_index << \", \""
        ]
    ],
    "Clean Code": [
        [
            "        const int input_end = limit * input_size_per_batch;",
            "        for (int64 index = input_start; index < input_end; index++) {",
            "          if (index >= argmax.NumElements()) {",
            "            break;",
            "          }",
            "          int64 grad_out_index = argmax_flat(index);",
            "          if (!include_batch_in_index) {",
            "            const int64 cur_batch = index / input_size_per_batch;",
            "            grad_out_index += cur_batch * output_size_per_batch;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-545v-42p7-98fq",
    "API Signature": "tf.raw_ops.MaxPoolGradWithArgmax(\n    input,\n    grad,\n    argmax,\n    ksize,\n    strides,\n    padding,\n    include_batch_in_index=False,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "input = tf.constant([10.0, 10.0, 10.0], shape=[1, 1, 3, 1], dtype=tf.float32) \nargmax = tf.constant([1], shape=[1], dtype=tf.int64)"
},
{
    "Title": "\n        Lack of validation in `SparseDenseCwiseMul`\n      ",
    "Bug description": "Due to lack of validation in  tf.raw_ops.SparseDenseCwiseMul , an attacker can trigger denial of service via  CHECK -fails or accesses to outside the bounds of heap allocated data:",
    "Sample Code": "indices = tf.constant([], shape=[10, 0], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\nshape = tf.constant([0, 0], shape=[2], dtype=tf.int64)\ndense = tf.constant([], shape=[0], dtype=tf.int64)\n  \ntf.raw_ops.SparseDenseCwiseMul(\n    (\n    sp_indices=indices, sp_values=values, sp_shape=shape, dense=dense)",
    "Code change": [
        "@@ -78,6 +78,11 @@ class SparseDenseBinaryOpShared : public OpKernel {\n                     \"but received shapes: \",\n                     values_t->shape().DebugString(), \" and \",\n                     shape_t->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n+        errors::InvalidArgument(\n+            \"The first dimension of values and indices should match. (\",\n+            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n \n     const auto indices_mat = indices_t->matrix<int64>();\n     const auto shape_vec = shape_t->vec<int64>();\n"
    ],
    "Buggy Code": [
        [
            "                    values_t->shape().DebugString(), \" and \",",
            "                    shape_t->shape().DebugString()));",
            "",
            "    const auto indices_mat = indices_t->matrix<int64>();",
            "    const auto shape_vec = shape_t->vec<int64>();",
            "    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));",
            "    const auto rhs_dims = BCast::FromShape(dense_t->shape());",
            "    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.",
            "",
            "    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal",
            "    // to dims in rhs (from right to left)."
        ]
    ],
    "Clean Code": [
        [
            "                    values_t->shape().DebugString(), \" and \",",
            "                    shape_t->shape().DebugString()));",
            "    OP_REQUIRES(",
            "        ctx, values_t->dim_size(0) == indices_t->dim_size(0),",
            "        errors::InvalidArgument(",
            "            \"The first dimension of values and indices should match. (\",",
            "            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));",
            "",
            "    const auto indices_mat = indices_t->matrix<int64>();",
            "    const auto shape_vec = shape_t->vec<int64>();",
            "    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wp3c-xw9g-gpcg",
    "API Signature": "tf.raw_ops.SparseDenseCwiseMul(\n    sp_indices, sp_values, sp_shape, dense, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "indices = tf.constant([], shape=[10, 0], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)"
},
{
    "Title": "\n        Reference binding to null in `ParameterizedTruncatedNormal`\n      ",
    "Bug description": "An attacker can trigger undefined behavior by binding to null pointer in  tf.raw_ops.ParameterizedTruncatedNormal :",
    "Sample Code": "shape = tf.constant([], shape=[0], dtype=tf.int32)\nmeans = tf.constant((1), dtype=tf.float32)\nstdevs = tf.constant((1), dtype=tf.float32)\nminvals = tf.constant((1), dtype=tf.float32)\nmaxvals = tf.constant((1), dtype=tf.float32)\n  \ntf.raw_ops.ParameterizedTruncatedNormal(\n  (\n  shape=shape, means=means, stdevs=stdevs, minvals=minvals, maxvals=maxvals)",
    "Code change": [
        "@@ -627,6 +627,9 @@ class ParameterizedTruncatedNormalOp : public OpKernel {\n         ctx, TensorShapeUtils::IsVector(shape_tensor.shape()),\n         errors::InvalidArgument(\"Input shape should be a vector, got shape: \",\n                                 shape_tensor.shape().DebugString()));\n+    OP_REQUIRES(ctx, shape_tensor.NumElements() > 0,\n+                errors::InvalidArgument(\"Shape tensor must not be empty, got \",\n+                                        shape_tensor.DebugString()));\n     int32 num_batches = shape_tensor.flat<int32>()(0);\n \n     int32 samples_per_batch = 1;\n"
    ],
    "Buggy Code": [
        [
            "        errors::InvalidArgument(\"Input shape should be a vector, got shape: \",",
            "                                shape_tensor.shape().DebugString()));",
            "    int32 num_batches = shape_tensor.flat<int32>()(0);",
            "",
            "    int32 samples_per_batch = 1;",
            "    const int32 num_dims = shape_tensor.dim_size(0);",
            "    for (int32 i = 1; i < num_dims; i++) {",
            "      samples_per_batch *= shape_tensor.flat<int32>()(i);",
            "    }"
        ]
    ],
    "Clean Code": [
        [
            "        errors::InvalidArgument(\"Input shape should be a vector, got shape: \",",
            "                                shape_tensor.shape().DebugString()));",
            "    OP_REQUIRES(ctx, shape_tensor.NumElements() > 0,",
            "                errors::InvalidArgument(\"Shape tensor must not be empty, got \",",
            "                                        shape_tensor.DebugString()));",
            "    int32 num_batches = shape_tensor.flat<int32>()(0);",
            "",
            "    int32 samples_per_batch = 1;",
            "    const int32 num_dims = shape_tensor.dim_size(0);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4p4p-www8-8fv9",
    "API Signature": "tf.raw_ops.ParameterizedTruncatedNormal(\n    shape, means, stdevs, minvals, maxvals, seed=0, seed2=0, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "shape = tf.constant([], shape=[0], dtype=tf.int32)"
},
{
    "Title": "\n        Null pointer dereference in `SparseFillEmptyRows`\n      ",
    "Bug description": "An attacker can trigger a null pointer dereference in the implementation of  tf.raw_ops.SparseFillEmptyRows :",
    "Sample Code": "indices = tf.constant([], shape=[0, 0], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\ndense_shape = tf.constant([], shape=[0], dtype=tf.int64)\ndefault_value = 0\n    \ntf.raw_ops.SparseFillEmptyRows(\n    indices=indices, values=values, dense_shape=dense_shape,\n    ,\n    default_value=default_value)",
    "Code change": [
        "@@ -228,7 +228,10 @@ void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                               default_value_t.shape().DebugString()),\n       done);\n   // TODO(ebrevdo): add shape checks between values, indices,\n-  // dense_shape.  Also add check that dense rank > 0.\n+  // Also add check that dense rank > 0.\n+  OP_REQUIRES_ASYNC(context, dense_shape_t.NumElements() != 0,\n+                    errors::InvalidArgument(\"Dense shape cannot be empty.\"),\n+                    done);\n \n   using FunctorType = functor::SparseFillEmptyRows<Device, T, Tindex>;\n   OP_REQUIRES_OK_ASYNC(context,\n"
    ],
    "Buggy Code": [
        [
            "      done);",
            "  // TODO(ebrevdo): add shape checks between values, indices,",
            "  // dense_shape.  Also add check that dense rank > 0.",
            "",
            "  using FunctorType = functor::SparseFillEmptyRows<Device, T, Tindex>;",
            "  OP_REQUIRES_OK_ASYNC(context,",
            "                       FunctorType()(context, default_value_t, indices_t,",
            "                                     values_t, dense_shape_t, done),",
            "                       done);",
            "}"
        ]
    ],
    "Clean Code": [
        [
            "      done);",
            "  // TODO(ebrevdo): add shape checks between values, indices,",
            "  // Also add check that dense rank > 0.",
            "  OP_REQUIRES_ASYNC(context, dense_shape_t.NumElements() != 0,",
            "                    errors::InvalidArgument(\"Dense shape cannot be empty.\"),",
            "                    done);",
            "",
            "  using FunctorType = functor::SparseFillEmptyRows<Device, T, Tindex>;",
            "  OP_REQUIRES_OK_ASYNC(context,",
            "                       FunctorType()(context, default_value_t, indices_t,"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-r6pg-pjwc-j585",
    "API Signature": "tf.raw_ops.SparseFillEmptyRows(\n    indices, values, dense_shape, default_value, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "dense_shape = tf.constant([], shape=[0], dtype=tf.int64),"
},
{
    "Title": "\n        Null pointer dereference in `EditDistance`\n      ",
    "Bug description": "An attacker can trigger a null pointer dereference in the implementation of  tf.raw_ops.EditDistance :",
    "Sample Code": "hypothesis_indices = tf.constant([247, 247, 247], shape=[1, 3], dtype=tf.int64)\nhypothesis_values = tf.constant([-9.9999], shape=[1], dtype=tf.float32)\nhypothesis_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\ntruth_indices = tf.constant([], shape=[0, 3], dtype=tf.int64)\ntruth_values = tf.constant([], shape=[0], dtype=tf.float32)\ntruth_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\n\ntf.raw_ops.EditDistance(\n    hypothesis_indices=hypothesis_indices, hypothesis_values=hypothesis_values,\n    hypothesis_shape=hypothesis_shape, truth_indices=truth_indices,\n    ,\n    truth_values=truth_values, truth_shape=truth_shape, normalize=True)",
    "Code change": [
        "@@ -64,6 +64,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\n     return errors::InvalidArgument(\n         \"truth_shape should be a vector, but got shape: \",\n         truth_shape.shape().DebugString());\n+  if (hypothesis_values.NumElements() != hypothesis_indices.dim_size(0))\n+    return errors::InvalidArgument(\n+        \"Expected hypothesis_values.NumElements == \"\n+        \"#rows(hypothesis_indices), their shapes are: \",\n+        hypothesis_values.shape().DebugString(), \" and \",\n+        hypothesis_indices.shape().DebugString());\n   if (hypothesis_shape.NumElements() != hypothesis_indices.dim_size(1))\n     return errors::InvalidArgument(\n         \"Expected hypothesis_shape.NumElements == \"\n@@ -75,6 +81,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\n         \"Input SparseTensors must have rank at least 2, but truth_shape \"\n         \"rank is: \",\n         truth_shape.NumElements());\n+  if (truth_values.NumElements() != truth_indices.dim_size(0))\n+    return errors::InvalidArgument(\n+        \"Expected truth_values.NumElements == \"\n+        \"#rows(truth_indices), their shapes are: \",\n+        truth_values.shape().DebugString(), \" and \",\n+        truth_indices.shape().DebugString());\n   if (truth_shape.NumElements() != truth_indices.dim_size(1))\n     return errors::InvalidArgument(\n         \"Expected truth_shape.NumElements == \"\n@@ -153,6 +165,11 @@ class EditDistanceOp : public OpKernel {\n       output_shape.AddDim(std::max(hypothesis_st_shape.dim_size(d),\n                                    truth_st_shape.dim_size(d)));\n     }\n+    const auto output_elements = output_shape.num_elements();\n+    OP_REQUIRES(\n+        ctx, output_elements > 0,\n+        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),\n+                                \" which has 0 elements\"));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\n@@ -185,6 +202,12 @@ class EditDistanceOp : public OpKernel {\n       if (g_truth == g_hypothesis) {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) =\n             gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);\n         if (normalize_) output_t(loc) /= truth_seq.size();\n@@ -194,6 +217,12 @@ class EditDistanceOp : public OpKernel {\n       } else if (g_truth > g_hypothesis) {  // zero-length truth\n         auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) = hypothesis_seq.size();\n         if (normalize_ && output_t(loc) != 0.0f) {\n           output_t(loc) = std::numeric_limits<float>::infinity();\n@@ -202,6 +231,12 @@ class EditDistanceOp : public OpKernel {\n       } else {  // zero-length hypothesis\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n         ++truth_iter;\n       }\n@@ -212,6 +247,12 @@ class EditDistanceOp : public OpKernel {\n       auto hypothesis_seq = hypothesis_j.values<T>();\n       auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                     output_strides.begin(), int64{0});\n+      OP_REQUIRES(\n+          ctx, loc < output_elements,\n+          errors::Internal(\"Got an inner product \", loc,\n+                           \" which would require in writing to outside of the \"\n+                           \"buffer for the output tensor (max elements \",\n+                           output_elements, \")\"));\n       output_t(loc) = hypothesis_seq.size();\n       if (normalize_ && output_t(loc) != 0.0f) {\n         output_t(loc) = std::numeric_limits<float>::infinity();\n@@ -224,6 +265,12 @@ class EditDistanceOp : public OpKernel {\n       auto truth_seq = truth_i.values<T>();\n       auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                     output_strides.begin(), int64{0});\n+      OP_REQUIRES(\n+          ctx, loc < output_elements,\n+          errors::Internal(\"Got an inner product \", loc,\n+                           \" which would require in writing to outside of the \"\n+                           \"buffer for the output tensor (max elements \",\n+                           output_elements, \")\"));\n       output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n       ++truth_iter;\n     }\n"
    ],
    "Buggy Code": [
        [
            "        \"truth_shape should be a vector, but got shape: \",",
            "        truth_shape.shape().DebugString());",
            "  if (hypothesis_shape.NumElements() != hypothesis_indices.dim_size(1))",
            "    return errors::InvalidArgument(",
            "        \"Expected hypothesis_shape.NumElements == \"",
            "        \"#cols(hypothesis_indices), their shapes are: \",",
            "        hypothesis_shape.shape().DebugString(), \" and \",",
            "        hypothesis_indices.shape().DebugString());",
            "  if (truth_shape.NumElements() < 2)",
            "    return errors::InvalidArgument(",
            "        \"Input SparseTensors must have rank at least 2, but truth_shape \"",
            "        \"rank is: \","
        ],
        [
            "        truth_shape.shape().DebugString(), \" and \",",
            "        truth_indices.shape().DebugString());",
            "  if (truth_shape.NumElements() != hypothesis_shape.NumElements())",
            "    return errors::InvalidArgument(",
            "        \"Expected truth and hypothesis to have matching ranks, but \"",
            "        \"their shapes are: \",",
            "        truth_shape.shape().DebugString(), \" and \",",
            "        hypothesis_shape.shape().DebugString());",
            "",
            "  return Status::OK();",
            "}",
            ""
        ],
        [
            "    }",
            "",
            "    auto hypothesis_grouper = hypothesis.group(group_dims);",
            "    auto truth_grouper = truth.group(group_dims);",
            "",
            "    auto hypothesis_iter = hypothesis_grouper.begin();",
            "    auto truth_iter = truth_grouper.begin();",
            "",
            "    auto cmp = std::equal_to<T>();",
            "",
            "    while (hypothesis_iter != hypothesis_grouper.end() &&"
        ],
        [
            "        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),",
            "                                      output_strides.begin(), int64{0});",
            "        output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "        ++truth_iter;",
            "      }",
            "    }",
            "    while (hypothesis_iter != hypothesis_grouper.end()) {  // zero-length truths",
            "      sparse::Group hypothesis_j = *hypothesis_iter;",
            "      std::vector<int64> g_hypothesis = hypothesis_j.group();",
            "      auto hypothesis_seq = hypothesis_j.values<T>();",
            "      auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),",
            "                                    output_strides.begin(), int64{0});"
        ],
        [
            "      }",
            "      ++hypothesis_iter;",
            "    }",
            "    while (truth_iter != truth_grouper.end()) {  // missing hypotheses",
            "      sparse::Group truth_i = *truth_iter;",
            "      std::vector<int64> g_truth = truth_i.group();",
            "      auto truth_seq = truth_i.values<T>();",
            "      auto loc = std::inner_product(g_truth.begin(), g_truth.end(),",
            "                                    output_strides.begin(), int64{0});",
            "      output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "      ++truth_iter;",
            "    }"
        ],
        [
            " private:",
            "  bool normalize_;",
            "",
            "  TF_DISALLOW_COPY_AND_ASSIGN(EditDistanceOp);",
            "};",
            "",
            "#define REGISTER_CPU_KERNEL(T)                                        \\",
            "  REGISTER_KERNEL_BUILDER(                                            \\",
            "      Name(\"EditDistance\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      EditDistanceOp<T>);",
            "",
            "TF_CALL_POD_STRING_TYPES(REGISTER_CPU_KERNEL);"
        ],
        [
            ""
        ],
        []
    ],
    "Clean Code": [
        [
            "        \"truth_shape should be a vector, but got shape: \",",
            "        truth_shape.shape().DebugString());",
            "  if (hypothesis_values.NumElements() != hypothesis_indices.dim_size(0))",
            "    return errors::InvalidArgument(",
            "        \"Expected hypothesis_values.NumElements == \"",
            "        \"#rows(hypothesis_indices), their shapes are: \",",
            "        hypothesis_values.shape().DebugString(), \" and \",",
            "        hypothesis_indices.shape().DebugString());",
            "  if (hypothesis_shape.NumElements() != hypothesis_indices.dim_size(1))",
            "    return errors::InvalidArgument(",
            "        \"Expected hypothesis_shape.NumElements == \"",
            "        \"#cols(hypothesis_indices), their shapes are: \","
        ],
        [
            "        \"rank is: \",",
            "        truth_shape.NumElements());",
            "  if (truth_values.NumElements() != truth_indices.dim_size(0))",
            "    return errors::InvalidArgument(",
            "        \"Expected truth_values.NumElements == \"",
            "        \"#rows(truth_indices), their shapes are: \",",
            "        truth_values.shape().DebugString(), \" and \",",
            "        truth_indices.shape().DebugString());",
            "  if (truth_shape.NumElements() != truth_indices.dim_size(1))",
            "    return errors::InvalidArgument(",
            "        \"Expected truth_shape.NumElements == \"",
            "        \"#cols(truth_indices), their shapes are: \","
        ],
        [
            "                                   truth_st_shape.dim_size(d)));",
            "    }",
            "    const auto output_elements = output_shape.num_elements();",
            "    OP_REQUIRES(",
            "        ctx, output_elements > 0,",
            "        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),",
            "                                \" which has 0 elements\"));",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));",
            "    auto output_t = output->flat<float>();"
        ],
        [
            "        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),",
            "                                      output_strides.begin(), int64{0});",
            "        OP_REQUIRES(",
            "            ctx, loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require in writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) =",
            "            gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);",
            "        if (normalize_) output_t(loc) /= truth_seq.size();",
            ""
        ],
        [
            "        auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),",
            "                                      output_strides.begin(), int64{0});",
            "        OP_REQUIRES(",
            "            ctx, loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require in writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) = hypothesis_seq.size();",
            "        if (normalize_ && output_t(loc) != 0.0f) {",
            "          output_t(loc) = std::numeric_limits<float>::infinity();",
            "        }"
        ],
        [
            "        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),",
            "                                      output_strides.begin(), int64{0});",
            "        OP_REQUIRES(",
            "            ctx, loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require in writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "        ++truth_iter;",
            "      }",
            "    }"
        ],
        [
            "      auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),",
            "                                    output_strides.begin(), int64{0});",
            "      OP_REQUIRES(",
            "          ctx, loc < output_elements,",
            "          errors::Internal(\"Got an inner product \", loc,",
            "                           \" which would require in writing to outside of the \"",
            "                           \"buffer for the output tensor (max elements \",",
            "                           output_elements, \")\"));",
            "      output_t(loc) = hypothesis_seq.size();",
            "      if (normalize_ && output_t(loc) != 0.0f) {",
            "        output_t(loc) = std::numeric_limits<float>::infinity();",
            "      }"
        ],
        [
            "      auto loc = std::inner_product(g_truth.begin(), g_truth.end(),",
            "                                    output_strides.begin(), int64{0});",
            "      OP_REQUIRES(",
            "          ctx, loc < output_elements,",
            "          errors::Internal(\"Got an inner product \", loc,",
            "                           \" which would require in writing to outside of the \"",
            "                           \"buffer for the output tensor (max elements \",",
            "                           output_elements, \")\"));",
            "      output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "      ++truth_iter;",
            "    }",
            "  }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-75f6-78jr-4656",
    "API Signature": "tf.raw_ops.EditDistance(\n    hypothesis_indices,\n    hypothesis_values,\n    hypothesis_shape,\n    truth_indices,\n    truth_values,\n    truth_shape,\n    normalize=True,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "hypothesis_indices = tf.constant([247, 247, 247], shape=[1, 3], dtype=tf.int64) \nhypothesis_values = tf.constant([-9.9999], shape=[1], dtype=tf.float32)"
},
{
    "Title": "\n        Null pointer dereference in `EditDistance`\n      ",
    "Bug description": "An attacker can trigger a null pointer dereference in the implementation of  tf.raw_ops.EditDistance :",
    "Sample Code": "hypothesis_indices = tf.constant([247, 247, 247], shape=[1, 3], dtype=tf.int64)\nhypothesis_values = tf.constant([-9.9999], shape=[1], dtype=tf.float32)\nhypothesis_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\ntruth_indices = tf.constant([], shape=[0, 3], dtype=tf.int64)\ntruth_values = tf.constant([], shape=[0], dtype=tf.float32)\ntruth_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\n\ntf.raw_ops.EditDistance(\n    hypothesis_indices=hypothesis_indices, hypothesis_values=hypothesis_values,\n    hypothesis_shape=hypothesis_shape, truth_indices=truth_indices,\n    ,\n    truth_values=truth_values, truth_shape=truth_shape, normalize=True)",
    "Code change": [
        "@@ -64,6 +64,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\n     return errors::InvalidArgument(\n         \"truth_shape should be a vector, but got shape: \",\n         truth_shape.shape().DebugString());\n+  if (hypothesis_values.NumElements() != hypothesis_indices.dim_size(0))\n+    return errors::InvalidArgument(\n+        \"Expected hypothesis_values.NumElements == \"\n+        \"#rows(hypothesis_indices), their shapes are: \",\n+        hypothesis_values.shape().DebugString(), \" and \",\n+        hypothesis_indices.shape().DebugString());\n   if (hypothesis_shape.NumElements() != hypothesis_indices.dim_size(1))\n     return errors::InvalidArgument(\n         \"Expected hypothesis_shape.NumElements == \"\n@@ -75,6 +81,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\n         \"Input SparseTensors must have rank at least 2, but truth_shape \"\n         \"rank is: \",\n         truth_shape.NumElements());\n+  if (truth_values.NumElements() != truth_indices.dim_size(0))\n+    return errors::InvalidArgument(\n+        \"Expected truth_values.NumElements == \"\n+        \"#rows(truth_indices), their shapes are: \",\n+        truth_values.shape().DebugString(), \" and \",\n+        truth_indices.shape().DebugString());\n   if (truth_shape.NumElements() != truth_indices.dim_size(1))\n     return errors::InvalidArgument(\n         \"Expected truth_shape.NumElements == \"\n@@ -153,6 +165,11 @@ class EditDistanceOp : public OpKernel {\n       output_shape.AddDim(std::max(hypothesis_st_shape.dim_size(d),\n                                    truth_st_shape.dim_size(d)));\n     }\n+    const auto output_elements = output_shape.num_elements();\n+    OP_REQUIRES(\n+        ctx, output_elements > 0,\n+        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),\n+                                \" which has 0 elements\"));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\n@@ -185,6 +202,12 @@ class EditDistanceOp : public OpKernel {\n       if (g_truth == g_hypothesis) {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) =\n             gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);\n         if (normalize_) output_t(loc) /= truth_seq.size();\n@@ -194,6 +217,12 @@ class EditDistanceOp : public OpKernel {\n       } else if (g_truth > g_hypothesis) {  // zero-length truth\n         auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) = hypothesis_seq.size();\n         if (normalize_ && output_t(loc) != 0.0f) {\n           output_t(loc) = std::numeric_limits<float>::infinity();\n@@ -202,6 +231,12 @@ class EditDistanceOp : public OpKernel {\n       } else {  // zero-length hypothesis\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64{0});\n+        OP_REQUIRES(\n+            ctx, loc < output_elements,\n+            errors::Internal(\"Got an inner product \", loc,\n+                             \" which would require in writing to outside of \"\n+                             \"the buffer for the output tensor (max elements \",\n+                             output_elements, \")\"));\n         output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n         ++truth_iter;\n       }\n@@ -212,6 +247,12 @@ class EditDistanceOp : public OpKernel {\n       auto hypothesis_seq = hypothesis_j.values<T>();\n       auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                     output_strides.begin(), int64{0});\n+      OP_REQUIRES(\n+          ctx, loc < output_elements,\n+          errors::Internal(\"Got an inner product \", loc,\n+                           \" which would require in writing to outside of the \"\n+                           \"buffer for the output tensor (max elements \",\n+                           output_elements, \")\"));\n       output_t(loc) = hypothesis_seq.size();\n       if (normalize_ && output_t(loc) != 0.0f) {\n         output_t(loc) = std::numeric_limits<float>::infinity();\n@@ -224,6 +265,12 @@ class EditDistanceOp : public OpKernel {\n       auto truth_seq = truth_i.values<T>();\n       auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                     output_strides.begin(), int64{0});\n+      OP_REQUIRES(\n+          ctx, loc < output_elements,\n+          errors::Internal(\"Got an inner product \", loc,\n+                           \" which would require in writing to outside of the \"\n+                           \"buffer for the output tensor (max elements \",\n+                           output_elements, \")\"));\n       output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n       ++truth_iter;\n     }\n"
    ],
    "Buggy Code": [
        [
            "        \"truth_shape should be a vector, but got shape: \",",
            "        truth_shape.shape().DebugString());",
            "  if (hypothesis_shape.NumElements() != hypothesis_indices.dim_size(1))",
            "    return errors::InvalidArgument(",
            "        \"Expected hypothesis_shape.NumElements == \"",
            "        \"#cols(hypothesis_indices), their shapes are: \",",
            "        hypothesis_shape.shape().DebugString(), \" and \",",
            "        hypothesis_indices.shape().DebugString());",
            "  if (truth_shape.NumElements() < 2)",
            "    return errors::InvalidArgument(",
            "        \"Input SparseTensors must have rank at least 2, but truth_shape \"",
            "        \"rank is: \","
        ],
        [
            "        truth_shape.shape().DebugString(), \" and \",",
            "        truth_indices.shape().DebugString());",
            "  if (truth_shape.NumElements() != hypothesis_shape.NumElements())",
            "    return errors::InvalidArgument(",
            "        \"Expected truth and hypothesis to have matching ranks, but \"",
            "        \"their shapes are: \",",
            "        truth_shape.shape().DebugString(), \" and \",",
            "        hypothesis_shape.shape().DebugString());",
            "",
            "  return Status::OK();",
            "}",
            ""
        ],
        [
            "    }",
            "",
            "    auto hypothesis_grouper = hypothesis.group(group_dims);",
            "    auto truth_grouper = truth.group(group_dims);",
            "",
            "    auto hypothesis_iter = hypothesis_grouper.begin();",
            "    auto truth_iter = truth_grouper.begin();",
            "",
            "    auto cmp = std::equal_to<T>();",
            "",
            "    while (hypothesis_iter != hypothesis_grouper.end() &&"
        ],
        [
            "        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),",
            "                                      output_strides.begin(), int64{0});",
            "        output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "        ++truth_iter;",
            "      }",
            "    }",
            "    while (hypothesis_iter != hypothesis_grouper.end()) {  // zero-length truths",
            "      sparse::Group hypothesis_j = *hypothesis_iter;",
            "      std::vector<int64> g_hypothesis = hypothesis_j.group();",
            "      auto hypothesis_seq = hypothesis_j.values<T>();",
            "      auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),",
            "                                    output_strides.begin(), int64{0});"
        ],
        [
            "      }",
            "      ++hypothesis_iter;",
            "    }",
            "    while (truth_iter != truth_grouper.end()) {  // missing hypotheses",
            "      sparse::Group truth_i = *truth_iter;",
            "      std::vector<int64> g_truth = truth_i.group();",
            "      auto truth_seq = truth_i.values<T>();",
            "      auto loc = std::inner_product(g_truth.begin(), g_truth.end(),",
            "                                    output_strides.begin(), int64{0});",
            "      output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "      ++truth_iter;",
            "    }"
        ],
        [
            " private:",
            "  bool normalize_;",
            "",
            "  TF_DISALLOW_COPY_AND_ASSIGN(EditDistanceOp);",
            "};",
            "",
            "#define REGISTER_CPU_KERNEL(T)                                        \\",
            "  REGISTER_KERNEL_BUILDER(                                            \\",
            "      Name(\"EditDistance\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
            "      EditDistanceOp<T>);",
            "",
            "TF_CALL_POD_STRING_TYPES(REGISTER_CPU_KERNEL);"
        ],
        [
            ""
        ],
        []
    ],
    "Clean Code": [
        [
            "        \"truth_shape should be a vector, but got shape: \",",
            "        truth_shape.shape().DebugString());",
            "  if (hypothesis_values.NumElements() != hypothesis_indices.dim_size(0))",
            "    return errors::InvalidArgument(",
            "        \"Expected hypothesis_values.NumElements == \"",
            "        \"#rows(hypothesis_indices), their shapes are: \",",
            "        hypothesis_values.shape().DebugString(), \" and \",",
            "        hypothesis_indices.shape().DebugString());",
            "  if (hypothesis_shape.NumElements() != hypothesis_indices.dim_size(1))",
            "    return errors::InvalidArgument(",
            "        \"Expected hypothesis_shape.NumElements == \"",
            "        \"#cols(hypothesis_indices), their shapes are: \","
        ],
        [
            "        \"rank is: \",",
            "        truth_shape.NumElements());",
            "  if (truth_values.NumElements() != truth_indices.dim_size(0))",
            "    return errors::InvalidArgument(",
            "        \"Expected truth_values.NumElements == \"",
            "        \"#rows(truth_indices), their shapes are: \",",
            "        truth_values.shape().DebugString(), \" and \",",
            "        truth_indices.shape().DebugString());",
            "  if (truth_shape.NumElements() != truth_indices.dim_size(1))",
            "    return errors::InvalidArgument(",
            "        \"Expected truth_shape.NumElements == \"",
            "        \"#cols(truth_indices), their shapes are: \","
        ],
        [
            "                                   truth_st_shape.dim_size(d)));",
            "    }",
            "    const auto output_elements = output_shape.num_elements();",
            "    OP_REQUIRES(",
            "        ctx, output_elements > 0,",
            "        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),",
            "                                \" which has 0 elements\"));",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));",
            "    auto output_t = output->flat<float>();"
        ],
        [
            "        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),",
            "                                      output_strides.begin(), int64{0});",
            "        OP_REQUIRES(",
            "            ctx, loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require in writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) =",
            "            gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);",
            "        if (normalize_) output_t(loc) /= truth_seq.size();",
            ""
        ],
        [
            "        auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),",
            "                                      output_strides.begin(), int64{0});",
            "        OP_REQUIRES(",
            "            ctx, loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require in writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) = hypothesis_seq.size();",
            "        if (normalize_ && output_t(loc) != 0.0f) {",
            "          output_t(loc) = std::numeric_limits<float>::infinity();",
            "        }"
        ],
        [
            "        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),",
            "                                      output_strides.begin(), int64{0});",
            "        OP_REQUIRES(",
            "            ctx, loc < output_elements,",
            "            errors::Internal(\"Got an inner product \", loc,",
            "                             \" which would require in writing to outside of \"",
            "                             \"the buffer for the output tensor (max elements \",",
            "                             output_elements, \")\"));",
            "        output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "        ++truth_iter;",
            "      }",
            "    }"
        ],
        [
            "      auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),",
            "                                    output_strides.begin(), int64{0});",
            "      OP_REQUIRES(",
            "          ctx, loc < output_elements,",
            "          errors::Internal(\"Got an inner product \", loc,",
            "                           \" which would require in writing to outside of the \"",
            "                           \"buffer for the output tensor (max elements \",",
            "                           output_elements, \")\"));",
            "      output_t(loc) = hypothesis_seq.size();",
            "      if (normalize_ && output_t(loc) != 0.0f) {",
            "        output_t(loc) = std::numeric_limits<float>::infinity();",
            "      }"
        ],
        [
            "      auto loc = std::inner_product(g_truth.begin(), g_truth.end(),",
            "                                    output_strides.begin(), int64{0});",
            "      OP_REQUIRES(",
            "          ctx, loc < output_elements,",
            "          errors::Internal(\"Got an inner product \", loc,",
            "                           \" which would require in writing to outside of the \"",
            "                           \"buffer for the output tensor (max elements \",",
            "                           output_elements, \")\"));",
            "      output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();",
            "      ++truth_iter;",
            "    }",
            "  }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-75f6-78jr-4656",
    "API Signature": "tf.raw_ops.EditDistance(\n    hypothesis_indices,\n    hypothesis_values,\n    hypothesis_shape,\n    truth_indices,\n    truth_values,\n    truth_shape,\n    normalize=True,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "truth_indices = tf.constant([], shape=[0, 3], dtype=tf.int64) \ntruth_values = tf.constant([], shape=[0], dtype=tf.float32)"
},
{
    "Title": "\n        `CHECK`-fail in `tf.raw_ops.RFFT`\n      ",
    "Bug description": "An attacker can cause a denial of service by exploiting a  CHECK -failure coming from the implementation of  tf.raw_ops.RFFT :",
    "Sample Code": "inputs = tf.constant([1], shape=[1], dtype=tf.float32)\nfft_length = tf.constant([0], shape=[1], dtype=tf.int32)\n\n)\n\ntf.raw_ops.RFFT(input=inputs, fft_length=fft_length)",
    "Code change": [
        "@@ -222,6 +222,9 @@ class FFTCPU : public FFTBase {\n       input_slice_sizes[i] = fft_shape[i - 1];\n       temp_shape.AddDim(fft_shape[i - 1]);\n     }\n+    OP_REQUIRES(ctx, temp_shape.num_elements() > 0,\n+                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\n+                                        temp_shape.DebugString()));\n \n     auto output = out->flat_inner_dims<ComplexT, FFTRank + 1>();\n     const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> zero_start_indices;\n"
    ],
    "Buggy Code": [
        [
            "      temp_shape.AddDim(fft_shape[i - 1]);",
            "    }",
            "",
            "    auto output = out->flat_inner_dims<ComplexT, FFTRank + 1>();",
            "    const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> zero_start_indices;",
            "",
            "    // Compute the full FFT using a temporary tensor.",
            "    Tensor temp;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),"
        ]
    ],
    "Clean Code": [
        [
            "      temp_shape.AddDim(fft_shape[i - 1]);",
            "    }",
            "    OP_REQUIRES(ctx, temp_shape.num_elements() > 0,",
            "                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",",
            "                                        temp_shape.DebugString()));",
            "",
            "    auto output = out->flat_inner_dims<ComplexT, FFTRank + 1>();",
            "    const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> zero_start_indices;",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-ph87-fvjr-v33w",
    "API Signature": "tf.raw_ops.RFFT(\n    input,\n    fft_length,\n    Tcomplex=tf.dtypes.complex64,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "fft_length = tf.constant([0], shape=[1], dtype=tf.int32)"
},
{
    "Title": "\n        `CHECK`-fail in `tf.raw_ops.IRFFT`\n      ",
    "Bug description": "An attacker can cause a denial of service by exploiting a  CHECK -failure coming from the implementation of  tf.raw_ops.IRFFT :",
    "Sample Code": "values = [-10.0] * 130\nvalues[0] = -9.999999999999995\ninputs = tf.constant(values, shape=[10, 13], dtype=tf.float32)\ninputs = tf.cast(inputs, dtype=tf.complex64)\nfft_length = tf.constant([0], shape=[1], dtype=tf.int32)\n\n)\n\ntf.raw_ops.IRFFT(input=inputs, fft_length=fft_length)",
    "Code change": [
        "@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include \"tensorflow/core/platform/errors.h\"\n #define EIGEN_USE_THREADS\n \n // See docs in ../ops/fft_ops.cc.\n@@ -261,6 +262,9 @@ class FFTCPU : public FFTBase {\n           i == FFTRank ? fft_shape[i - 1] / 2 + 1 : fft_shape[i - 1];\n       full_fft_shape.AddDim(fft_shape[i - 1]);\n     }\n+    OP_REQUIRES(ctx, full_fft_shape.num_elements() > 0,\n+                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\n+                                        full_fft_shape.DebugString()));\n \n     Tensor temp;\n     OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),\n"
    ],
    "Buggy Code": [
        [
            "==============================================================================*/",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "// See docs in ../ops/fft_ops.cc.",
            "",
            "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\""
        ],
        [
            "    }",
            "",
            "    Tensor temp;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),",
            "                                           full_fft_shape, &temp));",
            "    auto full_fft = temp.flat_inner_dims<ComplexT, FFTRank + 1>();",
            "",
            "    // Calculate the starting point and range of the source of",
            "    // negative frequency part."
        ]
    ],
    "Clean Code": [
        [
            "==============================================================================*/",
            "",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#define EIGEN_USE_THREADS",
            "",
            "// See docs in ../ops/fft_ops.cc.",
            ""
        ],
        [
            "      full_fft_shape.AddDim(fft_shape[i - 1]);",
            "    }",
            "    OP_REQUIRES(ctx, full_fft_shape.num_elements() > 0,",
            "                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",",
            "                                        full_fft_shape.DebugString()));",
            "",
            "    Tensor temp;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),",
            "                                           full_fft_shape, &temp));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-36vm-xw34-x4pj",
    "API Signature": "tf.raw_ops.IRFFT(\n    input,\n    fft_length,\n    Treal=tf.dtypes.float32,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "fft_length = tf.constant([0], shape=[1], dtype=tf.int32)"
},
{
    "Title": "\n        `CHECK`-fail in `LoadAndRemapMatrix` \n      ",
    "Bug description": "An attacker can cause a denial of service by exploiting a  CHECK -failure coming from  tf.raw_ops.LoadAndRemapMatrix :",
    "Sample Code": "ckpt_path = tf.constant([], shape=[0], dtype=tf.string)\nold_tensor_name = tf.constant(\"\")\nrow_remapping = tf.constant([], shape=[0], dtype=tf.int64)\ncol_remapping = tf.constant([1], shape=[1], dtype=tf.int64)\ninitializing_values = tf.constant(1.0)\n\ntf.raw_ops.LoadAndRemapMatrix(\n    ckpt_path=ckpt_path, old_tensor_name=old_tensor_name,\n    row_remapping=row_remapping, col_remapping=col_remapping,\n    ,\n    initializing_values=initializing_values, num_rows=0, num_cols=1)",
    "Code change": [
        "@@ -123,6 +123,11 @@ class LoadAndRemapMatrixOp : public OpKernel {\n     // Processes the checkpoint source and the provided Tensor name.\n     const Tensor* ckpt_path_t;\n     OP_REQUIRES_OK(context, context->input(\"ckpt_path\", &ckpt_path_t));\n+    OP_REQUIRES(\n+        context, ckpt_path_t->NumElements() == 1,\n+        errors::InvalidArgument(\"The `ckpt_path` tensor must have exactly one \"\n+                                \"element, got tensor of shape \",\n+                                ckpt_path_t->shape().DebugString()));\n     const string& ckpt_path = ckpt_path_t->scalar<tstring>()();\n     const Tensor* old_tensor_name_t;\n     OP_REQUIRES_OK(context,\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor* ckpt_path_t;",
            "    OP_REQUIRES_OK(context, context->input(\"ckpt_path\", &ckpt_path_t));",
            "    const string& ckpt_path = ckpt_path_t->scalar<tstring>()();",
            "    const Tensor* old_tensor_name_t;",
            "    OP_REQUIRES_OK(context,",
            "                   context->input(\"old_tensor_name\", &old_tensor_name_t));",
            "    const string& old_tensor_name = old_tensor_name_t->scalar<tstring>()();",
            "",
            "    LOG(INFO) << \"Processing checkpoint : \" << ckpt_path;",
            "    BundleReader reader(context->env(), ckpt_path);",
            "    OP_REQUIRES_OK(context, reader.status());"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor* ckpt_path_t;",
            "    OP_REQUIRES_OK(context, context->input(\"ckpt_path\", &ckpt_path_t));",
            "    OP_REQUIRES(",
            "        context, ckpt_path_t->NumElements() == 1,",
            "        errors::InvalidArgument(\"The `ckpt_path` tensor must have exactly one \"",
            "                                \"element, got tensor of shape \",",
            "                                ckpt_path_t->shape().DebugString()));",
            "    const string& ckpt_path = ckpt_path_t->scalar<tstring>()();",
            "    const Tensor* old_tensor_name_t;",
            "    OP_REQUIRES_OK(context,",
            "                   context->input(\"old_tensor_name\", &old_tensor_name_t));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gvm4-h8j3-rjrq",
    "API Signature": "tf.raw_ops.LoadAndRemapMatrix(\n    ckpt_path,\n    old_tensor_name,\n    row_remapping,\n    col_remapping,\n    initializing_values,\n    num_rows,\n    num_cols,\n    max_rows_in_memory=-1,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "ckpt_path = tf.constant([], shape=[0], dtype=tf.string)"
},
{
    "Title": "\n        Heap OOB access in unicode ops\n      ",
    "Bug description": "An attacker can access data outside of bounds of heap allocated array in  tf.raw_ops.UnicodeEncode :",
    "Sample Code": "input_values = tf.constant([58], shape=[1], dtype=tf.int32)\ninput_splits = tf.constant([[81, 101, 0]], shape=[3], dtype=tf.int32)\noutput_encoding = \"UTF-8\"\n\ntf.raw_ops.UnicodeEncode(\n    input_values=input_values, input_splits=input_splits,\n    ,\n    output_encoding=output_encoding)",
    "Code change": [
        "@@ -533,6 +533,17 @@ class UnicodeEncodeOp : public OpKernel {\n     const Tensor& input_splits = context->input(1);\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n \n+    // Operation will treat first argument in input_splits as if it were zero\n+    // regardless of its actual value since splits should begin with zero and\n+    // end with the length of the input values vector.\n+    OP_REQUIRES(\n+        context, input_splits_flat(0) == 0,\n+        errors::InvalidArgument(\"First value in input_splits must be zero.\"));\n+    OP_REQUIRES(context,\n+                input_splits_flat(input_splits_flat.size() - 1) ==\n+                    input_tensor_flat.size(),\n+                errors::InvalidArgument(\"Last value in input_splits must be \"\n+                                        \"equal to length of input_tensor.\"));\n     // Since we limit to a 2-D input (flat_values of rank 1 and a single splits\n     // tensor), our output dimension will be 1 with it's size equal to the\n     // number of splits (outer dimension or ragged tensor).\n@@ -548,6 +559,14 @@ class UnicodeEncodeOp : public OpKernel {\n     for (int i = 1; i < input_splits_flat.size(); ++i) {\n       icu::UnicodeString unicode_string;\n       icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);\n+      OP_REQUIRES(\n+          context, input_splits_flat(i - 1) <= input_splits_flat(i),\n+          errors::InvalidArgument(\n+              \"Values in input_splits must be equal or in ascending order.\"));\n+      OP_REQUIRES(\n+          context, input_splits_flat(i) <= input_tensor_flat.size(),\n+          errors::InvalidArgument(\"Values in input_splits must be less than or \"\n+                                  \"equal to input_tensor length.\"));\n       for (; idx < input_splits_flat(i); ++idx) {\n         int32 code_point = input_tensor_flat(idx);\n         // Check for invalid code point\n"
    ],
    "Buggy Code": [
        [
            "    const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();",
            "",
            "    // Since we limit to a 2-D input (flat_values of rank 1 and a single splits",
            "    // tensor), our output dimension will be 1 with it's size equal to the",
            "    // number of splits (outer dimension or ragged tensor).",
            "    TensorShape output_shape({input_splits.dim_size(0) - 1});",
            "    Tensor* output_tensor;",
            "    OP_REQUIRES_OK(context, context->allocate_output(\"output\", output_shape,",
            "                                                     &output_tensor));",
            "    auto output_tensor_flat = output_tensor->flat<tstring>();",
            "",
            "    // Use a single index over the flattened input values tensor.",
            "    int idx = 0;",
            "    // Loop through our split dimension to create a new string at each split.",
            "    for (int i = 1; i < input_splits_flat.size(); ++i) {",
            "      icu::UnicodeString unicode_string;",
            "      icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);"
        ],
        [
            "            code_point = error_options_.subst;",
            "          }",
            "        }",
            "        appendable_unicode_string.appendCodePoint(code_point);",
            "      }",
            "      // Encode our string and save in the output.",
            "      tstring result;",
            "      Encode(encoding_, unicode_string, &result);",
            "      output_tensor_flat(i - 1) = std::move(result);",
            "    }",
            "  }",
            "",
            " private:",
            "  UnicodeEncoding encoding_;"
        ]
    ],
    "Clean Code": [
        [
            "    const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();",
            "",
            "    // Operation will treat first argument in input_splits as if it were zero",
            "    // regardless of its actual value since splits should begin with zero and",
            "    // end with the length of the input values vector.",
            "    OP_REQUIRES(",
            "        context, input_splits_flat(0) == 0,",
            "        errors::InvalidArgument(\"First value in input_splits must be zero.\"));",
            "    OP_REQUIRES(context,",
            "                input_splits_flat(input_splits_flat.size() - 1) ==",
            "                    input_tensor_flat.size(),",
            "                errors::InvalidArgument(\"Last value in input_splits must be \"",
            "                                        \"equal to length of input_tensor.\"));",
            "    // Since we limit to a 2-D input (flat_values of rank 1 and a single splits",
            "    // tensor), our output dimension will be 1 with it's size equal to the",
            "    // number of splits (outer dimension or ragged tensor).",
            "    TensorShape output_shape({input_splits.dim_size(0) - 1});"
        ],
        [
            "      icu::UnicodeString unicode_string;",
            "      icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);",
            "      OP_REQUIRES(",
            "          context, input_splits_flat(i - 1) <= input_splits_flat(i),",
            "          errors::InvalidArgument(",
            "              \"Values in input_splits must be equal or in ascending order.\"));",
            "      OP_REQUIRES(",
            "          context, input_splits_flat(i) <= input_tensor_flat.size(),",
            "          errors::InvalidArgument(\"Values in input_splits must be less than or \"",
            "                                  \"equal to input_tensor length.\"));",
            "      for (; idx < input_splits_flat(i); ++idx) {",
            "        int32 code_point = input_tensor_flat(idx);",
            "        // Check for invalid code point",
            "        if (!U_IS_UNICODE_CHAR(code_point)) {"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-59q2-x2qc-4c97",
    "API Signature": "tf.raw_ops.UnicodeEncode(\n    input_values,\n    input_splits,\n    output_encoding,\n    errors='replace',\n    replacement_char=65533,\n    name=None\n)\n",
    "Score": 0.01079136690647482,
    "Anomaly": "Non sparse input tensor",
    "Anomaly Description": "A non-sparse input tensor refers to a tensor in which most of the elements are non-zero or have significant values, meaning it has a dense representation. In a non-sparse tensor, the majority of its elements contain meaningful data or contribute to computations.",
    "Category": "Tensor",
    "Argument": "input_splits = tf.constant([[81, 101, 0]], shape=[3], dtype=tf.int32)"
},
{
    "Title": "\n        Heap OOB access in unicode ops\n      ",
    "Bug description": "An attacker can access data outside of bounds of heap allocated array in  tf.raw_ops.UnicodeEncode :",
    "Sample Code": "input_values = tf.constant([58], shape=[1], dtype=tf.int32)\ninput_splits = tf.constant([[81, 101, 0]], shape=[3], dtype=tf.int32)\noutput_encoding = \"UTF-8\"\n\ntf.raw_ops.UnicodeEncode(\n    input_values=input_values, input_splits=input_splits,\n    ,\n    output_encoding=output_encoding)",
    "Code change": [
        "@@ -533,6 +533,17 @@ class UnicodeEncodeOp : public OpKernel {\n     const Tensor& input_splits = context->input(1);\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n \n+    // Operation will treat first argument in input_splits as if it were zero\n+    // regardless of its actual value since splits should begin with zero and\n+    // end with the length of the input values vector.\n+    OP_REQUIRES(\n+        context, input_splits_flat(0) == 0,\n+        errors::InvalidArgument(\"First value in input_splits must be zero.\"));\n+    OP_REQUIRES(context,\n+                input_splits_flat(input_splits_flat.size() - 1) ==\n+                    input_tensor_flat.size(),\n+                errors::InvalidArgument(\"Last value in input_splits must be \"\n+                                        \"equal to length of input_tensor.\"));\n     // Since we limit to a 2-D input (flat_values of rank 1 and a single splits\n     // tensor), our output dimension will be 1 with it's size equal to the\n     // number of splits (outer dimension or ragged tensor).\n@@ -548,6 +559,14 @@ class UnicodeEncodeOp : public OpKernel {\n     for (int i = 1; i < input_splits_flat.size(); ++i) {\n       icu::UnicodeString unicode_string;\n       icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);\n+      OP_REQUIRES(\n+          context, input_splits_flat(i - 1) <= input_splits_flat(i),\n+          errors::InvalidArgument(\n+              \"Values in input_splits must be equal or in ascending order.\"));\n+      OP_REQUIRES(\n+          context, input_splits_flat(i) <= input_tensor_flat.size(),\n+          errors::InvalidArgument(\"Values in input_splits must be less than or \"\n+                                  \"equal to input_tensor length.\"));\n       for (; idx < input_splits_flat(i); ++idx) {\n         int32 code_point = input_tensor_flat(idx);\n         // Check for invalid code point\n"
    ],
    "Buggy Code": [
        [
            "    const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();",
            "",
            "    // Since we limit to a 2-D input (flat_values of rank 1 and a single splits",
            "    // tensor), our output dimension will be 1 with it's size equal to the",
            "    // number of splits (outer dimension or ragged tensor).",
            "    TensorShape output_shape({input_splits.dim_size(0) - 1});",
            "    Tensor* output_tensor;",
            "    OP_REQUIRES_OK(context, context->allocate_output(\"output\", output_shape,",
            "                                                     &output_tensor));",
            "    auto output_tensor_flat = output_tensor->flat<tstring>();",
            "",
            "    // Use a single index over the flattened input values tensor.",
            "    int idx = 0;",
            "    // Loop through our split dimension to create a new string at each split.",
            "    for (int i = 1; i < input_splits_flat.size(); ++i) {",
            "      icu::UnicodeString unicode_string;",
            "      icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);"
        ],
        [
            "            code_point = error_options_.subst;",
            "          }",
            "        }",
            "        appendable_unicode_string.appendCodePoint(code_point);",
            "      }",
            "      // Encode our string and save in the output.",
            "      tstring result;",
            "      Encode(encoding_, unicode_string, &result);",
            "      output_tensor_flat(i - 1) = std::move(result);",
            "    }",
            "  }",
            "",
            " private:",
            "  UnicodeEncoding encoding_;"
        ]
    ],
    "Clean Code": [
        [
            "    const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();",
            "",
            "    // Operation will treat first argument in input_splits as if it were zero",
            "    // regardless of its actual value since splits should begin with zero and",
            "    // end with the length of the input values vector.",
            "    OP_REQUIRES(",
            "        context, input_splits_flat(0) == 0,",
            "        errors::InvalidArgument(\"First value in input_splits must be zero.\"));",
            "    OP_REQUIRES(context,",
            "                input_splits_flat(input_splits_flat.size() - 1) ==",
            "                    input_tensor_flat.size(),",
            "                errors::InvalidArgument(\"Last value in input_splits must be \"",
            "                                        \"equal to length of input_tensor.\"));",
            "    // Since we limit to a 2-D input (flat_values of rank 1 and a single splits",
            "    // tensor), our output dimension will be 1 with it's size equal to the",
            "    // number of splits (outer dimension or ragged tensor).",
            "    TensorShape output_shape({input_splits.dim_size(0) - 1});"
        ],
        [
            "      icu::UnicodeString unicode_string;",
            "      icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);",
            "      OP_REQUIRES(",
            "          context, input_splits_flat(i - 1) <= input_splits_flat(i),",
            "          errors::InvalidArgument(",
            "              \"Values in input_splits must be equal or in ascending order.\"));",
            "      OP_REQUIRES(",
            "          context, input_splits_flat(i) <= input_tensor_flat.size(),",
            "          errors::InvalidArgument(\"Values in input_splits must be less than or \"",
            "                                  \"equal to input_tensor length.\"));",
            "      for (; idx < input_splits_flat(i); ++idx) {",
            "        int32 code_point = input_tensor_flat(idx);",
            "        // Check for invalid code point",
            "        if (!U_IS_UNICODE_CHAR(code_point)) {"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-59q2-x2qc-4c97",
    "API Signature": "tf.raw_ops.UnicodeEncode(\n    input_values,\n    input_splits,\n    output_encoding,\n    errors='replace',\n    replacement_char=65533,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "input_values = tf.constant([58], shape=[1], dtype=tf.int32)\ninput_splits = tf.constant([[81, 101, 0]], shape=[3], dtype=tf.int32)"
},
{
    "Title": "\n        Heap buffer overflow in `SparseSplit`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow in  tf.raw_ops.SparseSplit :",
    "Sample Code": "shape_dims = tf.constant(0, dtype=tf.int64)\nindices = tf.ones([1, 1], dtype=tf.int64)\nvalues = tf.ones([1], dtype=tf.int64)\nshape = tf.ones([1], dtype=tf.int64)\n\ntf.raw_ops.SparseSplit(\n    split_dim=shape_dims, indices=indices, values=values,\n    ,\n    shape=shape, num_split=1)",
    "Code change": [
        "@@ -527,6 +527,10 @@ inline Status SparseTensor::Split(const SparseTensor& input_tensor,\n   for (int i = 0; i < input_tensor.indices().dim_size(0); ++i) {\n     const int dim = input_tensor.indices().matrix<int64>()(i, split_dim);\n     int slice_index = GetSliceIndex(dim, split_size, residual);\n+    if (slice_index >= num_values.size()) {\n+      return errors::InvalidArgument(\"Slice index \", slice_index,\n+                                     \" is larger than num_split.\");\n+    }\n     num_values[slice_index]++;\n   }\n \n"
    ],
    "Buggy Code": [
        [
            "    const int dim = input_tensor.indices().matrix<int64>()(i, split_dim);",
            "    int slice_index = GetSliceIndex(dim, split_size, residual);",
            "    num_values[slice_index]++;",
            "  }",
            "",
            "  for (int i = 0; i < num_split; ++i) {",
            "    // TODO(ataei): Pass an allocator to avoid allocating large memory buffer.",
            "    output_indices.emplace_back(DT_INT64,",
            "                                TensorShape({num_values[i], num_dim}));",
            "    output_values.emplace_back(DataTypeToEnum<T>::v(),"
        ]
    ],
    "Clean Code": [
        [
            "    const int dim = input_tensor.indices().matrix<int64>()(i, split_dim);",
            "    int slice_index = GetSliceIndex(dim, split_size, residual);",
            "    if (slice_index >= num_values.size()) {",
            "      return errors::InvalidArgument(\"Slice index \", slice_index,",
            "                                     \" is larger than num_split.\");",
            "    }",
            "    num_values[slice_index]++;",
            "  }",
            "",
            "  for (int i = 0; i < num_split; ++i) {"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-mqh2-9wrp-vx84",
    "API Signature": "tf.raw_ops.SparseSplit(\n    split_dim, indices, values, shape, num_split, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "indices = tf.ones([1, 1], dtype=tf.int64 \nnum_split=1"
},
{
    "Title": "\n        Division by 0 in `Reverse`\n      ",
    "Bug description": "An attacker can cause a denial of service via a FPE runtime error in  tf.raw_ops.Reverse :",
    "Sample Code": "tensor_input = tf.constant([], shape=[0, 1, 1], dtype=tf.int32)\ndims = tf.constant([False, True, False], shape=[3], dtype=tf.bool)\n\n)\n\ntf.raw_ops.Reverse(tensor=tensor_input, dims=dims)",
    "Code change": [
        "@@ -155,6 +155,12 @@ class ReverseOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n+    // If input is provided, check to make sure the first dimension is valid.\n+    if (input.dims() > 0) {\n+      OP_REQUIRES(\n+          context, input.dim_size(0) != 0,\n+          errors::InvalidArgument(\"Invalid input first dimension. Found 0.\"));\n+    }\n     const Tensor& dims = context->input(1);\n \n     if (TensorShapeUtils::IsScalar(input.shape())) {\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const Tensor& dims = context->input(1);",
            "",
            "    if (TensorShapeUtils::IsScalar(input.shape())) {",
            "      context->set_output(0, input);",
            "    } else {",
            "      const int input_dims = input.dims();",
            "      OP_REQUIRES(context, TensorShapeUtils::IsVector(dims.shape()),",
            "                  errors::InvalidArgument(\"'dims' must be 1-dimension, not \",",
            "                                          dims.dims()));",
            ""
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    // If input is provided, check to make sure the first dimension is valid.",
            "    if (input.dims() > 0) {",
            "      OP_REQUIRES(",
            "          context, input.dim_size(0) != 0,",
            "          errors::InvalidArgument(\"Invalid input first dimension. Found 0.\"));",
            "    }",
            "    const Tensor& dims = context->input(1);",
            "",
            "    if (TensorShapeUtils::IsScalar(input.shape())) {",
            "      context->set_output(0, input);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fxqh-cfjm-fp93",
    "API Signature": "tf.raw_ops.Reverse(\n    tensor, dims, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "tensor_input = tf.constant([], shape=[0, 1, 1], dtype=tf.int32)"
},
{
    "Title": "\n        Division by 0 in `SparseMatMul`\n      ",
    "Bug description": "An attacker can cause a denial of service via a FPE runtime error in  tf.raw_ops.SparseMatMul :",
    "Sample Code": "a = tf.constant([100.0, 100.0, 100.0, 100.0], shape=[2, 2], dtype=tf.float32)\nb = tf.constant([], shape=[0, 2], dtype=tf.float32)\n\ntf.raw_ops.SparseMatMul(\n    a=a, b=b, transpose_a=True, transpose_b=True,\n    ,\n    a_is_sparse=True, b_is_sparse=True)",
    "Code change": [
        "@@ -1039,6 +1039,10 @@ class SparseMatMulOp : public OpKernel {\n     if (transpose_b) {\n       // TODO(agarwal): avoid transposing the matrix here and directly handle\n       // transpose in CreateDenseSlices.\n+      OP_REQUIRES(ctx, right->dim_size(0) != 0,\n+                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n+      OP_REQUIRES(ctx, right->dim_size(1) != 0,\n+                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n       right_tr.reset(\n           new Tensor(right->dtype(),\n                      TensorShape({right->dim_size(1), right->dim_size(0)})));\n"
    ],
    "Buggy Code": [
        [
            "      // TODO(agarwal): avoid transposing the matrix here and directly handle",
            "      // transpose in CreateDenseSlices.",
            "      right_tr.reset(",
            "          new Tensor(right->dtype(),",
            "                     TensorShape({right->dim_size(1), right->dim_size(0)})));",
            "",
            "      const auto perm = dsizes_10();",
            "      if (transpose_output) {",
            "        right_tr->matrix<TL>().device(ctx->template eigen_device<CPUDevice>()) =",
            "            right->matrix<TL>().shuffle(perm);"
        ]
    ],
    "Clean Code": [
        [
            "      // TODO(agarwal): avoid transposing the matrix here and directly handle",
            "      // transpose in CreateDenseSlices.",
            "      OP_REQUIRES(ctx, right->dim_size(0) != 0,",
            "                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));",
            "      OP_REQUIRES(ctx, right->dim_size(1) != 0,",
            "                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));",
            "      right_tr.reset(",
            "          new Tensor(right->dtype(),",
            "                     TensorShape({right->dim_size(1), right->dim_size(0)})));",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xw93-v57j-fcgh",
    "API Signature": "tf.raw_ops.SparseMatMul(\n    a,\n    b,\n    transpose_a=False,\n    transpose_b=False,\n    a_is_sparse=False,\n    b_is_sparse=False,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "b = tf.constant([], shape=[0, 2], dtype=tf.float32)"
},
{
    "Title": "\n        Division by 0 in `FusedBatchNorm`\n      ",
    "Bug description": "An attacker can cause a denial of service via a FPE runtime error in  tf.raw_ops.FusedBatchNorm :",
    "Sample Code": "x = tf.constant([], shape=[1, 1, 1, 0], dtype=tf.float32)\nscale = tf.constant([], shape=[0], dtype=tf.float32)\noffset = tf.constant([], shape=[0], dtype=tf.float32)\nmean = tf.constant([], shape=[0], dtype=tf.float32)\nvariance = tf.constant([], shape=[0], dtype=tf.float32)\nepsilon = 0.0\nexponential_avg_factor = 0.0\ndata_format = \"NHWC\"\nis_training = False\n\ntf.raw_ops.FusedBatchNorm(\n    x=x, scale=scale, offset=offset, mean=mean,\n    variance=variance, epsilon=epsilon,\n    exponential_avg_factor=exponential_avg_factor,\n    ,\n    data_format=data_format, is_training=is_training)",
    "Code change": [
        "@@ -293,6 +293,9 @@ struct FusedBatchNorm<CPUDevice, T, U, /* is_training= */ false> {\n     const CPUDevice& d = context->eigen_device<CPUDevice>();\n \n     const int depth = x.dimension(3);\n+    OP_REQUIRES(\n+        context, depth != 0,\n+        errors::Internal(\"The 4th element in the input shape cannot be 0.\"));\n     const int size = x.size();\n     const int rest_size = size / depth;\n     Eigen::DSizes<Eigen::Index, 2> rest_by_depth(rest_size, depth);\n"
    ],
    "Buggy Code": [
        [
            "",
            "    const int depth = x.dimension(3);",
            "    const int size = x.size();",
            "    const int rest_size = size / depth;",
            "    Eigen::DSizes<Eigen::Index, 2> rest_by_depth(rest_size, depth);",
            "",
            "#if !defined(EIGEN_HAS_INDEX_LIST)",
            "    Eigen::DSizes<Eigen::Index, 2> one_by_depth(1, depth);",
            "    Eigen::array<int, 1> reduce_dims({0});"
        ]
    ],
    "Clean Code": [
        [
            "",
            "    const int depth = x.dimension(3);",
            "    OP_REQUIRES(",
            "        context, depth != 0,",
            "        errors::Internal(\"The 4th element in the input shape cannot be 0.\"));",
            "    const int size = x.size();",
            "    const int rest_size = size / depth;",
            "    Eigen::DSizes<Eigen::Index, 2> rest_by_depth(rest_size, depth);",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-r35g-4525-29fq",
    "API Signature": "tf.raw_ops.FusedBatchNorm(\n    x,\n    scale,\n    offset,\n    mean,\n    variance,\n    epsilon=0.0001,\n    exponential_avg_factor=1,\n    data_format='NHWC',\n    is_training=True,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "x = tf.constant([], shape=[1, 1, 1, 0], dtype=tf.float32)"
},
{
    "Title": "\n        Division by 0 in `DenseCountSparseOutput`\n      ",
    "Bug description": "An attacker can cause a denial of service via a FPE runtime error in  tf.raw_ops.DenseCountSparseOutput :",
    "Sample Code": "values = tf.constant([], shape=[0, 0], dtype=tf.int64)\nweights = tf.constant([])\n\ntf.raw_ops.DenseCountSparseOutput(\n  values=values, weights=weights,\n  ,\n  minlength=-1, maxlength=58, binary_output=True)",
    "Code change": [
        "@@ -122,6 +122,9 @@ class DenseCount : public OpKernel {\n \n     int num_batch_elements = 1;\n     for (int i = 0; i < num_batch_dimensions; ++i) {\n+      OP_REQUIRES(context, data.shape().dim_size(i) != 0,\n+                  errors::InvalidArgument(\n+                      \"Invalid input: Shapes dimension cannot be 0.\"));\n       num_batch_elements *= data.shape().dim_size(i);\n     }\n     int num_value_elements = data.shape().num_elements() / num_batch_elements;\n"
    ],
    "Buggy Code": [
        [
            "    int num_batch_elements = 1;",
            "    for (int i = 0; i < num_batch_dimensions; ++i) {",
            "      num_batch_elements *= data.shape().dim_size(i);",
            "    }",
            "    int num_value_elements = data.shape().num_elements() / num_batch_elements;",
            "    auto per_batch_counts = BatchedMap<W>(num_batch_elements);",
            "",
            "    T max_value = 0;",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    int num_batch_elements = 1;",
            "    for (int i = 0; i < num_batch_dimensions; ++i) {",
            "      OP_REQUIRES(context, data.shape().dim_size(i) != 0,",
            "                  errors::InvalidArgument(",
            "                      \"Invalid input: Shapes dimension cannot be 0.\"));",
            "      num_batch_elements *= data.shape().dim_size(i);",
            "    }",
            "    int num_value_elements = data.shape().num_elements() / num_batch_elements;",
            "    auto per_batch_counts = BatchedMap<W>(num_batch_elements);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qg48-85hg-mqc5",
    "API Signature": "tf.raw_ops.DenseCountSparseOutput(\n    values, weights, binary_output, minlength=-1, maxlength=-1, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "values = tf.constant([], shape=[0, 0], dtype=tf.int64)"
},
{
    "Title": "\n        `CHECK`-failure in `UnsortedSegmentJoin`\n      ",
    "Bug description": "An attacker can cause a denial of service by controlling the values of  num_segments  tensor argument for  UnsortedSegmentJoin :",
    "Sample Code": "inputs = tf.constant([], dtype=tf.string)\nsegment_ids = tf.constant([], dtype=tf.int32)\nnum_segments = tf.constant([], dtype=tf.int32)\nseparator = ''\n\ntf.raw_ops.UnsortedSegmentJoin(\n  inputs=inputs, segment_ids=segment_ids,\n  ,\n  num_segments=num_segments, separator=separator)",
    "Code change": [
        "@@ -90,6 +90,8 @@ class UnsortedSegmentJoinOp : public OpKernel {\n     const int32 segment_dims = segment_id_shape.dims();\n \n     const Tensor& num_segments_tensor = context->input(2);\n+    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,\n+                errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n     OP_REQUIRES(context, segment_dims != 0,\n"
    ],
    "Buggy Code": [
        [
            "",
            "    const Tensor& num_segments_tensor = context->input(2);",
            "    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();",
            "",
            "    OP_REQUIRES(context, segment_dims != 0,",
            "                errors::InvalidArgument(\"Segment_id cannot have rank 0\"));",
            "",
            "    OP_REQUIRES("
        ]
    ],
    "Clean Code": [
        [
            "",
            "    const Tensor& num_segments_tensor = context->input(2);",
            "    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,",
            "                errors::InvalidArgument(\"Number of segments cannot be empty.\"));",
            "    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();",
            "",
            "    OP_REQUIRES(context, segment_dims != 0,",
            "                errors::InvalidArgument(\"Segment_id cannot have rank 0\"));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-jhq9-wm9m-cf89",
    "API Signature": "tf.raw_ops.UnsortedSegmentJoin(\n    inputs, segment_ids, num_segments, separator='', name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "num_segments = tf.constant([], dtype=tf.int32)"
},
{
    "Title": "\n        Heap OOB in `QuantizeAndDequantizeV3`\n      ",
    "Bug description": "An attacker can read data outside of bounds of heap allocated buffer in  tf.raw_ops.QuantizeAndDequantizeV3 :",
    "Sample Code": "tf.raw_ops.QuantizeAndDequantizeV3(\n  input=[2.5,2.5], input_min=[0,0], input_max=[1,1], num_bits=[30],\n  ],\n  signed_input=False, range_given=False, narrow_range=False, axis=3)",
    "Code change": [
        "@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include \"tensorflow/core/framework/op_requires.h\"\n #define EIGEN_USE_THREADS\n \n #if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\n@@ -234,6 +235,10 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(ctx, axis_ < input.dims(),\n+                errors::InvalidArgument(\n+                    \"Axis requested is larger than input dimensions. Axis: \",\n+                    axis_, \" Input Dimensions: \", input.dims()));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n"
    ],
    "Buggy Code": [
        [
            "==============================================================================*/",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\",
            "    (defined(TENSORFLOW_USE_ROCM) && TENSORFLOW_USE_ROCM)",
            "#define EIGEN_USE_GPU"
        ],
        [
            "    const Tensor& input = ctx->input(0);",
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
            "",
            "    Tensor num_bits_tensor;",
            "    num_bits_tensor = ctx->input(3);",
            "    int num_bits_val = num_bits_tensor.scalar<int32>()();",
            "",
            "    OP_REQUIRES("
        ]
    ],
    "Clean Code": [
        [
            "==============================================================================*/",
            "",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "#define EIGEN_USE_THREADS",
            "",
            "#if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\",
            "    (defined(TENSORFLOW_USE_ROCM) && TENSORFLOW_USE_ROCM)"
        ],
        [
            "  void Compute(OpKernelContext* ctx) override {",
            "    const Tensor& input = ctx->input(0);",
            "    OP_REQUIRES(ctx, axis_ < input.dims(),",
            "                errors::InvalidArgument(",
            "                    \"Axis requested is larger than input dimensions. Axis: \",",
            "                    axis_, \" Input Dimensions: \", input.dims()));",
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h9px-9vqg-222h",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV3(\n    input,\n    input_min,\n    input_max,\n    num_bits,\n    signed_input=True,\n    range_given=True,\n    narrow_range=False,\n    axis=-1,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "input=[2.5,2.5] \naxis=3"
},
{
    "Title": "\n        OOB read in `MatrixTriangularSolve`\n      ",
    "Bug description": "The implementation of  MatrixTriangularSolve  fails to terminate kernel execution if one validation condition fails:",
    "Sample Code": "import numpy as np\n\nmatrix_array = np.array([])\nmatrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(1,0)),dtype=tf.float32)\nrhs_array = np.array([])\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(0,1)),dtype=tf.float32)\n\n)\n\ntf.raw_ops.MatrixTriangularSolve(matrix=matrix_tensor,rhs=rhs_tensor,lower=False,adjoint=False)",
    "Code change": [
        "@@ -162,6 +162,9 @@ class BaseMatrixTriangularSolveOp : public OpKernel {\n     const Tensor& in1 = ctx->input(1);\n \n     ValidateInputTensors(ctx, in0, in1);\n+    if (!ctx->status().ok()) {\n+      return;\n+    }\n \n     MatMulBCast bcast(in0.shape().dim_sizes(), in1.shape().dim_sizes());\n     OP_REQUIRES(\n@@ -230,13 +233,22 @@ class MatrixTriangularSolveOp\n  private:\n   void ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0,\n                             const Tensor& in1) override {\n+    const auto in0_num_dims = in0.dims();\n     OP_REQUIRES(\n-        ctx, in0.dims() >= 2,\n-        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\n+        ctx, in0_num_dims >= 2,\n+        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0_num_dims));\n \n+    const auto in1_num_dims = in1.dims();\n     OP_REQUIRES(\n-        ctx, in1.dims() >= 2,\n-        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in1.dims()));\n+        ctx, in1_num_dims >= 2,\n+        errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1_num_dims));\n+\n+    const auto in0_last_dim = in0.dim_size(in0_num_dims - 1);\n+    const auto in0_prev_dim = in0.dim_size(in0_num_dims - 2);\n+    OP_REQUIRES(ctx, in0_last_dim == in0_prev_dim,\n+                errors::InvalidArgument(\n+                    \"In[0] matrices in the last dimensions must be square (\",\n+                    in0_last_dim, \" =/= \", in0_prev_dim, \")\"));\n   }\n };\n \n"
    ],
    "Buggy Code": [
        [
            "",
            "    ValidateInputTensors(ctx, in0, in1);",
            "",
            "    MatMulBCast bcast(in0.shape().dim_sizes(), in1.shape().dim_sizes());",
            "    OP_REQUIRES(",
            "        ctx, bcast.IsValid(),",
            "        errors::InvalidArgument(",
            "            \"In[0] and In[1] must have compatible batch dimensions: \",",
            "            in0.shape().DebugString(), \" vs. \", in1.shape().DebugString()));"
        ],
        [
            "        ctx, in0.dims() >= 2,",
            "        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));",
            "",
            "    OP_REQUIRES(",
            "        ctx, in1.dims() >= 2,",
            "        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in1.dims()));",
            "  }",
            "};",
            "",
            "#define REGISTER_BATCH_MATRIX_TRIANGULAR_SOLVE_CPU(TYPE)             \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"MatrixTriangularSolve\")              \\",
            "                              .Device(DEVICE_CPU)                    \\",
            "                              .TypeConstraint<TYPE>(\"T\"),            \\",
            "                          MatrixTriangularSolveOp<CPUDevice, TYPE>); \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"BatchMatrixTriangularSolve\")         \\",
            "                              .Device(DEVICE_CPU)                    \\",
            "                              .TypeConstraint<TYPE>(\"T\"),            \\",
            "                          MatrixTriangularSolveOp<CPUDevice, TYPE>);",
            "",
            "#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
            "",
            "template <typename Scalar>"
        ]
    ],
    "Clean Code": [
        [
            "",
            "    ValidateInputTensors(ctx, in0, in1);",
            "    if (!ctx->status().ok()) {",
            "      return;",
            "    }",
            "",
            "    MatMulBCast bcast(in0.shape().dim_sizes(), in1.shape().dim_sizes());",
            "    OP_REQUIRES(",
            "        ctx, bcast.IsValid(),"
        ],
        [
            "  void ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0,",
            "                            const Tensor& in1) override {",
            "    const auto in0_num_dims = in0.dims();",
            "    OP_REQUIRES(",
            "        ctx, in0_num_dims >= 2,",
            "        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0_num_dims));",
            "",
            "    const auto in1_num_dims = in1.dims();",
            "    OP_REQUIRES(",
            "        ctx, in1_num_dims >= 2,",
            "        errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1_num_dims));",
            "",
            "    const auto in0_last_dim = in0.dim_size(in0_num_dims - 1);",
            "    const auto in0_prev_dim = in0.dim_size(in0_num_dims - 2);",
            "    OP_REQUIRES(ctx, in0_last_dim == in0_prev_dim,",
            "                errors::InvalidArgument(",
            "                    \"In[0] matrices in the last dimensions must be square (\",",
            "                    in0_last_dim, \" =/= \", in0_prev_dim, \")\"));",
            "  }",
            "};",
            "",
            "#define REGISTER_BATCH_MATRIX_TRIANGULAR_SOLVE_CPU(TYPE)             \\"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-vqw6-72r7-fgw7",
    "API Signature": "tf.raw_ops.MatrixTriangularSolve(\n    matrix, rhs, lower=True, adjoint=False, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "matrix_array = np.array([])\nrhs_array = np.array([])"
},
{
    "Title": "\n        Division by 0 in `FractionalAvgPool`\n      ",
    "Bug description": "An attacker can cause a runtime division by zero error and denial of service in  tf.raw_ops.FractionalAvgPool :",
    "Sample Code": "value = tf.constant([60], shape=[1, 1, 1, 1], dtype=tf.int32)\npooling_ratio = [1.0, 1.0000014345305555, 1.0, 1.0]\npseudo_random = False\noverlapping = False\ndeterministic = False\nseed = 0\nseed2 = 0\n\ntf.raw_ops.FractionalAvgPool(\n  value=value, pooling_ratio=pooling_ratio, pseudo_random=pseudo_random,\n  ,\n  overlapping=overlapping, deterministic=deterministic, seed=seed, seed2=seed2)",
    "Code change": [
        "@@ -80,6 +80,10 @@ class FractionalAvgPoolOp : public OpKernel {\n     std::vector<int> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n       input_size[i] = tensor_in.dim_size(i);\n+      OP_REQUIRES(\n+          context, pooling_ratio_[i] <= input_size[i],\n+          errors::InvalidArgument(\n+              \"Pooling ratio cannot be bigger than input tensor dim size.\"));\n     }\n     // Output size.\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n"
    ],
    "Buggy Code": [
        [
            "    for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      input_size[i] = tensor_in.dim_size(i);",
            "    }",
            "    // Output size.",
            "    for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      output_size[i] =",
            "          static_cast<int>(std::floor(input_size[i] / pooling_ratio_[i]));",
            "      DCHECK_GT(output_size[i], 0);",
            "    }",
            ""
        ]
    ],
    "Clean Code": [
        [
            "    for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      input_size[i] = tensor_in.dim_size(i);",
            "      OP_REQUIRES(",
            "          context, pooling_ratio_[i] <= input_size[i],",
            "          errors::InvalidArgument(",
            "              \"Pooling ratio cannot be bigger than input tensor dim size.\"));",
            "    }",
            "    // Output size.",
            "    for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
            "      output_size[i] ="
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-f78g-q7r4-9wcv",
    "API Signature": "tf.raw_ops.FractionalAvgPool(\n    value,\n    pooling_ratio,\n    pseudo_random=False,\n    overlapping=False,\n    deterministic=False,\n    seed=0,\n    seed2=0,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "value = tf.constant([60], shape=[1, 1, 1, 1], dtype=tf.int32)\npooling_ratio = [1.0, 1.0000014345305555, 1.0, 1.0]"
},
{
    "Title": "\n        Division by 0 in `QuantizedAdd`\n      ",
    "Bug description": "An attacker can cause a runtime division by zero error and denial of service in  tf.raw_ops.QuantizedAdd :",
    "Sample Code": "x = tf.constant([68, 228], shape=[2, 1], dtype=tf.quint8)\ny = tf.constant([], shape=[2, 0], dtype=tf.quint8)\n\nmin_x = tf.constant(10.723421015884028)\nmax_x = tf.constant(15.19578006631113)\nmin_y = tf.constant(-5.539003866682977)\nmax_y = tf.constant(42.18819949559947)\n\n)\n\ntf.raw_ops.QuantizedAdd(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y)",
    "Code change": [
        "@@ -538,6 +538,8 @@ class QuantizedAddOp : public OpKernel {\n         tensor_min = min_x;\n         tensor_max = max_x;\n       }\n+      OP_REQUIRES(context, vector_num_elements > 0,\n+                  errors::InvalidArgument(\"Must have some elements to add\"));\n       VectorTensorAddition<T, Toutput>(\n           vector_data, vector_min, vector_max, vector_num_elements, tensor_data,\n           tensor_min, tensor_max, tensor_num_elements, min_z_value, max_z_value,\n"
    ],
    "Buggy Code": [
        [
            "        tensor_max = max_x;",
            "      }",
            "      VectorTensorAddition<T, Toutput>(",
            "          vector_data, vector_min, vector_max, vector_num_elements, tensor_data,",
            "          tensor_min, tensor_max, tensor_num_elements, min_z_value, max_z_value,",
            "          z_data);",
            "    } else {",
            "      LOG(INFO) << \"ndims=\" << ndims;"
        ]
    ],
    "Clean Code": [
        [
            "        tensor_max = max_x;",
            "      }",
            "      OP_REQUIRES(context, vector_num_elements > 0,",
            "                  errors::InvalidArgument(\"Must have some elements to add\"));",
            "      VectorTensorAddition<T, Toutput>(",
            "          vector_data, vector_min, vector_max, vector_num_elements, tensor_data,",
            "          tensor_min, tensor_max, tensor_num_elements, min_z_value, max_z_value,",
            "          z_data);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x83m-p7pv-ch8v",
    "API Signature": "tf.raw_ops.QuantizedAdd(\n    x,\n    y,\n    min_x,\n    max_x,\n    min_y,\n    max_y,\n    Toutput=tf.dtypes.qint32,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "y = tf.constant([], shape=[2, 0], dtype=tf.quint8)"
},
{
    "Title": "\n        Division by 0 in `QuantizedBatchNormWithGlobalNormalization`\n      ",
    "Bug description": "An attacker can cause a runtime division by zero error and denial of service in  tf.raw_ops.QuantizedBatchNormWithGlobalNormalization :",
    "Sample Code": "t = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.quint8)\nt_min = tf.constant(-10.0, dtype=tf.float32)\nt_max = tf.constant(-10.0, dtype=tf.float32)\nm = tf.constant([], shape=[0], dtype=tf.quint8)\nm_min = tf.constant(-10.0, dtype=tf.float32)\nm_max = tf.constant(-10.0, dtype=tf.float32)\nv = tf.constant([], shape=[0], dtype=tf.quint8)\nv_min = tf.constant(-10.0, dtype=tf.float32)\nv_max = tf.constant(-10.0, dtype=tf.float32)\nbeta = tf.constant([], shape=[0], dtype=tf.quint8)\nbeta_min = tf.constant(-10.0, dtype=tf.float32)\nbeta_max = tf.constant(-10.0, dtype=tf.float32)\ngamma = tf.constant([], shape=[0], dtype=tf.quint8)\ngamma_min = tf.constant(-10.0, dtype=tf.float32)\ngamma_max = tf.constant(-10.0, dtype=tf.float32)\n\ntf.raw_ops.QuantizedBatchNormWithGlobalNormalization(\n  t=t, t_min=t_min, t_max=t_max, m=m, m_min=m_min, m_max=m_max,\n  v=v, v_min=v_min, v_max=v_max, beta=beta, beta_min=beta_min,\n  beta_max=beta_max, gamma=gamma, gamma_min=gamma_min,\n  gamma_max=gamma_max, out_type=tf.qint32,\n  ,\n  variance_epsilon=0.1, scale_after_normalization=True)",
    "Code change": [
        "@@ -173,20 +173,50 @@ class QuantizedBatchNormOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float input_min = context->input(1).flat<float>()(0);\n-    const float input_max = context->input(2).flat<float>()(0);\n+    const auto& input_min_tensor = context->input(1);\n+    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_min must have 1 element\"));\n+    const float input_min = input_min_tensor.flat<float>()(0);\n+    const auto& input_max_tensor = context->input(2);\n+    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_max must have 1 element\"));\n+    const float input_max = input_max_tensor.flat<float>()(0);\n     const Tensor& mean = context->input(3);\n-    const float mean_min = context->input(4).flat<float>()(0);\n-    const float mean_max = context->input(5).flat<float>()(0);\n+    const auto& mean_min_tensor = context->input(4);\n+    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_min must have 1 element\"));\n+    const float mean_min = mean_min_tensor.flat<float>()(0);\n+    const auto& mean_max_tensor = context->input(5);\n+    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_max must have 1 element\"));\n+    const float mean_max = mean_max_tensor.flat<float>()(0);\n     const Tensor& var = context->input(6);\n-    const float var_min = context->input(7).flat<float>()(0);\n-    const float var_max = context->input(8).flat<float>()(0);\n+    const auto& var_min_tensor = context->input(7);\n+    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_min must have 1 element\"));\n+    const float var_min = var_min_tensor.flat<float>()(0);\n+    const auto& var_max_tensor = context->input(8);\n+    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_max must have 1 element\"));\n+    const float var_max = var_max_tensor.flat<float>()(0);\n     const Tensor& beta = context->input(9);\n-    const float beta_min = context->input(10).flat<float>()(0);\n-    const float beta_max = context->input(11).flat<float>()(0);\n+    const auto& beta_min_tensor = context->input(10);\n+    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_min must have 1 element\"));\n+    const float beta_min = beta_min_tensor.flat<float>()(0);\n+    const auto& beta_max_tensor = context->input(11);\n+    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_max must have 1 element\"));\n+    const float beta_max = beta_max_tensor.flat<float>()(0);\n     const Tensor& gamma = context->input(12);\n-    const float gamma_min = context->input(13).flat<float>()(0);\n-    const float gamma_max = context->input(14).flat<float>()(0);\n+    const auto& gamma_min_tensor = context->input(13);\n+    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_min must have 1 element\"));\n+    const float gamma_min = gamma_min_tensor.flat<float>()(0);\n+    const auto& gamma_max_tensor = context->input(14);\n+    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_max must have 1 element\"));\n+    const float gamma_max = gamma_max_tensor.flat<float>()(0);\n \n     OP_REQUIRES(context, input.dims() == 4,\n                 errors::InvalidArgument(\"input must be 4-dimensional\",\n@@ -203,6 +233,33 @@ class QuantizedBatchNormOp : public OpKernel {\n     OP_REQUIRES(context, gamma.dims() == 1,\n                 errors::InvalidArgument(\"gamma must be 1-dimensional\",\n                                         gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\",\n+                                        gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\"));\n+    const auto last_dim = input.shape().dims() - 1;\n+    OP_REQUIRES(context,\n+                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\n+                errors::InvalidArgument(\"Must provide as many means as the \"\n+                                        \"last dimension of the input tensor: \",\n+                                        mean.shape().DebugString(), \" vs. \",\n+                                        input.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and variance tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and beta tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and gamma tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const float input_min = context->input(1).flat<float>()(0);",
            "    const float input_max = context->input(2).flat<float>()(0);",
            "    const Tensor& mean = context->input(3);",
            "    const float mean_min = context->input(4).flat<float>()(0);",
            "    const float mean_max = context->input(5).flat<float>()(0);",
            "    const Tensor& var = context->input(6);",
            "    const float var_min = context->input(7).flat<float>()(0);",
            "    const float var_max = context->input(8).flat<float>()(0);",
            "    const Tensor& beta = context->input(9);",
            "    const float beta_min = context->input(10).flat<float>()(0);",
            "    const float beta_max = context->input(11).flat<float>()(0);",
            "    const Tensor& gamma = context->input(12);",
            "    const float gamma_min = context->input(13).flat<float>()(0);",
            "    const float gamma_max = context->input(14).flat<float>()(0);",
            "",
            "    OP_REQUIRES(context, input.dims() == 4,",
            "                errors::InvalidArgument(\"input must be 4-dimensional\",",
            "                                        input.shape().DebugString()));",
            "    OP_REQUIRES(context, mean.dims() == 1,",
            "                errors::InvalidArgument(\"mean must be 1-dimensional\",",
            "                                        mean.shape().DebugString()));",
            "    OP_REQUIRES(context, var.dims() == 1,",
            "                errors::InvalidArgument(\"var must be 1-dimensional\",",
            "                                        var.shape().DebugString()));",
            "    OP_REQUIRES(context, beta.dims() == 1,",
            "                errors::InvalidArgument(\"beta must be 1-dimensional\",",
            "                                        beta.shape().DebugString()));",
            "    OP_REQUIRES(context, gamma.dims() == 1,",
            "                errors::InvalidArgument(\"gamma must be 1-dimensional\",",
            "                                        gamma.shape().DebugString()));",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "    float output_min;",
            "    float output_max;",
            "    FixedPointBatchNorm<T1, T2>(input, input_min, input_max, mean, mean_min,",
            "                                mean_max, var, var_min, var_max, beta, beta_min,",
            "                                beta_max, gamma, gamma_min, gamma_max,",
            "                                variance_epsilon_, scale_after_normalization_,",
            "                                output, &output_min, &output_max);",
            "",
            "    Tensor* output_min_tensor = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(1, {}, &output_min_tensor));",
            "    output_min_tensor->flat<float>()(0) = output_min;",
            "",
            "    Tensor* output_max_tensor = nullptr;"
        ],
        [
            "REGISTER_KERNEL_BUILDER(Name(\"QuantizedBatchNormWithGlobalNormalization\")",
            "                            .Device(DEVICE_CPU)",
            "                            .TypeConstraint<quint8>(\"Tinput\")",
            "                            .TypeConstraint<qint32>(\"out_type\"),",
            "                        QuantizedBatchNormOp<quint8, qint32>);",
            "",
            "}  // namespace tensorflow",
            ""
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const auto& input_min_tensor = context->input(1);",
            "    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"input_min must have 1 element\"));",
            "    const float input_min = input_min_tensor.flat<float>()(0);",
            "    const auto& input_max_tensor = context->input(2);",
            "    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"input_max must have 1 element\"));",
            "    const float input_max = input_max_tensor.flat<float>()(0);",
            "    const Tensor& mean = context->input(3);",
            "    const auto& mean_min_tensor = context->input(4);",
            "    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"mean_min must have 1 element\"));",
            "    const float mean_min = mean_min_tensor.flat<float>()(0);",
            "    const auto& mean_max_tensor = context->input(5);",
            "    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"mean_max must have 1 element\"));",
            "    const float mean_max = mean_max_tensor.flat<float>()(0);",
            "    const Tensor& var = context->input(6);",
            "    const auto& var_min_tensor = context->input(7);",
            "    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"var_min must have 1 element\"));",
            "    const float var_min = var_min_tensor.flat<float>()(0);",
            "    const auto& var_max_tensor = context->input(8);",
            "    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"var_max must have 1 element\"));",
            "    const float var_max = var_max_tensor.flat<float>()(0);",
            "    const Tensor& beta = context->input(9);",
            "    const auto& beta_min_tensor = context->input(10);",
            "    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"beta_min must have 1 element\"));",
            "    const float beta_min = beta_min_tensor.flat<float>()(0);",
            "    const auto& beta_max_tensor = context->input(11);",
            "    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"beta_max must have 1 element\"));",
            "    const float beta_max = beta_max_tensor.flat<float>()(0);",
            "    const Tensor& gamma = context->input(12);",
            "    const auto& gamma_min_tensor = context->input(13);",
            "    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"gamma_min must have 1 element\"));",
            "    const float gamma_min = gamma_min_tensor.flat<float>()(0);",
            "    const auto& gamma_max_tensor = context->input(14);",
            "    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"gamma_max must have 1 element\"));",
            "    const float gamma_max = gamma_max_tensor.flat<float>()(0);",
            "",
            "    OP_REQUIRES(context, input.dims() == 4,",
            "                errors::InvalidArgument(\"input must be 4-dimensional\",",
            "                                        input.shape().DebugString()));"
        ],
        [
            "                errors::InvalidArgument(\"gamma must be 1-dimensional\",",
            "                                        gamma.shape().DebugString()));",
            "    OP_REQUIRES(context, mean.NumElements() > 1,",
            "                errors::InvalidArgument(\"Must have at least a mean value\",",
            "                                        gamma.shape().DebugString()));",
            "    OP_REQUIRES(context, mean.NumElements() > 1,",
            "                errors::InvalidArgument(\"Must have at least a mean value\"));",
            "    const auto last_dim = input.shape().dims() - 1;",
            "    OP_REQUIRES(context,",
            "                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),",
            "                errors::InvalidArgument(\"Must provide as many means as the \"",
            "                                        \"last dimension of the input tensor: \",",
            "                                        mean.shape().DebugString(), \" vs. \",",
            "                                        input.shape().DebugString()));",
            "    OP_REQUIRES(",
            "        context, mean.shape().dim_size(0) == var.shape().dim_size(0),",
            "        errors::InvalidArgument(",
            "            \"Mean and variance tensors must have the same shape: \",",
            "            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));",
            "    OP_REQUIRES(",
            "        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),",
            "        errors::InvalidArgument(",
            "            \"Mean and beta tensors must have the same shape: \",",
            "            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));",
            "    OP_REQUIRES(",
            "        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),",
            "        errors::InvalidArgument(",
            "            \"Mean and gamma tensors must have the same shape: \",",
            "            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-p45v-v4pw-77jr",
    "API Signature": "tf.raw_ops.QuantizedBatchNormWithGlobalNormalization(\n    t,\n    t_min,\n    t_max,\n    m,\n    m_min,\n    m_max,\n    v,\n    v_min,\n    v_max,\n    beta,\n    beta_min,\n    beta_max,\n    gamma,\n    gamma_min,\n    gamma_max,\n    out_type,\n    variance_epsilon,\n    scale_after_normalization,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "t = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.quint8)\nm = tf.constant([], shape=[0], dtype=tf.quint8)\nv = tf.constant([], shape=[0], dtype=tf.quint8)\nbeta = tf.constant([], shape=[0], dtype=tf.quint8)\ngamma = tf.constant([], shape=[0], dtype=tf.quint8)"
},
{
    "Title": "\n        Division by 0 in `QuantizedBatchNormWithGlobalNormalization`\n      ",
    "Bug description": "An attacker can cause a runtime division by zero error and denial of service in  tf.raw_ops.QuantizedBatchNormWithGlobalNormalization :",
    "Sample Code": "t = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.quint8)\nt_min = tf.constant(-10.0, dtype=tf.float32)\nt_max = tf.constant(-10.0, dtype=tf.float32)\nm = tf.constant([], shape=[0], dtype=tf.quint8)\nm_min = tf.constant(-10.0, dtype=tf.float32)\nm_max = tf.constant(-10.0, dtype=tf.float32)\nv = tf.constant([], shape=[0], dtype=tf.quint8)\nv_min = tf.constant(-10.0, dtype=tf.float32)\nv_max = tf.constant(-10.0, dtype=tf.float32)\nbeta = tf.constant([], shape=[0], dtype=tf.quint8)\nbeta_min = tf.constant(-10.0, dtype=tf.float32)\nbeta_max = tf.constant(-10.0, dtype=tf.float32)\ngamma = tf.constant([], shape=[0], dtype=tf.quint8)\ngamma_min = tf.constant(-10.0, dtype=tf.float32)\ngamma_max = tf.constant(-10.0, dtype=tf.float32)\n\ntf.raw_ops.QuantizedBatchNormWithGlobalNormalization(\n  t=t, t_min=t_min, t_max=t_max, m=m, m_min=m_min, m_max=m_max,\n  v=v, v_min=v_min, v_max=v_max, beta=beta, beta_min=beta_min,\n  beta_max=beta_max, gamma=gamma, gamma_min=gamma_min,\n  gamma_max=gamma_max, out_type=tf.qint32,\n  ,\n  variance_epsilon=0.1, scale_after_normalization=True)",
    "Code change": [
        "@@ -173,20 +173,50 @@ class QuantizedBatchNormOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float input_min = context->input(1).flat<float>()(0);\n-    const float input_max = context->input(2).flat<float>()(0);\n+    const auto& input_min_tensor = context->input(1);\n+    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_min must have 1 element\"));\n+    const float input_min = input_min_tensor.flat<float>()(0);\n+    const auto& input_max_tensor = context->input(2);\n+    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_max must have 1 element\"));\n+    const float input_max = input_max_tensor.flat<float>()(0);\n     const Tensor& mean = context->input(3);\n-    const float mean_min = context->input(4).flat<float>()(0);\n-    const float mean_max = context->input(5).flat<float>()(0);\n+    const auto& mean_min_tensor = context->input(4);\n+    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_min must have 1 element\"));\n+    const float mean_min = mean_min_tensor.flat<float>()(0);\n+    const auto& mean_max_tensor = context->input(5);\n+    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_max must have 1 element\"));\n+    const float mean_max = mean_max_tensor.flat<float>()(0);\n     const Tensor& var = context->input(6);\n-    const float var_min = context->input(7).flat<float>()(0);\n-    const float var_max = context->input(8).flat<float>()(0);\n+    const auto& var_min_tensor = context->input(7);\n+    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_min must have 1 element\"));\n+    const float var_min = var_min_tensor.flat<float>()(0);\n+    const auto& var_max_tensor = context->input(8);\n+    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_max must have 1 element\"));\n+    const float var_max = var_max_tensor.flat<float>()(0);\n     const Tensor& beta = context->input(9);\n-    const float beta_min = context->input(10).flat<float>()(0);\n-    const float beta_max = context->input(11).flat<float>()(0);\n+    const auto& beta_min_tensor = context->input(10);\n+    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_min must have 1 element\"));\n+    const float beta_min = beta_min_tensor.flat<float>()(0);\n+    const auto& beta_max_tensor = context->input(11);\n+    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_max must have 1 element\"));\n+    const float beta_max = beta_max_tensor.flat<float>()(0);\n     const Tensor& gamma = context->input(12);\n-    const float gamma_min = context->input(13).flat<float>()(0);\n-    const float gamma_max = context->input(14).flat<float>()(0);\n+    const auto& gamma_min_tensor = context->input(13);\n+    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_min must have 1 element\"));\n+    const float gamma_min = gamma_min_tensor.flat<float>()(0);\n+    const auto& gamma_max_tensor = context->input(14);\n+    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_max must have 1 element\"));\n+    const float gamma_max = gamma_max_tensor.flat<float>()(0);\n \n     OP_REQUIRES(context, input.dims() == 4,\n                 errors::InvalidArgument(\"input must be 4-dimensional\",\n@@ -203,6 +233,33 @@ class QuantizedBatchNormOp : public OpKernel {\n     OP_REQUIRES(context, gamma.dims() == 1,\n                 errors::InvalidArgument(\"gamma must be 1-dimensional\",\n                                         gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\",\n+                                        gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\"));\n+    const auto last_dim = input.shape().dims() - 1;\n+    OP_REQUIRES(context,\n+                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\n+                errors::InvalidArgument(\"Must provide as many means as the \"\n+                                        \"last dimension of the input tensor: \",\n+                                        mean.shape().DebugString(), \" vs. \",\n+                                        input.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and variance tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and beta tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and gamma tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n"
    ],
    "Buggy Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const float input_min = context->input(1).flat<float>()(0);",
            "    const float input_max = context->input(2).flat<float>()(0);",
            "    const Tensor& mean = context->input(3);",
            "    const float mean_min = context->input(4).flat<float>()(0);",
            "    const float mean_max = context->input(5).flat<float>()(0);",
            "    const Tensor& var = context->input(6);",
            "    const float var_min = context->input(7).flat<float>()(0);",
            "    const float var_max = context->input(8).flat<float>()(0);",
            "    const Tensor& beta = context->input(9);",
            "    const float beta_min = context->input(10).flat<float>()(0);",
            "    const float beta_max = context->input(11).flat<float>()(0);",
            "    const Tensor& gamma = context->input(12);",
            "    const float gamma_min = context->input(13).flat<float>()(0);",
            "    const float gamma_max = context->input(14).flat<float>()(0);",
            "",
            "    OP_REQUIRES(context, input.dims() == 4,",
            "                errors::InvalidArgument(\"input must be 4-dimensional\",",
            "                                        input.shape().DebugString()));",
            "    OP_REQUIRES(context, mean.dims() == 1,",
            "                errors::InvalidArgument(\"mean must be 1-dimensional\",",
            "                                        mean.shape().DebugString()));",
            "    OP_REQUIRES(context, var.dims() == 1,",
            "                errors::InvalidArgument(\"var must be 1-dimensional\",",
            "                                        var.shape().DebugString()));",
            "    OP_REQUIRES(context, beta.dims() == 1,",
            "                errors::InvalidArgument(\"beta must be 1-dimensional\",",
            "                                        beta.shape().DebugString()));",
            "    OP_REQUIRES(context, gamma.dims() == 1,",
            "                errors::InvalidArgument(\"gamma must be 1-dimensional\",",
            "                                        gamma.shape().DebugString()));",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "    float output_min;",
            "    float output_max;",
            "    FixedPointBatchNorm<T1, T2>(input, input_min, input_max, mean, mean_min,",
            "                                mean_max, var, var_min, var_max, beta, beta_min,",
            "                                beta_max, gamma, gamma_min, gamma_max,",
            "                                variance_epsilon_, scale_after_normalization_,",
            "                                output, &output_min, &output_max);",
            "",
            "    Tensor* output_min_tensor = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(1, {}, &output_min_tensor));",
            "    output_min_tensor->flat<float>()(0) = output_min;",
            "",
            "    Tensor* output_max_tensor = nullptr;"
        ],
        [
            "REGISTER_KERNEL_BUILDER(Name(\"QuantizedBatchNormWithGlobalNormalization\")",
            "                            .Device(DEVICE_CPU)",
            "                            .TypeConstraint<quint8>(\"Tinput\")",
            "                            .TypeConstraint<qint32>(\"out_type\"),",
            "                        QuantizedBatchNormOp<quint8, qint32>);",
            "",
            "}  // namespace tensorflow",
            ""
        ]
    ],
    "Clean Code": [
        [
            "  void Compute(OpKernelContext* context) override {",
            "    const Tensor& input = context->input(0);",
            "    const auto& input_min_tensor = context->input(1);",
            "    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"input_min must have 1 element\"));",
            "    const float input_min = input_min_tensor.flat<float>()(0);",
            "    const auto& input_max_tensor = context->input(2);",
            "    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"input_max must have 1 element\"));",
            "    const float input_max = input_max_tensor.flat<float>()(0);",
            "    const Tensor& mean = context->input(3);",
            "    const auto& mean_min_tensor = context->input(4);",
            "    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"mean_min must have 1 element\"));",
            "    const float mean_min = mean_min_tensor.flat<float>()(0);",
            "    const auto& mean_max_tensor = context->input(5);",
            "    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"mean_max must have 1 element\"));",
            "    const float mean_max = mean_max_tensor.flat<float>()(0);",
            "    const Tensor& var = context->input(6);",
            "    const auto& var_min_tensor = context->input(7);",
            "    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"var_min must have 1 element\"));",
            "    const float var_min = var_min_tensor.flat<float>()(0);",
            "    const auto& var_max_tensor = context->input(8);",
            "    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"var_max must have 1 element\"));",
            "    const float var_max = var_max_tensor.flat<float>()(0);",
            "    const Tensor& beta = context->input(9);",
            "    const auto& beta_min_tensor = context->input(10);",
            "    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"beta_min must have 1 element\"));",
            "    const float beta_min = beta_min_tensor.flat<float>()(0);",
            "    const auto& beta_max_tensor = context->input(11);",
            "    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"beta_max must have 1 element\"));",
            "    const float beta_max = beta_max_tensor.flat<float>()(0);",
            "    const Tensor& gamma = context->input(12);",
            "    const auto& gamma_min_tensor = context->input(13);",
            "    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"gamma_min must have 1 element\"));",
            "    const float gamma_min = gamma_min_tensor.flat<float>()(0);",
            "    const auto& gamma_max_tensor = context->input(14);",
            "    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,",
            "                errors::InvalidArgument(\"gamma_max must have 1 element\"));",
            "    const float gamma_max = gamma_max_tensor.flat<float>()(0);",
            "",
            "    OP_REQUIRES(context, input.dims() == 4,",
            "                errors::InvalidArgument(\"input must be 4-dimensional\",",
            "                                        input.shape().DebugString()));"
        ],
        [
            "                errors::InvalidArgument(\"gamma must be 1-dimensional\",",
            "                                        gamma.shape().DebugString()));",
            "    OP_REQUIRES(context, mean.NumElements() > 1,",
            "                errors::InvalidArgument(\"Must have at least a mean value\",",
            "                                        gamma.shape().DebugString()));",
            "    OP_REQUIRES(context, mean.NumElements() > 1,",
            "                errors::InvalidArgument(\"Must have at least a mean value\"));",
            "    const auto last_dim = input.shape().dims() - 1;",
            "    OP_REQUIRES(context,",
            "                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),",
            "                errors::InvalidArgument(\"Must provide as many means as the \"",
            "                                        \"last dimension of the input tensor: \",",
            "                                        mean.shape().DebugString(), \" vs. \",",
            "                                        input.shape().DebugString()));",
            "    OP_REQUIRES(",
            "        context, mean.shape().dim_size(0) == var.shape().dim_size(0),",
            "        errors::InvalidArgument(",
            "            \"Mean and variance tensors must have the same shape: \",",
            "            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));",
            "    OP_REQUIRES(",
            "        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),",
            "        errors::InvalidArgument(",
            "            \"Mean and beta tensors must have the same shape: \",",
            "            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));",
            "    OP_REQUIRES(",
            "        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),",
            "        errors::InvalidArgument(",
            "            \"Mean and gamma tensors must have the same shape: \",",
            "            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-p45v-v4pw-77jr",
    "API Signature": "tf.raw_ops.QuantizedBatchNormWithGlobalNormalization(\n    t,\n    t_min,\n    t_max,\n    m,\n    m_min,\n    m_max,\n    v,\n    v_min,\n    v_max,\n    beta,\n    beta_min,\n    beta_max,\n    gamma,\n    gamma_min,\n    gamma_max,\n    out_type,\n    variance_epsilon,\n    scale_after_normalization,\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "m = tf.constant([], shape=[0], dtype=tf.quint8) \nv = tf.constant([], shape=[0], dtype=tf.quint8) \nbeta = tf.constant([], shape=[0], dtype=tf.quint8) \ngamma = tf.constant([], shape=[0], dtype=tf.quint8)"
},
{
    "Title": "\n        Division by 0 in `QuantizedBiasAdd`\n      ",
    "Bug description": "An attacker can trigger an integer division by zero undefined behavior in  tf.raw_ops.QuantizedBiasAdd :",
    "Sample Code": "input_tensor = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.quint8)\nbias = tf.constant([], shape=[0], dtype=tf.quint8)\nmin_input = tf.constant(-10.0, dtype=tf.float32)\nmax_input = tf.constant(-10.0, dtype=tf.float32)\nmin_bias = tf.constant(-10.0, dtype=tf.float32)\nmax_bias = tf.constant(-10.0, dtype=tf.float32)\n\ntf.raw_ops.QuantizedBiasAdd(input=input_tensor, bias=bias, min_input=min_input,\n                            max_input=max_input, min_bias=min_bias,\n                            ,\n                            max_bias=max_bias, out_type=tf.qint32)",
    "Code change": [
        "@@ -56,6 +56,8 @@ class QuantizedBiasAddOp : public OpKernel {\n             \"Must provide as many biases as the last dimension \"\n             \"of the input tensor: \",\n             bias.shape().DebugString(), \" vs. \", input.shape().DebugString()));\n+    OP_REQUIRES(context, bias.NumElements() > 0,\n+                errors::InvalidArgument(\"Must provide at least 1 bias\"));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n"
    ],
    "Buggy Code": [
        [
            "            \"of the input tensor: \",",
            "            bias.shape().DebugString(), \" vs. \", input.shape().DebugString()));",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));",
            "",
            "    float total_min;"
        ]
    ],
    "Clean Code": [
        [
            "            \"of the input tensor: \",",
            "            bias.shape().DebugString(), \" vs. \", input.shape().DebugString()));",
            "    OP_REQUIRES(context, bias.NumElements() > 0,",
            "                errors::InvalidArgument(\"Must provide at least 1 bias\"));",
            "",
            "    Tensor* output = nullptr;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input.shape(), &output));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m34j-p8rj-wjxq",
    "API Signature": "tf.raw_ops.QuantizedBiasAdd(\n    input, bias, min_input, max_input, min_bias, max_bias, out_type, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "bias = tf.constant([], shape=[0], dtype=tf.quint8)"
},
{
    "Title": "\n        `CHECK`-fail in `CTCGreedyDecoder`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in  tf.raw_ops.CTCGreedyDecoder :",
    "Sample Code": "inputs = tf.constant([], shape=[18, 2, 0], dtype=tf.float32)\nsequence_length = tf.constant([-100, 17], shape=[2], dtype=tf.int32)\nmerge_repeated = False\n\n\n\ntf.raw_ops.CTCGreedyDecoder(inputs=inputs, sequence_length=sequence_length, merge_repeated=merge_repeated)",
    "Code change": [
        "@@ -232,6 +232,8 @@ class CTCGreedyDecoderOp : public OpKernel {\n         int prev_indices = -1;\n         for (int t = 0; t < seq_len_t(b); ++t) {\n           int max_class_indices;\n+          OP_REQUIRES(ctx, input_list_t[t].dimension(1) > 0,\n+                      errors::InvalidArgument(\"Invalid input dimensions.\"));\n           log_prob_t(b, 0) +=\n               -RowMax<T>(input_list_t[t], b, &max_class_indices);\n           if (max_class_indices != blank_index &&\n"
    ],
    "Buggy Code": [
        [
            "        for (int t = 0; t < seq_len_t(b); ++t) {",
            "          int max_class_indices;",
            "          log_prob_t(b, 0) +=",
            "              -RowMax<T>(input_list_t[t], b, &max_class_indices);",
            "          if (max_class_indices != blank_index &&",
            "              !(merge_repeated_ && max_class_indices == prev_indices)) {",
            "            sequence.push_back(max_class_indices);",
            "          }"
        ]
    ],
    "Clean Code": [
        [
            "        for (int t = 0; t < seq_len_t(b); ++t) {",
            "          int max_class_indices;",
            "          OP_REQUIRES(ctx, input_list_t[t].dimension(1) > 0,",
            "                      errors::InvalidArgument(\"Invalid input dimensions.\"));",
            "          log_prob_t(b, 0) +=",
            "              -RowMax<T>(input_list_t[t], b, &max_class_indices);",
            "          if (max_class_indices != blank_index &&",
            "              !(merge_repeated_ && max_class_indices == prev_indices)) {"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-fphq-gw9m-ghrv",
    "API Signature": "tf.raw_ops.CTCGreedyDecoder(\n    inputs, sequence_length, merge_repeated=False, blank_index=-1, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "inputs = tf.constant([], shape=[18, 2, 0], dtype=tf.float32)"
},
{
    "Title": "\n        `CHECK`-fail in `QuantizeAndDequantizeV4Grad`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in  tf.raw_ops.QuantizeAndDequantizeV4Grad :",
    "Sample Code": "gradient_tensor = tf.constant([0.0], shape=[1])\ninput_tensor = tf.constant([0.0], shape=[1])\ninput_min = tf.constant([[0.0]], shape=[1, 1])\ninput_max = tf.constant([[0.0]], shape=[1, 1])\n\ntf.raw_ops.QuantizeAndDequantizeV4Grad(\n  gradients=gradient_tensor, input=input_tensor,\n  ,\n  input_min=input_min, input_max=input_max, axis=0)",
    "Code change": [
        "@@ -160,7 +160,17 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n         errors::InvalidArgument(\"gradient and input must be the same size\"));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     const Tensor& input_min_tensor = ctx->input(2);\n+    OP_REQUIRES(ctx,\n+                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n+                errors::InvalidArgument(\n+                    \"Input min tensor must have dimension 1. Recieved \",\n+                    input_min_tensor.dims(), \".\"));\n     const Tensor& input_max_tensor = ctx->input(3);\n+    OP_REQUIRES(ctx,\n+                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n+                errors::InvalidArgument(\n+                    \"Input max tensor must have dimension 1. Recieved \",\n+                    input_max_tensor.dims(), \".\"));\n     if (axis_ != -1) {\n       OP_REQUIRES(\n           ctx, input_min_tensor.dim_size(0) == depth,\n"
    ],
    "Buggy Code": [
        [
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    const Tensor& input_min_tensor = ctx->input(2);",
            "    const Tensor& input_max_tensor = ctx->input(3);",
            "    if (axis_ != -1) {",
            "      OP_REQUIRES(",
            "          ctx, input_min_tensor.dim_size(0) == depth,",
            "          errors::InvalidArgument(\"min has incorrect size, expected \", depth,",
            "                                  \" was \", input_min_tensor.dim_size(0)));",
            "      OP_REQUIRES(",
            "          ctx, input_max_tensor.dim_size(0) == depth,",
            "          errors::InvalidArgument(\"max has incorrect size, expected \", depth,",
            "                                  \" was \", input_max_tensor.dim_size(0)));",
            "    }",
            "",
            "    TensorShape min_max_shape(input_min_tensor.shape());",
            "    Tensor* input_min_backprop;",
            "    OP_REQUIRES_OK(ctx,"
        ]
    ],
    "Clean Code": [
        [
            "    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
            "    const Tensor& input_min_tensor = ctx->input(2);",
            "    OP_REQUIRES(ctx,",
            "                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,",
            "                errors::InvalidArgument(",
            "                    \"Input min tensor must have dimension 1. Recieved \",",
            "                    input_min_tensor.dims(), \".\"));",
            "    const Tensor& input_max_tensor = ctx->input(3);",
            "    OP_REQUIRES(ctx,",
            "                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,",
            "                errors::InvalidArgument(",
            "                    \"Input max tensor must have dimension 1. Recieved \",",
            "                    input_max_tensor.dims(), \".\"));",
            "    if (axis_ != -1) {",
            "      OP_REQUIRES(",
            "          ctx, input_min_tensor.dim_size(0) == depth,",
            "          errors::InvalidArgument(\"min has incorrect size, expected \", depth,"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6g85-3hm8-83f9",
    "API Signature": "tf.raw_ops.QuantizeAndDequantizeV4Grad(\n    gradients, input, input_min, input_max, axis=-1, name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "input_min = tf.constant([[0.0]], shape=[1, 1])\ninput_max = tf.constant([[0.0]], shape=[1, 1])"
},
{
    "Title": "\n        Heap buffer overflow in `Conv2DBackpropFilter`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow to occur in  Conv2DBackpropFilter :",
    "Sample Code": "input_tensor = tf.constant([], shape=[0, 1, 1, 5], dtype=tf.float32)\nfilter_sizes = tf.constant([3, 8, 1, 1], shape=[4], dtype=tf.int32)\nout_backprop = tf.constant([], shape=[0, 1, 1, 1], dtype=tf.float32)\n\ntf.raw_ops.Conv2DBackpropFilter(\n  input=input_tensor,\n  filter_sizes=filter_sizes, \n  out_backprop=out_backprop,\n  strides=[1, 66, 49, 1], \n  use_cudnn_on_gpu=True,\n  padding='VALID',\n  explicit_paddings=[],\n  data_format='NHWC',\n  dilations=[1, 1, 1, 1]\n)]\n)",
    "Code change": [
        "@@ -495,6 +495,14 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n     const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                   dims.spatial_dims[1].filter_size *\n                                   dims.in_depth;\n+    OP_REQUIRES(\n+        context,\n+        filter_total_size * dims.out_depth == filter_backprop->NumElements(),\n+        errors::InvalidArgument(\n+            \"filter_size does not have enough elements, requested \",\n+            filter_total_size * dims.out_depth, \", got \",\n+            filter_backprop->NumElements()));\n+\n     // The output image size is the spatial size of the output.\n     const int output_image_size =\n         dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n@@ -518,6 +526,11 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n \n     const size_t work_unit_size = size_A + size_B + size_C;\n \n+    OP_REQUIRES(\n+        context, work_unit_size != 0,\n+        errors::InvalidArgument(\n+            \"Work size for convolution would be 0, which is not acceptable\"));\n+\n     const size_t shard_size =\n         (target_working_set_size + work_unit_size - 1) / work_unit_size;\n \n"
    ],
    "Buggy Code": [
        [
            "                                  dims.spatial_dims[1].filter_size *",
            "                                  dims.in_depth;",
            "    // The output image size is the spatial size of the output.",
            "    const int output_image_size =",
            "        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;",
            "",
            "    // Shard 'batch' images into 'shard_size' groups of images to be fed",
            "    // into the parallel matmul. Calculate 'shard_size' by dividing the L3 cache",
            "    // size ('target_working_set_size') by the matmul size of an individual",
            "    // image ('work_unit_size').",
            "",
            "    // TODO(andydavis)",
            "    // *) Get L3 cache size from device at runtime (30MB is from ivybridge).",
            "    // *) Consider reducing 'target_working_set_size' if L3 is shared by"
        ],
        [
            "                       DataTypeToEnum<T>::value,",
            "                       TensorShape({static_cast<int64>(shard_size),",
            "                                    static_cast<int64>(output_image_size),",
            "                                    static_cast<int64>(filter_total_size)}),",
            "                       &col_buffer));",
            "",
            "    // The input offset corresponding to a single input image.",
            "    const int input_offset = dims.spatial_dims[0].input_size *",
            "                             dims.spatial_dims[1].input_size * dims.in_depth;",
            "    // The output offset corresponding to a single output image.",
            "    const int output_offset = dims.spatial_dims[0].output_size *"
        ]
    ],
    "Clean Code": [
        [
            "                                  dims.spatial_dims[1].filter_size *",
            "                                  dims.in_depth;",
            "    OP_REQUIRES(",
            "        context,",
            "        filter_total_size * dims.out_depth == filter_backprop->NumElements(),",
            "        errors::InvalidArgument(",
            "            \"filter_size does not have enough elements, requested \",",
            "            filter_total_size * dims.out_depth, \", got \",",
            "            filter_backprop->NumElements()));",
            "",
            "    // The output image size is the spatial size of the output.",
            "    const int output_image_size =",
            "        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;",
            ""
        ],
        [
            "    const size_t work_unit_size = size_A + size_B + size_C;",
            "",
            "    OP_REQUIRES(",
            "        context, work_unit_size != 0,",
            "        errors::InvalidArgument(",
            "            \"Work size for convolution would be 0, which is not acceptable\"));",
            "",
            "    const size_t shard_size =",
            "        (target_working_set_size + work_unit_size - 1) / work_unit_size;",
            "",
            "    Tensor col_buffer;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xgc3-m89p-vr3x",
    "API Signature": "tf.raw_ops.Conv2DBackpropFilter(\n    input,\n    filter_sizes,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "input_tensor = tf.constant([386.078431372549, 386.07843139643234], shape=[1, 1, 1, 2], dtype=tf.float32)\nfilter_sizes = tf.constant([1, 1, 1, 1], shape=[4], dtype=tf.int32)"
},
{
    "Title": "\n        Heap buffer overflow in `Conv2DBackpropFilter`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow to occur in  Conv2DBackpropFilter :",
    "Sample Code": "input_tensor = tf.constant([], shape=[0, 1, 1, 5], dtype=tf.float32)\nfilter_sizes = tf.constant([3, 8, 1, 1], shape=[4], dtype=tf.int32)\nout_backprop = tf.constant([], shape=[0, 1, 1, 1], dtype=tf.float32)\n\ntf.raw_ops.Conv2DBackpropFilter(\n  input=input_tensor,\n  filter_sizes=filter_sizes, \n  out_backprop=out_backprop,\n  strides=[1, 66, 49, 1], \n  use_cudnn_on_gpu=True,\n  padding='VALID',\n  explicit_paddings=[],\n  data_format='NHWC',\n  dilations=[1, 1, 1, 1]\n)]\n)",
    "Code change": [
        "@@ -495,6 +495,14 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n     const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                   dims.spatial_dims[1].filter_size *\n                                   dims.in_depth;\n+    OP_REQUIRES(\n+        context,\n+        filter_total_size * dims.out_depth == filter_backprop->NumElements(),\n+        errors::InvalidArgument(\n+            \"filter_size does not have enough elements, requested \",\n+            filter_total_size * dims.out_depth, \", got \",\n+            filter_backprop->NumElements()));\n+\n     // The output image size is the spatial size of the output.\n     const int output_image_size =\n         dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n@@ -518,6 +526,11 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n \n     const size_t work_unit_size = size_A + size_B + size_C;\n \n+    OP_REQUIRES(\n+        context, work_unit_size != 0,\n+        errors::InvalidArgument(\n+            \"Work size for convolution would be 0, which is not acceptable\"));\n+\n     const size_t shard_size =\n         (target_working_set_size + work_unit_size - 1) / work_unit_size;\n \n"
    ],
    "Buggy Code": [
        [
            "                                  dims.spatial_dims[1].filter_size *",
            "                                  dims.in_depth;",
            "    // The output image size is the spatial size of the output.",
            "    const int output_image_size =",
            "        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;",
            "",
            "    // Shard 'batch' images into 'shard_size' groups of images to be fed",
            "    // into the parallel matmul. Calculate 'shard_size' by dividing the L3 cache",
            "    // size ('target_working_set_size') by the matmul size of an individual",
            "    // image ('work_unit_size').",
            "",
            "    // TODO(andydavis)",
            "    // *) Get L3 cache size from device at runtime (30MB is from ivybridge).",
            "    // *) Consider reducing 'target_working_set_size' if L3 is shared by"
        ],
        [
            "                       DataTypeToEnum<T>::value,",
            "                       TensorShape({static_cast<int64>(shard_size),",
            "                                    static_cast<int64>(output_image_size),",
            "                                    static_cast<int64>(filter_total_size)}),",
            "                       &col_buffer));",
            "",
            "    // The input offset corresponding to a single input image.",
            "    const int input_offset = dims.spatial_dims[0].input_size *",
            "                             dims.spatial_dims[1].input_size * dims.in_depth;",
            "    // The output offset corresponding to a single output image.",
            "    const int output_offset = dims.spatial_dims[0].output_size *"
        ]
    ],
    "Clean Code": [
        [
            "                                  dims.spatial_dims[1].filter_size *",
            "                                  dims.in_depth;",
            "    OP_REQUIRES(",
            "        context,",
            "        filter_total_size * dims.out_depth == filter_backprop->NumElements(),",
            "        errors::InvalidArgument(",
            "            \"filter_size does not have enough elements, requested \",",
            "            filter_total_size * dims.out_depth, \", got \",",
            "            filter_backprop->NumElements()));",
            "",
            "    // The output image size is the spatial size of the output.",
            "    const int output_image_size =",
            "        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;",
            ""
        ],
        [
            "    const size_t work_unit_size = size_A + size_B + size_C;",
            "",
            "    OP_REQUIRES(",
            "        context, work_unit_size != 0,",
            "        errors::InvalidArgument(",
            "            \"Work size for convolution would be 0, which is not acceptable\"));",
            "",
            "    const size_t shard_size =",
            "        (target_working_set_size + work_unit_size - 1) / work_unit_size;",
            "",
            "    Tensor col_buffer;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xgc3-m89p-vr3x",
    "API Signature": "tf.raw_ops.Conv2DBackpropFilter(\n    input,\n    filter_sizes,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "input_tensor = tf.constant([], shape=[0, 1, 1, 5], dtype=tf.float32)"
},
{
    "Title": "\n        Heap buffer overflow in `QuantizedReshape`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow in  QuantizedReshape  by passing in invalid thresholds for the quantization:",
    "Sample Code": "tensor = tf.constant([], dtype=tf.qint32)\nshape = tf.constant([], dtype=tf.int32)\ninput_min = tf.constant([], dtype=tf.float32)\ninput_max = tf.constant([], dtype=tf.float32)\n\n)\n\ntf.raw_ops.QuantizedReshape(tensor=tensor, shape=shape, input_min=input_min, input_max=input_max)",
    "Code change": [
        "@@ -17,6 +17,7 @@ limitations under the License.\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/tensor_types.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/reshape_op.h\"\n@@ -30,9 +31,29 @@ class QuantizedReshapeOp : public ReshapeOp {\n   void Compute(OpKernelContext* ctx) override {\n     // This call processes inputs 1 and 2 to write output 0.\n     ReshapeOp::Compute(ctx);\n+    if (!ctx->status().ok()) {\n+      return;\n+    }\n+\n+    const auto& input_min_float_tensor = ctx->input(2);\n+    const auto& input_min_float_shape = input_min_float_tensor.shape();\n+    OP_REQUIRES(ctx,\n+                TensorShapeUtils::IsScalar(input_min_float_shape) ||\n+                    (TensorShapeUtils::IsVector(input_min_float_shape) &&\n+                     (input_min_float_shape.dim_size(0) == 1)),\n+                errors::InvalidArgument(\n+                    \"input_min must be a scalar or a vector of 1 element\"));\n+    const float input_min_float = input_min_float_tensor.flat<float>()(0);\n+    const auto& input_max_float_tensor = ctx->input(3);\n+    const auto& input_max_float_shape = input_max_float_tensor.shape();\n+    OP_REQUIRES(ctx,\n+                TensorShapeUtils::IsScalar(input_max_float_shape) ||\n+                    (TensorShapeUtils::IsVector(input_max_float_shape) &&\n+                     (input_max_float_shape.dim_size(0) == 1)),\n+                errors::InvalidArgument(\n+                    \"input_max must be a scalar or a vector of 1 element\"));\n+    const float input_max_float = input_max_float_tensor.flat<float>()(0);\n \n-    const float input_min_float = ctx->input(2).flat<float>()(0);\n-    const float input_max_float = ctx->input(3).flat<float>()(0);\n     Tensor* output_min = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));\n     output_min->flat<float>()(0) = input_min_float;\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor_types.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/kernels/reshape_op.h\"",
            "",
            "namespace tensorflow {"
        ],
        [
            "    ReshapeOp::Compute(ctx);",
            "",
            "    const float input_min_float = ctx->input(2).flat<float>()(0);",
            "    const float input_max_float = ctx->input(3).flat<float>()(0);",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));",
            "    output_min->flat<float>()(0) = input_min_float;",
            "",
            "    Tensor* output_max = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(2, TensorShape({}), &output_max));",
            "    output_max->flat<float>()(0) = input_max_float;",
            "  }",
            "};",
            "",
            "#define REGISTER_CPU_KERNEL(type)                         \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"QuantizedReshape\")        \\",
            "                              .Device(DEVICE_CPU)         \\",
            "                              .HostMemory(\"shape\")        \\",
            "                              .TypeConstraint<type>(\"T\"), \\",
            "                          QuantizedReshapeOp)",
            "",
            "REGISTER_CPU_KERNEL(::tensorflow::quint8);",
            "REGISTER_CPU_KERNEL(::tensorflow::qint32);",
            "",
            "#undef REGISTER_CPU_KERNEL",
            "",
            "}  // namespace tensorflow",
            ""
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/framework/tensor_types.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/kernels/reshape_op.h\"",
            ""
        ],
        [
            "    // This call processes inputs 1 and 2 to write output 0.",
            "    ReshapeOp::Compute(ctx);",
            "    if (!ctx->status().ok()) {",
            "      return;",
            "    }",
            "",
            "    const auto& input_min_float_tensor = ctx->input(2);",
            "    const auto& input_min_float_shape = input_min_float_tensor.shape();",
            "    OP_REQUIRES(ctx,",
            "                TensorShapeUtils::IsScalar(input_min_float_shape) ||",
            "                    (TensorShapeUtils::IsVector(input_min_float_shape) &&",
            "                     (input_min_float_shape.dim_size(0) == 1)),",
            "                errors::InvalidArgument(",
            "                    \"input_min must be a scalar or a vector of 1 element\"));",
            "    const float input_min_float = input_min_float_tensor.flat<float>()(0);",
            "    const auto& input_max_float_tensor = ctx->input(3);",
            "    const auto& input_max_float_shape = input_max_float_tensor.shape();",
            "    OP_REQUIRES(ctx,",
            "                TensorShapeUtils::IsScalar(input_max_float_shape) ||",
            "                    (TensorShapeUtils::IsVector(input_max_float_shape) &&",
            "                     (input_max_float_shape.dim_size(0) == 1)),",
            "                errors::InvalidArgument(",
            "                    \"input_max must be a scalar or a vector of 1 element\"));",
            "    const float input_max_float = input_max_float_tensor.flat<float>()(0);",
            "",
            "    Tensor* output_min = nullptr;",
            "    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));",
            "    output_min->flat<float>()(0) = input_min_float;",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2gfx-95x2-5v3x",
    "API Signature": "tf.raw_ops.QuantizedReshape(\n    tensor, shape, input_min, input_max, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "tensor = tf.constant([], dtype=tf.qint32) \nshape = tf.constant([], dtype=tf.int32) \ninput_min = tf.constant([], dtype=tf.float32) \ninput_max = tf.constant([], dtype=tf.float32)"
},
{
    "Title": "\n        Heap buffer overflow in `QuantizedResizeBilinear`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow in  QuantizedResizeBilinear  by passing in invalid thresholds for the quantization:",
    "Sample Code": "images = tf.constant([], shape=[0], dtype=tf.qint32)\nsize = tf.constant([], shape=[0], dtype=tf.int32) \nmin = tf.constant([], dtype=tf.float32)\nmax = tf.constant([], dtype=tf.float32)\n\n)\n\ntf.raw_ops.QuantizedResizeBilinear(images=images, size=size, min=min, max=max, align_corners=False, half_pixel_centers=False)",
    "Code change": [
        "@@ -702,8 +702,14 @@ class QuantizedResizeBilinearOp : public OpKernel {\n   }\n \n   void Compute(OpKernelContext* context) override {\n-    const float in_min = context->input(2).flat<float>()(0);\n-    const float in_max = context->input(3).flat<float>()(0);\n+    const auto& in_min_tensor = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(in_min_tensor.shape()),\n+                errors::InvalidArgument(\"min must be a scalar\"));\n+    const float in_min = in_min_tensor.flat<float>()(0);\n+    const auto& in_max_tensor = context->input(3);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(in_max_tensor.shape()),\n+                errors::InvalidArgument(\"max must be a scalar\"));\n+    const float in_max = in_max_tensor.flat<float>()(0);\n \n     ImageResizerState st(align_corners_, false);\n     st.ValidateAndCreateOutput(context);\n"
    ],
    "Buggy Code": [
        [
            "",
            "  void Compute(OpKernelContext* context) override {",
            "    const float in_min = context->input(2).flat<float>()(0);",
            "    const float in_max = context->input(3).flat<float>()(0);",
            "",
            "    ImageResizerState st(align_corners_, false);",
            "    st.ValidateAndCreateOutput(context);",
            "",
            "    if (!context->status().ok()) return;",
            "",
            "    // Return if the output is empty.",
            "    if (st.output->NumElements() == 0) return;",
            "",
            "    typename TTypes<T, 4>::ConstTensor image_data("
        ]
    ],
    "Clean Code": [
        [
            "",
            "  void Compute(OpKernelContext* context) override {",
            "    const auto& in_min_tensor = context->input(2);",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(in_min_tensor.shape()),",
            "                errors::InvalidArgument(\"min must be a scalar\"));",
            "    const float in_min = in_min_tensor.flat<float>()(0);",
            "    const auto& in_max_tensor = context->input(3);",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(in_max_tensor.shape()),",
            "                errors::InvalidArgument(\"max must be a scalar\"));",
            "    const float in_max = in_max_tensor.flat<float>()(0);",
            "",
            "    ImageResizerState st(align_corners_, false);",
            "    st.ValidateAndCreateOutput(context);",
            ""
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-8c89-2vwr-chcq",
    "API Signature": "tf.raw_ops.QuantizedResizeBilinear(\n    images,\n    size,\n    min,\n    max,\n    align_corners=False,\n    half_pixel_centers=False,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "images = tf.constant([], shape=[0], dtype=tf.qint32)\nsize = tf.constant([], shape=[0], dtype=tf.int32) \nmin = tf.constant([], dtype=tf.float32)\nmax = tf.constant([], dtype=tf.float32)"
},
{
    "Title": "\n        `CHECK`-fail in `SparseConcat`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in  tf.raw_ops.SparseConcat :",
    "Sample Code": "import numpy as np\n\nindices_1 = tf.constant([[514, 514], [514, 514]], dtype=tf.int64)\nindices_2 = tf.constant([[514, 530], [599, 877]], dtype=tf.int64)\nindices = [indices_1, indices_2]\n\nvalues_1 = tf.zeros([0], dtype=tf.int64)\nvalues_2 = tf.zeros([0], dtype=tf.int64)\nvalues = [values_1, values_2]\n\nshape_1 = tf.constant([442, 514, 514, 515, 606, 347, 943, 61, 2], dtype=tf.int64)\nshape_2 = tf.zeros([9], dtype=tf.int64)\nshapes = [shape_1, shape_2]\n\n]\n\ntf.raw_ops.SparseConcat(indices=indices, values=values, shapes=shapes, concat_dim=2)",
    "Code change": [
        "@@ -21,9 +21,6 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n-#include \"tensorflow/core/framework/op_kernel.h\"\n-#include \"tensorflow/core/framework/register_types.h\"\n-\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/resource_mgr.h\"\n@@ -31,6 +28,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n #include \"tensorflow/core/util/sparse/sparse_tensor.h\"\n \n namespace tensorflow {\n@@ -254,7 +252,22 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n         errors::InvalidArgument(\n             \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n \n-    TensorShape tensor_input_shape(input_shape->vec<int64>());\n+    auto input_shape_vec = input_shape->vec<int64>();\n+    int new_num_elements = 1;\n+    bool overflow_ocurred = false;\n+    for (int i = 0; i < input_shape_vec.size(); i++) {\n+      new_num_elements =\n+          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n+      if (new_num_elements < 0) {\n+        overflow_ocurred = true;\n+      }\n+    }\n+\n+    OP_REQUIRES(\n+        context, !overflow_ocurred,\n+        errors::Internal(\"Encountered overflow from large input shape.\"));\n+\n+    TensorShape tensor_input_shape(input_shape_vec);\n     gtl::InlinedVector<int64, 8> std_order(rank);\n     std::iota(std_order.begin(), std_order.end(), 0);\n     SparseTensor input_st;\n@@ -262,8 +275,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n                                                  tensor_input_shape, std_order,\n                                                  &input_st));\n \n-    auto input_shape_t = input_shape->vec<int64>();\n-    const int64 N = input_shape_t(0);\n+    const int64 N = input_shape_vec(0);\n \n     Tensor sparse_handles(DT_INT64, TensorShape({N}));\n     auto sparse_handles_t = sparse_handles.vec<int64>();\n@@ -274,7 +286,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n     // minibatch entries.\n     TensorShape output_shape;\n     OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n-                                input_shape_t.data() + 1,\n+                                input_shape_vec.data() + 1,\n                                 input_shape->NumElements() - 1, &output_shape));\n \n     // Get groups by minibatch dimension\n"
    ],
    "Buggy Code": [
        [
            "#include <vector>",
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\""
        ],
        [
            "#include \"tensorflow/core/framework/resource_mgr.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "#include \"tensorflow/core/util/sparse/sparse_tensor.h\"",
            ""
        ],
        [
            "        context, rank > 1,",
            "        errors::InvalidArgument(",
            "            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));",
            "",
            "    TensorShape tensor_input_shape(input_shape->vec<int64>());",
            "    gtl::InlinedVector<int64, 8> std_order(rank);",
            "    std::iota(std_order.begin(), std_order.end(), 0);",
            "    SparseTensor input_st;",
            "    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,",
            "                                                 tensor_input_shape, std_order,",
            "                                                 &input_st));",
            "",
            "    auto input_shape_t = input_shape->vec<int64>();",
            "    const int64 N = input_shape_t(0);",
            "",
            "    Tensor sparse_handles(DT_INT64, TensorShape({N}));",
            "    auto sparse_handles_t = sparse_handles.vec<int64>();",
            "",
            "    OP_REQUIRES_OK(context, input_st.IndicesValid());",
            "",
            "    // We can generate the output shape proto string now, for all",
            "    // minibatch entries."
        ],
        [
            "    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(",
            "                                input_shape_t.data() + 1,",
            "                                input_shape->NumElements() - 1, &output_shape));",
            "",
            "    // Get groups by minibatch dimension",
            "    std::unordered_set<int64> visited;",
            "    sparse::GroupIterable minibatch = input_st.group({0});"
        ],
        [
            "          context, b > -1 && b < N,",
            "          errors::InvalidArgument(",
            "              \"Received unexpected column 0 value in input SparseTensor: \", b,",
            "              \" < 0 or >= N (= \", N, \")\"));",
            "",
            "      const auto indices = subset.indices();",
            "      const auto values = subset.values<T>();"
        ]
    ],
    "Clean Code": [
        [
            "#include <vector>",
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/resource_mgr.h\"",
            "#include \"tensorflow/core/framework/tensor.h\""
        ],
        [
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "#include \"tensorflow/core/util/overflow.h\"",
            "#include \"tensorflow/core/util/sparse/sparse_tensor.h\"",
            "",
            "namespace tensorflow {",
            ""
        ],
        [
            "            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));",
            "",
            "    auto input_shape_vec = input_shape->vec<int64>();",
            "    int new_num_elements = 1;",
            "    bool overflow_ocurred = false;",
            "    for (int i = 0; i < input_shape_vec.size(); i++) {",
            "      new_num_elements =",
            "          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));",
            "      if (new_num_elements < 0) {",
            "        overflow_ocurred = true;",
            "      }",
            "    }",
            "",
            "    OP_REQUIRES(",
            "        context, !overflow_ocurred,",
            "        errors::Internal(\"Encountered overflow from large input shape.\"));",
            "",
            "    TensorShape tensor_input_shape(input_shape_vec);",
            "    gtl::InlinedVector<int64, 8> std_order(rank);",
            "    std::iota(std_order.begin(), std_order.end(), 0);",
            "    SparseTensor input_st;",
            "    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,"
        ],
        [
            "                                                 &input_st));",
            "",
            "    const int64 N = input_shape_vec(0);",
            "",
            "    Tensor sparse_handles(DT_INT64, TensorShape({N}));",
            "    auto sparse_handles_t = sparse_handles.vec<int64>();",
            ""
        ],
        [
            "    TensorShape output_shape;",
            "    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(",
            "                                input_shape_vec.data() + 1,",
            "                                input_shape->NumElements() - 1, &output_shape));",
            "",
            "    // Get groups by minibatch dimension",
            "    std::unordered_set<int64> visited;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6j9c-grc6-5m6g",
    "API Signature": "tf.raw_ops.SparseConcat(\n    indices, values, shapes, concat_dim, name=None\n)\n",
    "Score": 0.02158273381294964,
    "Anomaly": "Large input tensor",
    "Anomaly Description": "A large tensor refers to a tensor that has a large number of elements or values or occupies a significant amount of memory.",
    "Category": "Tensor",
    "Argument": "shape_1 = tf.constant([442, 514, 514, 515, 606, 347, 943, 61, 2], dtype=tf.int64)"
},
{
    "Title": "\n        Heap buffer overflow in `QuantizedMul`\n      ",
    "Bug description": "An attacker can cause a heap buffer overflow in  QuantizedMul  by passing in invalid thresholds for the quantization:",
    "Sample Code": "x = tf.constant([256, 328], shape=[1, 2], dtype=tf.quint8)\ny = tf.constant([256, 328], shape=[1, 2], dtype=tf.quint8)\nmin_x = tf.constant([], dtype=tf.float32)\nmax_x = tf.constant([], dtype=tf.float32)\nmin_y = tf.constant([], dtype=tf.float32)\nmax_y = tf.constant([], dtype=tf.float32)\n\n)\n\ntf.raw_ops.QuantizedMul(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y)",
    "Code change": [
        "@@ -284,10 +284,22 @@ class QuantizedMulOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& x = context->input(0);\n     const Tensor& y = context->input(1);\n-    const float min_x = context->input(2).flat<float>()(0);\n-    const float max_x = context->input(3).flat<float>()(0);\n-    const float min_y = context->input(4).flat<float>()(0);\n-    const float max_y = context->input(5).flat<float>()(0);\n+    auto& min_x_tensor = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),\n+                errors::InvalidArgument(\"min_x must be a scalar\"));\n+    const float min_x = min_x_tensor.flat<float>()(0);\n+    auto& max_x_tensor = context->input(3);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),\n+                errors::InvalidArgument(\"max_x must be a scalar\"));\n+    const float max_x = max_x_tensor.flat<float>()(0);\n+    auto& min_y_tensor = context->input(4);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),\n+                errors::InvalidArgument(\"min_y must be a scalar\"));\n+    const float min_y = min_y_tensor.flat<float>()(0);\n+    auto& max_y_tensor = context->input(5);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),\n+                errors::InvalidArgument(\"max_y must be a scalar\"));\n+    const float max_y = max_y_tensor.flat<float>()(0);\n \n     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n     if (!bcast.IsValid()) {\n"
    ],
    "Buggy Code": [
        [
            "    const Tensor& x = context->input(0);",
            "    const Tensor& y = context->input(1);",
            "    const float min_x = context->input(2).flat<float>()(0);",
            "    const float max_x = context->input(3).flat<float>()(0);",
            "    const float min_y = context->input(4).flat<float>()(0);",
            "    const float max_y = context->input(5).flat<float>()(0);",
            "",
            "    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
            "    if (!bcast.IsValid()) {",
            "      context->SetStatus(errors::InvalidArgument(",
            "          \"Incompatible shapes: \", x.shape().DebugString(), \" vs. \",",
            "          y.shape().DebugString()));",
            "      return;",
            "    }",
            "    Tensor* z;",
            "    OP_REQUIRES_OK(context, context->allocate_output(",
            "                                0, BCast::ToShape(bcast.output_shape()), &z));",
            "",
            "    // Make sure that we have valid quantization ranges for the input buffers.",
            "    // If the difference between the min and max is negative or zero, it makes",
            "    // it hard to do meaningful intermediate operations on the values.",
            "    OP_REQUIRES(context, (max_x > min_x),"
        ]
    ],
    "Clean Code": [
        [
            "    const Tensor& x = context->input(0);",
            "    const Tensor& y = context->input(1);",
            "    auto& min_x_tensor = context->input(2);",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),",
            "                errors::InvalidArgument(\"min_x must be a scalar\"));",
            "    const float min_x = min_x_tensor.flat<float>()(0);",
            "    auto& max_x_tensor = context->input(3);",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),",
            "                errors::InvalidArgument(\"max_x must be a scalar\"));",
            "    const float max_x = max_x_tensor.flat<float>()(0);",
            "    auto& min_y_tensor = context->input(4);",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),",
            "                errors::InvalidArgument(\"min_y must be a scalar\"));",
            "    const float min_y = min_y_tensor.flat<float>()(0);",
            "    auto& max_y_tensor = context->input(5);",
            "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),",
            "                errors::InvalidArgument(\"max_y must be a scalar\"));",
            "    const float max_y = max_y_tensor.flat<float>()(0);",
            "",
            "    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
            "    if (!bcast.IsValid()) {",
            "      context->SetStatus(errors::InvalidArgument("
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m3f9-w3p3-p669",
    "API Signature": "tf.raw_ops.QuantizedMul(\n    x,\n    y,\n    min_x,\n    max_x,\n    min_y,\n    max_y,\n    Toutput=tf.dtypes.qint32,\n    name=None\n)\n",
    "Score": 0.07913669064748201,
    "Anomaly": "Non scalar input tensor",
    "Anomaly Description": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Category": "Tensor",
    "Argument": "min_x = tf.constant([], dtype=tf.float32) \nmax_x = tf.constant([], dtype=tf.float32) \nmin_y = tf.constant([], dtype=tf.float32) \nmax_y = tf.constant([], dtype=tf.float32)"
},
{
    "Title": "\n        `CHECK`-fail in `DrawBoundingBoxes`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK  failure by passing an empty image to  tf.raw_ops.DrawBoundingBoxes :",
    "Sample Code": "images = tf.fill([53, 0, 48, 1], 0.)\nboxes = tf.fill([53, 31, 4], 0.)\nboxes = tf.Variable(boxes)\nboxes[0, 0, 0].assign(3.90621)\n)\ntf.raw_ops.DrawBoundingBoxes(images=images, boxes=boxes)",
    "Code change": [
        "@@ -147,22 +147,46 @@ class DrawBoundingBoxesOp : public OpKernel {\n \n         // At this point, {min,max}_box_{row,col}_clamp are inside the\n         // image.\n-        CHECK_GE(min_box_row_clamp, 0);\n-        CHECK_GE(max_box_row_clamp, 0);\n-        CHECK_LT(min_box_row_clamp, height);\n-        CHECK_LT(max_box_row_clamp, height);\n-        CHECK_GE(min_box_col_clamp, 0);\n-        CHECK_GE(max_box_col_clamp, 0);\n-        CHECK_LT(min_box_col_clamp, width);\n-        CHECK_LT(max_box_col_clamp, width);\n+        OP_REQUIRES(\n+            context, min_box_row_clamp >= 0,\n+            errors::InvalidArgument(\"Min box row clamp is less than 0.\"));\n+        OP_REQUIRES(\n+            context, max_box_row_clamp >= 0,\n+            errors::InvalidArgument(\"Max box row clamp is less than 0.\"));\n+        OP_REQUIRES(context, min_box_row_clamp <= height,\n+                    errors::InvalidArgument(\n+                        \"Min box row clamp is greater than height.\"));\n+        OP_REQUIRES(context, max_box_row_clamp <= height,\n+                    errors::InvalidArgument(\n+                        \"Max box row clamp is greater than height.\"));\n+\n+        OP_REQUIRES(\n+            context, min_box_col_clamp >= 0,\n+            errors::InvalidArgument(\"Min box col clamp is less than 0.\"));\n+        OP_REQUIRES(\n+            context, max_box_col_clamp >= 0,\n+            errors::InvalidArgument(\"Max box col clamp is less than 0.\"));\n+        OP_REQUIRES(context, min_box_col_clamp <= width,\n+                    errors::InvalidArgument(\n+                        \"Min box col clamp is greater than width.\"));\n+        OP_REQUIRES(context, max_box_col_clamp <= width,\n+                    errors::InvalidArgument(\n+                        \"Max box col clamp is greater than width.\"));\n \n         // At this point, the min_box_row and min_box_col are either\n         // in the image or above/left of it, and max_box_row and\n         // max_box_col are either in the image or below/right or it.\n-        CHECK_LT(min_box_row, height);\n-        CHECK_GE(max_box_row, 0);\n-        CHECK_LT(min_box_col, width);\n-        CHECK_GE(max_box_col, 0);\n+\n+        OP_REQUIRES(\n+            context, min_box_row <= height,\n+            errors::InvalidArgument(\"Min box row is greater than height.\"));\n+        OP_REQUIRES(context, max_box_row >= 0,\n+                    errors::InvalidArgument(\"Max box row is less than 0.\"));\n+        OP_REQUIRES(\n+            context, min_box_col <= width,\n+            errors::InvalidArgument(\"Min box col is greater than width.\"));\n+        OP_REQUIRES(context, max_box_col >= 0,\n+                    errors::InvalidArgument(\"Max box col is less than 0.\"));\n \n         // Draw top line.\n         if (min_box_row >= 0) {\n"
    ],
    "Buggy Code": [
        [
            "        // At this point, {min,max}_box_{row,col}_clamp are inside the",
            "        // image.",
            "        CHECK_GE(min_box_row_clamp, 0);",
            "        CHECK_GE(max_box_row_clamp, 0);",
            "        CHECK_LT(min_box_row_clamp, height);",
            "        CHECK_LT(max_box_row_clamp, height);",
            "        CHECK_GE(min_box_col_clamp, 0);",
            "        CHECK_GE(max_box_col_clamp, 0);",
            "        CHECK_LT(min_box_col_clamp, width);",
            "        CHECK_LT(max_box_col_clamp, width);",
            "",
            "        // At this point, the min_box_row and min_box_col are either",
            "        // in the image or above/left of it, and max_box_row and",
            "        // max_box_col are either in the image or below/right or it.",
            "        CHECK_LT(min_box_row, height);",
            "        CHECK_GE(max_box_row, 0);",
            "        CHECK_LT(min_box_col, width);",
            "        CHECK_GE(max_box_col, 0);",
            "",
            "        // Draw top line.",
            "        if (min_box_row >= 0) {",
            "          for (int64 j = min_box_col_clamp; j <= max_box_col_clamp; ++j)",
            "            for (int64 c = 0; c < depth; c++) {",
            "              canvas(b, min_box_row, j, c) =",
            "                  static_cast<T>(color_table[color_index][c]);",
            "            }",
            "        }",
            "        // Draw bottom line.",
            "        if (max_box_row < height) {",
            "          for (int64 j = min_box_col_clamp; j <= max_box_col_clamp; ++j)",
            "            for (int64 c = 0; c < depth; c++) {",
            "              canvas(b, max_box_row, j, c) =",
            "                  static_cast<T>(color_table[color_index][c]);",
            "            }",
            "        }",
            "        // Draw left line.",
            "        if (min_box_col >= 0) {",
            "          for (int64 i = min_box_row_clamp; i <= max_box_row_clamp; ++i)",
            "            for (int64 c = 0; c < depth; c++) {",
            "              canvas(b, i, min_box_col, c) =",
            "                  static_cast<T>(color_table[color_index][c]);",
            "            }",
            "        }",
            "        // Draw right line.",
            "        if (max_box_col < width) {",
            "          for (int64 i = min_box_row_clamp; i <= max_box_row_clamp; ++i)"
        ]
    ],
    "Clean Code": [
        [
            "        // At this point, {min,max}_box_{row,col}_clamp are inside the",
            "        // image.",
            "        OP_REQUIRES(",
            "            context, min_box_row_clamp >= 0,",
            "            errors::InvalidArgument(\"Min box row clamp is less than 0.\"));",
            "        OP_REQUIRES(",
            "            context, max_box_row_clamp >= 0,",
            "            errors::InvalidArgument(\"Max box row clamp is less than 0.\"));",
            "        OP_REQUIRES(context, min_box_row_clamp <= height,",
            "                    errors::InvalidArgument(",
            "                        \"Min box row clamp is greater than height.\"));",
            "        OP_REQUIRES(context, max_box_row_clamp <= height,",
            "                    errors::InvalidArgument(",
            "                        \"Max box row clamp is greater than height.\"));",
            "",
            "        OP_REQUIRES(",
            "            context, min_box_col_clamp >= 0,",
            "            errors::InvalidArgument(\"Min box col clamp is less than 0.\"));",
            "        OP_REQUIRES(",
            "            context, max_box_col_clamp >= 0,",
            "            errors::InvalidArgument(\"Max box col clamp is less than 0.\"));",
            "        OP_REQUIRES(context, min_box_col_clamp <= width,",
            "                    errors::InvalidArgument(",
            "                        \"Min box col clamp is greater than width.\"));",
            "        OP_REQUIRES(context, max_box_col_clamp <= width,",
            "                    errors::InvalidArgument(",
            "                        \"Max box col clamp is greater than width.\"));",
            "",
            "        // At this point, the min_box_row and min_box_col are either",
            "        // in the image or above/left of it, and max_box_row and",
            "        // max_box_col are either in the image or below/right or it.",
            "",
            "        OP_REQUIRES(",
            "            context, min_box_row <= height,",
            "            errors::InvalidArgument(\"Min box row is greater than height.\"));",
            "        OP_REQUIRES(context, max_box_row >= 0,",
            "                    errors::InvalidArgument(\"Max box row is less than 0.\"));",
            "        OP_REQUIRES(",
            "            context, min_box_col <= width,",
            "            errors::InvalidArgument(\"Min box col is greater than width.\"));",
            "        OP_REQUIRES(context, max_box_col >= 0,",
            "                    errors::InvalidArgument(\"Max box col is less than 0.\"));",
            "",
            "        // Draw top line.",
            "        if (min_box_row >= 0) {",
            "          for (int64 j = min_box_col_clamp; j <= max_box_col_clamp; ++j)"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-393f-2jr3-cp69",
    "API Signature": "tf.raw_ops.DrawBoundingBoxes(\n    images, boxes, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "images = tf.fill([], 0.)"
},
{
    "Title": "\n        Heap out of bounds read in `RaggedCross`\n      ",
    "Bug description": "An attacker can force accesses outside the bounds of heap allocated arrays by passing in invalid tensor values to  tf.raw_ops.RaggedCross :",
    "Sample Code": "ragged_values = []\nragged_row_splits = [] \nsparse_indices = []\nsparse_values = []\nsparse_shape = []\n\ndense_inputs_elem = tf.constant([], shape=[92, 0], dtype=tf.int64)\ndense_inputs = [dense_inputs_elem]\n\ninput_order = \"R\"\nhashed_output = False\nnum_buckets = 0\nhash_key = 0 \n\ntf.raw_ops.RaggedCross(ragged_values=ragged_values,\n    ragged_row_splits=ragged_row_splits,\n    sparse_indices=sparse_indices,\n    sparse_values=sparse_values,\n    sparse_shape=sparse_shape,\n    dense_inputs=dense_inputs,\n    input_order=input_order,\n    hashed_output=hashed_output,\n    num_buckets=num_buckets,\n    hash_key=hash_key,\n    out_values_type=tf.int64,\n    ,\n    out_row_splits_type=tf.int64)",
    "Code change": [
        "@@ -21,6 +21,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/fingerprint.h\"\n #include \"tensorflow/core/util/util.h\"\n #include \"tensorflow/core/util/work_sharder.h\"\n@@ -466,16 +467,45 @@ class RaggedCrossOp : public OpKernel {\n     int next_dense = 0;\n     for (char c : input_order_) {\n       if (c == 'R') {\n+        if (next_ragged >= ragged_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor value at index \",\n+              next_ragged, \" from a list of \", ragged_values_list.size(),\n+              \" values.\");\n+        if (next_ragged >= ragged_splits_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor split at index \",\n+              next_ragged, \" from a list of \", ragged_splits_list.size(),\n+              \" splits.\");\n         TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\n             ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\n             features));\n         next_ragged++;\n       } else if (c == 'S') {\n+        if (next_sparse >= sparse_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor value at index \",\n+              next_sparse, \" from a list of \", sparse_values_list.size(),\n+              \" values.\");\n+        if (next_sparse >= sparse_indices_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor index at index \",\n+              next_sparse, \" from a list of \", sparse_indices_list.size(),\n+              \" indices.\");\n         TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\n             sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\n             batch_size, features));\n         next_sparse++;\n       } else if (c == 'D') {\n+        if (next_dense >= dense_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a dense tensor at index \", next_dense,\n+              \" from a list of \", dense_list.size(), \" tensors.\");\n         TF_RETURN_IF_ERROR(\n             BuildDenseFeatureReader(dense_list[next_dense++], features));\n       } else {\n"
    ],
    "Buggy Code": [
        [
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/platform/fingerprint.h\"",
            "#include \"tensorflow/core/util/util.h\"",
            "#include \"tensorflow/core/util/work_sharder.h\"",
            "",
            "namespace tensorflow {"
        ],
        [
            "      if (c == 'R') {",
            "        TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(",
            "            ragged_values_list[next_ragged], ragged_splits_list[next_ragged],",
            "            features));",
            "        next_ragged++;",
            "      } else if (c == 'S') {",
            "        TF_RETURN_IF_ERROR(BuildSparseFeatureReader(",
            "            sparse_indices_list[next_sparse], sparse_values_list[next_sparse],",
            "            batch_size, features));",
            "        next_sparse++;",
            "      } else if (c == 'D') {",
            "        TF_RETURN_IF_ERROR(",
            "            BuildDenseFeatureReader(dense_list[next_dense++], features));",
            "      } else {",
            "        return errors::InvalidArgument(\"Unexpected input_order value.\");",
            "      }",
            "    }",
            "",
            "    return Status::OK();",
            "  }",
            "",
            "  // Builds a RaggedReatureReader",
            "  static Status BuildRaggedFeatureReader(const Tensor& values,",
            "                                         const Tensor& splits,",
            "                                         FeatureReaders* features) {",
            "    if (values.dtype() != DT_INT64 && values.dtype() != DT_STRING) {",
            "      return errors::InvalidArgument(\"Unexpected dtype for input \",",
            "                                     (features->size() + 1), \": \",",
            "                                     values.dtype());",
            "    }",
            "    if (splits.dtype() != DT_INT64 && splits.dtype() != DT_INT32) {",
            "      return errors::InvalidArgument(\"Unexpected row_splits.dtype for input \",",
            "                                     (features->size() + 1), \": \",",
            "                                     values.dtype());",
            "    }",
            "    if (values.dtype() == DT_INT64) {",
            "      if (splits.dtype() == DT_INT64) {",
            "        features->emplace_back(",
            "            new RaggedFeatureReader<int64, int64>(values, splits));",
            "      } else {",
            "        features->emplace_back(",
            "            new RaggedFeatureReader<int64, int32>(values, splits));",
            "      }",
            "    } else {",
            "      if (splits.dtype() == DT_INT64) {"
        ]
    ],
    "Clean Code": [
        [
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_shape.h\"",
            "#include \"tensorflow/core/platform/errors.h\"",
            "#include \"tensorflow/core/platform/fingerprint.h\"",
            "#include \"tensorflow/core/util/util.h\"",
            "#include \"tensorflow/core/util/work_sharder.h\"",
            ""
        ],
        [
            "    for (char c : input_order_) {",
            "      if (c == 'R') {",
            "        if (next_ragged >= ragged_values_list.size())",
            "          return errors::InvalidArgument(",
            "              \"input_order \\\"\", input_order_,",
            "              \"\\\" specifies reading a ragged tensor value at index \",",
            "              next_ragged, \" from a list of \", ragged_values_list.size(),",
            "              \" values.\");",
            "        if (next_ragged >= ragged_splits_list.size())",
            "          return errors::InvalidArgument(",
            "              \"input_order \\\"\", input_order_,",
            "              \"\\\" specifies reading a ragged tensor split at index \",",
            "              next_ragged, \" from a list of \", ragged_splits_list.size(),",
            "              \" splits.\");",
            "        TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(",
            "            ragged_values_list[next_ragged], ragged_splits_list[next_ragged],",
            "            features));",
            "        next_ragged++;",
            "      } else if (c == 'S') {",
            "        if (next_sparse >= sparse_values_list.size())",
            "          return errors::InvalidArgument(",
            "              \"input_order \\\"\", input_order_,",
            "              \"\\\" specifies reading a sparse tensor value at index \",",
            "              next_sparse, \" from a list of \", sparse_values_list.size(),",
            "              \" values.\");",
            "        if (next_sparse >= sparse_indices_list.size())",
            "          return errors::InvalidArgument(",
            "              \"input_order \\\"\", input_order_,",
            "              \"\\\" specifies reading a sparse tensor index at index \",",
            "              next_sparse, \" from a list of \", sparse_indices_list.size(),",
            "              \" indices.\");",
            "        TF_RETURN_IF_ERROR(BuildSparseFeatureReader(",
            "            sparse_indices_list[next_sparse], sparse_values_list[next_sparse],",
            "            batch_size, features));",
            "        next_sparse++;",
            "      } else if (c == 'D') {",
            "        if (next_dense >= dense_list.size())",
            "          return errors::InvalidArgument(",
            "              \"input_order \\\"\", input_order_,",
            "              \"\\\" specifies reading a dense tensor at index \", next_dense,",
            "              \" from a list of \", dense_list.size(), \" tensors.\");",
            "        TF_RETURN_IF_ERROR(",
            "            BuildDenseFeatureReader(dense_list[next_dense++], features));",
            "      } else {",
            "        return errors::InvalidArgument(\"Unexpected input_order value.\");"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-j47f-4232-hvv8",
    "API Signature": "tf.raw_ops.RaggedCross(\n    ragged_values,\n    ragged_row_splits,\n    sparse_indices,\n    sparse_values,\n    sparse_shape,\n    dense_inputs,\n    input_order,\n    hashed_output,\n    num_buckets,\n    hash_key,\n    out_values_type,\n    out_row_splits_type,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "ragged_values = [] \nragged_row_splits = [] \nsparse_indices = [] \nsparse_values = [] \nsparse_shape = [] \n\ndense_inputs_elem = tf.constant([], shape=[92, 0], dtype=tf.int64)"
},
{
    "Title": "\n        `CHECK`-fail in `tf.raw_ops.EncodePng`\n      ",
    "Bug description": "An attacker can trigger a  CHECK  fail in PNG encoding by providing an empty input tensor as the pixel data:",
    "Sample Code": "image = tf.zeros([0, 0, 3])\nimage = tf.cast(image, dtype=tf.uint8) \n) \ntf.raw_ops.EncodePng(image=image) ",
    "Code change": [
        "@@ -54,6 +54,8 @@ class EncodePngOp : public OpKernel {\n     OP_REQUIRES(context, image.dims() == 3,\n                 errors::InvalidArgument(\"image must be 3-dimensional\",\n                                         image.shape().DebugString()));\n+    OP_REQUIRES(context, image.NumElements() > 0,\n+                errors::Internal(\"Invalid image provided.\"));\n     OP_REQUIRES(\n         context,\n         FastBoundsCheck(image.NumElements(), std::numeric_limits<int32>::max()),\n"
    ],
    "Buggy Code": [
        [
            "                errors::InvalidArgument(\"image must be 3-dimensional\",",
            "                                        image.shape().DebugString()));",
            "    OP_REQUIRES(",
            "        context,",
            "        FastBoundsCheck(image.NumElements(), std::numeric_limits<int32>::max()),",
            "        errors::InvalidArgument(\"image cannot have >= int32 max elements\"));",
            "    const int32 height = static_cast<int32>(image.dim_size(0));",
            "    const int32 width = static_cast<int32>(image.dim_size(1));"
        ]
    ],
    "Clean Code": [
        [
            "                errors::InvalidArgument(\"image must be 3-dimensional\",",
            "                                        image.shape().DebugString()));",
            "    OP_REQUIRES(context, image.NumElements() > 0,",
            "                errors::Internal(\"Invalid image provided.\"));",
            "    OP_REQUIRES(",
            "        context,",
            "        FastBoundsCheck(image.NumElements(), std::numeric_limits<int32>::max()),",
            "        errors::InvalidArgument(\"image cannot have >= int32 max elements\"));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-3qxp-qjq7-w4hf",
    "API Signature": "tf.raw_ops.EncodePng(\n    image, compression=-1, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "image = tf.zeros([0, 0, 3])"
},
{
    "Title": "\n        Invalid validation in `SparseMatrixSparseCholesky`\n      ",
    "Bug description": "An attacker can trigger a null pointer dereference by providing an invalid  permutation  to  tf.raw_ops.SparseMatrixSparseCholesky :",
    "Sample Code": "import numpy as np\nfrom tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops\n\nindices_array = np.array([[0, 0]])\nvalue_array = np.array([-10.0], dtype=np.float32)\ndense_shape = [1, 1]\nst = tf.SparseTensor(indices_array, value_array, dense_shape)\n\ninput = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n       st.indices, st.values, st.dense_shape)\n\npermutation = tf.constant([], shape=[1, 0], dtype=tf.int32)\n \n)\n \ntf.raw_ops.SparseMatrixSparseCholesky(input=input, permutation=permutation, type=tf.float32)",
    "Code change": [
        "@@ -17,6 +17,8 @@ limitations under the License.\n #include <numeric>\n #include <vector>\n \n+#include \"tensorflow/core/framework/op_requires.h\"\n+\n #define EIGEN_USE_THREADS\n \n #include \"third_party/eigen3/Eigen/Core\"\n@@ -82,8 +84,8 @@ class CSRSparseCholeskyCPUOp : public OpKernel {\n \n     int64 num_rows;\n     int batch_size;\n-    ValidateInputs(ctx, *input_matrix, input_permutation_indices, &batch_size,\n-                   &num_rows);\n+    OP_REQUIRES_OK(ctx, ValidateInputs(*input_matrix, input_permutation_indices,\n+                                       &batch_size, &num_rows));\n \n     // Allocate batch pointers.\n     Tensor batch_ptr(cpu_allocator(), DT_INT32, TensorShape({batch_size + 1}));\n@@ -226,49 +228,48 @@ class CSRSparseCholeskyCPUOp : public OpKernel {\n   }\n \n  private:\n-  void ValidateInputs(OpKernelContext* ctx,\n-                      const CSRSparseMatrix& sparse_matrix,\n-                      const Tensor& permutation_indices, int* batch_size,\n-                      int64* num_rows) {\n-    OP_REQUIRES(ctx, sparse_matrix.dtype() == DataTypeToEnum<T>::value,\n-                errors::InvalidArgument(\n-                    \"Asked for a CSRSparseMatrix of type \",\n-                    DataTypeString(DataTypeToEnum<T>::value),\n-                    \" but saw dtype: \", DataTypeString(sparse_matrix.dtype())));\n+  Status ValidateInputs(const CSRSparseMatrix& sparse_matrix,\n+                        const Tensor& permutation_indices, int* batch_size,\n+                        int64* num_rows) {\n+    if (sparse_matrix.dtype() != DataTypeToEnum<T>::value)\n+      return errors::InvalidArgument(\n+          \"Asked for a CSRSparseMatrix of type \",\n+          DataTypeString(DataTypeToEnum<T>::value),\n+          \" but saw dtype: \", DataTypeString(sparse_matrix.dtype()));\n \n     const Tensor& dense_shape = sparse_matrix.dense_shape();\n     const int rank = dense_shape.dim_size(0);\n-    OP_REQUIRES(ctx, rank == 2 || rank == 3,\n-                errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\n-                                        \"but dense_shape has size \", rank));\n+    if (rank < 2 || rank > 3)\n+      return errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\n+                                     \"but dense_shape has size \", rank);\n     const int row_dim = (rank == 2) ? 0 : 1;\n     auto dense_shape_vec = dense_shape.vec<int64>();\n     *num_rows = dense_shape_vec(row_dim);\n     const int64 num_cols = dense_shape_vec(row_dim + 1);\n-    OP_REQUIRES(ctx, *num_rows == num_cols,\n-                errors::InvalidArgument(\"sparse matrix must be square; got: \",\n-                                        *num_rows, \" != \", num_cols));\n+    if (*num_rows != num_cols)\n+      return errors::InvalidArgument(\n+          \"sparse matrix must be square; got: \", *num_rows, \" != \", num_cols);\n     const TensorShape& perm_shape = permutation_indices.shape();\n-    OP_REQUIRES(\n-        ctx, perm_shape.dims() + 1 == rank,\n-        errors::InvalidArgument(\n-            \"sparse matrix must have the same rank as permutation; got: \", rank,\n-            \" != \", perm_shape.dims(), \" + 1.\"));\n-    OP_REQUIRES(\n-        ctx, perm_shape.dim_size(rank - 2) == *num_rows,\n-        errors::InvalidArgument(\n-            \"permutation must have the same number of elements in each batch \"\n-            \"as the number of rows in sparse matrix; got: \",\n-            perm_shape.dim_size(rank - 2), \" != \", *num_rows));\n+    if (perm_shape.dims() + 1 != rank)\n+      return errors::InvalidArgument(\n+          \"sparse matrix must have the same rank as permutation; got: \", rank,\n+          \" != \", perm_shape.dims(), \" + 1.\");\n+    if (perm_shape.dim_size(rank - 2) != *num_rows)\n+      return errors::InvalidArgument(\n+          \"permutation must have the same number of elements in each batch \"\n+          \"as the number of rows in sparse matrix; got: \",\n+          perm_shape.dim_size(rank - 2), \" != \", *num_rows);\n \n     *batch_size = sparse_matrix.batch_size();\n     if (*batch_size > 1) {\n-      OP_REQUIRES(\n-          ctx, perm_shape.dim_size(0) == *batch_size,\n-          errors::InvalidArgument(\"permutation must have the same batch size \"\n-                                  \"as sparse matrix; got: \",\n-                                  perm_shape.dim_size(0), \" != \", *batch_size));\n+      if (perm_shape.dim_size(0) != *batch_size)\n+        return errors::InvalidArgument(\n+            \"permutation must have the same batch size \"\n+            \"as sparse matrix; got: \",\n+            perm_shape.dim_size(0), \" != \", *batch_size);\n     }\n+\n+    return Status::OK();\n   }\n };\n \n"
    ],
    "Buggy Code": [
        [
            "#include <vector>",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#include \"third_party/eigen3/Eigen/Core\"",
            "#include \"third_party/eigen3/Eigen/SparseCholesky\"",
            "#include \"third_party/eigen3/Eigen/SparseCore\"",
            "#include \"third_party/eigen3/Eigen/OrderingMethods\""
        ],
        [
            "    ValidateInputs(ctx, *input_matrix, input_permutation_indices, &batch_size,",
            "                   &num_rows);",
            "",
            "    // Allocate batch pointers.",
            "    Tensor batch_ptr(cpu_allocator(), DT_INT32, TensorShape({batch_size + 1}));",
            "    auto batch_ptr_vec = batch_ptr.vec<int32>();",
            "    batch_ptr_vec(0) = 0;",
            ""
        ],
        [
            "  void ValidateInputs(OpKernelContext* ctx,",
            "                      const CSRSparseMatrix& sparse_matrix,",
            "                      const Tensor& permutation_indices, int* batch_size,",
            "                      int64* num_rows) {",
            "    OP_REQUIRES(ctx, sparse_matrix.dtype() == DataTypeToEnum<T>::value,",
            "                errors::InvalidArgument(",
            "                    \"Asked for a CSRSparseMatrix of type \",",
            "                    DataTypeString(DataTypeToEnum<T>::value),",
            "                    \" but saw dtype: \", DataTypeString(sparse_matrix.dtype())));",
            "",
            "    const Tensor& dense_shape = sparse_matrix.dense_shape();",
            "    const int rank = dense_shape.dim_size(0);",
            "    OP_REQUIRES(ctx, rank == 2 || rank == 3,",
            "                errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",",
            "                                        \"but dense_shape has size \", rank));",
            "    const int row_dim = (rank == 2) ? 0 : 1;",
            "    auto dense_shape_vec = dense_shape.vec<int64>();",
            "    *num_rows = dense_shape_vec(row_dim);",
            "    const int64 num_cols = dense_shape_vec(row_dim + 1);",
            "    OP_REQUIRES(ctx, *num_rows == num_cols,",
            "                errors::InvalidArgument(\"sparse matrix must be square; got: \",",
            "                                        *num_rows, \" != \", num_cols));",
            "    const TensorShape& perm_shape = permutation_indices.shape();",
            "    OP_REQUIRES(",
            "        ctx, perm_shape.dims() + 1 == rank,",
            "        errors::InvalidArgument(",
            "            \"sparse matrix must have the same rank as permutation; got: \", rank,",
            "            \" != \", perm_shape.dims(), \" + 1.\"));",
            "    OP_REQUIRES(",
            "        ctx, perm_shape.dim_size(rank - 2) == *num_rows,",
            "        errors::InvalidArgument(",
            "            \"permutation must have the same number of elements in each batch \"",
            "            \"as the number of rows in sparse matrix; got: \",",
            "            perm_shape.dim_size(rank - 2), \" != \", *num_rows));",
            "",
            "    *batch_size = sparse_matrix.batch_size();",
            "    if (*batch_size > 1) {",
            "      OP_REQUIRES(",
            "          ctx, perm_shape.dim_size(0) == *batch_size,",
            "          errors::InvalidArgument(\"permutation must have the same batch size \"",
            "                                  \"as sparse matrix; got: \",",
            "                                  perm_shape.dim_size(0), \" != \", *batch_size));",
            "    }",
            "  }",
            "};",
            "",
            "#define REGISTER_CPU(T)                                      \\",
            "  REGISTER_KERNEL_BUILDER(Name(\"SparseMatrixSparseCholesky\") \\"
        ]
    ],
    "Clean Code": [
        [
            "#include <vector>",
            "",
            "#include \"tensorflow/core/framework/op_requires.h\"",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#include \"third_party/eigen3/Eigen/Core\"",
            "#include \"third_party/eigen3/Eigen/SparseCholesky\""
        ],
        [
            "    int64 num_rows;",
            "    int batch_size;",
            "    OP_REQUIRES_OK(ctx, ValidateInputs(*input_matrix, input_permutation_indices,",
            "                                       &batch_size, &num_rows));",
            "",
            "    // Allocate batch pointers.",
            "    Tensor batch_ptr(cpu_allocator(), DT_INT32, TensorShape({batch_size + 1}));",
            "    auto batch_ptr_vec = batch_ptr.vec<int32>();"
        ],
        [
            "",
            " private:",
            "  Status ValidateInputs(const CSRSparseMatrix& sparse_matrix,",
            "                        const Tensor& permutation_indices, int* batch_size,",
            "                        int64* num_rows) {",
            "    if (sparse_matrix.dtype() != DataTypeToEnum<T>::value)",
            "      return errors::InvalidArgument(",
            "          \"Asked for a CSRSparseMatrix of type \",",
            "          DataTypeString(DataTypeToEnum<T>::value),",
            "          \" but saw dtype: \", DataTypeString(sparse_matrix.dtype()));",
            "",
            "    const Tensor& dense_shape = sparse_matrix.dense_shape();",
            "    const int rank = dense_shape.dim_size(0);",
            "    if (rank < 2 || rank > 3)",
            "      return errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",",
            "                                     \"but dense_shape has size \", rank);",
            "    const int row_dim = (rank == 2) ? 0 : 1;",
            "    auto dense_shape_vec = dense_shape.vec<int64>();",
            "    *num_rows = dense_shape_vec(row_dim);",
            "    const int64 num_cols = dense_shape_vec(row_dim + 1);",
            "    if (*num_rows != num_cols)",
            "      return errors::InvalidArgument(",
            "          \"sparse matrix must be square; got: \", *num_rows, \" != \", num_cols);",
            "    const TensorShape& perm_shape = permutation_indices.shape();",
            "    if (perm_shape.dims() + 1 != rank)",
            "      return errors::InvalidArgument(",
            "          \"sparse matrix must have the same rank as permutation; got: \", rank,",
            "          \" != \", perm_shape.dims(), \" + 1.\");",
            "    if (perm_shape.dim_size(rank - 2) != *num_rows)",
            "      return errors::InvalidArgument(",
            "          \"permutation must have the same number of elements in each batch \"",
            "          \"as the number of rows in sparse matrix; got: \",",
            "          perm_shape.dim_size(rank - 2), \" != \", *num_rows);",
            "",
            "    *batch_size = sparse_matrix.batch_size();",
            "    if (*batch_size > 1) {",
            "      if (perm_shape.dim_size(0) != *batch_size)",
            "        return errors::InvalidArgument(",
            "            \"permutation must have the same batch size \"",
            "            \"as sparse matrix; got: \",",
            "            perm_shape.dim_size(0), \" != \", *batch_size);",
            "    }",
            "",
            "    return Status::OK();",
            "  }",
            "};",
            "",
            "#define REGISTER_CPU(T)                                      \\"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xcwj-wfcm-m23c",
    "API Signature": "tf.raw_ops.SparseMatrixSparseCholesky(\n    input, permutation, type, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "permutation = tf.constant([], shape=[1, 0], dtype=tf.int32)"
},
{
    "Title": "\n        Division by 0 in `QuantizedMul`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.QuantizedMul :",
    "Sample Code": "x = tf.zeros([4, 1], dtype=tf.quint8)\ny = tf.constant([], dtype=tf.quint8)\nmin_x = tf.constant(0.0)\nmax_x = tf.constant(0.0010000000474974513)\nmin_y = tf.constant(0.0)\nmax_y = tf.constant(0.0010000000474974513)\n\n)\n\ntf.raw_ops.QuantizedMul(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y)",
    "Code change": [
        "@@ -347,6 +347,11 @@ class QuantizedMulOp : public OpKernel {\n         tensor_num_elements = x.NumElements();\n         tensor_offset = offset_x;\n       }\n+      if (vector_num_elements == 0) {\n+        context->SetStatus(\n+            errors::InvalidArgument(\"vector must have at least 1 element\"));\n+        return;\n+      }\n       VectorTensorMultiply<T, Toutput>(\n           vector_data, vector_offset, vector_num_elements, tensor_data,\n           tensor_offset, tensor_num_elements, z_data);\n"
    ],
    "Buggy Code": [
        [
            "        tensor_offset = offset_x;",
            "      }",
            "      VectorTensorMultiply<T, Toutput>(",
            "          vector_data, vector_offset, vector_num_elements, tensor_data,",
            "          tensor_offset, tensor_num_elements, z_data);",
            "    } else {",
            "      LOG(INFO) << \"ndims=\" << ndims;",
            "      LOG(INFO) << \"bcast.x_reshape()=\"",
            "                << TensorShape(bcast.x_reshape()).DebugString();",
            "      LOG(INFO) << \"bcast.y_reshape()=\"",
            "                << TensorShape(bcast.y_reshape()).DebugString();"
        ]
    ],
    "Clean Code": [
        [
            "        tensor_offset = offset_x;",
            "      }",
            "      if (vector_num_elements == 0) {",
            "        context->SetStatus(",
            "            errors::InvalidArgument(\"vector must have at least 1 element\"));",
            "        return;",
            "      }",
            "      VectorTensorMultiply<T, Toutput>(",
            "          vector_data, vector_offset, vector_num_elements, tensor_data,",
            "          tensor_offset, tensor_num_elements, z_data);",
            "    } else {"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6f84-42vf-ppwp",
    "API Signature": "tf.raw_ops.QuantizedMul(\n    x,\n    y,\n    min_x,\n    max_x,\n    min_y,\n    max_y,\n    Toutput=tf.dtypes.qint32,\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "y = tf.constant([], dtype=tf.quint8)"
},
{
    "Title": "\n        Division by 0 in `QuantizedConv2D`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.QuantizedConv2D :",
    "Sample Code": "input = tf.zeros([1, 1, 1, 1], dtype=tf.quint8)\nfilter = tf.constant([], shape=[1, 0, 1, 1], dtype=tf.quint8)\nmin_input = tf.constant(0.0)\nmax_input = tf.constant(0.0001)\nmin_filter = tf.constant(0.0)\nmax_filter = tf.constant(0.0001)\nstrides = [1, 1, 1, 1]\npadding = \"SAME\"               \n                               \n\n               \n                               \n\ntf.raw_ops.QuantizedConv2D(input=input, filter=filter, min_input=min_input, max_input=max_input, min_filter=min_filter, max_filter=max_filter, strides=strides, padding=padding)",
    "Code change": [
        "@@ -18,6 +18,8 @@ limitations under the License.\n #include <algorithm>\n #include <vector>\n \n+#include \"tensorflow/core/platform/errors.h\"\n+\n #define EIGEN_USE_THREADS\n \n #define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\n@@ -227,8 +229,12 @@ class Im2ColConvFunctor {\n       return;\n     }\n \n-    CHECK_GT(output_width, 0);\n-    CHECK_GT(output_height, 0);\n+    OP_REQUIRES(\n+        context, output_width > 0,\n+        errors::InvalidArgument(\"output_width must be strictly positive\"));\n+    OP_REQUIRES(\n+        context, output_height > 0,\n+        errors::InvalidArgument(\"output_height must be strictly positive\"));\n     int filter_left_offset;\n     int filter_top_offset;\n     if (padding == VALID) {\n@@ -255,6 +261,9 @@ class Im2ColConvFunctor {\n     // by the width, then the height. This is the standard memory order in the\n     // image world if it helps to visualize it.\n     const int filter_value_count = filter_width * filter_height * input_depth;\n+    OP_REQUIRES(context, filter_value_count > 0,\n+                errors::InvalidArgument(\n+                    \"filter patch must contain at least one element\"));\n     const int64 patches_per_chunk =\n         kMaxChunkSize / (filter_value_count * sizeof(T1));\n     const int64 chunk_value_count =\n"
    ],
    "Buggy Code": [
        [
            "#include <vector>",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK",
            "#include \"public/gemmlowp.h\"",
            "#include \"tensorflow/core/framework/kernel_shape_util.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\""
        ],
        [
            "    CHECK_GT(output_width, 0);",
            "    CHECK_GT(output_height, 0);",
            "    int filter_left_offset;",
            "    int filter_top_offset;",
            "    if (padding == VALID) {",
            "      filter_left_offset =",
            "          ((output_width - 1) * stride + filter_width - input_width + 1) / 2;",
            "      filter_top_offset =",
            "          ((output_height - 1) * stride + filter_height - input_height + 1) / 2;",
            "    } else {",
            "      filter_left_offset =",
            "          ((output_width - 1) * stride + filter_width - input_width) / 2;"
        ],
        [
            "    // TODO(petewarden) - Memory allocation can be very slow on Android. Can we",
            "    // optimize this by keeping the scratch buffer around?",
            "    // Because memory allocation is very expensive on mobile platforms, try to",
            "    // allocate a persistent buffer that will be kept around between calls. We",
            "    // use TensorFlow's resource management to ensure that the memory will be",
            "    // released when the session is over.",
            "    Im2ColBufferResource<T1, chunk_value_count>* im2col_buffer_resource;",
            "    std::function<Status(Im2ColBufferResource<T1, chunk_value_count>**)>",
            "        creator = [](Im2ColBufferResource<T1, chunk_value_count>** resource) {"
        ]
    ],
    "Clean Code": [
        [
            "#include <vector>",
            "",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK",
            "#include \"public/gemmlowp.h\""
        ],
        [
            "    }",
            "",
            "    OP_REQUIRES(",
            "        context, output_width > 0,",
            "        errors::InvalidArgument(\"output_width must be strictly positive\"));",
            "    OP_REQUIRES(",
            "        context, output_height > 0,",
            "        errors::InvalidArgument(\"output_height must be strictly positive\"));",
            "    int filter_left_offset;",
            "    int filter_top_offset;",
            "    if (padding == VALID) {",
            "      filter_left_offset ="
        ],
        [
            "    // image world if it helps to visualize it.",
            "    const int filter_value_count = filter_width * filter_height * input_depth;",
            "    OP_REQUIRES(context, filter_value_count > 0,",
            "                errors::InvalidArgument(",
            "                    \"filter patch must contain at least one element\"));",
            "    const int64 patches_per_chunk =",
            "        kMaxChunkSize / (filter_value_count * sizeof(T1));",
            "    const int64 chunk_value_count =",
            "        (kMaxChunkSize + (sizeof(T1) - 1)) / sizeof(T1);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x4g7-fvjj-prg8",
    "API Signature": "tf.raw_ops.QuantizedConv2D(\n    input,\n    filter,\n    min_input,\n    max_input,\n    min_filter,\n    max_filter,\n    strides,\n    padding,\n    out_type=tf.dtypes.qint32,\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "min_input = tf.constant(0.0) \nmin_filter = tf.constant(0.0)"
},
{
    "Title": "\n        Division by 0 in `QuantizedConv2D`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.QuantizedConv2D :",
    "Sample Code": "input = tf.zeros([1, 1, 1, 1], dtype=tf.quint8)\nfilter = tf.constant([], shape=[1, 0, 1, 1], dtype=tf.quint8)\nmin_input = tf.constant(0.0)\nmax_input = tf.constant(0.0001)\nmin_filter = tf.constant(0.0)\nmax_filter = tf.constant(0.0001)\nstrides = [1, 1, 1, 1]\npadding = \"SAME\"               \n                               \n\n               \n                               \n\ntf.raw_ops.QuantizedConv2D(input=input, filter=filter, min_input=min_input, max_input=max_input, min_filter=min_filter, max_filter=max_filter, strides=strides, padding=padding)",
    "Code change": [
        "@@ -18,6 +18,8 @@ limitations under the License.\n #include <algorithm>\n #include <vector>\n \n+#include \"tensorflow/core/platform/errors.h\"\n+\n #define EIGEN_USE_THREADS\n \n #define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\n@@ -227,8 +229,12 @@ class Im2ColConvFunctor {\n       return;\n     }\n \n-    CHECK_GT(output_width, 0);\n-    CHECK_GT(output_height, 0);\n+    OP_REQUIRES(\n+        context, output_width > 0,\n+        errors::InvalidArgument(\"output_width must be strictly positive\"));\n+    OP_REQUIRES(\n+        context, output_height > 0,\n+        errors::InvalidArgument(\"output_height must be strictly positive\"));\n     int filter_left_offset;\n     int filter_top_offset;\n     if (padding == VALID) {\n@@ -255,6 +261,9 @@ class Im2ColConvFunctor {\n     // by the width, then the height. This is the standard memory order in the\n     // image world if it helps to visualize it.\n     const int filter_value_count = filter_width * filter_height * input_depth;\n+    OP_REQUIRES(context, filter_value_count > 0,\n+                errors::InvalidArgument(\n+                    \"filter patch must contain at least one element\"));\n     const int64 patches_per_chunk =\n         kMaxChunkSize / (filter_value_count * sizeof(T1));\n     const int64 chunk_value_count =\n"
    ],
    "Buggy Code": [
        [
            "#include <vector>",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK",
            "#include \"public/gemmlowp.h\"",
            "#include \"tensorflow/core/framework/kernel_shape_util.h\"",
            "#include \"tensorflow/core/framework/op_kernel.h\""
        ],
        [
            "    CHECK_GT(output_width, 0);",
            "    CHECK_GT(output_height, 0);",
            "    int filter_left_offset;",
            "    int filter_top_offset;",
            "    if (padding == VALID) {",
            "      filter_left_offset =",
            "          ((output_width - 1) * stride + filter_width - input_width + 1) / 2;",
            "      filter_top_offset =",
            "          ((output_height - 1) * stride + filter_height - input_height + 1) / 2;",
            "    } else {",
            "      filter_left_offset =",
            "          ((output_width - 1) * stride + filter_width - input_width) / 2;"
        ],
        [
            "    // TODO(petewarden) - Memory allocation can be very slow on Android. Can we",
            "    // optimize this by keeping the scratch buffer around?",
            "    // Because memory allocation is very expensive on mobile platforms, try to",
            "    // allocate a persistent buffer that will be kept around between calls. We",
            "    // use TensorFlow's resource management to ensure that the memory will be",
            "    // released when the session is over.",
            "    Im2ColBufferResource<T1, chunk_value_count>* im2col_buffer_resource;",
            "    std::function<Status(Im2ColBufferResource<T1, chunk_value_count>**)>",
            "        creator = [](Im2ColBufferResource<T1, chunk_value_count>** resource) {"
        ]
    ],
    "Clean Code": [
        [
            "#include <vector>",
            "",
            "#include \"tensorflow/core/platform/errors.h\"",
            "",
            "#define EIGEN_USE_THREADS",
            "",
            "#define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK",
            "#include \"public/gemmlowp.h\""
        ],
        [
            "    }",
            "",
            "    OP_REQUIRES(",
            "        context, output_width > 0,",
            "        errors::InvalidArgument(\"output_width must be strictly positive\"));",
            "    OP_REQUIRES(",
            "        context, output_height > 0,",
            "        errors::InvalidArgument(\"output_height must be strictly positive\"));",
            "    int filter_left_offset;",
            "    int filter_top_offset;",
            "    if (padding == VALID) {",
            "      filter_left_offset ="
        ],
        [
            "    // image world if it helps to visualize it.",
            "    const int filter_value_count = filter_width * filter_height * input_depth;",
            "    OP_REQUIRES(context, filter_value_count > 0,",
            "                errors::InvalidArgument(",
            "                    \"filter patch must contain at least one element\"));",
            "    const int64 patches_per_chunk =",
            "        kMaxChunkSize / (filter_value_count * sizeof(T1));",
            "    const int64 chunk_value_count =",
            "        (kMaxChunkSize + (sizeof(T1) - 1)) / sizeof(T1);"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-x4g7-fvjj-prg8",
    "API Signature": "tf.raw_ops.QuantizedConv2D(\n    input,\n    filter,\n    min_input,\n    max_input,\n    min_filter,\n    max_filter,\n    strides,\n    padding,\n    out_type=tf.dtypes.qint32,\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "filter = tf.constant([], shape=[1, 0, 1, 1], dtype=tf.quint8)"
},
{
    "Title": "\n        Division by 0 in `Conv2D`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.Conv2D :",
    "Sample Code": "input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\nfilter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\n\nstrides = [1, 1, 1, 1]\npadding = \"SAME\"\n                               \n\n                               \ntf.raw_ops.Conv2D(input=input, filter=filter, strides=strides, padding=padding)",
    "Code change": [
        "@@ -260,6 +260,11 @@ struct LaunchConv2DOp<CPUDevice, T> {\n     const int64 out_depth = output->dim_size(3);\n     const int64 patch_depth = filter.dim_size(2);\n \n+    if (patch_depth <= 0) {\n+      ctx->SetStatus(errors::InvalidArgument(\n+          \"filter depth must be stricly positive, got \", patch_depth));\n+      return;\n+    }\n     if (in_depth % patch_depth != 0) {\n       ctx->SetStatus(errors::InvalidArgument(\n           \"input depth must be evenly divisible by filter depth: \", in_depth,\n@@ -268,6 +273,11 @@ struct LaunchConv2DOp<CPUDevice, T> {\n     }\n \n     const int64 num_groups = in_depth / patch_depth;\n+    if (num_groups <= 0) {\n+      ctx->SetStatus(errors::InvalidArgument(\n+          \"number of groups must be stricly positive, got \", num_groups));\n+      return;\n+    }\n     if (out_depth % num_groups != 0 || out_depth < num_groups) {\n       ctx->SetStatus(errors::InvalidArgument(\n           \"output depth must be evenly divisible by number of groups: \",\n@@ -536,6 +546,9 @@ Status ComputeConv2DDimension(const Conv2DParameters& params,\n               errors::InvalidArgument(\"Patch depth too large\"));\n   const int in_depth = static_cast<int>(in_depth_raw);\n   const int patch_depth = static_cast<int>(patch_depth_raw);\n+  TF_REQUIRES(patch_depth > 0,\n+              errors::InvalidArgument(\n+                  \"filter depth must be stricly positive, got \", patch_depth));\n   TF_REQUIRES(in_depth % patch_depth == 0,\n               errors::InvalidArgument(\n                   \"input depth must be evenly divisible by filter depth: \",\n"
    ],
    "Buggy Code": [
        [
            "    const int64 patch_depth = filter.dim_size(2);",
            "",
            "    if (in_depth % patch_depth != 0) {",
            "      ctx->SetStatus(errors::InvalidArgument(",
            "          \"input depth must be evenly divisible by filter depth: \", in_depth,",
            "          \" vs \", patch_depth));",
            "      return;",
            "    }",
            "",
            "    const int64 num_groups = in_depth / patch_depth;",
            "    if (out_depth % num_groups != 0 || out_depth < num_groups) {"
        ],
        [
            "          out_depth, \" vs \", num_groups));",
            "      return;",
            "    }",
            "",
            "    if (in_depth != patch_depth) {",
            "      LaunchGrouped<T>()(ctx, input, filter, row_stride, col_stride,",
            "                         row_dilation, col_dilation, padding, explicit_paddings,",
            "                         output, data_format);",
            "    } else {",
            "      LaunchGeneric<CPUDevice, T>()(ctx, input, filter, row_stride, col_stride,",
            "                                    row_dilation, col_dilation, padding,"
        ],
        [
            "  // The second dimension for input is rows/height.",
            "  // The first dimension for filter is rows/height.",
            "  const int64 input_rows_raw = GetTensorDim(input, params.data_format, 'H');",
            "  TF_REQUIRES(FastBoundsCheck(input_rows_raw, std::numeric_limits<int>::max()),",
            "              errors::InvalidArgument(\"Input rows too large\"));",
            "  const int input_rows = static_cast<int>(input_rows_raw);",
            "  const int filter_rows = static_cast<int>(filter.dim_size(0));",
            "",
            "  // The third dimension for input is columns/width."
        ]
    ],
    "Clean Code": [
        [
            "    const int64 patch_depth = filter.dim_size(2);",
            "",
            "    if (patch_depth <= 0) {",
            "      ctx->SetStatus(errors::InvalidArgument(",
            "          \"filter depth must be stricly positive, got \", patch_depth));",
            "      return;",
            "    }",
            "    if (in_depth % patch_depth != 0) {",
            "      ctx->SetStatus(errors::InvalidArgument(",
            "          \"input depth must be evenly divisible by filter depth: \", in_depth,",
            "          \" vs \", patch_depth));"
        ],
        [
            "",
            "    const int64 num_groups = in_depth / patch_depth;",
            "    if (num_groups <= 0) {",
            "      ctx->SetStatus(errors::InvalidArgument(",
            "          \"number of groups must be stricly positive, got \", num_groups));",
            "      return;",
            "    }",
            "    if (out_depth % num_groups != 0 || out_depth < num_groups) {",
            "      ctx->SetStatus(errors::InvalidArgument(",
            "          \"output depth must be evenly divisible by number of groups: \",",
            "          out_depth, \" vs \", num_groups));"
        ],
        [
            "  const int in_depth = static_cast<int>(in_depth_raw);",
            "  const int patch_depth = static_cast<int>(patch_depth_raw);",
            "  TF_REQUIRES(patch_depth > 0,",
            "              errors::InvalidArgument(",
            "                  \"filter depth must be stricly positive, got \", patch_depth));",
            "  TF_REQUIRES(in_depth % patch_depth == 0,",
            "              errors::InvalidArgument(",
            "                  \"input depth must be evenly divisible by filter depth: \",",
            "                  in_depth, \" vs \", patch_depth));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4vf2-4xcg-65cx",
    "API Signature": "tf.raw_ops.Conv2D(\n    input,\n    filter,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32) \nfilter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)"
},
{
    "Title": "\n        Division by 0 in `Conv2DBackpropInput`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.Conv2DBackpropInput :",
    "Sample Code": "input_tensor = tf.constant([52, 1, 1, 5], shape=[4], dtype=tf.int32)\nfilter_tensor = tf.constant([], shape=[0, 1, 5, 0], dtype=tf.float32)\nout_backprop = tf.constant([], shape=[52, 1, 1, 0], dtype=tf.float32)\n\ntf.raw_ops.Conv2DBackpropInput(input_sizes=input_tensor, filter=filter_tensor,\n                               out_backprop=out_backprop, strides=[1, 1, 1, 1],\n                               use_cudnn_on_gpu=True, padding='SAME',\n                               explicit_paddings=[], data_format='NHWC',\n                               ,\n                               dilations=[1, 1, 1, 1])",
    "Code change": [
        "@@ -649,6 +649,11 @@ class Conv2DCustomBackpropInputOp : public OpKernel {\n         dims.batch_size == 1 ||\n         thread_work_unit_size >= min_thread_work_unit_size;\n \n+    OP_REQUIRES(\n+        context, work_unit_size > 0,\n+        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n+                                \"must all have at least 1 element\"));\n+\n     const size_t shard_size =\n         use_parallel_contraction\n             ? 1\n"
    ],
    "Buggy Code": [
        [
            "        thread_work_unit_size >= min_thread_work_unit_size;",
            "",
            "    const size_t shard_size =",
            "        use_parallel_contraction",
            "            ? 1",
            "            : (target_working_set_size + work_unit_size - 1) / work_unit_size;",
            "",
            "    Tensor col_buffer;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_temp(",
            "                       DataTypeToEnum<T>::value,"
        ]
    ],
    "Clean Code": [
        [
            "        thread_work_unit_size >= min_thread_work_unit_size;",
            "",
            "    OP_REQUIRES(",
            "        context, work_unit_size > 0,",
            "        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"",
            "                                \"must all have at least 1 element\"));",
            "",
            "    const size_t shard_size =",
            "        use_parallel_contraction",
            "            ? 1",
            "            : (target_working_set_size + work_unit_size - 1) / work_unit_size;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xm2v-8rrw-w9pm",
    "API Signature": "tf.raw_ops.Conv2DBackpropInput(\n    input_sizes,\n    filter,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "filter_tensor = tf.constant([], shape=[0, 1, 5, 0], dtype=tf.float32) \nout_backprop = tf.constant([], shape=[52, 1, 1, 0], dtype=tf.float32)"
},
{
    "Title": "\n        Division by 0 in `Conv2DBackpropFilter`\n      ",
    "Bug description": "An attacker can trigger a division by 0 in  tf.raw_ops.Conv2DBackpropFilter :",
    "Sample Code": "input_tensor = tf.constant([], shape=[0, 0, 1, 0], dtype=tf.float32)\nfilter_sizes = tf.constant([1, 1, 1, 1], shape=[4], dtype=tf.int32)\nout_backprop = tf.constant([], shape=[0, 0, 1, 1], dtype=tf.float32)\n\ntf.raw_ops.Conv2DBackpropFilter(input=input_tensor, filter_sizes=filter_sizes,\n                                out_backprop=out_backprop,\n                                strides=[1, 66, 18, 1], use_cudnn_on_gpu=True,\n                                padding='SAME', explicit_paddings=[],\n                                [],\n                                data_format='NHWC', dilations=[1, 1, 1, 1])",
    "Code change": [
        "@@ -127,6 +127,10 @@ Status ConvBackpropComputeDimensionsV2(\n   // dimensions of the filter Tensor.\n   VLOG(2) << \"input vs filter_in depth \" << dims->in_depth << \" \"\n           << filter_shape.dim_size(num_dims - 2);\n+  if (filter_shape.dim_size(num_dims - 2) <= 0) {\n+    return errors ::InvalidArgument(\n+        label, \": filter depth must be strictly greated than zero\");\n+  }\n   if (dims->in_depth % filter_shape.dim_size(num_dims - 2)) {\n     return errors::InvalidArgument(\n         label, \": input depth must be evenly divisible by filter depth\");\n"
    ],
    "Buggy Code": [
        [
            "  VLOG(2) << \"input vs filter_in depth \" << dims->in_depth << \" \"",
            "          << filter_shape.dim_size(num_dims - 2);",
            "  if (dims->in_depth % filter_shape.dim_size(num_dims - 2)) {",
            "    return errors::InvalidArgument(",
            "        label, \": input depth must be evenly divisible by filter depth\");",
            "  }",
            "  dims->out_depth = filter_shape.dim_size(num_dims - 1);",
            "  if (dims->out_depth != out_backprop_shape.dim_size(feature_dim)) {",
            "    return errors::InvalidArgument(",
            "        label, \": filter and out_backprop must have the same out_depth\");"
        ]
    ],
    "Clean Code": [
        [
            "  VLOG(2) << \"input vs filter_in depth \" << dims->in_depth << \" \"",
            "          << filter_shape.dim_size(num_dims - 2);",
            "  if (filter_shape.dim_size(num_dims - 2) <= 0) {",
            "    return errors ::InvalidArgument(",
            "        label, \": filter depth must be strictly greated than zero\");",
            "  }",
            "  if (dims->in_depth % filter_shape.dim_size(num_dims - 2)) {",
            "    return errors::InvalidArgument(",
            "        label, \": input depth must be evenly divisible by filter depth\");",
            "  }"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-r4pj-74mg-8868",
    "API Signature": "tf.raw_ops.Conv2DBackpropFilter(\n    input,\n    filter_sizes,\n    out_backprop,\n    strides,\n    padding,\n    use_cudnn_on_gpu=True,\n    explicit_paddings=[],\n    data_format='NHWC',\n    dilations=[1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "input_tensor = tf.constant([], shape=[0, 0, 1, 0], dtype=tf.float32) \nout_backprop = tf.constant([], shape=[0, 0, 1, 1], dtype=tf.float32)"
},
{
    "Title": "\n        `CHECK`-fail in `AddManySparseToTensorsMap`\n      ",
    "Bug description": "An attacker can trigger a denial of service via a  CHECK -fail in   tf.raw_ops.AddManySparseToTensorsMap :",
    "Sample Code": "import numpy as np\n\nsparse_indices = tf.constant(530, shape=[1, 1], dtype=tf.int64)\nsparse_values = tf.ones([1], dtype=tf.int64)\n\nshape = tf.Variable(tf.ones([55], dtype=tf.int64))\nshape[:8].assign(np.array([855, 901, 429, 892, 892, 852, 93, 96], dtype=np.int64))\n\ntf.raw_ops.AddManySparseToTensorsMap(sparse_indices=sparse_indices,\n                    sparse_values=sparse_values,\n                    ,\n                    sparse_shape=shape)",
    "Code change": [
        "@@ -21,9 +21,6 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n-#include \"tensorflow/core/framework/op_kernel.h\"\n-#include \"tensorflow/core/framework/register_types.h\"\n-\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/resource_mgr.h\"\n@@ -31,6 +28,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n #include \"tensorflow/core/util/sparse/sparse_tensor.h\"\n \n namespace tensorflow {\n@@ -254,7 +252,22 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n         errors::InvalidArgument(\n             \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n \n-    TensorShape tensor_input_shape(input_shape->vec<int64>());\n+    auto input_shape_vec = input_shape->vec<int64>();\n+    int new_num_elements = 1;\n+    bool overflow_ocurred = false;\n+    for (int i = 0; i < input_shape_vec.size(); i++) {\n+      new_num_elements =\n+          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n+      if (new_num_elements < 0) {\n+        overflow_ocurred = true;\n+      }\n+    }\n+\n+    OP_REQUIRES(\n+        context, !overflow_ocurred,\n+        errors::Internal(\"Encountered overflow from large input shape.\"));\n+\n+    TensorShape tensor_input_shape(input_shape_vec);\n     gtl::InlinedVector<int64, 8> std_order(rank);\n     std::iota(std_order.begin(), std_order.end(), 0);\n     SparseTensor input_st;\n@@ -262,8 +275,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n                                                  tensor_input_shape, std_order,\n                                                  &input_st));\n \n-    auto input_shape_t = input_shape->vec<int64>();\n-    const int64 N = input_shape_t(0);\n+    const int64 N = input_shape_vec(0);\n \n     Tensor sparse_handles(DT_INT64, TensorShape({N}));\n     auto sparse_handles_t = sparse_handles.vec<int64>();\n@@ -274,7 +286,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n     // minibatch entries.\n     TensorShape output_shape;\n     OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n-                                input_shape_t.data() + 1,\n+                                input_shape_vec.data() + 1,\n                                 input_shape->NumElements() - 1, &output_shape));\n \n     // Get groups by minibatch dimension\n"
    ],
    "Buggy Code": [
        [
            "#include <vector>",
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\""
        ],
        [
            "#include \"tensorflow/core/framework/resource_mgr.h\"",
            "#include \"tensorflow/core/framework/tensor.h\"",
            "#include \"tensorflow/core/framework/tensor_util.h\"",
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "#include \"tensorflow/core/util/sparse/sparse_tensor.h\"",
            ""
        ],
        [
            "        context, rank > 1,",
            "        errors::InvalidArgument(",
            "            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));",
            "",
            "    TensorShape tensor_input_shape(input_shape->vec<int64>());",
            "    gtl::InlinedVector<int64, 8> std_order(rank);",
            "    std::iota(std_order.begin(), std_order.end(), 0);",
            "    SparseTensor input_st;",
            "    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,",
            "                                                 tensor_input_shape, std_order,",
            "                                                 &input_st));",
            "",
            "    auto input_shape_t = input_shape->vec<int64>();",
            "    const int64 N = input_shape_t(0);",
            "",
            "    Tensor sparse_handles(DT_INT64, TensorShape({N}));",
            "    auto sparse_handles_t = sparse_handles.vec<int64>();",
            "",
            "    OP_REQUIRES_OK(context, input_st.IndicesValid());",
            "",
            "    // We can generate the output shape proto string now, for all",
            "    // minibatch entries."
        ],
        [
            "    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(",
            "                                input_shape_t.data() + 1,",
            "                                input_shape->NumElements() - 1, &output_shape));",
            "",
            "    // Get groups by minibatch dimension",
            "    std::unordered_set<int64> visited;",
            "    sparse::GroupIterable minibatch = input_st.group({0});"
        ],
        [
            "          context, b > -1 && b < N,",
            "          errors::InvalidArgument(",
            "              \"Received unexpected column 0 value in input SparseTensor: \", b,",
            "              \" < 0 or >= N (= \", N, \")\"));",
            "",
            "      const auto indices = subset.indices();",
            "      const auto values = subset.values<T>();"
        ]
    ],
    "Clean Code": [
        [
            "#include <vector>",
            "",
            "#include \"tensorflow/core/framework/op_kernel.h\"",
            "#include \"tensorflow/core/framework/register_types.h\"",
            "#include \"tensorflow/core/framework/resource_mgr.h\"",
            "#include \"tensorflow/core/framework/tensor.h\""
        ],
        [
            "#include \"tensorflow/core/framework/types.h\"",
            "#include \"tensorflow/core/lib/gtl/inlined_vector.h\"",
            "#include \"tensorflow/core/util/overflow.h\"",
            "#include \"tensorflow/core/util/sparse/sparse_tensor.h\"",
            "",
            "namespace tensorflow {",
            ""
        ],
        [
            "            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));",
            "",
            "    auto input_shape_vec = input_shape->vec<int64>();",
            "    int new_num_elements = 1;",
            "    bool overflow_ocurred = false;",
            "    for (int i = 0; i < input_shape_vec.size(); i++) {",
            "      new_num_elements =",
            "          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));",
            "      if (new_num_elements < 0) {",
            "        overflow_ocurred = true;",
            "      }",
            "    }",
            "",
            "    OP_REQUIRES(",
            "        context, !overflow_ocurred,",
            "        errors::Internal(\"Encountered overflow from large input shape.\"));",
            "",
            "    TensorShape tensor_input_shape(input_shape_vec);",
            "    gtl::InlinedVector<int64, 8> std_order(rank);",
            "    std::iota(std_order.begin(), std_order.end(), 0);",
            "    SparseTensor input_st;",
            "    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,"
        ],
        [
            "                                                 &input_st));",
            "",
            "    const int64 N = input_shape_vec(0);",
            "",
            "    Tensor sparse_handles(DT_INT64, TensorShape({N}));",
            "    auto sparse_handles_t = sparse_handles.vec<int64>();",
            ""
        ],
        [
            "    TensorShape output_shape;",
            "    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(",
            "                                input_shape_vec.data() + 1,",
            "                                input_shape->NumElements() - 1, &output_shape));",
            "",
            "    // Get groups by minibatch dimension",
            "    std::unordered_set<int64> visited;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-2cpx-427x-q2c6",
    "API Signature": "tf.raw_ops.AddManySparseToTensorsMap(\n    sparse_indices,\n    sparse_values,\n    sparse_shape,\n    container='',\n    shared_name='',\n    name=None\n)\n",
    "Score": 0.02158273381294964,
    "Anomaly": "Large input tensor",
    "Anomaly Description": "A large tensor refers to a tensor that has a large number of elements or values or occupies a significant amount of memory.",
    "Category": "Tensor",
    "Argument": "shape = tf.Variable(tf.ones([55], dtype=tf.int64))\nshape[:8].assign(np.array([855, 901, 429, 892, 892, 852, 93, 96], dtype=np.int64))"
},
{
    "Title": "\n        Division by 0 in `Conv3DBackprop*`\n      ",
    "Bug description": "The  tf.raw_ops.Conv3DBackprop*  operations fail to validate that the input tensors are not empty. In turn, this would result in a division by 0:",
    "Sample Code": "input_sizes = tf.constant([1], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\nfilter_tensor = tf.constant([0, 0, 0, 1, 0], shape=[5], dtype=tf.int32)\nout_backprop = tf.constant([], shape=[1, 1, 1, 1, 0], dtype=tf.float32)\n\n)\n\ntf.raw_ops.Conv3DBackpropFilterV2(input=input_sizes, filter_sizes=filter_tensor, out_backprop=out_backprop, strides=[1, 1, 1, 1, 1], padding='SAME', data_format='NDHWC', dilations=[1, 1, 1, 1, 1])",
    "Code change": [
        "@@ -239,6 +239,14 @@ class Conv3DBackpropInputOp : public OpKernel {\n       input_shape = context->input(0).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -360,6 +368,14 @@ class Conv3DCustomBackpropInputOp : public OpKernel {\n       input_shape = context->input(0).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -444,6 +460,11 @@ class Conv3DCustomBackpropInputOp : public OpKernel {\n     // contraction compared to sharding and matmuls.\n     const bool use_parallel_contraction = dims.batch_size == 1;\n \n+    OP_REQUIRES(\n+        context, work_unit_size > 0,\n+        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n+                                \"must all have at least 1 element\"));\n+\n     const size_t shard_size =\n         use_parallel_contraction\n             ? 1\n@@ -724,6 +745,14 @@ class Conv3DBackpropFilterOp : public OpKernel {\n       filter_shape = context->input(1).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -850,6 +879,14 @@ class Conv3DCustomBackpropFilterOp : public OpKernel {\n       filter_shape = context->input(1).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -936,6 +973,11 @@ class Conv3DCustomBackpropFilterOp : public OpKernel {\n \n     const int64 work_unit_size = size_A + size_B + size_C;\n \n+    OP_REQUIRES(\n+        context, work_unit_size > 0,\n+        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n+                                \"must all have at least 1 element\"));\n+\n     const size_t shard_size =\n         (target_working_set_size + work_unit_size - 1) / work_unit_size;\n \n"
    ],
    "Buggy Code": [
        [
            "    }",
            "",
            "    OP_REQUIRES(",
            "        context, input_shape.dim_size(4) == filter_shape.dim_size(3),",
            "        errors::InvalidArgument(\"input and filter_sizes must have the same \"",
            "                                \"number of channels. Got \",",
            "                                input_shape.dim_size(4), \" for input and \",",
            "                                filter_shape.dim_size(3), \" for filter_sizes\"));",
            "    OP_REQUIRES(",
            "        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),",
            "        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"",
            "                                \"same number of channels. Got \",",
            "                                out_backprop_shape.dim_size(4),",
            "                                \" for out_backprop and \","
        ],
        [
            "    OP_REQUIRES(",
            "        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),",
            "        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"",
            "                                \"same number of channels. Got \",",
            "                                out_backprop_shape.dim_size(4),",
            "                                \" for out_backprop and \",",
            "                                filter_shape.dim_size(4), \" for filter_sizes\"));",
            "",
            "    ConvBackpropDimensions dims;",
            "    OP_REQUIRES_OK(context, ConvBackpropComputeDimensions(",
            "                                \"Conv3DBackpropInputOp\", /*num_spatial_dims=*/3,",
            "                                input_shape, filter_shape, out_backprop_shape,",
            "                                stride_, padding_, data_format_, &dims));",
            ""
        ],
        [
            "    int64 col_buffer_elements = col_buffer_shape.num_elements();",
            "",
            "    // If the temporary allocation overhead is too large, fallback on Eigen",
            "    // implementation which requires much less memory.",
            "    int64 col_buffer_overhead = col_buffer_elements / total_tensor_elements;",
            "    if (col_buffer_overhead > kMaxTempAllocationOverhead) {",
            "      VLOG(2) << \"Fallback on Eigen implementation of Conv3DBackpropInputOp: \"",
            "                 \"col_buffer_overhead=\"",
            "              << col_buffer_overhead;",
            "",
            "      functor::CuboidConvolutionBackwardInput<Device, T>()("
        ],
        [
            "                       padding_, data_format_, &dims));",
            "",
            "    Tensor* filter_backprop;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, filter_shape, &filter_backprop));",
            "",
            "    if (input_shape.num_elements() == 0) {",
            "      filter_backprop->template flat<T>().setZero();",
            "      return;",
            "    }",
            "",
            "    functor::CuboidConvolutionBackwardFilter<Device, T>()(",
            "        context->eigen_device<Device>(),",
            "        filter_backprop->tensor<T, 5>(),                 // filter_backward"
        ],
        [
            "      return;",
            "    }",
            "",
            "    int64 top_pad_planes, bottom_pad_planes;",
            "    int64 top_pad_rows, bottom_pad_rows;",
            "    int64 left_pad_cols, right_pad_cols;",
            "",
            "    OP_REQUIRES_OK(context, GetWindowedOutputSizeVerbose(",
            "                                dims.spatial_dims[0].input_size,",
            "                                dims.spatial_dims[0].filter_size,",
            "                                dims.spatial_dims[0].stride, padding_,",
            "                                &dims.spatial_dims[0].output_size,",
            "                                &top_pad_planes, &bottom_pad_planes));",
            "    OP_REQUIRES_OK(context, GetWindowedOutputSizeVerbose("
        ],
        [
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_temp(DataTypeToEnum<T>::value,",
            "                                          col_buffer_shape, &col_buffer));",
            "",
            "    // The input offset corresponding to a single input image.",
            "    const int64 input_offset = dims.spatial_dims[0].input_size *",
            "                               dims.spatial_dims[1].input_size *",
            "                               dims.spatial_dims[2].input_size * dims.in_depth;",
            "    // The output offset corresponding to a single output image.",
            "    const int64 output_offset =",
            "        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size *"
        ]
    ],
    "Clean Code": [
        [
            "    }",
            "",
            "    OP_REQUIRES(context, input_shape.dims() == 5,",
            "                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, filter_shape.dims() == 5,",
            "        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, out_backprop_shape.dims() == 5,",
            "        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, input_shape.dim_size(4) == filter_shape.dim_size(3),",
            "        errors::InvalidArgument(\"input and filter_sizes must have the same \"",
            "                                \"number of channels. Got \","
        ],
        [
            "    }",
            "",
            "    OP_REQUIRES(context, input_shape.dims() == 5,",
            "                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, filter_shape.dims() == 5,",
            "        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, out_backprop_shape.dims() == 5,",
            "        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, input_shape.dim_size(4) == filter_shape.dim_size(3),",
            "        errors::InvalidArgument(\"input and filter_sizes must have the same \"",
            "                                \"number of channels. Got \","
        ],
        [
            "    const bool use_parallel_contraction = dims.batch_size == 1;",
            "",
            "    OP_REQUIRES(",
            "        context, work_unit_size > 0,",
            "        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"",
            "                                \"must all have at least 1 element\"));",
            "",
            "    const size_t shard_size =",
            "        use_parallel_contraction",
            "            ? 1",
            "            : (target_working_set_size + work_unit_size - 1) / work_unit_size;"
        ],
        [
            "    }",
            "",
            "    OP_REQUIRES(context, input_shape.dims() == 5,",
            "                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, filter_shape.dims() == 5,",
            "        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, out_backprop_shape.dims() == 5,",
            "        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, input_shape.dim_size(4) == filter_shape.dim_size(3),",
            "        errors::InvalidArgument(\"input and filter_sizes must have the same \"",
            "                                \"number of channels. Got \","
        ],
        [
            "    }",
            "",
            "    OP_REQUIRES(context, input_shape.dims() == 5,",
            "                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, filter_shape.dims() == 5,",
            "        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, out_backprop_shape.dims() == 5,",
            "        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));",
            "    OP_REQUIRES(",
            "        context, input_shape.dim_size(4) == filter_shape.dim_size(3),",
            "        errors::InvalidArgument(\"input and filter_sizes must have the same \"",
            "                                \"number of channels. Got \","
        ],
        [
            "    const int64 work_unit_size = size_A + size_B + size_C;",
            "",
            "    OP_REQUIRES(",
            "        context, work_unit_size > 0,",
            "        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"",
            "                                \"must all have at least 1 element\"));",
            "",
            "    const size_t shard_size =",
            "        (target_working_set_size + work_unit_size - 1) / work_unit_size;",
            "",
            "    // Total number of elements in all the tensors used by this kernel."
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c968-pq7h-7fxv",
    "API Signature": "tf.raw_ops.Conv3DBackpropFilterV2(\n    input,\n    filter_sizes,\n    out_backprop,\n    strides,\n    padding,\n    data_format='NDHWC',\n    dilations=[1, 1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "filter_tensor = tf.constant([], shape=[0, 0, 0, 1, 0], dtype=tf.float32) \nout_backprop = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)"
},
{
    "Title": "\n        Heap buffer overflow in `Conv3DBackprop*`\n      ",
    "Bug description": "Missing validation between arguments to  tf.raw_ops.Conv3DBackprop*  operations can result in heap buffer overflows:",
    "Sample Code": "input_values = [-10.0] * (7 * 7 * 7 * 7 * 7)\ninput_values[0] = 429.6491056791816\ninput_sizes = tf.constant(input_values, shape=[7, 7, 7, 7, 7], dtype=tf.float32)\nfilter_tensor = tf.constant([7, 7, 7, 1, 1], shape=[5], dtype=tf.int32)\nout_backprop = tf.constant([-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], shape=[7, 1, 1, 1, 1], dtype=tf.float32)\n  \n)\n  \ntf.raw_ops.Conv3DBackpropFilterV2(input=input_sizes, filter_sizes=filter_tensor, out_backprop=out_backprop, strides=[1, 37, 65, 93, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 1, 1])",
    "Code change": [
        "@@ -239,6 +239,20 @@ class Conv3DBackpropInputOp : public OpKernel {\n       input_shape = context->input(0).shape();\n     }\n \n+    OP_REQUIRES(\n+        context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n+        errors::InvalidArgument(\"input and filter_sizes must have the same \"\n+                                \"number of channels. Got \",\n+                                input_shape.dim_size(4), \" for input and \",\n+                                filter_shape.dim_size(3), \" for filter_sizes\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),\n+        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"\n+                                \"same number of channels. Got \",\n+                                out_backprop_shape.dim_size(4),\n+                                \" for out_backprop and \",\n+                                filter_shape.dim_size(4), \" for filter_sizes\"));\n+\n     ConvBackpropDimensions dims;\n     OP_REQUIRES_OK(context, ConvBackpropComputeDimensions(\n                                 \"Conv3DBackpropInputOp\", /*num_spatial_dims=*/3,\n@@ -346,6 +360,20 @@ class Conv3DCustomBackpropInputOp : public OpKernel {\n       input_shape = context->input(0).shape();\n     }\n \n+    OP_REQUIRES(\n+        context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n+        errors::InvalidArgument(\"input and filter_sizes must have the same \"\n+                                \"number of channels. Got \",\n+                                input_shape.dim_size(4), \" for input and \",\n+                                filter_shape.dim_size(3), \" for filter_sizes\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),\n+        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"\n+                                \"same number of channels. Got \",\n+                                out_backprop_shape.dim_size(4),\n+                                \" for out_backprop and \",\n+                                filter_shape.dim_size(4), \" for filter_sizes\"));\n+\n     ConvBackpropDimensions dims;\n     OP_REQUIRES_OK(context, ConvBackpropComputeDimensions(\n                                 \"Conv3DBackpropInputOp\", /*num_spatial_dims=*/3,\n@@ -696,6 +724,20 @@ class Conv3DBackpropFilterOp : public OpKernel {\n       filter_shape = context->input(1).shape();\n     }\n \n+    OP_REQUIRES(\n+        context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n+        errors::InvalidArgument(\"input and filter_sizes must have the same \"\n+                                \"number of channels. Got \",\n+                                input_shape.dim_size(4), \" for input and \",\n+                                filter_shape.dim_size(3), \" for filter_sizes\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),\n+        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"\n+                                \"same number of channels. Got \",\n+                                out_backprop_shape.dim_size(4),\n+                                \" for out_backprop and \",\n+                                filter_shape.dim_size(4), \" for filter_sizes\"));\n+\n     ConvBackpropDimensions dims;\n     OP_REQUIRES_OK(context,\n                    ConvBackpropComputeDimensions(\n@@ -808,6 +850,20 @@ class Conv3DCustomBackpropFilterOp : public OpKernel {\n       filter_shape = context->input(1).shape();\n     }\n \n+    OP_REQUIRES(\n+        context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n+        errors::InvalidArgument(\"input and filter_sizes must have the same \"\n+                                \"number of channels. Got \",\n+                                input_shape.dim_size(4), \" for input and \",\n+                                filter_shape.dim_size(3), \" for filter_sizes\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),\n+        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"\n+                                \"same number of channels. Got \",\n+                                out_backprop_shape.dim_size(4),\n+                                \" for out_backprop and \",\n+                                filter_shape.dim_size(4), \" for filter_sizes\"));\n+\n     ConvBackpropDimensions dims;\n     OP_REQUIRES_OK(context,\n                    ConvBackpropComputeDimensions(\n"
    ],
    "Buggy Code": [
        [
            "    }",
            "",
            "    ConvBackpropDimensions dims;",
            "    OP_REQUIRES_OK(context, ConvBackpropComputeDimensions(",
            "                                \"Conv3DBackpropInputOp\", /*num_spatial_dims=*/3,",
            "                                input_shape, filter_shape, out_backprop_shape,",
            "                                stride_, padding_, data_format_, &dims));",
            "",
            "    Tensor* in_backprop;",
            "    OP_REQUIRES_OK(context,",
            "                   context->allocate_output(0, input_shape, &in_backprop));",
            "",
            "    functor::CuboidConvolutionBackwardInput<Device, T>()(",
            "        context->eigen_device<Device>(),",
            "        in_backprop->tensor<T, 5>(),                     // input_backward",
            "        filter.tensor<T, 5>(),                           // filter",
            "        out_backprop.tensor<T, 5>(),                     // output_backward",
            "        static_cast<int>(dims.spatial_dims[0].stride),   // stride_planes",
            "        static_cast<int>(dims.spatial_dims[1].stride),   // stride_rows",
            "        static_cast<int>(dims.spatial_dims[2].stride));  // stride_cols"
        ],
        [
            "    int64 left_pad_cols, right_pad_cols;",
            "",
            "    OP_REQUIRES_OK(context, GetWindowedOutputSizeVerbose(",
            "                                dims.spatial_dims[0].input_size,",
            "                                dims.spatial_dims[0].filter_size,",
            "                                dims.spatial_dims[0].stride, padding_,",
            "                                &dims.spatial_dims[0].output_size,",
            "                                &top_pad_planes, &bottom_pad_planes));",
            "    OP_REQUIRES_OK(context, GetWindowedOutputSizeVerbose(",
            "                                dims.spatial_dims[1].input_size,",
            "                                dims.spatial_dims[1].filter_size,",
            "                                dims.spatial_dims[1].stride, padding_,",
            "                                &dims.spatial_dims[1].output_size,",
            "                                &top_pad_rows, &bottom_pad_rows));",
            "    OP_REQUIRES_OK(context, GetWindowedOutputSizeVerbose(",
            "                                dims.spatial_dims[2].input_size,",
            "                                dims.spatial_dims[2].filter_size,",
            "                                dims.spatial_dims[2].stride, padding_,",
            "                                &dims.spatial_dims[2].output_size,",
            "                                &left_pad_cols, &right_pad_cols));"
        ],
        [
            " private:",
            "  std::vector<int32> dilation_;",
            "  std::vector<int32> stride_;",
            "  Padding padding_;",
            "  TensorFormat data_format_;",
            "  bool takes_shape_;",
            "",
            "  TF_DISALLOW_COPY_AND_ASSIGN(Conv3DBackpropFilterOp);",
            "};",
            "",
            "// Custom backprop for filter that explicitly does the work sharding and calls",
            "// Eigen only to multiply matrices.",
            "template <typename Device, class T>",
            "class Conv3DCustomBackpropFilterOp : public OpKernel {",
            "  // Limit the maximum size of allocated temporary buffer to",
            "  // kMaxTempAllocationOverhead times the size of the input tensors (input,",
            "  // filter, out_backprop). If the size of the temporary buffer exceeds this",
            "  // limit, fallback on Eigen implementation.",
            "  static constexpr int kMaxTempAllocationOverhead = 25;",
            ""
        ],
        [
            "    // functions in conv_grad_ops, and update 2d convolution backprop.",
            "",
            "    // The total dimension size of each kernel.",
            "    const int64 filter_total_size =",
            "        dims.spatial_dims[0].filter_size * dims.spatial_dims[1].filter_size *",
            "        dims.spatial_dims[2].filter_size * dims.in_depth;",
            "    // The output image size is the spatial size of the output.",
            "    const int64 output_image_size = dims.spatial_dims[0].output_size *",
            "                                    dims.spatial_dims[1].output_size *",
            "                                    dims.spatial_dims[2].output_size;",
            "",
            "    // Shard 'batch' images (volumes) into 'shard_size' groups of images",
            "    // (volumes) to be fed into the parallel matmul. Calculate 'shard_size' by",
            "    // dividing the L3 cache size ('target_working_set_size') by the matmul size",
            "    // of an individual image ('work_unit_size').",
            "",
            "    const auto cache_sizes = Eigen::internal::CacheSizes();",
            "    const ptrdiff_t l3_cache_size = cache_sizes.m_l3;",
            "",
            "    // TODO(andydavis)"
        ]
    ],
    "Clean Code": [
        [
            "    }",
            "",
            "    OP_REQUIRES(",
            "        context, input_shape.dim_size(4) == filter_shape.dim_size(3),",
            "        errors::InvalidArgument(\"input and filter_sizes must have the same \"",
            "                                \"number of channels. Got \",",
            "                                input_shape.dim_size(4), \" for input and \",",
            "                                filter_shape.dim_size(3), \" for filter_sizes\"));",
            "    OP_REQUIRES(",
            "        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),",
            "        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"",
            "                                \"same number of channels. Got \",",
            "                                out_backprop_shape.dim_size(4),",
            "                                \" for out_backprop and \",",
            "                                filter_shape.dim_size(4), \" for filter_sizes\"));",
            "",
            "    ConvBackpropDimensions dims;",
            "    OP_REQUIRES_OK(context, ConvBackpropComputeDimensions(",
            "                                \"Conv3DBackpropInputOp\", /*num_spatial_dims=*/3,",
            "                                input_shape, filter_shape, out_backprop_shape,"
        ],
        [
            "    }",
            "",
            "    OP_REQUIRES(",
            "        context, input_shape.dim_size(4) == filter_shape.dim_size(3),",
            "        errors::InvalidArgument(\"input and filter_sizes must have the same \"",
            "                                \"number of channels. Got \",",
            "                                input_shape.dim_size(4), \" for input and \",",
            "                                filter_shape.dim_size(3), \" for filter_sizes\"));",
            "    OP_REQUIRES(",
            "        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),",
            "        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"",
            "                                \"same number of channels. Got \",",
            "                                out_backprop_shape.dim_size(4),",
            "                                \" for out_backprop and \",",
            "                                filter_shape.dim_size(4), \" for filter_sizes\"));",
            "",
            "    ConvBackpropDimensions dims;",
            "    OP_REQUIRES_OK(context, ConvBackpropComputeDimensions(",
            "                                \"Conv3DBackpropInputOp\", /*num_spatial_dims=*/3,",
            "                                input_shape, filter_shape, out_backprop_shape,"
        ],
        [
            "    }",
            "",
            "    OP_REQUIRES(",
            "        context, input_shape.dim_size(4) == filter_shape.dim_size(3),",
            "        errors::InvalidArgument(\"input and filter_sizes must have the same \"",
            "                                \"number of channels. Got \",",
            "                                input_shape.dim_size(4), \" for input and \",",
            "                                filter_shape.dim_size(3), \" for filter_sizes\"));",
            "    OP_REQUIRES(",
            "        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),",
            "        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"",
            "                                \"same number of channels. Got \",",
            "                                out_backprop_shape.dim_size(4),",
            "                                \" for out_backprop and \",",
            "                                filter_shape.dim_size(4), \" for filter_sizes\"));",
            "",
            "    ConvBackpropDimensions dims;",
            "    OP_REQUIRES_OK(context,",
            "                   ConvBackpropComputeDimensions(",
            "                       \"Conv3DBackpropFilterOp\", /*num_spatial_dims=*/3,"
        ],
        [
            "    }",
            "",
            "    OP_REQUIRES(",
            "        context, input_shape.dim_size(4) == filter_shape.dim_size(3),",
            "        errors::InvalidArgument(\"input and filter_sizes must have the same \"",
            "                                \"number of channels. Got \",",
            "                                input_shape.dim_size(4), \" for input and \",",
            "                                filter_shape.dim_size(3), \" for filter_sizes\"));",
            "    OP_REQUIRES(",
            "        context, out_backprop_shape.dim_size(4) == filter_shape.dim_size(4),",
            "        errors::InvalidArgument(\"out_backprop and filter_sizes must have the \"",
            "                                \"same number of channels. Got \",",
            "                                out_backprop_shape.dim_size(4),",
            "                                \" for out_backprop and \",",
            "                                filter_shape.dim_size(4), \" for filter_sizes\"));",
            "",
            "    ConvBackpropDimensions dims;",
            "    OP_REQUIRES_OK(context,",
            "                   ConvBackpropComputeDimensions(",
            "                       \"Conv3DBackpropFilterOp\", /*num_spatial_dims=*/3,"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wcv5-qrj6-9pfm",
    "API Signature": "tf.raw_ops.Conv3DBackpropInputV2(\n    input_sizes,\n    filter,\n    out_backprop,\n    strides,\n    padding,\n    data_format='NDHWC',\n    dilations=[1, 1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "input_sizes = tf.constant([1, 1, 1, 1, 2], shape=[5], dtype=tf.int32)\nfilter_tensor = tf.constant([734.6274508233133, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0,\n-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0,\n-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], shape=[4, 1, 6, 1, 1], dtype=tf.float32)\nout_backprop = tf.constant([-10.0], shape=[1, 1, 1, 1, 1], dtype=tf.float32)"
},
{
    "Title": "\n        Segfault in `SparseCountSparseOutput`\n      ",
    "Bug description": "Specifying a negative dense shape in  tf.raw_ops.SparseCountSparseOutput  results in a segmentation fault being thrown out from the standard library as  std::vector  invariants are broken.",
    "Sample Code": "indices = tf.constant([], shape=[0, 0], dtype=tf.int64)\nvalues = tf.constant([], shape=[0, 0], dtype=tf.int64)\ndense_shape = tf.constant([-100, -100, -100], shape=[3], dtype=tf.int64)\nweights = tf.constant([], shape=[0, 0], dtype=tf.int64)\n\n)\n\ntf.raw_ops.SparseCountSparseOutput(indices=indices, values=values, dense_shape=dense_shape, weights=weights, minlength=79, maxlength=96, binary_output=False)",
    "Code change": [
        "@@ -197,9 +197,17 @@ class SparseCount : public OpKernel {\n                     \"The shape argument requires at least one element.\"));\n \n     bool is_1d = shape.NumElements() == 1;\n-    int num_batches = is_1d ? 1 : shape.flat<int64>()(0);\n+    auto shape_vector = shape.flat<int64>();\n+    int num_batches = is_1d ? 1 : shape_vector(0);\n     int num_values = values.NumElements();\n \n+    for (int b = 0; b < shape_vector.size(); b++) {\n+      OP_REQUIRES(context, shape_vector(b) >= 0,\n+                  errors::InvalidArgument(\n+                      \"Elements in dense_shape must be >= 0. Instead got:\",\n+                      shape.DebugString()));\n+    }\n+\n     OP_REQUIRES(context, num_values == indices.shape().dim_size(0),\n                 errors::InvalidArgument(\n                     \"Number of values must match first dimension of indices.\",\n"
    ],
    "Buggy Code": [
        [
            "",
            "    bool is_1d = shape.NumElements() == 1;",
            "    int num_batches = is_1d ? 1 : shape.flat<int64>()(0);",
            "    int num_values = values.NumElements();",
            "",
            "    OP_REQUIRES(context, num_values == indices.shape().dim_size(0),",
            "                errors::InvalidArgument(",
            "                    \"Number of values must match first dimension of indices.\",",
            "                    \"Got \", num_values,",
            "                    \" values, indices shape: \", indices.shape().DebugString()));",
            "",
            "    const auto indices_values = indices.matrix<int64>();",
            "    const auto values_values = values.flat<T>();",
            "    const auto weight_values = weights.flat<W>();",
            "",
            "    auto per_batch_counts = BatchedMap<W>(num_batches);",
            ""
        ]
    ],
    "Clean Code": [
        [
            "",
            "    bool is_1d = shape.NumElements() == 1;",
            "    auto shape_vector = shape.flat<int64>();",
            "    int num_batches = is_1d ? 1 : shape_vector(0);",
            "    int num_values = values.NumElements();",
            "",
            "    for (int b = 0; b < shape_vector.size(); b++) {",
            "      OP_REQUIRES(context, shape_vector(b) >= 0,",
            "                  errors::InvalidArgument(",
            "                      \"Elements in dense_shape must be >= 0. Instead got:\",",
            "                      shape.DebugString()));",
            "    }",
            "",
            "    OP_REQUIRES(context, num_values == indices.shape().dim_size(0),",
            "                errors::InvalidArgument(",
            "                    \"Number of values must match first dimension of indices.\",",
            "                    \"Got \", num_values,"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hr84-fqvp-48mm",
    "API Signature": "tf.raw_ops.SparseCountSparseOutput(\n    indices,\n    values,\n    dense_shape,\n    weights,\n    binary_output,\n    minlength=-1,\n    maxlength=-1,\n    name=None\n)\n",
    "Score": 0.025179856115107913,
    "Anomaly": "Negative input tensor",
    "Anomaly Description": "A negative input tensor refers to a tensor that contains negative values. In other words, the elements of the tensor have a value less than zero.",
    "Category": "Tensor",
    "Argument": "dense_shape = tf.constant([-100, -100, -100], shape=[3], dtype=tf.int64)"
},
{
    "Title": "\n        Session operations in eager mode lead to null pointer dereferences\n      ",
    "Bug description": "In eager mode (default in TF 2.0 and later), session operations are invalid. However, users could still call the raw ops associated with them and trigger a null pointer dereference:",
    "Sample Code": " tensorflow as tf\ntf.raw_ops.DeleteSessionTensor(handle=['])",
    "Code change": [
        "@@ -91,7 +91,6 @@ TF_CALL_NUMBER_TYPES(REGISTER_GPU_KERNEL);\n REGISTER_GPU_KERNEL(bool);\n #undef REGISTER_GPU_KERNEL\n \n-\n class GetSessionTensorOp : public OpKernel {\n  public:\n   explicit GetSessionTensorOp(OpKernelConstruction* context)\n@@ -101,7 +100,11 @@ class GetSessionTensorOp : public OpKernel {\n     const Tensor& handle = ctx->input(0);\n     const string& name = handle.scalar<tstring>()();\n     Tensor val;\n-    OP_REQUIRES_OK(ctx, ctx->session_state()->GetTensor(name, &val));\n+    auto session_state = ctx->session_state();\n+    OP_REQUIRES(ctx, session_state != nullptr,\n+                errors::FailedPrecondition(\n+                    \"GetSessionTensor called on null session state\"));\n+    OP_REQUIRES_OK(ctx, session_state->GetTensor(name, &val));\n     ctx->set_output(0, val);\n   }\n \n@@ -122,7 +125,6 @@ TF_CALL_NUMBER_TYPES(REGISTER_GPU_KERNEL);\n REGISTER_GPU_KERNEL(bool);\n #undef REGISTER_GPU_KERNEL\n \n-\n class DeleteSessionTensorOp : public OpKernel {\n  public:\n   explicit DeleteSessionTensorOp(OpKernelConstruction* context)\n@@ -131,7 +133,11 @@ class DeleteSessionTensorOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& handle = ctx->input(0);\n     const string& name = handle.scalar<tstring>()();\n-    OP_REQUIRES_OK(ctx, ctx->session_state()->DeleteTensor(name));\n+    auto session_state = ctx->session_state();\n+    OP_REQUIRES(ctx, session_state != nullptr,\n+                errors::FailedPrecondition(\n+                    \"DeleteSessionTensor called on null session state\"));\n+    OP_REQUIRES_OK(ctx, session_state->DeleteTensor(name));\n   }\n \n   TF_DISALLOW_COPY_AND_ASSIGN(DeleteSessionTensorOp);\n"
    ],
    "Buggy Code": [
        [
            "#undef REGISTER_GPU_KERNEL",
            "",
            "",
            "class GetSessionTensorOp : public OpKernel {",
            " public:",
            "  explicit GetSessionTensorOp(OpKernelConstruction* context)"
        ],
        [
            "    const Tensor& handle = ctx->input(0);",
            "    const string& name = handle.scalar<tstring>()();",
            "    Tensor val;",
            "    OP_REQUIRES_OK(ctx, ctx->session_state()->GetTensor(name, &val));",
            "    ctx->set_output(0, val);",
            "  }",
            "",
            "  TF_DISALLOW_COPY_AND_ASSIGN(GetSessionTensorOp);",
            "};",
            "",
            "REGISTER_KERNEL_BUILDER(Name(\"GetSessionTensor\").Device(DEVICE_CPU),"
        ],
        [
            "class DeleteSessionTensorOp : public OpKernel {",
            " public:",
            "  explicit DeleteSessionTensorOp(OpKernelConstruction* context)",
            "      : OpKernel(context) {}",
            "",
            "  void Compute(OpKernelContext* ctx) override {"
        ],
        [
            "    OP_REQUIRES_OK(ctx, ctx->session_state()->DeleteTensor(name));",
            "  }",
            "",
            "  TF_DISALLOW_COPY_AND_ASSIGN(DeleteSessionTensorOp);",
            "};",
            "",
            "REGISTER_KERNEL_BUILDER(Name(\"DeleteSessionTensor\").Device(DEVICE_CPU),",
            "                        DeleteSessionTensorOp);",
            "REGISTER_KERNEL_BUILDER(",
            "    Name(\"DeleteSessionTensor\").Device(DEVICE_GPU).HostMemory(\"handle\"),",
            "    DeleteSessionTensorOp);"
        ]
    ],
    "Clean Code": [
        [
            "#undef REGISTER_GPU_KERNEL",
            "",
            "class GetSessionTensorOp : public OpKernel {",
            " public:",
            "  explicit GetSessionTensorOp(OpKernelConstruction* context)",
            "      : OpKernel(context) {}"
        ],
        [
            "    const string& name = handle.scalar<tstring>()();",
            "    Tensor val;",
            "    auto session_state = ctx->session_state();",
            "    OP_REQUIRES(ctx, session_state != nullptr,",
            "                errors::FailedPrecondition(",
            "                    \"GetSessionTensor called on null session state\"));",
            "    OP_REQUIRES_OK(ctx, session_state->GetTensor(name, &val));",
            "    ctx->set_output(0, val);",
            "  }",
            "",
            "  TF_DISALLOW_COPY_AND_ASSIGN(GetSessionTensorOp);"
        ],
        [
            "#undef REGISTER_GPU_KERNEL",
            "",
            "class DeleteSessionTensorOp : public OpKernel {",
            " public:",
            "  explicit DeleteSessionTensorOp(OpKernelConstruction* context)",
            "      : OpKernel(context) {}"
        ],
        [
            "    const Tensor& handle = ctx->input(0);",
            "    const string& name = handle.scalar<tstring>()();",
            "    auto session_state = ctx->session_state();",
            "    OP_REQUIRES(ctx, session_state != nullptr,",
            "                errors::FailedPrecondition(",
            "                    \"DeleteSessionTensor called on null session state\"));",
            "    OP_REQUIRES_OK(ctx, session_state->DeleteTensor(name));",
            "  }",
            "",
            "  TF_DISALLOW_COPY_AND_ASSIGN(DeleteSessionTensorOp);",
            "};"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-62gx-355r-9fhg",
    "API Signature": "tf.raw_ops.GetSessionTensor(\n    handle, dtype, name=None\n)\n",
    "Score": 0.007194244604316547,
    "Anomaly": "Invalid string list element",
    "Anomaly Description": "An invalid string list element refers to a string element within a list that does not conform to the expected format or does not meet certain criteria. It represents a string value that is not considered valid or appropriate based on specific requirements or rules. The definition of an invalid string list element can vary depending on the context and the specific criteria being evaluated. It could include strings that are empty, contain forbidden characters, exceed length limits, or fail to meet certain formatting or validation rules.",
    "Category": "List",
    "Argument": "handle=['\\x12\\x1a\\x07']"
},
{
    "Title": "\n        Division by zero in `Conv3D`\n      ",
    "Bug description": "A malicious user could trigger a division by 0 in  Conv3D  implementation:",
    "Sample Code": "input_tensor = tf.constant([], shape=[2, 2, 2, 2, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 2, 6, 2], dtype=tf.float32)\n\n)\n\ntf.raw_ops.Conv3D(input=input_tensor, filter=filter_tensor, strides=[1, 56, 39, 34, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 1, 1])",
    "Code change": [
        "@@ -69,6 +69,11 @@ struct LaunchConvOp<CPUDevice, T> {\n                 errors::InvalidArgument(\"CPU implementation of Conv3D \"\n                                         \"currently only supports dilated rates \"\n                                         \"of 1.\"));\n+    OP_REQUIRES(context, filter.dim_size(3) == input.dim_size(input.dims() - 1),\n+                errors::InvalidArgument(\n+                    \"Number of channels in filter (\", filter.dim_size(3),\n+                    \") must match last dimension of input (\",\n+                    input.dim_size(input.dims() - 1), \")\"));\n     functor::CuboidConvolution<CPUDevice, T>()(\n         context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),\n         input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],\n@@ -142,6 +147,8 @@ class Conv3DOp : public BinaryOp<T> {\n     const int64 filter_depth = filter.dim_size(3);\n     const int64 out_depth = filter.dim_size(4);\n \n+    OP_REQUIRES(context, filter_depth != 0,\n+                errors::InvalidArgument(\"filter_depth must be non-zero\"));\n     OP_REQUIRES(context, in_depth % filter_depth == 0,\n                 errors::InvalidArgument(\n                     \"Input depth must be evenly divisible by filter depth: \",\n"
    ],
    "Buggy Code": [
        [
            "                                        \"currently only supports dilated rates \"",
            "                                        \"of 1.\"));",
            "    functor::CuboidConvolution<CPUDevice, T>()(",
            "        context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),",
            "        input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],",
            "        strides[0], BrainPadding2EigenPadding(padding));",
            "  }",
            "};",
            "",
            "template <typename Device, typename T>",
            "class Conv3DOp : public BinaryOp<T> {"
        ],
        [
            "                    in_depth, \" vs \", filter_depth));",
            "",
            "    // Dimension order for these arrays is: z, y, x.",
            "    std::array<int64, 3> input_size = {",
            "        {GetTensorDim(input, data_format_, '0'),",
            "         GetTensorDim(input, data_format_, '1'),",
            "         GetTensorDim(input, data_format_, '2')}};",
            "    std::array<int64, 3> filter_size = {"
        ]
    ],
    "Clean Code": [
        [
            "                                        \"currently only supports dilated rates \"",
            "                                        \"of 1.\"));",
            "    OP_REQUIRES(context, filter.dim_size(3) == input.dim_size(input.dims() - 1),",
            "                errors::InvalidArgument(",
            "                    \"Number of channels in filter (\", filter.dim_size(3),",
            "                    \") must match last dimension of input (\",",
            "                    input.dim_size(input.dims() - 1), \")\"));",
            "    functor::CuboidConvolution<CPUDevice, T>()(",
            "        context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),",
            "        input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],",
            "        strides[0], BrainPadding2EigenPadding(padding));"
        ],
        [
            "    const int64 out_depth = filter.dim_size(4);",
            "",
            "    OP_REQUIRES(context, filter_depth != 0,",
            "                errors::InvalidArgument(\"filter_depth must be non-zero\"));",
            "    OP_REQUIRES(context, in_depth % filter_depth == 0,",
            "                errors::InvalidArgument(",
            "                    \"Input depth must be evenly divisible by filter depth: \",",
            "                    in_depth, \" vs \", filter_depth));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-772p-x54p-hjrv",
    "API Signature": "tf.raw_ops.Conv3D(\n    input,\n    filter,\n    strides,\n    padding,\n    data_format='NDHWC',\n    dilations=[1, 1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "input_tensor = tf.constant([], shape=[2, 2, 2, 2, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 2, 6, 2], dtype=tf.float32)"
},
{
    "Title": "\n        Division by zero in `Conv3D`\n      ",
    "Bug description": "A malicious user could trigger a division by 0 in  Conv3D  implementation:",
    "Sample Code": "input_tensor = tf.constant([], shape=[2, 2, 2, 2, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 2, 6, 2], dtype=tf.float32)\n\n)\n\ntf.raw_ops.Conv3D(input=input_tensor, filter=filter_tensor, strides=[1, 56, 39, 34, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 1, 1])",
    "Code change": [
        "@@ -69,6 +69,11 @@ struct LaunchConvOp<CPUDevice, T> {\n                 errors::InvalidArgument(\"CPU implementation of Conv3D \"\n                                         \"currently only supports dilated rates \"\n                                         \"of 1.\"));\n+    OP_REQUIRES(context, filter.dim_size(3) == input.dim_size(input.dims() - 1),\n+                errors::InvalidArgument(\n+                    \"Number of channels in filter (\", filter.dim_size(3),\n+                    \") must match last dimension of input (\",\n+                    input.dim_size(input.dims() - 1), \")\"));\n     functor::CuboidConvolution<CPUDevice, T>()(\n         context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),\n         input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],\n@@ -142,6 +147,8 @@ class Conv3DOp : public BinaryOp<T> {\n     const int64 filter_depth = filter.dim_size(3);\n     const int64 out_depth = filter.dim_size(4);\n \n+    OP_REQUIRES(context, filter_depth != 0,\n+                errors::InvalidArgument(\"filter_depth must be non-zero\"));\n     OP_REQUIRES(context, in_depth % filter_depth == 0,\n                 errors::InvalidArgument(\n                     \"Input depth must be evenly divisible by filter depth: \",\n"
    ],
    "Buggy Code": [
        [
            "                                        \"currently only supports dilated rates \"",
            "                                        \"of 1.\"));",
            "    functor::CuboidConvolution<CPUDevice, T>()(",
            "        context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),",
            "        input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],",
            "        strides[0], BrainPadding2EigenPadding(padding));",
            "  }",
            "};",
            "",
            "template <typename Device, typename T>",
            "class Conv3DOp : public BinaryOp<T> {"
        ],
        [
            "                    in_depth, \" vs \", filter_depth));",
            "",
            "    // Dimension order for these arrays is: z, y, x.",
            "    std::array<int64, 3> input_size = {",
            "        {GetTensorDim(input, data_format_, '0'),",
            "         GetTensorDim(input, data_format_, '1'),",
            "         GetTensorDim(input, data_format_, '2')}};",
            "    std::array<int64, 3> filter_size = {"
        ]
    ],
    "Clean Code": [
        [
            "                                        \"currently only supports dilated rates \"",
            "                                        \"of 1.\"));",
            "    OP_REQUIRES(context, filter.dim_size(3) == input.dim_size(input.dims() - 1),",
            "                errors::InvalidArgument(",
            "                    \"Number of channels in filter (\", filter.dim_size(3),",
            "                    \") must match last dimension of input (\",",
            "                    input.dim_size(input.dims() - 1), \")\"));",
            "    functor::CuboidConvolution<CPUDevice, T>()(",
            "        context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),",
            "        input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],",
            "        strides[0], BrainPadding2EigenPadding(padding));"
        ],
        [
            "    const int64 out_depth = filter.dim_size(4);",
            "",
            "    OP_REQUIRES(context, filter_depth != 0,",
            "                errors::InvalidArgument(\"filter_depth must be non-zero\"));",
            "    OP_REQUIRES(context, in_depth % filter_depth == 0,",
            "                errors::InvalidArgument(",
            "                    \"Input depth must be evenly divisible by filter depth: \",",
            "                    in_depth, \" vs \", filter_depth));"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-772p-x54p-hjrv",
    "API Signature": "tf.raw_ops.Conv3D(\n    input,\n    filter,\n    strides,\n    padding,\n    data_format='NDHWC',\n    dilations=[1, 1, 1, 1, 1],\n    name=None\n)\n",
    "Score": 0.2014388489208633,
    "Anomaly": "Dimension mismatch",
    "Anomaly Description": "Tensor shape mismatch: If the shapes of the input tensors are not compatible for a given operation, such as matrix multiplication, concatenation, or element-wise operations. For example, attempting to multiply two tensors with incompatible shapes like (3, 4) and (5, 6) will result in a dimension mismatch error.\n\nInconsistent dimensions in additional arguments: Some APIs require additional arguments like dimensions or indices to specify the dimensions or specific elements of the tensors to operate on. If these dimensions or indices are not valid or do not align with the input tensors' shapes, a dimension mismatch can occur.",
    "Category": "Tensor",
    "Argument": "input_tensor = tf.constant([], shape=[2, 2, 2, 2, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 2, 6, 2], dtype=tf.float32)"
},
{
    "Title": "\n        Reference binding to null pointer in `MatrixDiag*` ops\n      ",
    "Bug description": "The implementation of  MatrixDiag*  does not validate that the tensor arguments are non-empty:",
    "Sample Code": "d = tf.convert_to_tensor([],dtype=tf.float32)\np = tf.convert_to_tensor([],dtype=tf.float32)\n)\ntf.raw_ops.MatrixDiagV2(diagonal=d, k=0, num_rows=0, num_cols=0, padding_value=p)",
    "Code change": [
        "@@ -192,9 +192,22 @@ class MatrixDiagOp : public OpKernel {\n           upper_diag_index = diag_index.flat<int32>()(1);\n         }\n       }\n-      num_rows = context->input(2).flat<int32>()(0);\n-      num_cols = context->input(3).flat<int32>()(0);\n-      padding_value = context->input(4).flat<T>()(0);\n+\n+      auto& num_rows_tensor = context->input(2);\n+      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_rows_tensor.shape()),\n+                  errors::InvalidArgument(\"num_rows must be a scalar\"));\n+      num_rows = num_rows_tensor.flat<int32>()(0);\n+\n+      auto& num_cols_tensor = context->input(3);\n+      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_cols_tensor.shape()),\n+                  errors::InvalidArgument(\"num_cols must be a scalar\"));\n+      num_cols = num_cols_tensor.flat<int32>()(0);\n+\n+      auto& padding_value_tensor = context->input(4);\n+      OP_REQUIRES(context,\n+                  TensorShapeUtils::IsScalar(padding_value_tensor.shape()),\n+                  errors::InvalidArgument(\"padding_value must be a scalar\"));\n+      padding_value = padding_value_tensor.flat<T>()(0);\n     }\n \n     // Size validations.\n"
    ],
    "Buggy Code": [
        [
            "        }",
            "      }",
            "      num_rows = context->input(2).flat<int32>()(0);",
            "      num_cols = context->input(3).flat<int32>()(0);",
            "      padding_value = context->input(4).flat<T>()(0);",
            "    }",
            "",
            "    // Size validations.",
            "    const TensorShape& diagonal_shape = diagonal.shape();",
            "    const int diag_rank = diagonal_shape.dims();",
            "    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;",
            "    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diagonal_shape),",
            "                errors::InvalidArgument(",
            "                    \"diagonal must be at least 1-dim, received shape: \",",
            "                    diagonal.shape().DebugString()));",
            "    OP_REQUIRES(",
            "        context, lower_diag_index <= upper_diag_index,",
            "        errors::InvalidArgument(",
            "            \"lower_diag_index must not be larger than upper_diag_index: \",",
            "            lower_diag_index, \" > \", upper_diag_index));",
            "    OP_REQUIRES(context,",
            "                lower_diag_index == upper_diag_index ||"
        ]
    ],
    "Clean Code": [
        [
            "        }",
            "      }",
            "",
            "      auto& num_rows_tensor = context->input(2);",
            "      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_rows_tensor.shape()),",
            "                  errors::InvalidArgument(\"num_rows must be a scalar\"));",
            "      num_rows = num_rows_tensor.flat<int32>()(0);",
            "",
            "      auto& num_cols_tensor = context->input(3);",
            "      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_cols_tensor.shape()),",
            "                  errors::InvalidArgument(\"num_cols must be a scalar\"));",
            "      num_cols = num_cols_tensor.flat<int32>()(0);",
            "",
            "      auto& padding_value_tensor = context->input(4);",
            "      OP_REQUIRES(context,",
            "                  TensorShapeUtils::IsScalar(padding_value_tensor.shape()),",
            "                  errors::InvalidArgument(\"padding_value must be a scalar\"));",
            "      padding_value = padding_value_tensor.flat<T>()(0);",
            "    }",
            "",
            "    // Size validations.",
            "    const TensorShape& diagonal_shape = diagonal.shape();"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hc6c-75p4-hmq4",
    "API Signature": "tf.raw_ops.MatrixDiagV2(\n    diagonal, k, num_rows, num_cols, padding_value, name=None\n)\n",
    "Score": 0.2158273381294964,
    "Anomaly": "Empty input tensor",
    "Anomaly Description": "An empty input tensor refers to a tensor that has no elements or has a size of zero along one or more dimensions. It represents a tensor with no data or empty content.",
    "Category": "Tensor",
    "Argument": "d = tf.convert_to_tensor([],dtype=tf.float32) \np = tf.convert_to_tensor([],dtype=tf.float32)"
},
{
    "Title": "\n        Heap out of bounds write in `RaggedBinCount`\n      ",
    "Bug description": "If the  splits  argument of  RaggedBincount  does not specify a valid  SparseTensor , then an attacker can trigger a heap buffer overflow:",
    "Sample Code": "tf.raw_ops.RaggedBincount(splits=[7,8], values= [5, 16, 51, 76, 29, 27, 54, 95],\\\n                          size= 59, weights= [0, 0, 0, 0, 0, 0, 0, 0],\\\n                          ],\\\n                          binary_output=False)",
    "Code change": [
        "@@ -420,6 +420,15 @@ class RaggedBincountOp : public OpKernel {\n     int num_values = values.size();\n     int batch_idx = 0;\n \n+    OP_REQUIRES(ctx, splits(0) == 0,\n+                errors::InvalidArgument(\"Splits must start with 0, not with \",\n+                                        splits(0)));\n+\n+    OP_REQUIRES(ctx, splits(num_rows) == num_values,\n+                errors::InvalidArgument(\n+                    \"Splits must end with the number of values, got \",\n+                    splits(num_rows), \" instead of \", num_values));\n+\n     Tensor* out_t;\n     OP_REQUIRES_OK(\n         ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));\n"
    ],
    "Buggy Code": [
        [
            "    int batch_idx = 0;",
            "",
            "    Tensor* out_t;",
            "    OP_REQUIRES_OK(",
            "        ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));",
            "    functor::SetZeroFunctor<Device, T> fill;",
            "    fill(ctx->eigen_device<Device>(), out_t->flat<T>());",
            "    const auto out = out_t->matrix<T>();",
            "",
            "    for (int idx = 0; idx < num_values; ++idx) {",
            "      while (idx >= splits(batch_idx)) {",
            "        batch_idx++;",
            "      }",
            "      Tidx bin = values(idx);",
            "      OP_REQUIRES(ctx, bin >= 0,"
        ]
    ],
    "Clean Code": [
        [
            "    int batch_idx = 0;",
            "",
            "    OP_REQUIRES(ctx, splits(0) == 0,",
            "                errors::InvalidArgument(\"Splits must start with 0, not with \",",
            "                                        splits(0)));",
            "",
            "    OP_REQUIRES(ctx, splits(num_rows) == num_values,",
            "                errors::InvalidArgument(",
            "                    \"Splits must end with the number of values, got \",",
            "                    splits(num_rows), \" instead of \", num_values));",
            "",
            "    Tensor* out_t;",
            "    OP_REQUIRES_OK(",
            "        ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));",
            "    functor::SetZeroFunctor<Device, T> fill;"
        ]
    ],
    "Link": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-8h46-5m9h-7553",
    "API Signature": "tf.raw_ops.RaggedBincount(\n    splits, values, size, weights, binary_output=False, name=None\n)\n",
    "Score": 0.01079136690647482,
    "Anomaly": "Non sparse input tensor",
    "Anomaly Description": "A non-sparse input tensor refers to a tensor in which most of the elements are non-zero or have significant values, meaning it has a dense representation. In a non-sparse tensor, the majority of its elements contain meaningful data or contribute to computations.",
    "Category": "Tensor",
    "Argument": "splits=[7,8]"
}
]