[
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92830",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([3], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.neg(torch.rand([], dtype=torch.float32))\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.neg(torch.rand([3, 3, 3], dtype=torch.float16))\r\narg_3 = arg_3_tensor.clone()\r\ntry:\r\n  res = torch.lt(arg_1,arg_2,out=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\n\n### ",
        "API Signature": "\n torch. lt ( input ,  other ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92828",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(0,2,[], dtype=torch.bool)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([3], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.neg(torch.rand([3, 3, 3], dtype=torch.float16))\r\narg_3 = arg_3_tensor.clone()\r\ntry:\r\n  res = torch.igamma(arg_1,arg_2,out=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\n\n### ",
        "API Signature": "\n torch. igamma ( input ,  other ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91587",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\nWhen running torch.nn.functional.conv_transpose1d with the following input combination, it throws floating point exception:\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-8192,32,[3, 4], dtype=torch.int64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(-16384,4096,[3, 3, 3], dtype=torch.int64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.randint(-1024,256,[3], dtype=torch.int64)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 2\r\narg_4 = [arg_4_0,]\r\narg_5 = 2\r\narg_6_0 = 1\r\narg_6 = [arg_6_0,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv_transpose1d(arg_1,arg_2,arg_3,stride=arg_4,padding=arg_5,output_padding=arg_6,groups=arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([1, 3, 4], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([3, 3, 3], dtype=torch.float64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([3], dtype=torch.float64)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 2\r\narg_4 = [arg_4_0,]\r\narg_5 = 2\r\narg_6_0 = 1\r\narg_6 = [arg_6_0,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv_transpose1d(arg_1,arg_2,arg_3,stride=arg_4,padding=arg_5,output_padding=arg_6,groups=arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. conv_transpose1d ( input ,  weight ,  bias ,  stride ,  padding ,  output_padding ,  groups ,  dilation )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91558",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\nIf torch.nn.functional.conv2d given zero element for last parameter, it results in floating point exception on pytorch 1.8.0 and 1.12.0. \r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([4, 8, 224, 224], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([4, 2, 3, 3], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([4], dtype=torch.float32)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 2\r\narg_4_1 = 2\r\narg_4 = [arg_4_0,arg_4_1,]\r\narg_5_0 = 1\r\narg_5_1 = 1\r\narg_5 = [arg_5_0,arg_5_1,]\r\narg_6_0 = 1\r\narg_6_1 = 1\r\narg_6 = [arg_6_0,arg_6_1,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv2d(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nAnd :\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([4, 6, 5], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([6, 2, 3, 2], dtype=torch.float64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.neg(torch.rand([], dtype=torch.float64))\r\narg_3 = arg_3_tensor.clone()\r\narg_4 = 0\r\ntry:\r\n  res = torch.nn.functional.conv2d(arg_1,arg_2,arg_3,groups=arg_4,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. conv2d ( input ,  weight ,  bias ,  stride ,  padding ,  dilation ,  groups )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92827",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\n\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-16,16,[], dtype=torch.int8)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([3], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.randint(-8192,16,[3, 3, 3], dtype=torch.int64)\r\narg_3 = arg_3_tensor.clone()\r\ntry:\r\n  res = torch.logical_xor(arg_1,arg_2,out=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\n\n### ",
        "API Signature": "\n torch. logical_xor ( input ,  other ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91592",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\nWhen running torch.nn.functional.conv3d with the following input combinations, i get floating point exceptions:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([4, 3, 4, 5], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([5, 4, 3, 3, 3], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([5], dtype=torch.float32)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 1\r\narg_4_1 = 1\r\narg_4_2 = 1\r\narg_4 = [arg_4_0,arg_4_1,arg_4_2,]\r\narg_5_0 = 0\r\narg_5_1 = 0\r\narg_5_2 = 0\r\narg_5 = [arg_5_0,arg_5_1,arg_5_2,]\r\narg_6_0 = 1\r\narg_6_1 = 1\r\narg_6_2 = 1\r\narg_6 = [arg_6_0,arg_6_1,arg_6_2,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv3d(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nAnd this one:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-1024,4,[3, 1, 3, 3], dtype=torch.int64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([1, 1, 3, 3, 3], dtype=torch.complex64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([1], dtype=torch.complex64)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 1\r\narg_4_1 = 1\r\narg_4_2 = 1\r\narg_4 = [arg_4_0,arg_4_1,arg_4_2,]\r\narg_5_0 = 0\r\narg_5_1 = 0\r\narg_5_2 = 0\r\narg_5 = [arg_5_0,arg_5_1,arg_5_2,]\r\narg_6_0 = 1\r\narg_6_1 = 1\r\narg_6_2 = 1\r\narg_6 = [arg_6_0,arg_6_1,arg_6_2,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv3d(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. conv3d ( input ,  weight ,  bias ,  stride ,  padding ,  dilation ,  groups )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92825",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\n\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([2, 5, 5], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(-1024,4,[2, 5], dtype=torch.int32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([5, 5], dtype=torch.float64)\r\narg_3 = arg_3_tensor.clone()\r\narg_4 = False\r\ntry:\r\n  res = torch.linalg.ldl_solve(arg_1,arg_2,arg_3,hermitian=arg_4,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\r\n\r\nLog message:\r\n\r\n```\r\nmunmap_chunk(): invalid pointer\r\nAborted\r\n\r\n```\n\n### ",
        "API Signature": "\n torch.linalg. ldl_solve ( LD ,  pivots ,  B ,  * ,  hermitian ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92819",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nProbably due to empty tensor:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.neg(torch.rand([2], dtype=torch.float64))\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.tensor([], dtype=torch.bool)\r\narg_2 = arg_2_tensor.clone()\r\ntry:\r\n  res = torch.linalg.inv(arg_1,out=arg_2,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\r\n\r\nThis is a machine generated test cases. \n\n### ",
        "API Signature": "\n torch.linalg. inv ( A ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92818",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\nProbably due to empty tensor:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([], dtype=torch.float16)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([3], dtype=torch.complex64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([3, 3, 3], dtype=torch.complex128)\r\narg_3 = arg_3_tensor.clone()\r\ntry:\r\n  res = torch.atan2(arg_1,arg_2,out=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\r\n\r\nPlease note that this is a machine generated test cases (using fuzz testing). \n\n### ",
        "API Signature": "\n torch. atan2 ( input ,  other ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92800",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.tensor([], dtype=torch.bool)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(0,4,[1], dtype=torch.uint8)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.neg(torch.rand([3, 3, 3], dtype=torch.complex128))\r\narg_3 = arg_3_tensor.clone()\r\ntry:\r\n  res = torch.gt(arg_1,arg_2,out=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\n\n### ",
        "API Signature": "\n torch. gt ( input ,  other ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92799",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-16,4,[], dtype=torch.int64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(0,1,[1], dtype=torch.uint8)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.neg(torch.rand([3, 3, 3], dtype=torch.complex128))\r\narg_3 = arg_3_tensor.clone()\r\ntry:\r\n  res = torch.eq(arg_1,arg_2,out=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\n\n### ",
        "API Signature": "\n torch. eq ( input ,  other ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92798",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(0,256,[1, 1, 1, 0], dtype=torch.uint8)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = 1\r\ntry:\r\n  res = torch.nn.functional.pixel_shuffle(arg_1,upscale_factor=arg_2,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\n\n### ",
        "API Signature": "\n torch.nn.functional. pixel_shuffle ( input ,  upscale_factor )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92797",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\nCode:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-128,2,[3], dtype=torch.int32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(-16,8192,[], dtype=torch.int32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([3, 3, 3], dtype=torch.bfloat16)\r\narg_3 = arg_3_tensor.clone()\r\ntry:\r\n  res = torch.div(arg_1,arg_2,out=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\n\n### ",
        "API Signature": "\n torch. div ( input ,  other ,  * ,  rounding_mode ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91594",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([5, 1, 224], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([2, 1, 3], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3 = None\r\narg_4_0 = 2\r\narg_4 = [arg_4_0,]\r\narg_5_0 = 1\r\narg_5 = [arg_5_0,]\r\narg_6_0 = 1\r\narg_6 = [arg_6_0,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv1d(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.neg(torch.rand([2, 4], dtype=torch.bfloat16))\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([2, 2, 3], dtype=torch.bfloat16)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.neg(torch.rand([3, 3, 3], dtype=torch.complex128))\r\narg_3 = arg_3_tensor.clone()\r\narg_4 = 3\r\narg_5 = 1\r\narg_6 = 0\r\narg_7 = 2\r\ntry:\r\n  res = torch.nn.functional.conv1d(arg_1,arg_2,arg_3,stride=arg_4,padding=arg_5,groups=arg_6,dilation=arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. conv1d ( input ,  weight ,  bias ,  stride ,  padding ,  dilation ,  groups )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92796",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\n\r\n\r\n```\r\nresults = dict()\r\nimport torch\r\narg_1_tensor = torch.rand([2, 2, 4, 4, 4], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = 0\r\narg_3 = True\r\ntry:\r\n  results[\"res_cpu\"] = torch.nn.functional.adaptive_max_pool3d(arg_1,arg_2,arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\narg_1 = arg_1_tensor.clone().cuda()\r\ntry:\r\n  results[\"res_gpu\"] = torch.nn.functional.adaptive_max_pool3d(arg_1,arg_2,arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\nprint(results)\r\n```\n\n### ",
        "API Signature": "\n torch.nn.functional. adaptive_max_pool3d ( * ,  ** ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92795",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\nCode:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-4,256,[1, 1, 0, 1], dtype=torch.int16)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = 1\r\ntry:\r\n  res = torch.nn.functional.pixel_unshuffle(arg_1,downscale_factor=arg_2,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": "\n torch.nn.functional. pixel_unshuffle ( input ,  downscale_factor )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92794",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\nDue to dimension mismatch:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([3], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(0,8,[], dtype=torch.uint8)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.neg(torch.rand([3, 3, 3], dtype=torch.complex64))\r\narg_3 = arg_3_tensor.clone()\r\ntry:\r\n  res = torch.ge(arg_1,arg_2,out=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": "\n torch. ge ( input ,  other ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92793",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\n\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([2, 2], dtype=torch.complex64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(-64,4096,[], dtype=torch.int32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3 = True\r\ntry:\r\n  res = torch.lu_unpack(arg_1,arg_2,unpack_pivots=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\n\n\n### ",
        "API Signature": "\n torch. lu_unpack ( LU_data ,  LU_pivots ,  unpack_data ,  unpack_pivots ,  * ,  out ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92792",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\nCode:\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([2, 2, 14, 8], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([2, 3, 4, 4], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([3], dtype=torch.float32)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 1\r\narg_4_1 = 1\r\narg_4 = [arg_4_0,arg_4_1,]\r\narg_5_0 = 2\r\narg_5_1 = 2\r\narg_5 = [arg_5_0,arg_5_1,]\r\narg_6_0 = 0\r\narg_6_1 = 0\r\narg_6 = [arg_6_0,arg_6_1,]\r\narg_7 = 0\r\narg_8_0 = 3\r\narg_8_1 = 3\r\narg_8 = [arg_8_0,arg_8_1,]\r\ntry:\r\n  res = torch.nn.functional.conv_transpose2d(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,arg_7,arg_8,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\n\n\n### ",
        "API Signature": "\n torch.nn.functional. conv_transpose2d ( input ,  weight ,  bias ,  stride ,  padding ,  output_padding ,  groups ,  dilation )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92791",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\n\r\n\r\nCode:\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([4, 3, 4, 5], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([4, 5, 3, 3, 3], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([5], dtype=torch.float32)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 1\r\narg_4_1 = 1\r\narg_4_2 = 1\r\narg_4 = [arg_4_0,arg_4_1,arg_4_2,]\r\narg_5_0 = 0\r\narg_5_1 = 0\r\narg_5_2 = 0\r\narg_5 = [arg_5_0,arg_5_1,arg_5_2,]\r\narg_6_0 = 0\r\narg_6_1 = 0\r\narg_6_2 = 0\r\narg_6 = [arg_6_0,arg_6_1,arg_6_2,]\r\narg_7 = 0\r\narg_8_0 = 1\r\narg_8_1 = 1\r\narg_8_2 = 1\r\narg_8 = [arg_8_0,arg_8_1,arg_8_2,]\r\ntry:\r\n  res = torch.nn.functional.conv_transpose3d(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,arg_7,arg_8,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": "\n torch.nn.functional. conv_transpose3d ( input ,  weight ,  bias ,  stride ,  padding ,  output_padding ,  groups ,  dilation )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92790",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\nCode:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.neg(torch.rand([100, 100, 100, 5, 5, 5], dtype=torch.complex128))\r\narg_1 = arg_1_tensor.clone()\r\ntry:\r\n  res = torch.Tensor.is_coalesced(arg_1,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nLog message:\r\n\r\n```\r\nError:Could not run 'aten::is_coalesced' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::is_coalesced' is only available for these backends: [FuncTorchGradWrapper, Functionalize, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseXPU, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\r\n\r\nSparseCPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/build/aten/src/ATen/RegisterSparseCPU.cpp:1858 [kernel]\r\nSparseCUDA: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/build/aten/src/ATen/RegisterSparseCUDA.cpp:2018 [kernel]\r\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\r\nPython: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\r\nNamed: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\r\nConjugate: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\r\nNegative: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\r\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\r\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\r\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradIPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nTracer: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/TraceType_2.cpp:14069 [kernel]\r\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\r\nAutocast: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\r\nBatched: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\r\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\r\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\r\n\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92789",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\nCode:\r\n\r\n```\r\nresults = dict()\r\nimport torch\r\narg_1_tensor = torch.randint(-512,512,[100, 100, 100, 5, 5, 5], dtype=torch.int64)\r\narg_1 = arg_1_tensor.clone()\r\ntry:\r\n  results[\"res_cpu\"] = torch.Tensor.indices(arg_1,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\narg_1 = arg_1_tensor.clone().cuda()\r\ntry:\r\n  results[\"res_gpu\"] = torch.Tensor.indices(arg_1,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\nprint(results)\r\n```\r\n\r\nLog message:\r\n\r\n```\r\nError:Could not run 'aten::indices' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::indices' is only available for these backends: [FuncTorchGradWrapper, Functionalize, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseXPU, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\r\n\r\nSparseCPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/build/aten/src/ATen/RegisterSparseCPU.cpp:1858 [kernel]\r\nSparseCUDA: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/build/aten/src/ATen/RegisterSparseCUDA.cpp:2018 [kernel]\r\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\r\nPython: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\r\nNamed: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\r\nConjugate: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\r\nNegative: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\r\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\r\nADInplaceOrView: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:3016 [kernel]\r\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradIPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nTracer: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/TraceType_2.cpp:14069 [kernel]\r\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\r\nAutocast: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\r\nBatched: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\r\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/build/aten/src/ATen/RegisterFunctionalization_2.cpp:11616 [kernel]\r\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\r\n\r\nError:Could not run 'aten::indices' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::indices' is only available for these backends: [FuncTorchGradWrapper, Functionalize, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseXPU, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\r\n\r\nSparseCPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/build/aten/src/ATen/RegisterSparseCPU.cpp:1858 [kernel]\r\nSparseCUDA: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/build/aten/src/ATen/RegisterSparseCUDA.cpp:2018 [kernel]\r\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\r\nPython: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\r\nNamed: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\r\nConjugate: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\r\nNegative: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\r\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\r\nADInplaceOrView: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:3016 [kernel]\r\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradIPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/VariableType_2.cpp:14210 [autograd kernel]\r\nTracer: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/torch/csrc/autograd/generated/TraceType_2.cpp:14069 [kernel]\r\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\r\nAutocast: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\r\nBatched: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\r\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/build/aten/src/ATen/RegisterFunctionalization_2.cpp:11616 [kernel]\r\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1656352616446/work/aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\r\n\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91550",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\nIf torch.nn.functional.conv_transpose3d is given this input combination, it results in floating point exception in pytorch 1.8.0 and 1.12.0.\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([1, 3, 4, 4, 4], dtype=torch.complex64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([3, 3, 3, 3, 3], dtype=torch.complex64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([3], dtype=torch.complex64)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 2\r\narg_4_1 = 2\r\narg_4_2 = 2\r\narg_4 = [arg_4_0,arg_4_1,arg_4_2,]\r\narg_5 = 2\r\narg_6_0 = 1\r\narg_6_1 = 1\r\narg_6_2 = 1\r\narg_6 = [arg_6_0,arg_6_1,arg_6_2,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv_transpose3d(arg_1,arg_2,arg_3,stride=arg_4,padding=arg_5,output_padding=arg_6,groups=arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n```\r\nFloating point exception (core dumped)\r\n```\r\nI couldn't get traceback for this bug.\r\n\r\nTo test on 1.12.0, please run [link to gist](https://colab.research.google.com/gist/nimashiri/263d9f5d4bc4b7b1e52edbc8b582d451/tensorflow-python-ops-gen_list_ops-tensor_list_from_tensor.ipynb)\n\n### ",
        "API Signature": "\n torch.nn.functional. conv_transpose3d ( input ,  weight ,  bias ,  stride ,  padding ,  output_padding ,  groups ,  dilation )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91549",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\nIf torch.nn.functional.conv_transpose2d is given empty list input parameter, it results in floating point exception in pytorch 1.8.0 and 1.12.0. \r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([1, 3, 4, 4], dtype=torch.complex64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([3, 3, 3, 3], dtype=torch.complex64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([3], dtype=torch.complex64)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 2\r\narg_4_1 = 2\r\narg_4 = [arg_4_0,arg_4_1,]\r\narg_5 = 2\r\narg_6_0 = 1\r\narg_6_1 = 1\r\narg_6 = [arg_6_0,arg_6_1,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv_transpose2d(arg_1,arg_2,arg_3,stride=arg_4,padding=arg_5,output_padding=arg_6,groups=arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-32,1024,[2, 2, 18, 8], dtype=torch.int16)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([2, 3, 4, 4], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([3], dtype=torch.float32)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 1\r\narg_4_1 = 1\r\narg_4 = [arg_4_0,arg_4_1,]\r\narg_5_0 = 28\r\narg_5_1 = 63\r\narg_5 = [arg_5_0,arg_5_1,]\r\narg_6_0 = 0\r\narg_6_1 = 0\r\narg_6 = [arg_6_0,arg_6_1,]\r\narg_7 = 0\r\narg_8_0 = 3\r\narg_8_1 = 3\r\narg_8 = [arg_8_0,arg_8_1,]\r\ntry:\r\n  res = torch.nn.functional.conv_transpose2d(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,arg_7,arg_8,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\r\n\r\nThe log message I get is:\r\n\r\n```\r\nFloating point exception (core dumped)\r\n```\r\n\r\nI couldn't get traceback for this bug. \r\n\r\nTo test on 1.12.0, please run [link to gist](https://colab.research.google.com/gist/nimashiri/7105853e9a675434ac19ccc336451390/tensorflow-python-ops-gen_list_ops-tensor_list_from_tensor.ipynb)\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. conv_transpose2d ( input ,  weight ,  bias ,  stride ,  padding ,  output_padding ,  groups ,  dilation )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91552",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nOverflow when running  torch.nn.AdaptiveMaxPool2d with very large list elements:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_0 = 125091515651\r\narg_1_1 = 125091515651\r\narg_1 = [arg_1_0,arg_1_1,]\r\narg_class = torch.nn.AdaptiveMaxPool2d(arg_1,)\r\narg_2_0_tensor = torch.rand([1, 3, 5, 6], dtype=torch.float64)\r\narg_2_0 = arg_2_0_tensor.clone()\r\narg_2 = [arg_2_0,]\r\ntry:\r\n  res = arg_class(*arg_2)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nThe log message is:\r\n\r\n```\r\nError:Storage size calculation overflowed with sizes=[1, 3, 125091515651, 125091515651]\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91553",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nIf torch.nn.AdaptiveMaxPool2d is given very large list elements, it results in segmentation fault:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_0 = 125091515651\r\narg_1_1 = 125091515651\r\narg_1 = [arg_1_0,arg_1_1,]\r\narg_class = torch.nn.AdaptiveMaxPool2d(arg_1,)\r\narg_2_0_tensor = torch.rand([1, 3, 5, 6], dtype=torch.float64)\r\narg_2_0 = arg_2_0_tensor.clone()\r\narg_2 = [arg_2_0,]\r\ntry:\r\n  res = arg_class(*arg_2)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nThe log message is:\r\n\r\n```\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nHere is the link to [gist](https://colab.research.google.com/gist/nimashiri/973e5abe10001083c7ebce01171a11da/tensorflow-python-ops-gen_list_ops-tensor_list_from_tensor.ipynb)\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91555",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nIf torch.nn.functional.max_unpool3d is given negative input tensor, it results in crash:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.neg(torch.rand([1, 2, 4, 6, 3], dtype=torch.float64))\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(-1,32,[1, 2, 4, 6, 3], dtype=torch.int64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3 = 3\r\narg_4_0 = 2\r\narg_4_1 = 1\r\narg_4_2 = 2\r\narg_4 = [arg_4_0,arg_4_1,arg_4_2,]\r\narg_5 = 1\r\narg_6_0 = 1\r\narg_6_1 = 2\r\narg_6_2 = 6\r\narg_6_3 = 6\r\narg_6_4 = 5\r\narg_6 = [arg_6_0,arg_6_1,arg_6_2,arg_6_3,arg_6_4,]\r\ntry:\r\n  res = torch.nn.functional.max_unpool3d(arg_1,arg_2,kernel_size=arg_3,stride=arg_4,padding=arg_5,output_size=arg_6,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nThe log message is:\r\n\r\n```\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  found an invalid max index -2 (output volumes are of size 3x6x5\r\nException raised from max_unpooling3d_forward_out_cpu_frame at /pytorch/aten/src/ATen/native/MaxUnpooling.cpp:204 (most recent call first):\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fc440e9a2f2 in /home/nimashiri/.local/lib/python3.8/site-packages/torch/lib/libc10.so)\r\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x5b (0x7fc440e9767b in /home/nimashiri/.local/lib/python3.8/site-packages/torch/lib/libc10.so)\r\nframe #2: <unknown function> + 0x1021e10 (0x7fc422edfe10 in /home/nimashiri/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\r\nframe #3: <unknown function> + 0x16405 (0x7fc442f09405 in /home/nimashiri/.local/lib/python3.8/site-packages/torch/lib/libgomp-a34b3233.so.1)\r\nframe #4: <unknown function> + 0x8609 (0x7fc4caa38609 in /lib/x86_64-linux-gnu/libpthread.so.0)\r\nframe #5: clone + 0x43 (0x7fc4cab72163 in /lib/x86_64-linux-gnu/libc.so.6)\r\n\r\nAborted (core dumped)\r\n```\r\n\r\nPlease follow this [link](https://colab.research.google.com/gist/nimashiri/23e554ae8933bee3e4abed9e4cd77106/tensorflow-python-ops-gen_list_ops-tensor_list_from_tensor.ipynb)\n\n### ",
        "API Signature": "\n torch.nn.functional. max_unpool3d ( input ,  indices ,  kernel_size ,  stride ,  padding ,  output_size ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91556",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\nWhen running torch.nn.AdaptiveMaxPool3d, it overflows with very large elements in input lists. \r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_0 = 125091515651\r\narg_1_1 = 125091515651\r\narg_1_2 = 125091515651\r\narg_1 = [arg_1_0,arg_1_1,arg_1_2,]\r\narg_class = torch.nn.AdaptiveMaxPool3d(arg_1,)\r\narg_2_0_tensor = torch.rand([2, 3, 5, 6, 7], dtype=torch.float64)\r\narg_2_0 = arg_2_0_tensor.clone()\r\narg_2 = [arg_2_0,]\r\ntry:\r\n  res = arg_class(*arg_2)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nLog message:\r\n\r\n```\r\nError:Storage size calculation overflowed with sizes=[2, 3, 125091515651, 125091515651, 125091515651]\r\n```\r\n\r\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91558",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\nIf torch.nn.functional.conv2d given zero element for last parameter, it results in floating point exception on pytorch 1.8.0 and 1.12.0. \r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([4, 8, 224, 224], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([4, 2, 3, 3], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([4], dtype=torch.float32)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 2\r\narg_4_1 = 2\r\narg_4 = [arg_4_0,arg_4_1,]\r\narg_5_0 = 1\r\narg_5_1 = 1\r\narg_5 = [arg_5_0,arg_5_1,]\r\narg_6_0 = 1\r\narg_6_1 = 1\r\narg_6 = [arg_6_0,arg_6_1,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv2d(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nAnd :\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([4, 6, 5], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([6, 2, 3, 2], dtype=torch.float64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.neg(torch.rand([], dtype=torch.float64))\r\narg_3 = arg_3_tensor.clone()\r\narg_4 = 0\r\ntry:\r\n  res = torch.nn.functional.conv2d(arg_1,arg_2,arg_3,groups=arg_4,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. conv2d ( input ,  weight ,  bias ,  stride ,  padding ,  dilation ,  groups )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91583",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nProcess killed when runnning torch.nn.LayerNorm with very large input:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_0 = 4050212686\r\narg_1 = [arg_1_0,]\r\narg_2 = 0.001\r\narg_class = torch.nn.LayerNorm(arg_1,arg_2,)\r\narg_3_0_tensor = torch.rand([4, 5, 5], dtype=torch.float64)\r\narg_3_0 = arg_3_0_tensor.clone()\r\narg_3 = [arg_3_0,]\r\ntry:\r\n  res = arg_class(*arg_3)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91584",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([0, 1, 4, 6, 7], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = 2239310108\r\narg_3 = 2\r\ntry:\r\n  res = torch.tensor_split(arg_1,arg_2,arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": "\n torch. tensor_split ( input ,  indices_or_sections ,  dim )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91585",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([2, 1, 1], dtype=torch.complex128)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([2, 1, 1], dtype=torch.complex128)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.randint(-32768,1,[2, 1], dtype=torch.int32)\r\narg_3 = arg_3_tensor.clone()\r\ntry:\r\n  res = torch.lu_solve(arg_1,arg_2,arg_3,)\r\n  print(res)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": "\n torch. lu_solve ( b ,  LU_data ,  LU_pivots ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91586",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.neg(torch.rand([2, 1, 3, 4, 2], dtype=torch.float32))\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([4, 4], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.randint(-64,32,[4], dtype=torch.int32)\r\narg_3 = arg_3_tensor.clone()\r\ntry:\r\n  res = torch.lu_solve(arg_1,arg_2,arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nError:\r\n\r\n```\r\ndouble free or corruption (out)\r\nAborted\r\n\r\n```\n\n### ",
        "API Signature": "\n torch. lu_solve ( b ,  LU_data ,  LU_pivots ,  * ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91791",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nProcess get killed when running torch.Tensor.repeat_interleave with the following input arguments:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-8192,128,[3], dtype=torch.int64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = 433894953\r\ntry:\r\n  res = torch.Tensor.repeat_interleave(arg_1,arg_2,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91793",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nProcess get killed when running with the following arguments:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1 = 3431068031\r\narg_2 = 0.001\r\narg_3 = 0.3\r\narg_4 = False\r\narg_class = torch.nn.BatchNorm3d(arg_1,arg_2,arg_3,arg_4,)\r\narg_5_0_tensor = torch.rand([0, 5, 2, 2, 2], dtype=torch.float64)\r\narg_5_0 = arg_5_0_tensor.clone()\r\narg_5 = [arg_5_0,]\r\ntry:\r\n  res = arg_class(*arg_5)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91595",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-2048,32768,[1, 1, 1, 0], dtype=torch.int32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = 1\r\ntry:\r\n  res = torch.nn.functional.pixel_unshuffle(arg_1,downscale_factor=arg_2,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-128,16,[1, 1, 1, 0], dtype=torch.int64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = 1\r\ntry:\r\n  res = torch.nn.functional.pixel_unshuffle(arg_1,downscale_factor=arg_2,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. pixel_unshuffle ( input ,  downscale_factor )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91594",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([5, 1, 224], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([2, 1, 3], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3 = None\r\narg_4_0 = 2\r\narg_4 = [arg_4_0,]\r\narg_5_0 = 1\r\narg_5 = [arg_5_0,]\r\narg_6_0 = 1\r\narg_6 = [arg_6_0,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv1d(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.neg(torch.rand([2, 4], dtype=torch.bfloat16))\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([2, 2, 3], dtype=torch.bfloat16)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.neg(torch.rand([3, 3, 3], dtype=torch.complex128))\r\narg_3 = arg_3_tensor.clone()\r\narg_4 = 3\r\narg_5 = 1\r\narg_6 = 0\r\narg_7 = 2\r\ntry:\r\n  res = torch.nn.functional.conv1d(arg_1,arg_2,arg_3,stride=arg_4,padding=arg_5,groups=arg_6,dilation=arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. conv1d ( input ,  weight ,  bias ,  stride ,  padding ,  dilation ,  groups )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91593",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nWhen I run torch.nn.functional.lp_pool1d with second argument as zero, it results in division by zero\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([3, 7], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = 0\r\narg_3 = 2\r\narg_4 = 3\r\narg_5 = False\r\ntry:\r\n  res = torch.nn.functional.lp_pool1d(arg_1,arg_2,arg_3,arg_4,arg_5,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nThe log message is:\r\n\r\n```\r\nError:float division by zero\r\n\r\n```\n\n### ",
        "API Signature": "\n torch.nn.functional. lp_pool1d ( input ,  norm_type ,  kernel_size ,  stride ,  ceil_mode ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91590",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "",
        "API Signature": "\n torch.linalg. ldl_solve ( LD ,  pivots ,  B ,  * ,  hermitian ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91591",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nWhen running torch.linalg.ldl_solve  with the following input combinations, i get segfault:\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.neg(torch.rand([2, 2, 5, 5], dtype=torch.complex64))\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(-128,512,[2, 2, 5], dtype=torch.int32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([2, 2, 5, 1], dtype=torch.complex64)\r\narg_3 = arg_3_tensor.clone()\r\narg_4 = True\r\ntry:\r\n  res = torch.linalg.ldl_solve(arg_1,arg_2,arg_3,hermitian=arg_4,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": "\n torch.linalg. ldl_solve ( LD ,  pivots ,  B ,  * ,  hermitian ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91592",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\nWhen running torch.nn.functional.conv3d with the following input combinations, i get floating point exceptions:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([4, 3, 4, 5], dtype=torch.float32)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([5, 4, 3, 3, 3], dtype=torch.float32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([5], dtype=torch.float32)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 1\r\narg_4_1 = 1\r\narg_4_2 = 1\r\narg_4 = [arg_4_0,arg_4_1,arg_4_2,]\r\narg_5_0 = 0\r\narg_5_1 = 0\r\narg_5_2 = 0\r\narg_5 = [arg_5_0,arg_5_1,arg_5_2,]\r\narg_6_0 = 1\r\narg_6_1 = 1\r\narg_6_2 = 1\r\narg_6 = [arg_6_0,arg_6_1,arg_6_2,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv3d(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nAnd this one:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-1024,4,[3, 1, 3, 3], dtype=torch.int64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([1, 1, 3, 3, 3], dtype=torch.complex64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([1], dtype=torch.complex64)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 1\r\narg_4_1 = 1\r\narg_4_2 = 1\r\narg_4 = [arg_4_0,arg_4_1,arg_4_2,]\r\narg_5_0 = 0\r\narg_5_1 = 0\r\narg_5_2 = 0\r\narg_5 = [arg_5_0,arg_5_1,arg_5_2,]\r\narg_6_0 = 1\r\narg_6_1 = 1\r\narg_6_2 = 1\r\narg_6 = [arg_6_0,arg_6_1,arg_6_2,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv3d(arg_1,arg_2,arg_3,arg_4,arg_5,arg_6,arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. conv3d ( input ,  weight ,  bias ,  stride ,  padding ,  dilation ,  groups )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91589",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nI get unknown error when running torch.tensordot with the following input combinations:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([0, 0, 1, 2, 3, 0], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([1, 2, 3, 0], dtype=torch.float64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3 = 95063276620\r\ntry:\r\n  res = torch.tensordot(arg_1,arg_2,dims=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nThe log message is:\r\n```\r\nError:\r\n\r\n```\n\n### ",
        "API Signature": "\n torch. tensordot ( a ,  b ,  dims ,  out ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91588",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nI get bad allocation error when running torch.combination with the following input arguments:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([2], dtype=torch.bfloat16)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = 102919646178\r\narg_3 = False\r\ntry:\r\n  res = torch.combinations(arg_1,r=arg_2,with_replacement=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nLog message:\r\n\r\n```\r\nError:std::bad_alloc\r\n```\n\n### ",
        "API Signature": "\n torch. combinations ( input ,  r ,  with_replacement )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91587",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\nWhen running torch.nn.functional.conv_transpose1d with the following input combination, it throws floating point exception:\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-8192,32,[3, 4], dtype=torch.int64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(-16384,4096,[3, 3, 3], dtype=torch.int64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.randint(-1024,256,[3], dtype=torch.int64)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 2\r\narg_4 = [arg_4_0,]\r\narg_5 = 2\r\narg_6_0 = 1\r\narg_6 = [arg_6_0,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv_transpose1d(arg_1,arg_2,arg_3,stride=arg_4,padding=arg_5,output_padding=arg_6,groups=arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([1, 3, 4], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([3, 3, 3], dtype=torch.float64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([3], dtype=torch.float64)\r\narg_3 = arg_3_tensor.clone()\r\narg_4_0 = 2\r\narg_4 = [arg_4_0,]\r\narg_5 = 2\r\narg_6_0 = 1\r\narg_6 = [arg_6_0,]\r\narg_7 = 0\r\ntry:\r\n  res = torch.nn.functional.conv_transpose1d(arg_1,arg_2,arg_3,stride=arg_4,padding=arg_5,output_padding=arg_6,groups=arg_7,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\n```\r\n\r\n### ",
        "API Signature": "\n torch.nn.functional. conv_transpose1d ( input ,  weight ,  bias ,  stride ,  padding ,  output_padding ,  groups ,  dilation )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91611",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\nThis API has very weird behavior, when I run it, it results in segmentation fault, then I run it for the second time, the segfault disappears. You can see the segfault by running multiple times. \r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([5, 5], dtype=torch.complex64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(-1,512,[5], dtype=torch.int16)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.rand([5, 1], dtype=torch.complex64)\r\narg_3 = arg_3_tensor.clone()\r\narg_4 = True\r\ntry:\r\n  res = torch.linalg.ldl_solve(arg_1,arg_2,arg_3,hermitian=arg_4,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nI get the following log messages:\r\n```\r\ncorrupted size vs. prev_size\r\nAborted\r\n```\r\nand\r\n```\r\nSegmentation fault\r\n```\r\n\r\n### ",
        "API Signature": "\n torch.linalg. ldl_solve ( LD ,  pivots ,  B ,  * ,  hermitian ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91633",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nWith the following input combinations, it results in segfault:\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([2, 4, 5, 5, 5], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_0 = 2\r\narg_2_1 = 2\r\narg_2_2 = 2\r\narg_2 = [arg_2_0,arg_2_1,arg_2_2,]\r\narg_3 = None\r\narg_4_0 = 0.5\r\narg_4_1 = 0.5\r\narg_4_2 = 0.5\r\narg_4 = [arg_4_0,arg_4_1,arg_4_2,]\r\narg_5 = False\r\narg_6_tensor = torch.tensor([], dtype=torch.float64)\r\narg_6 = arg_6_tensor.clone()\r\ntry:\r\n  res = torch.nn.functional.fractional_max_pool3d(arg_1,arg_2,arg_3,arg_4,arg_5,_random_samples=arg_6,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": "\n torch.nn.functional. fractional_max_pool3d ( * ,  ** ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91556",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\r\n\r\nWhen running torch.nn.AdaptiveMaxPool3d, it overflows with very large elements in input lists. \r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_0 = 125091515651\r\narg_1_1 = 125091515651\r\narg_1_2 = 125091515651\r\narg_1 = [arg_1_0,arg_1_1,arg_1_2,]\r\narg_class = torch.nn.AdaptiveMaxPool3d(arg_1,)\r\narg_2_0_tensor = torch.rand([2, 3, 5, 6, 7], dtype=torch.float64)\r\narg_2_0 = arg_2_0_tensor.clone()\r\narg_2 = [arg_2_0,]\r\ntry:\r\n  res = arg_class(*arg_2)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nLog message:\r\n\r\n```\r\nError:Storage size calculation overflowed with sizes=[2, 3, 125091515651, 125091515651, 125091515651]\r\n```\r\n\r\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91659",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([1, 3, 5, 7], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_0 = 2\r\narg_2_1 = 2\r\narg_2 = [arg_2_0,arg_2_1,]\r\narg_3 = None\r\narg_4_0 = 0.5\r\narg_4_1 = 0.5\r\narg_4 = [arg_4_0,arg_4_1,]\r\narg_5 = False\r\narg_6_tensor = torch.tensor([], dtype=torch.float64)\r\narg_6 = arg_6_tensor.clone()\r\ntry:\r\n  res = torch.nn.functional.fractional_max_pool2d(arg_1,arg_2,arg_3,arg_4,arg_5,_random_samples=arg_6,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": "\n torch.nn.functional. fractional_max_pool2d ( * ,  ** ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91589",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nI get unknown error when running torch.tensordot with the following input combinations:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([0, 0, 1, 2, 3, 0], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([1, 2, 3, 0], dtype=torch.float64)\r\narg_2 = arg_2_tensor.clone()\r\narg_3 = 95063276620\r\ntry:\r\n  res = torch.tensordot(arg_1,arg_2,dims=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nThe log message is:\r\n```\r\nError:\r\n\r\n```\n\n### ",
        "API Signature": "\n torch. tensordot ( a ,  b ,  dims ,  out ) [source] \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/91588",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nI get bad allocation error when running torch.combination with the following input arguments:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([2], dtype=torch.bfloat16)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = 102919646178\r\narg_3 = False\r\ntry:\r\n  res = torch.combinations(arg_1,r=arg_2,with_replacement=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\nLog message:\r\n\r\n```\r\nError:std::bad_alloc\r\n```\n\n### ",
        "API Signature": "\n torch. combinations ( input ,  r ,  with_replacement )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92776",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nProbably due to negative tensor.\r\n\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.rand([1, 0, 5, 5], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(-512,256,[1, 0], dtype=torch.int32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3 = True\r\ntry:\r\n  res = torch.lu_unpack(arg_1,arg_2,unpack_pivots=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": "\n torch. lu_unpack ( LU_data ,  LU_pivots ,  unpack_data ,  unpack_pivots ,  * ,  out ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92777",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nProbably due to zero list elements.\r\n```\r\nresults = dict()\r\nimport torch\r\narg_1_tensor = torch.rand([2, 3, 6, 4, 10], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_0 = 0\r\narg_2_1 = 0\r\narg_2_2 = 0\r\narg_2 = [arg_2_0,arg_2_1,arg_2_2,]\r\narg_3 = False\r\ntry:\r\n  results[\"res_cpu\"] = torch.nn.functional.adaptive_max_pool3d(arg_1,arg_2,arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\narg_1 = arg_1_tensor.clone().cuda()\r\narg_2 = [arg_2_0,arg_2_1,arg_2_2,]\r\ntry:\r\n  results[\"res_gpu\"] = torch.nn.functional.adaptive_max_pool3d(arg_1,arg_2,arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\nprint(results)\r\n```\n\n### ",
        "API Signature": "\n torch.nn.functional. adaptive_max_pool3d ( * ,  ** ) \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92778",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nProcess get killed when feeding negative large or even small tensors:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.neg(torch.rand([60000], dtype=torch.float16))\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.rand([60000, 1], dtype=torch.float64)\r\narg_2 = arg_2_tensor.clone()\r\ntry:\r\n  res = torch.normal(arg_1,arg_2,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": "\n torch. normal ( mean ,  std ,  * ,  generator ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92780",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nDue to negative tensor:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.neg(torch.rand([5], dtype=torch.float32))\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.neg(torch.rand([5, 0], dtype=torch.float16))\r\narg_2 = arg_2_tensor.clone()\r\ntry:\r\n  res = torch.Tensor.copy_(arg_1,arg_2,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92781",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nProbably due to zero argument:\r\n\r\n```\r\nresults = dict()\r\nimport torch\r\narg_1 = 0\r\narg_2 = True\r\narg_class = torch.nn.AdaptiveMaxPool3d(arg_1,return_indices=arg_2,)\r\narg_3_0_tensor = torch.rand([2, 2, 4, 4, 4], dtype=torch.float32)\r\narg_3_0 = arg_3_0_tensor.clone()\r\narg_3 = [arg_3_0,]\r\ntry:\r\n  results[\"res_cpu\"] = arg_class(*arg_3)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\narg_class = arg_class.cuda()\r\narg_3_0 = arg_3_0_tensor.clone().cuda()\r\narg_3 = [arg_3_0,]\r\ntry:\r\n  results[\"res_gpu\"] = arg_class(*arg_3)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\nprint(results)\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92782",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nProbably due to negative tensor:\r\n\r\n```\r\nresults = dict()\r\nimport torch\r\narg_1_tensor = torch.rand([5, 5], dtype=torch.float64)\r\narg_1 = arg_1_tensor.clone()\r\narg_2_tensor = torch.randint(-16384,2048,[5], dtype=torch.int32)\r\narg_2 = arg_2_tensor.clone()\r\narg_3_tensor = torch.neg(torch.rand([5, 1], dtype=torch.float64))\r\narg_3 = arg_3_tensor.clone()\r\narg_4 = False\r\ntry:\r\n  results[\"res_cpu\"] = torch.linalg.ldl_solve(arg_1,arg_2,arg_3,hermitian=arg_4,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\narg_1 = arg_1_tensor.clone().cuda()\r\narg_2 = arg_2_tensor.clone().cuda()\r\narg_3 = arg_3_tensor.clone().cuda()\r\ntry:\r\n  results[\"res_gpu\"] = torch.linalg.ldl_solve(arg_1,arg_2,arg_3,hermitian=arg_4,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\nprint(results)\r\n```\r\n\r\nLog message:\r\n\r\n```\r\n{'res_cpu': tensor([[-1.6075e-01],\r\n        [-3.7725e-01],\r\n        [-7.3882e-01],\r\n        [-1.0747e+00],\r\n        [5.5829e-322]], dtype=torch.float64), 'res_gpu': tensor([[-0.1607],\r\n        [-0.3772],\r\n        [-0.7388],\r\n        [-1.0747],\r\n        [ 0.0000]], device='cuda:0', dtype=torch.float64)}\r\nfree(): invalid next size (fast)\r\nAborted\r\n\r\n```\n\n### ",
        "API Signature": "\n torch.linalg. ldl_solve ( LD ,  pivots ,  B ,  * ,  hermitian ,  out )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92783",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\nProcess get killed even when feeding tensor with lower dimensions:\r\n\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\narg_1_tensor = torch.randint(-512,16384,[4], dtype=torch.int16)\r\narg_1 = arg_1_tensor.clone()\r\narg_2 = 17\r\narg_3 = False\r\ntry:\r\n  res = torch.combinations(arg_1,r=arg_2,with_replacement=arg_3,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n```\r\n\r\n\n\n### ",
        "API Signature": "\n torch. combinations ( input ,  r ,  with_replacement )   \u2192 \u00b6",
        "Bug fix": ""
    },
    {
        "Issue link": "https://api.github.com/repos/pytorch/pytorch/issues/92786",
        "Issue title": "",
        "Bug description": "",
        "Sample Code": "\n\n\r\n```\r\nresults = dict()\r\nimport torch\r\narg_1_tensor = torch.neg(torch.rand([100, 100, 100, 5, 5, 5], dtype=torch.complex64))\r\narg_1 = arg_1_tensor.clone()\r\ntry:\r\n  results[\"res_cpu\"] = torch.Tensor.coalesce(arg_1,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\narg_1 = arg_1_tensor.clone().cuda()\r\ntry:\r\n  results[\"res_gpu\"] = torch.Tensor.coalesce(arg_1,)\r\nexcept Exception as e:\r\n  print(\"Error:\"+str(e))\r\n\r\nprint(results)\r\n```\r\n\r\nLog message:\r\n\r\n```\r\nError:Could not run 'aten::is_coalesced' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::is_coalesced' is only available for these backends: [SparseCPU, SparseCUDA, SparseMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\r\n\r\nSparseCPU: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/build/aten/src/ATen/RegisterSparseCPU.cpp:1261 [kernel]\r\nSparseCUDA: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/build/aten/src/ATen/RegisterSparseCUDA.cpp:1422 [kernel]\r\nSparseMeta: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/build/aten/src/ATen/RegisterSparseMeta.cpp:249 [kernel]\r\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\r\nPython: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\r\nFuncTorchDynamicLayerBackMode: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\r\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]\r\nNamed: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\r\nConjugate: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\r\nNegative: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\r\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\r\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\r\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradHIP: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradIPU: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradVE: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradMeta: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradNestedTensor: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nTracer: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/TraceType_2.cpp:16890 [kernel]\r\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\r\nAutocastCUDA: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\r\nFuncTorchBatched: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\r\nFuncTorchVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\r\nBatched: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\r\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\nFuncTorchGradWrapper: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\r\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\r\nFuncTorchDynamicLayerFrontMode: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\r\nPythonDispatcher: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\r\n\r\nError:Could not run 'aten::is_coalesced' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::is_coalesced' is only available for these backends: [SparseCPU, SparseCUDA, SparseMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\r\n\r\nSparseCPU: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/build/aten/src/ATen/RegisterSparseCPU.cpp:1261 [kernel]\r\nSparseCUDA: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/build/aten/src/ATen/RegisterSparseCUDA.cpp:1422 [kernel]\r\nSparseMeta: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/build/aten/src/ATen/RegisterSparseMeta.cpp:249 [kernel]\r\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\r\nPython: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\r\nFuncTorchDynamicLayerBackMode: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\r\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]\r\nNamed: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\r\nConjugate: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\r\nNegative: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\r\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\r\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\r\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradHIP: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradIPU: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradVE: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradMeta: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nAutogradNestedTensor: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\r\nTracer: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/autograd/generated/TraceType_2.cpp:16890 [kernel]\r\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\r\nAutocastCUDA: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\r\nFuncTorchBatched: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\r\nFuncTorchVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\r\nBatched: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\r\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\nFuncTorchGradWrapper: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\r\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\r\nFuncTorchDynamicLayerFrontMode: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\r\nPythonDispatcher: registered at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\r\n\r\n```\n\n### ",
        "API Signature": null,
        "Bug fix": ""
    }
]
