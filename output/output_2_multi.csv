https://github.com/pytorch/pytorch/commit/b6920405da340bbd3397b80bf16d9c360b0c48d2,"static bool check_has_torch_dispatch(PyObject *obj) {
  PyTypeObject *tp = Py_TYPE(obj);
  py::object attr = PyObject_FastGetAttrString(obj, ""__torch_dispatch__"");
  return (
    !THPVariable_CheckTypeExact(tp) &&
    attr.ptr() != nullptr &&
    attr.ptr() != torch::disabled_torch_dispatch_impl()
  );
}"
https://github.com/pytorch/pytorch/commit/157d478a30f27fd9d866c1235841721a559c8d0b,"```python
for j in range(index.ndim):
    if k + j < len(self.shape):  # Check if the index is within the shape of the object
        check(
            index[j] <= self.shape[k + j],
            lambda: f""The shape of the mask {index.shape} at index {i} ""
                    f""does not match the shape of the indexed tensor {self.shape} at index {k + j}"",
            IndexError
        )
        result.append(nonzero.select(1, j))
    else:
        raise IndexError(""Index out of bounds for the object's shape"")
```"
https://github.com/tensorflow/tensorflow/commit/9f8ad5ff118166537d42f87f1ee254f83ba553f0,"```cpp
port::StatusOr<std::vector<uint8>> LinkGpuAsm(
    gpu::GpuContext* context, std::vector<CubinOrPTXImage> images) {
  const bool linking_supported = [] {
    if (CUDA_VERSION < 11000) { // assuming CUDA 11.0 is represented as 11000
      return true;
    }
    auto version_or_status = gpu::Diagnostician::FindKernelDriverVersion();
    if (!version_or_status.ok()) {
      LOG(WARNING) << ""Couldn't read CUDA driver version."";
      return false;
    }
    // Additional logic based on CUDA version if needed
    return true;
  }();
  // Additional code using linking_supported variable
  // Additional code logic
}
```"
https://github.com/pytorch/pytorch/commit/c99277e177cf16736262251c7e92ea5e9ba2c5c2,"@register_acc_op
def sum(*, input, dim=None, keepdim=False, dtype=None):
    if dim is not None:
        return torch.sum(input, dim=dim, keepdim=keepdim, dtype=dtype)
    else:
        return input.sum(dtype=dtype)"
https://github.com/tensorflow/tensorflow/commit/1908d7ef706f0f3f8c7a300068355bf795fb3d17,"while (utf8_chars_counted < num_utf8_chars_to_shift && *pos < size) {
    do {
      if (*pos < size && IsTrailByte(in[*pos])) {
        ++*pos;
      } else {
        break;
      }
    } while (true);
    ++utf8_chars_counted;
}
return utf8_chars_counted == num_utf8_chars_to_shift;"
https://github.com/tensorflow/tensorflow/commit/a0ca4bcb81dfd07fdb1c7872b5852f84cfc1a081,"outputs = nn.bias_add(
        outputs,
        self.bias,
        data_format=utils.convert_data_format(self.data_format, ndim=4))

if self.activation is not None:
    outputs = self.activation(outputs)"
https://github.com/pytorch/pytorch/commit/6b4c686b9a33a1503a4a4133f9067dd31e0822f7,"    def generate_load_kernel_once(
        self, name: str, mangled_name: str, cubin_path: str, shared_mem: int
    ):
        if not hasattr(self, name):  # Check if the kernel pointer has already been initialized
            if V.graph.aot_mode:
                self.writeline(
                    f""""""kernels.{name} = loadKernel(""{cubin_path}"", ""{mangled_name}"", {shared_mem}, this->cubin_dir_);""""""
                )
            else:
                self.writeline(
                    f""""""{name} = loadKernel(""{cubin_path}"", ""{mangled_name}"", {shared_mem});""""""
                )

    def generate_args_decl(self, call_args):
        dynamic_symbols = V.graph.sizevars.free_symbols()
        new_args = []
        for arg in call_args:
            # Existing code for generating arguments declaration
            pass
        <answer end>"
https://github.com/tensorflow/tensorflow/commit/cb164786dc891ea11d3a900e90367c339305dc7b,"ret = full_type::SpecializeType(attrs_, op_def);
if (!ret.status().ok()) {
  // Handle error case appropriately, e.g. log an error message or throw an exception
}
ret_types_ = ret.ValueOrDie();

input_tensors_ = input_tensors;
input_tensors_as_shapes_ = input_tensors_as_shapes;

construction_status_ = "
https://github.com/tensorflow/tensorflow/commit/653d47379b3a716f82058148c35b2f491bfa2856,"void UnpackDenseInt4IntoInt8(const int8_t* src_buffer, int num_elements,
                             int8_t* dst_buffer) {
  for (int i = 0; i < num_elements; i += 2) {
    dst_buffer[i] = static_cast<int8_t>(src_buffer[i / 2] << 4) >> 4;
    if (i + 1 == num_elements) break;
    dst_buffer[i + 1] = static_cast<int8_t>(src_buffer[i / 2]) >> 4;
  }
}
    </answer>"
https://github.com/pytorch/pytorch/commit/f02b7a9c36dd6182da694bc47a5c345285dfd951,"```cpp
if (mode == at::padding_mode::constant) {
    if (value.has_value()) {
        return at::constant_pad_nd(self, pad, value.value());
    } else {
        return at::constant_pad_nd(self, pad, 0.0);
    }
}

TORCH_CHECK(
    !value.has_value(), ""Padding mode \"""",
    padding_mode_string(mode),
    ""\"" doesn't take in value argument"");

if (pad.size() == 2 && (input_dim == 2 || input_dim == 3)) {
    switch (mode) {
        case at::padding_mode::reflect: return at::reflection_pad1d(self, pad);
        case at::padding_mode::replicate: return at::replication_pad1d(self, pad);
        case at::padding_mode::circular: return at::_pad_circular(self, pad);
    }
}
```"
https://github.com/tensorflow/tensorflow/commit/c7f79bb75b5b83c3011e164ccd617a6ada910ea4,"```cpp
      }
      const auto& stored = detail->outputs[slot];
      const auto& current = output.tensor_description();
      bool do_shapes_match = true;
      if (stored.shape().dim_size() != current.shape().dim_size()) {
        do_shapes_match = false;
      } else {
        for (int i = 0; i < stored.shape().dim_size(); ++i) {
          if (stored.shape().dim(i).size() != current.shape().dim(i).size()) {
            do_shapes_match = false;
          }
        }
      }

      if ((stored.dtype() != current.dtype()) || !do_shapes_match) {
        LOG(WARNING) << ""Output tensor changed between runs for '""
                     << ns.node_name();
      }
    }
  }
}
```"
https://github.com/pytorch/pytorch/commit/63cbdc92a750a667ffdcfbdac563d02db6fd9559,"```cpp
namespace torch {
inline bool is_symint_node(py::handle obj) {
  auto static tp_symn = py::type::of<c10::SymIntNodeImpl>();
  if (py::isinstance(obj, tp_symn)) {
    TORCH_CHECK(
        !jit::tracer::isTracing(), ""JIT tracing of SymInts isn't supported!"");
    return true;
  }
  return false;
}
```"
https://github.com/pytorch/pytorch/commit/babb28d2a3a755424f72518bc360d9f511a24463,"
```cpp
for (int i = 0; i < N; ++i) {
    const float* label_data = T.data<float>();
    for (int j = 0; j < D; ++j) {
        CAFFE_ENFORCE(
            label_data[i * D + j] >= 0,
            ""Label prob seems incorrect: label prob value must be nonnegative: "",
            label_data[i * D + j]);
        float l = 0.0;
        float total_prob = 0.0;
        float weight = weights ? weights[i] : 1.0;
        l += -log(std::max(Pdata[i * D + j], 1e-20f)) * label_data[i * D + j] * weight;
        total_prob += label_data[i * D + j];
        loss_sum += l;
        weight_sum += weight;
    }
}

avg_loss->Resize(vector<TIndex>());
float* avg_loss_data = avg_loss->mutable_data<float>();
```"
https://github.com/pytorch/pytorch/commit/be253b8ee8a104997773d11ed28928a48193217d,"```cpp
  for (int64_t i = dim - 1; i >= 0; i--) {
    if (sizes[i] == 0) {
      return true;
    }
    if (strides[i] != expected_stride) {
      contig_if_nonempty = false;
    }
    expected_stride *= sizes[i];
  }

  return contig_if_nonempty;
}
```"
https://github.com/tensorflow/tensorflow/commit/5bc536f1afbaff5d3d5a14a9185cd1e3cc31b302,"if (!shaped_type || !shaped_type.hasStaticShape()) {
  return false;
}
if (index == 0) {
  shape = shaped_type.getShape();
} else {
  if (shape != shaped_type.getShape()) {
    return false;
  }
}
index++;"
https://github.com/tensorflow/tensorflow/commit/9a4b6b6bcc7a813162bf0378727950e321aca19c,"def imag(input, name=None):
    if input.dtype.is_complex:
        real_dtype = input.dtype.real_dtype
        return gen_math_ops.imag(input, Tout=real_dtype, name=name)
    elif tf.debugging.is_numeric_tensor(input) or tf.debugging.is_complex(input):
        return tf.zeros_like(input)
    else:
        raise TypeError(""input must be a numeric tensor, but got tensor with dtype {}"".format(input.dtype))"
https://github.com/pytorch/pytorch/commit/a9deda5469a6ef73692a9dd796cc4eeba4436d6c,"```python
min_indices = indices.min(dim=1, keepdim=False)[0]
max_indices = indices.max(dim=1, keepdim=False)[0]
cpu_min_indices = min_indices.to(indices.device)
cpu_max_indices = max_indices.to(indices.device)
```"
https://github.com/pytorch/pytorch/commit/ee91c328da5739ce03b3127cd7c542ce505212b8,"```python
if any(x is not None and not (x.is_cuda or 'cpu' in str(x.device)) for x in tensor_args):
    why_not_fast_path = ""some Tensor argument is neither CUDA nor CPU""
elif torch.is_grad_enabled() and any(x is not None and x.requires_grad for x in tensor_args):
    why_not_fast_path = (""grad is enabled and at least one of query or the ""
                         ""input/output projection weights or biases requires_grad"")
if not why_not_fast_path:
    merged_mask, mask_type = self.merge_masks(attn_mask, key_padding_mask, query)
```"
https://github.com/tensorflow/tensorflow/commit/c9b4689bc4d4024aa16b7d6cfc1c65fa1ed8486e,"if not graph and context.executing_eagerly():
    graph = ops.get_default_graph()

  if options == _DEFAULT_ADVISE_OPTIONS:
    options = ALL_ADVICE.copy()"
https://github.com/tensorflow/tensorflow/commit/2f3b69e4976d3b14eaa6ae070eb68f37d1556d98,"```python
if (isinstance(checkpointable_object, data_structures.CheckpointableDataStructure) and
    not checkpointable_object.variables):
    continue
  self._checkpoint.all_python_objects.add(checkpointable_object)
unused_python_objects = (
    _ObjectIdentitySet(self._checkpoint.all_python_objects)
    - _ObjectIdentitySet(self._checkpoint.object_by_proto_id.values()))
if unused_python_objects:
```"
https://github.com/tensorflow/tensorflow/commit/4a1d1c8413a3752af7dc91a7128e202660b0f05c,"REGISTER_OP(""SampleDistortedBoundingBox"")
    .Input(""image_size: T"")
    .Input(""bounding_boxes: float"")
    .Attr(""T: {int32, int64}"")
    .SetShapeFn([](shape_inference::InferenceContext* c) {
      shape_inference::ShapeHandle images;
      TF_RETURN_IF_ERROR(WithRank(c->input(0), 4, &images));

      c->set_output(0, c->Matrix(c->UnknownDim(), 4));
      c->set_output(1, c->Matrix(c->UnknownDim(), 4));
      c->set_output(2, c->Matrix(c->UnknownDim(), 1));
      
      return Status::OK();
    });"
https://github.com/tensorflow/tensorflow/commit/c7c4a42c4372ca560ea415fe3a798e18286cedec,"```python
    if input_tensor is not None and hasattr(input_tensor, 'dtype') and input_tensor.dtype != dtype:
        raise ValueError('`input_tensor.dtype` differs from `dtype`.')

    super(InputLayer, self).__init__(dtype=dtype, name=name)
    self.built = True
    self.sparse = sparse
    self.batch_size = batch_size
    self.supports_masking = True
```"
https://github.com/tensorflow/tensorflow/commit/9c92b50fc4b95985a0749101976d04896bf19bfe,"const TfLiteTensor* bias = GetInput(context, node, 3);

if (bias) {
  TF_LITE_ENSURE(context, bias->dims->size == 1);
  TF_LITE_ENSURE_EQ(context, bias->dims->data[0], filter->dims->data[3]);
}

if (params->dilation_depth_factor > 1 || params->dilation_height_factor > 1 ||
    params->dilation_width_factor > 1) {
  kernel_type = kReference;
}"
https://github.com/tensorflow/tensorflow/commit/1ff493ed1a2059f82f7607a7f0a0aa2ce8d5a542,"```cpp
DCHECK(out_can_pick_device != nullptr);
DCHECK(out_device_picked != nullptr);

absl::flat_hash_set<absl::string_view> device_names_set;
for (absl::string_view device_name : device_names) {
  if (!device_name.empty()) {
    device_names_set.insert(device_name);
  }
}

absl::optional<absl::string_view> maybe_gpu_device;
absl::optional<absl::string_view> maybe_cpu_device;
absl::optional<absl::string_view> maybe_unknown_device;
```"
https://github.com/tensorflow/tensorflow/commit/b68b869e75916e6de37c2ca23a93643faf333011,"```python
self._batch_input_shape = batch_input_shape
else:
    raise_eager_tensor_error = False
    if keras_tensor.keras_tensors_enabled():
        if not isinstance(input_tensor, keras_tensor.Tensor): 
            raise_eager_tensor_error = True
    else:
        if not tf_utils.is_symbolic_tensor(input_tensor):
            raise_eager_tensor_error = True
    if raise_eager_tensor_error:
        raise ValueError('You should not pass an EagerTensor to `Input`. ')
```"
https://github.com/pytorch/pytorch/commit/bede7d999523d02e636a8981c0dff233b67f1a62,"const char* getAttributeName(AttributeKind kind) {
    const char* names[] = {""gs"",
                            ""ty"",
                            ""tys"",
                            ""ival""};
    
    assert(static_cast<size_t>(kind) < sizeof(names) / sizeof(names[0]));
    
    return names[int(kind)];
}

struct AttributeValue {
    AttributeValue(AttributeKind kind) : kind(kind) {}
    using Ptr = std::unique_ptr<AttributeValue>;
    AttributeKind kind;
};

int main() {
    AttributeValue::Ptr attribute = std::make_unique<AttributeValue>(gs);
    std::cout << ""Attribute name: "" << getAttributeName(attribute->kind) << std::endl;

    return 0;
}"
https://github.com/tensorflow/tensorflow/commit/8a2e7deb21f02e4072d6b62cf7f447b9264afe01,"```python
  if isinstance(tensors, tf.Tensor):
    return apply_fn(tensors)
  elif isinstance(tensors, tf.Variable):
    return apply_fn(tensors.value())
  elif isinstance(tensors, (list, tuple)):
    tensors = [_recursive_apply(t, apply_fn) for t in tensors]
    if isinstance(tensors, list):
    <answer end>
```"
https://github.com/pytorch/pytorch/commit/0584fd9339af7c939ab7d955db05743ba58ff86d,"if node.op == 'call_function':
        if node.target in fixed_qparam_ops and not isinstance(node.args[0], torch.nn.modules.activation.CopyNode):
            if activation_dtype(qconfig) == torch.float16:
                insert_observer(
                    node, qconfig.activation(),
                    model, activation_post_process_map, env, observed_graph,
                    load_arg, observed_node_names_set)
            else:
                insert_observer(
                    node, qconfig.activation(),
                    model, activation_post_process_map, env, observed_graph,
                    load_arg, observed_node_names_set)
  </answer>"
https://github.com/pytorch/pytorch/commit/0c0c9e743e82b398435ed07719e998aa15ac1ce1,"    const int M = FIRSTDIMS
        ? input.size_to_dim(num_reduce_dims_)
        : input.size_to_dim(input.ndim() - num_reduce_dims_);
    const int N = FIRSTDIMS
        ? input.size_from_dim(num_reduce_dims_)
        : input.size_from_dim(input.ndim() - num_reduce_dims_);

    const auto* input_data = input.template data<T>();
    "
https://github.com/pytorch/pytorch/commit/e9c1ccee2247a7746fde202067a7d47b72809968,"```cpp
Tensor& normal_meta_(Tensor& self, double mean, double std, c10::optional<Generator> gen) {
  // TORCH_CHECK(std > 0.0, ""normal_ expects std > 0.0, but found std="", std);  // TODO: dedupe
  return self;
}

Tensor& normal_out(const Tensor& mean, double std, c10::optional<Generator> gen, Tensor& output) {
  return at::native::templates::normal_out_impl<NormalStub, Generator>(output, mean, std, gen);
}
```"
https://github.com/tensorflow/tensorflow/commit/076f909b70b251daea6c443c9b1929b9745aed20,"for (int i = 1; i < element_dims.size(); i++) {
    OP_REQUIRES(ctx, element_dims[i] == 1,
                errors::Unimplemented(""All dimensions except the first one must be 1""));
}"
https://github.com/pytorch/pytorch/commit/c1384ef99e7a0d8a439df8972532fe4f155a5683,"```cpp
      setTensorDescriptor<T>(X.ndim(), order_, N, C, H, W, D, bottom_desc_);
      setTensorDescriptor<T>(
          Y.ndim(), order_, N, C, H_out, W_out, D_out, top_desc_);
      if (pad_t() != pad_b() || pad_l() != pad_r()) {
        CAFFE_ENFORCE(
            legacy_pad_ == LegacyPadding::CAFFE_LEGACY_POOLING,
            ""Cudnn pooling only supports symmetric padding on both sides, with ""
            ""the only exception of the Caffe legacy pooling case where we ""
            ""try to preserve backward compatibility with Caffe."");
      }
      if (kernel_.size() == 2) {
        CUDNN_ENFORCE(cudnnSetPooling2dDescriptor(
            pooling_desc_,
            mode_,
            CUDNN_NOT_PROPAGATE_NAN,
```
"
https://github.com/pytorch/pytorch/commit/611080a118fff166c85f3200d860f3b059abac6f,"```cmake
if(CUDA_VERSION VERSION_LESS ""11.1"")
    set(CUDA_LIMIT_GPU_ARCHITECTURE ""8.6"")
    list(APPEND CUDA_COMMON_GPU_ARCHITECTURES ""8.0+PTX"")
endif()

if(CUDA_VERSION VERSION_GREATER ""11.0"")
    list(APPEND CUDA_COMMON_GPU_ARCHITECTURES ""8.6"" ""8.6+PTX"")
    list(APPEND CUDA_ALL_GPU_ARCHITECTURES ""8.6"")

    if(CUDA_VERSION VERSION_LESS ""12.0"")
        set(CUDA_LIMIT_GPU_ARCHITECTURE ""9.0"")
    endif()
endif()
```"
https://github.com/tensorflow/tensorflow/commit/58759659ee547a957c5d36e72f2274ab34fdb6cb,"```cpp
  const int64 result_index = compile_result.aot->result_buffer_index();
  const xla::BufferSizes& temp_sizes = compile_result.aot->buffer_sizes();
  if (result_index < 0 || result_index >= temp_sizes.size()) {
    return errors::InvalidArgument(""result index: "", result_index,
                                   "" is outside the range of temp sizes: [0,"",
                                   temp_sizes.size(), "")"");
  }
```"
https://github.com/tensorflow/tensorflow/commit/be5116dd131a92da298dbb68d26e0d47f66f2fe5,"```python
def _BroadcastToGrad(op, grad):
    input_value = op.inputs[0]
    broadcast_shape = op.inputs[1]
    input_value_shape = array_ops.shape(input_value)
    if not context.executing_eagerly() and broadcast_shape.shape.is_fully_defined():
        broadcast_shape = broadcast_shape
```"
https://github.com/pytorch/pytorch/commit/b8ab3080b1043a610ba2825a2be406a1833b1d70,"if (helper.HasArgument(""kernel_h"") && helper.HasArgument(""kernel_w"")) {
  kernel.push_back(helper.GetSingleArgument<int>(""kernel_h"", 1));
  kernel.push_back(helper.GetSingleArgument<int>(""kernel_w"", 1));
} else {
  kernel.resize(2, helper.GetSingleArgument<int>(""kernel"", 1));
}

if (helper.HasArgument(""stride"")) {
  strides.resize(2, helper.GetSingleArgument<int>(""stride"", 1));
}"
https://github.com/tensorflow/tensorflow/commit/d23458fdd2655c83ff9d54725062ded31b644ba4,"```cpp
  if (allocation.is_entry_computation_parameter()) {
    se::DeviceMemoryBase out = arguments[allocation.parameter_number()]
                                   .Buffer(allocation.param_shape_index())
                                   .AsDeviceMemoryBase();
    CHECK_GE(out.size(), allocation.size())
        << ""Size mismatch on param "" << allocation.parameter_number()
        << "" at shape index "" << allocation.param_shape_index().ToString();
    VLOG(3) << ""allocation is a parameter"";
    return MaybeOwningDeviceMemory{out};
  } else if (allocation.is_constant()) {
    VLOG(3) << ""allocation is a constant"";
```"
https://github.com/pytorch/pytorch/commit/91066559a8c8e5978ed4de722317576b222267c5,"```python
assert isinstance(prefix, basestring), ""NameScope takes in a string as its argument.""
old_scope = CurrentNameScope()
prefix = prefix + _NAMESCOPE_SEPARATOR if prefix else ''
if reset:
    _threadlocal_scope.namescope = prefix
else:
    _threadlocal_scope.namescope = _threadlocal_scope.namescope + prefix
```"
https://github.com/tensorflow/tensorflow/commit/9a0de0ca6a39f3037e1be6ec740829863bcda3e8,"```cpp
bool IsMatrixMultiplication(OpType output_primitive_type,
                            const Shape& lhs_shape,
                            const Shape& rhs_shape,
                            const Shape& dot_shape,
                            const DimNumbers& dim_numbers) {
  bool type_is_allowed =
      (output_primitive_type == F16 || output_primitive_type == BF16 ||
       output_primitive_type == F32 || output_primitive_type == F64 ||
       output_primitive_type == C64 || output_primitive_type == C128) ||
      (output_primitive_type == S32 && lhs_shape.element_type() == S8 &&
       rhs_shape.element_type() == S8);

  bool shapes_are_valid =
      type_is_allowed &&
      IsRank2(lhs_shape, dim_numbers.lhs_batch_dimensions_size()) &&
      IsRank2(rhs_shape, dim_numbers.lhs_batch_dimensions_size()) &&
      IsRank2(dot_shape, dim_numbers.lhs_batch_dimensions_size()) &&
      !ShapeUtil::IsZeroElementArray(lhs_shape) &&
      !ShapeUtil::IsZeroElementArray(rhs_shape);
  
  return shapes_are_valid;
}
```"
https://github.com/tensorflow/tensorflow/commit/c2ff14318050e26302785a49a1719d29ddcc91b4,"```c
if (begin[i] + size[i] > input_shape->data[i]) {
  TF_LITE_MAYBE_KERNEL_LOG(logging_context,
                           ""begin + size (%"" PRId64 "" + %"" PRId64
                           "") must be less input ""
                           ""dimension %d in SLICE node #%d"",
                           begin[i], size[i], input_shape->data[i],
                           node_index);
  return kTfLiteError;
}
```"
https://github.com/tensorflow/tensorflow/commit/bd1f1ac1fec05d38f1b8fc98f650c1c55ac06790,"if operator_a is not None and operator_b is not None:
    if operator_a.is_square is not None and operator_b.is_square is not None:
        if operator_a.is_square != operator_b.is_square:
            return False

return None"
https://github.com/tensorflow/tensorflow/commit/48393637f8154be16088d84742485a0e153ecbb2,"if (dims.size() > 6) {
  LOG(FATAL) << ""dims vector can be no larger than 6 values"";
  return;
}
```"
https://github.com/tensorflow/tensorflow/commit/1a1a381b5be7701843c3f1e34aa1846ae2a1d0ce,"if (!attr) {
    return false;
}"
https://github.com/pytorch/pytorch/commit/9234f5026dbaf09a41b82bb6cf5f10ad4eeb03f2,"```cpp
bool ProcessGroupNCCL::WorkNCCL::finishedGPUExecutionInternal() const {
  for (size_t i = 0; i < devices_.size(); ++i) {
    if ((*cudaEvents_)[i] == nullptr) {
      return false;
    }

    auto ret = cudaEventQuery((*cudaEvents_)[i]);
    if (ret != cudaSuccess && ret != cudaErrorNotReady) {
      AT_CUDA_CHECK(ret);
    }
    if (ret == cudaErrorNotReady) {
      return false;
    }
  }
  return true;
}
```"
https://github.com/pytorch/pytorch/commit/5023995292f5119c447de15c20a375b7e3aa2d0b,"```python
for (int j = 0; j < MAX_DIMS; j++) {
    if (j >= real_shape.rank()) {
        begin_ptr[j] = 0;
        end_ptr[j] = -1;
    } else {
        begin_ptr[j] = 0;
        if (max_shape[j] > real_shape.dims(j)) {
            end_ptr[j] = real_shape.dims(j);
            mismatch += 1;
        } else {
            end_ptr[j] = -1;
        }
    }
}
```"
https://github.com/pytorch/pytorch/commit/b2d110447190abe5d66b0b59a775cc4881f3e30e,"```python
self.head_dim = embed_dim // num_heads
assert embed_dim % num_heads == 0, ""embed_dim must be divisible by num_heads""

if not self._qkv_same_embed_dim:
    self.q_proj_weight = Parameter(torch.empty((embed_dim, embed_dim), **factory_kwargs))
    self.k_proj_weight = Parameter(torch.empty((embed_dim, embed_dim // num_heads), **factory_kwargs))
    self.v_proj_weight = Parameter(torch.empty((embed_dim, embed_dim // num_heads), **factory_kwargs))
    self.register_parameter('in_proj_weight', None)
else:
    self.in_proj_weight = Parameter(torch.empty((3 * embed_dim, embed_dim), **factory_kwargs))
```"
https://github.com/tensorflow/tensorflow/commit/4a343043dbc6ce229b4dcf2258f7b6352db32b64,"```python
def main():
    parser = create_parser()
    args = parser.parse_args()
    if not hasattr(args, 'func'):
        parser.error(""too few arguments"")
    args.func(args)

if __name__ == '__main__':
    sys.exit(main())
```"
https://github.com/pytorch/pytorch/commit/bbb5e106ad6228953df6c7f5c8916b26dc0cb457,"  using arg0_t = typename traits::result_type;
  constexpr int ntensors = traits::arity + 1;

  at::detail::Array<char*, ntensors> data;
  for (int i = 0; i < ntensors; i++) {
    if (i < traits::arity) {
      TORCH_INTERNAL_ASSERT(iter.can_use_32bit_indexing(i));
    } else {
      TORCH_INTERNAL_ASSERT(iter.ntensors() == traits::arity + 1);
    }
    
    data[i] = (char*)iter.data_ptr(i);
  }
  "
https://github.com/tensorflow/tensorflow/commit/25821f0d91623d654bb1bdd62423e644bae9f7f8,"if (params.depth_window > 1) {
      OP_REQUIRES(context, params.out_depth % params.depth_window == 0,
                  errors::Unimplemented(
                      ""Depthwise max pooling requires ""
                      ""the depth window to evenly divide the input depth.""));
      OP_REQUIRES(
          context, params.out_depth == params.depth_stride,
          errors::Unimplemented(""Depthwise max pooling requires ""
                                ""the depth window to equal the depth stride.""));

      DepthwiseMaxPool(context, output, tensor_in, params);
    } else {
      SpatialMaxPool(context, output, tensor_in, params, padding_);
    }"
https://github.com/tensorflow/tensorflow/commit/3a7b36bca7f43ce4f0d0791ce0e0d84ece8683d9,"bool CanDedupControlWithRegularInput(const MutableGraphView& graph, absl::string_view control_node_name) {
    NodeDef* control_node = graph.GetNode(control_node_name);
    if (control_node == nullptr) {
        return false;
    }

    return CanDedupControlWithRegularInput(graph, *control_node);
}

bool HasRegularFaninNode(const MutableGraphView& graph, const NodeDef& node, absl::string_view fanin_node_name) {
    const int num_regular_fanins = node.regular_fanin_size();
    if (num_regular_fanins < 0) {
        return false;
    }

    for (int i = 0; i < num_regular_fanins; ++i) {
        const NodeDef& fanin_node = graph.GetRegularFanin(node, i);
        if (fanin_node.name() == std::string(fanin_node_name)) {
            return true;
        }
    }

    return false;
}
"
