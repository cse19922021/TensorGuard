[{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/ee50d1e00f81f62a4517453f721c634bbb478307",
    "API Name": "tensorflow.python.ops.nn_ops.fractional_avg_pool_v2",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "nn_ops.fractional_avg_pool_v2 and nn_ops.fractional_max_pool_v2 require the first and fourth elements of their parameter pooling_ratio to be equal to 1.0, as pooling on batch and channel dimensions is not supported.",
    "Backend Root Cause": "Lack of validating tensor malformed shape values received from front-end",
    "Vulnerability Impact": "Double Free",
    "Vulnerability Fixing Commit Description": "Update macro checker to check shape compatibility",
    "Vulnerable Code": [
        "    }",
        "    OP_REQUIRES(",
        "        context, pooling_ratio_[0] == 1 || pooling_ratio_[3] == 1,",
        "        errors::Unimplemented(\"Fractional average pooling is not yet \"",
        "                              \"supported on the batch nor channel dimension.\"));",
        "    OP_REQUIRES_OK(context, context->GetAttr(\"deterministic\", &deterministic_));",
        "    OP_REQUIRES_OK(context, context->GetAttr(\"seed\", &seed_));"
    ],
    "Clean Code": [
        "    }",
        "    OP_REQUIRES(",
        "        context, pooling_ratio_[0] == 1 && pooling_ratio_[3] == 1,",
        "        errors::Unimplemented(\"Fractional average pooling is not yet \"",
        "                              \"supported on the batch nor channel dimension.\"));",
        "    OP_REQUIRES_OK(context, context->GetAttr(\"deterministic\", &deterministic_));",
        "    OP_REQUIRES_OK(context, context->GetAttr(\"seed\", &seed_));"
    ],
    "Added_Lines": "+        context, pooling_ratio_[0] == 1 && pooling_ratio_[3] == 1,\n",
    "Deleted Lines": "-        context, pooling_ratio_[0] == 1 || pooling_ratio_[3] == 1,\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/da66bc6d5ff466aee084f9e7397980a24890cd15",
    "API Name": "tf.raw_ops.ParallelConcat",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "When running with XLA, tf.raw_ops.ParallelConcat segfaults with a nullptr dereference when given a parameter shape with rank that is not greater than zero.",
    "Backend Root Cause": "Lack of validating tensor malformed shape values received from front-end",
    "Vulnerability Impact": "Null dereference",
    "Vulnerability Fixing Commit Description": "Check for unexpected scalars in the shape argument to ParallelConcat. ",
    "Vulnerable Code": [
        "        }",
        "        DimensionHandle unused;",
        "        if (!c->WithValue(c->Dim(c->input(i), 0), 1, &unused).ok()) {",
        "          return errors::InvalidArgument(\"Size of first dimension must be 1.\");",
        "        }",
        "        TF_RETURN_WITH_CONTEXT_IF_ERROR(c->Merge(c->input(i), cur, &cur),",
        "                                        \"From merging shape \", i,",
        "                                        \" with other shapes.\");",
        "      }",
        "",
        "      c->set_output(0, passed_shape);",
        ""
    ],
    "Clean Code": [
        "              \"All input shapes must be fully defined.\");",
        "        }",
        "        if (c->Rank(c->input(i)) < 1) {",
        "          return errors::InvalidArgument(",
        "              \"The rank of all input shapes must be greater than 0, \"",
        "              \"but input \",",
        "              i, \" had rank \", c->Rank(c->input(i)), \".\");",
        "        }",
        "        DimensionHandle unused;",
        "        if (!c->WithValue(c->Dim(c->input(i), 0), 1, &unused).ok()) {",
        "          return errors::InvalidArgument(\"Size of first dimension must be 1.\");",
        "        }"
    ],
    "Added_Lines": "+#include <vector>\n+        if (c->Rank(c->input(i)) < 1) {\n+          return errors::InvalidArgument(\n+              \"The rank of all input shapes must be greater than 0, \"\n+              \"but input \",\n+              i, \" had rank \", c->Rank(c->input(i)), \".\");\n+        }\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/728113a3be690facad6ce436660a0bc1858017fa",
    "API Name": "tf.raw_ops.RandomShuffle",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "Feeding negative integer value as the length value",
    "Backend Root Cause": "Lack of validating if All lengths must be positive",
    "Vulnerability Impact": "Null dereference",
    "Vulnerability Fixing Commit Description": "Update macro checker to only accept positive integer value for the length",
    "Vulnerable Code": [
        "                  errors::Unimplemented(\"All lengths have to be the same\"));",
        "    }",
        "    OP_REQUIRES(",
        "        ctx, element_dims[0] % length == 0,",
        "        errors::Unimplemented(\"Buffer size has to be a multiple of length\"));",
        "    std::vector<int64_t> new_dims = {element_dims[0] / length, length};",
        "    for (int i = 1; i < element_dims.size(); i++) {",
        "      new_dims.push_back(element_dims[i]);"
    ],
    "Clean Code": [
        "                  errors::Unimplemented(\"All lengths have to be the same\"));",
        "    }",
        "    OP_REQUIRES(ctx, length,",
        "                errors::Unimplemented(\"All lengths must be positive\"));",
        "    OP_REQUIRES(",
        "        ctx, element_dims[0] % length == 0,",
        "        errors::Unimplemented(\"Buffer size has to be a multiple of length\"));",
        "    std::vector<int64_t> new_dims = {element_dims[0] / length, length};"
    ],
    "Added_Lines": "+    OP_REQUIRES(ctx, length,\n+                errors::Unimplemented(\"All lengths must be positive\"));\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/980b22536abcbbe1b4a5642fc940af33d8c19b69",
    "API Name": "tf.raw_ops.LookupTableImportV2",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "The function tf.raw_ops.LookupTableImportV2 cannot handle scalars in the values parameter and gives an NPE.",
    "Backend Root Cause": "Lack of validating if the backend can handle scalar values",
    "Vulnerability Impact": "Null dereference",
    "Vulnerability Fixing Commit Description": "Fixes shape inference of LookupTableImportV2 to handle scalar values. ",
    "Vulnerable Code": [
        "      ShapeHandle keys;",
        "      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &keys));",
        "      DimensionHandle unused;",
        "      TF_RETURN_IF_ERROR(",
        "          c->Merge(c->Dim(keys, 0), c->Dim(c->input(2), 0), &unused));",
        "      return OkStatus();",
        "    });",
        "",
        "Status MutableHashTableShape(InferenceContext* c, const ShapeHandle& key,",
        "                             const ShapeHandle& value) {"
    ],
    "Clean Code": [
        "      ShapeHandle keys;",
        "      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &keys));",
        "      ShapeHandle values;",
        "      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(2), 1, &values));",
        "      DimensionHandle unused;",
        "      TF_RETURN_IF_ERROR(c->Merge(c->Dim(keys, 0), c->Dim(values, 0), &unused));",
        "      return OkStatus();",
        "    });",
        "",
        "Status MutableHashTableShape(InferenceContext* c, const ShapeHandle& key,"
    ],
    "Added_Lines": "+      ShapeHandle values;\n+      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(2), 1, &values));\n+      TF_RETURN_IF_ERROR(c->Merge(c->Dim(keys, 0), c->Dim(values, 0), &unused));\n",
    "Deleted Lines": "-      TF_RETURN_IF_ERROR(\n-          c->Merge(c->Dim(keys, 0), c->Dim(c->input(2), 0), &unused));\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/1295ae4dbb52fe06b19733b0257e2340d7b63b8d",
    "API Name": "tf.raw_ops.AvgPoolGrad",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "If the stride and window size are not positive for tf.raw_ops.AvgPoolGrad, it can give an FPE.",
    "Backend Root Cause": "Lack of checking if the sliding window ksize field for dimension is positive",
    "Vulnerability Impact": "Floating Point Exception",
    "Vulnerability Fixing Commit Description": "Validate that stride and window size are positive ",
    "Vulnerable Code": [
        "    // Here, we implement a bitwise hack: we use the hi 16 bits of input for",
        "    // separate max pooling alongside each of the hi and lo 16 bits of",
        "    // out_backprop packed into 16 lo bits, which we then glue back together at",
        "    // the end to get a full 32 bits of gradient.",
        "    //",
        "    // This could select the wrong backprop value for two x values that are",
        "    // equally maximal up to the first 16 bits, in which case we are taking the",
        "    // latter.",
        "    //",
        "    // Note that in principle we could use 32 separate maxpools to recover each",
        "    // of 32 bits of the gradient while preserving 31 bits of input for the max",
        "    // pooling criteria; here, we just truncate to the first 16 bits of input."
    ],
    "Clean Code": [
        "                                        \"specify \",",
        "                                        num_dims(), \" dimensions\"));",
        "    OP_REQUIRES_OK(ctx, ValidateKernelSizes(ksize_));",
        "    OP_REQUIRES(ctx, stride_.size() == num_dims(),",
        "                errors::InvalidArgument(\"Sliding window strides field must \"",
        "                                        \"specify \",",
        "                                        num_dims(), \" dimensions\"));",
        "    OP_REQUIRES_OK(ctx, ValidateStrides(stride_));",
        "",
        "    const TensorShape tensor_in_shape = ctx->InputShape(0);",
        "    const TensorShape tensor_out_shape = ctx->InputShape(1);",
        "    const TensorShape out_backprop_shape = ctx->InputShape(2);"
    ],
    "Added_Lines": "+#include \"tensorflow/core/framework/op_requires.h\"\n+#include \"tensorflow/tsl/platform/errors.h\"\n+template <typename T>\n+static Status ValidateKernelSizes(const T& ksizes) {\n+  for (size_t i = 0; i < ksizes.size(); ++i) {\n+    if (ksizes[i] <= 0) {\n+      return errors::InvalidArgument(\n+          \"Sliding window ksize field for dimension \", i,\n+          \" must be positive but is \", ksizes[i]);\n+    }\n+  }\n+  return OkStatus();\n+}\n+\n+template <typename T>\n+static Status ValidateStrides(const T& strides) {\n+  for (size_t i = 0; i < strides.size(); ++i) {\n+    if (strides[i] <= 0) {\n+      return errors::InvalidArgument(\n+          \"Sliding window stride field for dimension \", i,\n+          \" must be positive but is \", strides[i]);\n+    }\n+  }\n+  return OkStatus();\n+}\n+\n+    if (ctx->num_inputs() == 1) {\n+      ksize = ksize_;\n+    } else {\n+      const TensorShape ksize_shape = ctx->InputShape(1);\n+      // Validate input sizes.\n+      if (!TensorShapeUtils::IsVector(ksize_shape)) {\n+        return errors::InvalidArgument(\"ksize must be a vector, not shape \",\n+                                       ksize_shape.DebugString());\n+      }\n+      if (ksize_shape.num_elements() != num_dims()) {\n+        return errors::InvalidArgument(\n+            \"Sliding window ksize field must \"\n+            \"specify \",\n+            num_dims(), \" dimensions\");\n+      }\n+      auto status = ctx->ConstantInputAsIntVector(1, &ksize);\n+      if (!status.ok()) {\n+        return status;\n+      }\n+    TF_RETURN_IF_ERROR(ValidateKernelSizes(ksize));\n+    if (ctx->num_inputs() == 1) {\n+      stride = stride_;\n+    } else {\n+      const TensorShape stride_shape = ctx->InputShape(2);\n+      // Validate input sizes.\n+      if (!TensorShapeUtils::IsVector(stride_shape)) {\n+        return errors::InvalidArgument(\"stride must be a vector, not shape \",\n+                                       stride_shape.DebugString());\n+      }\n+      if (stride_shape.num_elements() != num_dims()) {\n+        return errors::InvalidArgument(\n+            \"Sliding window stride field must \"\n+            \"specify \",\n+            num_dims(), \" dimensions\");\n+      }\n+      auto status = ctx->ConstantInputAsIntVector(2, &stride);\n+      if (!status.ok()) {\n+        return status;\n+      }\n+    TF_RETURN_IF_ERROR(ValidateStrides(stride));\n+    OP_REQUIRES_OK(ctx, ValidateKernelSizes(ksize_));\n+    OP_REQUIRES_OK(ctx, ValidateStrides(stride_));\n+    OP_REQUIRES_OK(ctx, ValidateKernelSizes(ksize_));\n+    OP_REQUIRES_OK(ctx, ValidateStrides(stride_));\n+    OP_REQUIRES_OK(ctx, ValidateKernelSizes(ksize_));\n+    OP_REQUIRES_OK(ctx, ValidateStrides(stride_));\n",
    "Deleted Lines": "-    if (ctx->num_inputs() == 1) {\n-      return ksize_;\n-    }\n-    const TensorShape ksize_shape = ctx->InputShape(1);\n-    // Validate input sizes.\n-    if (!TensorShapeUtils::IsVector(ksize_shape)) {\n-      return errors::InvalidArgument(\"ksize must be a vector, not shape \",\n-                                     ksize_shape.DebugString());\n-    }\n-    if (ksize_shape.num_elements() != num_dims()) {\n-      return errors::InvalidArgument(\n-          \"Sliding window ksize field must \"\n-          \"specify \",\n-          num_dims(), \" dimensions\");\n-    }\n-    auto status = ctx->ConstantInputAsIntVector(1, &ksize);\n-    if (!status.ok()) {\n-      return status;\n-    if (ctx->num_inputs() == 1) {\n-      return stride_;\n-    }\n-    const TensorShape stride_shape = ctx->InputShape(2);\n-    // Validate input sizes.\n-    if (!TensorShapeUtils::IsVector(stride_shape)) {\n-      return errors::InvalidArgument(\"stride must be a vector, not shape \",\n-                                     stride_shape.DebugString());\n-    }\n-    if (stride_shape.num_elements() != num_dims()) {\n-      return errors::InvalidArgument(\n-          \"Sliding window stride field must \"\n-          \"specify \",\n-          num_dims(), \" dimensions\");\n-    }\n-    auto status = ctx->ConstantInputAsIntVector(2, &stride);\n-    if (!status.ok()) {\n-      return status;\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/f3f9cb38ecfe5a8a703f2c4a8fead434ef291713",
    "API Name": "tf.raw_ops.QuantizeAndDequantizeV3",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Backend Root Cause": "QuantizeAndDequantizeV3Op, which accepts `num_bits` as a tensor, has a precondition that it should be rank <= 1 and the number of elements should be 1.",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Validate the rank and number of elements of the num_bits tensor for QuantizeAndDequantizeV3.",
    "Vulnerable Code": [
        "                              .TypeConstraint<T>(\"T\"),                         \\",
        "                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\",
        "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
        "                              .Device(DEVICE_GPU)                              \\",
        "                              .HostMemory(\"input_min\")                         \\",
        "                              .HostMemory(\"input_max\")                         \\",
        "                              .HostMemory(\"num_bits\")                          \\",
        "                              .TypeConstraint<T>(\"T\"),                         \\",
        "                          QuantizeAndDequantizeV3Op<GPUDevice, T>);            \\",
        "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
        "                              .Device(DEVICE_GPU)                              \\",
        "                              .HostMemory(\"input_min\")                         \\",
        "                              .HostMemory(\"input_max\")                         \\",
        "                              .TypeConstraint<T>(\"T\"),                         \\",
        "                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\",
        "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
        "                              .Device(DEVICE_GPU)                              \\",
        "                              .HostMemory(\"input_min\")                         \\",
        "                              .HostMemory(\"input_max\")                         \\",
        "                              .TypeConstraint<T>(\"T\"),                         \\",
        "                          QuantizeAndDequantizeV4GradientOp<GPUDevice, T>);    \\",
        "  REGISTER_KERNEL_BUILDER(                                                     \\",
        "      Name(\"QuantizeAndDequantize\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
        "      QuantizeAndDequantizeOp<GPUDevice, T>);",
        "TF_CALL_float(REGISTER_GPU_KERNEL);",
        "TF_CALL_double(REGISTER_GPU_KERNEL);",
        "#undef REGISTER_GPU_KERNEL",
        "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
        "}  // namespace tensorflow"
    ],
    "Clean Code": [
        "                              .HostMemory(\"input_max\")                         \\",
        "                              .TypeConstraint<T>(\"T\"),                         \\",
        "                          QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\",
        "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
        "                              .Device(DEVICE_GPU)                              \\",
        "                              .HostMemory(\"input_min\")                         \\",
        "                              .HostMemory(\"input_max\")                         \\",
        "                              .HostMemory(\"num_bits\")                          \\",
        "                              .TypeConstraint<T>(\"T\"),                         \\",
        "                          QuantizeAndDequantizeV3Op<GpuDevice, T>);            \\",
        "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
        "                              .Device(DEVICE_GPU)                              \\",
        "                              .HostMemory(\"input_min\")                         \\",
        "                              .HostMemory(\"input_max\")                         \\",
        "                              .TypeConstraint<T>(\"T\"),                         \\",
        "                          QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\",
        "  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
        "                              .Device(DEVICE_GPU)                              \\",
        "                              .HostMemory(\"input_min\")                         \\",
        "                              .HostMemory(\"input_max\")                         \\",
        "                              .TypeConstraint<T>(\"T\"),                         \\",
        "                          QuantizeAndDequantizeV4GradientOp<GpuDevice, T>);    \\",
        "  REGISTER_KERNEL_BUILDER(                                                     \\",
        "      Name(\"QuantizeAndDequantize\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
        "      QuantizeAndDequantizeOp<GpuDevice, T>);",
        "TF_CALL_float(REGISTER_GPU_KERNEL);",
        "TF_CALL_double(REGISTER_GPU_KERNEL);",
        "#undef REGISTER_GPU_KERNEL",
        "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM"
    ],
    "Added_Lines": "+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"\n+namespace {\n+using CpuDevice = ::Eigen::ThreadPoolDevice;\n+using GpuDevice = ::Eigen::GpuDevice;\n+using ::tensorflow::errors::InvalidArgument;\n+\n+}  // namespace\n+                InvalidArgument(\"num_bits is out of range: \", num_bits_,\n+                                \" with signed_input_ \", signed_input_));\n+        InvalidArgument(\"Round mode string must be \"\n+                        \"'HALF_UP' or \"\n+                        \"'HALF_TO_EVEN', is '\" +\n+                        round_mode_string + \"'\"));\n+    OP_REQUIRES(ctx, axis_ >= -1,\n+                InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n+    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n+                InvalidArgument(\"Shape must be at least rank \", axis_ + 1,\n+                    InvalidArgument(\"Invalid range: input_min \", min_val,\n+                                    \" > input_max \", max_val));\n+        OP_REQUIRES(\n+            ctx, input_min_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_min_tensor has incorrect size, was \",\n+                            input_min_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_min_tensor.shape()));\n+        OP_REQUIRES(\n+            ctx, input_max_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_max_tensor has incorrect size, was \",\n+                            input_max_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_max_tensor.shape()));\n+    OP_REQUIRES(ctx, axis_ >= -1,\n+                InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n+                InvalidArgument(\n+    OP_REQUIRES(ctx, input.IsSameSize(gradient),\n+                InvalidArgument(\"gradient and input must be the same size\"));\n+                InvalidArgument(\n+                InvalidArgument(\n+      OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n+                  InvalidArgument(\"min has incorrect size, expected \", depth,\n+      OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n+                  InvalidArgument(\"max has incorrect size, expected \", depth,\n+      OP_REQUIRES(\n+          ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n+          InvalidArgument(\"input_min must be a scalar if axis is unspecified\"));\n+      OP_REQUIRES(\n+          ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n+          InvalidArgument(\"input_max must be a scalar if axis is unspecified\"));\n+                InvalidArgument(\n+    // Get num_bits and validate.\n+    const Tensor num_bits_tensor = ctx->input(3);\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(num_bits_tensor.shape()),\n+                InvalidArgument(\"Invalid shape. The `num_bits` tensor should \"\n+                                \"be a scalar. Got dimensions: \",\n+                                num_bits_tensor.dims()));\n+    const int num_bits_val = num_bits_tensor.scalar<int32>()();\n+    OP_REQUIRES(ctx,\n+                num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),\n+                InvalidArgument(\"num_bits is out of range: \", num_bits_val,\n+                                \" with `signed_input_` \", signed_input_));\n+        const auto min_val = input_min_tensor.scalar<T>()();\n+        const auto max_val = input_max_tensor.scalar<T>()();\n+                    InvalidArgument(\"Invalid range: input_min \", min_val,\n+                                    \" > input_max \", max_val));\n+        OP_REQUIRES(\n+            ctx, input_min_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_min_tensor has incorrect size, was \",\n+                            input_min_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_min_tensor.shape()));\n+        OP_REQUIRES(\n+            ctx, input_max_tensor.dim_size(0) == depth,\n+            InvalidArgument(\"input_max_tensor has incorrect size, was \",\n+                            input_max_tensor.dim_size(0), \" expected \", depth,\n+                            \" to match dim \", axis_, \" of the input \",\n+                            input_max_tensor.shape()));\n+                InvalidArgument(\"num_bits is out of range: \", num_bits_,\n+                                \" with signed_input_ \", signed_input_));\n+      OP_REQUIRES(ctx, input_min_ <= input_max_,\n+                  InvalidArgument(\"Invalid range: input_min \", input_min_,\n+// Specializations for CpuDevice.\n+struct QuantizeAndDequantizeOneScaleFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d, typename TTypes<T>::ConstVec input,\n+    QuantizeAndDequantizeOneScaleImpl<CpuDevice, T>::Compute(\n+struct QuantizeAndDequantizePerChannelFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d, typename TTypes<T, 3>::ConstTensor input,\n+    QuantizeAndDequantizePerChannelImpl<CpuDevice, T>::Compute(\n+struct QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d, typename TTypes<T>::ConstFlat gradient,\n+    QuantizeAndDequantizeOneScaleGradientImpl<CpuDevice, T>::Compute(\n+struct QuantizeAndDequantizePerChannelGradientFunctor<CpuDevice, T> {\n+  void operator()(const CpuDevice& d,\n+    QuantizeAndDequantizePerChannelGradientImpl<CpuDevice, T>::Compute(\n+template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice,\n+    CpuDevice, double>;\n+                          QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\\n+                          QuantizeAndDequantizeV3Op<CpuDevice, T>);            \\\n+                          QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\\n+                          QuantizeAndDequantizeV4GradientOp<CpuDevice, T>);    \\\n+      QuantizeAndDequantizeOp<CpuDevice, T>);\n+                          QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\\n+                          QuantizeAndDequantizeV3Op<GpuDevice, T>);            \\\n+                          QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\\n+                          QuantizeAndDequantizeV4GradientOp<GpuDevice, T>);    \\\n+      QuantizeAndDequantizeOp<GpuDevice, T>);\n",
    "Deleted Lines": "-#include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"\n-\n-typedef Eigen::ThreadPoolDevice CPUDevice;\n-typedef Eigen::GpuDevice GPUDevice;\n-                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n-                                        \" with signed_input_ \", signed_input_));\n-        errors::InvalidArgument(\"Round mode string must be \"\n-                                \"'HALF_UP' or \"\n-                                \"'HALF_TO_EVEN', is '\" +\n-                                round_mode_string + \"'\"));\n-    OP_REQUIRES(\n-        ctx, axis_ >= -1,\n-        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n-    OP_REQUIRES(\n-        ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n-        errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,\n-                    errors::InvalidArgument(\"Invalid range: input_min \",\n-                                            min_val, \" > input_max \", max_val));\n-        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_min_tensor has incorrect size, was \",\n-                        input_min_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_min_tensor.shape()));\n-        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_max_tensor has incorrect size, was \",\n-                        input_max_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_max_tensor.shape()));\n-    OP_REQUIRES(\n-        ctx, axis_ >= -1,\n-        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n-                errors::InvalidArgument(\n-    OP_REQUIRES(\n-        ctx, input.IsSameSize(gradient),\n-        errors::InvalidArgument(\"gradient and input must be the same size\"));\n-                errors::InvalidArgument(\n-                errors::InvalidArgument(\n-      OP_REQUIRES(\n-          ctx, input_min_tensor.dim_size(0) == depth,\n-          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n-      OP_REQUIRES(\n-          ctx, input_max_tensor.dim_size(0) == depth,\n-          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n-      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n-                  errors::InvalidArgument(\n-                      \"input_min must be a scalar if axis is unspecified\"));\n-      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n-                  errors::InvalidArgument(\n-                      \"input_max must be a scalar if axis is unspecified\"));\n-                errors::InvalidArgument(\n-    Tensor num_bits_tensor;\n-    num_bits_tensor = ctx->input(3);\n-    int num_bits_val = num_bits_tensor.scalar<int32>()();\n-    OP_REQUIRES(\n-        ctx, num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),\n-        errors::InvalidArgument(\"num_bits is out of range: \", num_bits_val,\n-                                \" with signed_input_ \", signed_input_));\n-        auto min_val = input_min_tensor.scalar<T>()();\n-        auto max_val = input_max_tensor.scalar<T>()();\n-                    errors::InvalidArgument(\"Invalid range: input_min \",\n-                                            min_val, \" > input_max \", max_val));\n-        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_min_tensor has incorrect size, was \",\n-                        input_min_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_min_tensor.shape()));\n-        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n-                    errors::InvalidArgument(\n-                        \"input_max_tensor has incorrect size, was \",\n-                        input_max_tensor.dim_size(0), \" expected \", depth,\n-                        \" to match dim \", axis_, \" of the input \",\n-                        input_max_tensor.shape()));\n-                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n-                                        \" with signed_input_ \", signed_input_));\n-      OP_REQUIRES(\n-          ctx, input_min_ <= input_max_,\n-          errors::InvalidArgument(\"Invalid range: input_min \", input_min_,\n-// Specializations for CPUDevice.\n-struct QuantizeAndDequantizeOneScaleFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d, typename TTypes<T>::ConstVec input,\n-    QuantizeAndDequantizeOneScaleImpl<CPUDevice, T>::Compute(\n-struct QuantizeAndDequantizePerChannelFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d, typename TTypes<T, 3>::ConstTensor input,\n-    QuantizeAndDequantizePerChannelImpl<CPUDevice, T>::Compute(\n-struct QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d, typename TTypes<T>::ConstFlat gradient,\n-    QuantizeAndDequantizeOneScaleGradientImpl<CPUDevice, T>::Compute(\n-struct QuantizeAndDequantizePerChannelGradientFunctor<CPUDevice, T> {\n-  void operator()(const CPUDevice& d,\n-    QuantizeAndDequantizePerChannelGradientImpl<CPUDevice, T>::Compute(\n-template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice,\n-    CPUDevice, double>;\n-                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\\n-                          QuantizeAndDequantizeV3Op<CPUDevice, T>);            \\\n-                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\\n-                          QuantizeAndDequantizeV4GradientOp<CPUDevice, T>);    \\\n-      QuantizeAndDequantizeOp<CPUDevice, T>);\n-                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\\n-                          QuantizeAndDequantizeV3Op<GPUDevice, T>);            \\\n-                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\\n-                          QuantizeAndDequantizeV4GradientOp<GPUDevice, T>);    \\\n-      QuantizeAndDequantizeOp<GPUDevice, T>);\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/f3cf67ac5705f4f04721d15e485e192bb319feed",
    "API Name": "tf.quantization.fake_quant_with_min_max_vars_gradient",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Backend Root Cause": "Lack of validating if min` must be rank 0 but is rank",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Add IsScalar / IsVector (rank) checks to input min/max tensors for FakeQuantWithMinMaxVarsPerChannelGradientOp and FakeQuantWithMinMaxVarsGradientOp.",
    "Vulnerable Code": [
        "    OP_REQUIRES(context, max.dim_size(0) == depth,",
        "                InvalidArgument(\"max has incorrect size, expected \", depth,",
        "                                \" was \", max.dim_size(0)));",
        "",
        "    Tensor* grad_wrt_input;",
        "    OP_REQUIRES_OK(context,",
        "                   context->allocate_output(0, input.shape(), &grad_wrt_input));",
        "",
        "    TensorShape min_max_shape({input.dim_size(input.dims() - 1)});",
        "    Tensor* grad_wrt_min;",
        "    OP_REQUIRES_OK(context,",
        "                   context->allocate_output(1, min_max_shape, &grad_wrt_min));",
        "",
        "    Tensor* grad_wrt_max;",
        "    OP_REQUIRES_OK(context,",
        "                   context->allocate_output(2, min_max_shape, &grad_wrt_max));"
    ],
    "Clean Code": [
        "    const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
        "    const Tensor& min = context->input(2);",
        "    OP_REQUIRES(",
        "        context, TensorShapeUtils::IsVector(min.shape()),",
        "        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
        "    OP_REQUIRES(context, min.dim_size(0) == depth,",
        "                InvalidArgument(\"min has incorrect size, expected \", depth,",
        "                                \" was \", min.dim_size(0)));",
        "    const Tensor& max = context->input(3);",
        "    OP_REQUIRES(",
        "        context, TensorShapeUtils::IsVector(max.shape()),",
        "        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
        "    OP_REQUIRES(context, max.dim_size(0) == depth,",
        "                InvalidArgument(\"max has incorrect size, expected \", depth,",
        "                                \" was \", max.dim_size(0)));",
        ""
    ],
    "Added_Lines": "+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/552bfced6ce4809db5f3ca305f60ff80dd40c5a3",
    "API Name": "tf.random.gamma",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "A large tensor refers to a tensor that has a large number of elements or values or occupies a significant amount of memory.",
    "Backend Root Cause": "Lack of size checking for large input shape and rates. ",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": " Fix size check for large input shape and rates. To address a check failure for exceedingly large output shapes, we need to `AppendShapeWithStatus`.",
    "Vulnerable Code": [
        "    const int64_t samples_per_alpha = samples_shape.num_elements();",
        "",
        "    samples_shape.AppendShape(alpha_t.shape());",
        "    // Allocate output samples.",
        "    Tensor* samples_t = nullptr;",
        "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));",
        ""
    ],
    "Clean Code": [
        "    const int64_t samples_per_alpha = samples_shape.num_elements();",
        "",
        "    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(alpha_t.shape()));",
        "    // Allocate output samples.",
        "    Tensor* samples_t = nullptr;",
        "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));",
        ""
    ],
    "Added_Lines": "+    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(alpha_t.shape()));\n",
    "Deleted Lines": "-    samples_shape.AppendShape(alpha_t.shape());\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/4419d10d576adefa36b0e0a9425d2569f7c0189f",
    "API Name": "tf.raw_ops.Unbatch",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "A non-scalar input tensor refers to a tensor that has more than one element or value. It represents a multi-dimensional array or a collection of values organized in a specific shape.",
    "Backend Root Cause": "Lack of checking whether input argument is a scalar before trying to extract value.",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": " Fix check failure in Unbatch Op kernel by checking whether input argument is a scalar before trying to extract value.",
    "Vulnerable Code": [
        "",
        "    const int64_t batch_key = context->input(2).scalar<int64_t>()();",
        "    const bool nonempty_input = batch_index_t.dim_size(0) > 0;",
        "",
        "    // If we have a non-empty tensor, slice it up.",
        "    // (It is important to do this outside of the critical section below.)",
        "    // The following variables are populated iff 'nonempty_input==true'.",
        "    std::vector<int64_t> sizes;",
        "    std::vector<int64_t> batch_keys;",
        "    std::vector<Tensor> split_inputs;",
        "    if (nonempty_input) {",
        "      auto batch_indices ="
    ],
    "Clean Code": [
        "    }",
        "",
        "    if (!TensorShapeUtils::IsScalar(context->input(2).shape())) {",
        "      return errors::InvalidArgument(",
        "          \"Input id should be scalar; \"",
        "          \"Got: \",",
        "          context->input(2).DebugString(), \".\");",
        "    }",
        "    const int64_t batch_key = context->input(2).scalar<int64_t>()();",
        "    const bool nonempty_input = batch_index_t.dim_size(0) > 0;",
        "",
        "    // If we have a non-empty tensor, slice it up."
    ],
    "Added_Lines": "+#include \"tensorflow/core/framework/tensor_shape.h\"\n+    if (!TensorShapeUtils::IsScalar(context->input(2).shape())) {\n+      return errors::InvalidArgument(\n+          \"Input id should be scalar; \"\n+          \"Got: \",\n+          context->input(2).DebugString(), \".\");\n+    }\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/da0d65cdc1270038e72157ba35bf74b85d9bda11",
    "API Name": "tf.raw_ops.DrawBoundingBoxes",
    "Vulnerability Category": "Data Type Issue",
    "Trigger Mechanism": "An input tensor with a half data type refers to a tensor that uses the float16 data type. The float16 data type, also known as half-precision floating-point format, represents a floating-point number with reduced precision compared to the standard float32 data type.",
    "Backend Root Cause": "Using Improper Data Type",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": " Fix dtype bug in draw bounding boxes. Boxes always needs to be type `float`.",
    "Vulnerable Code": [
        "    for (int64_t b = 0; b < batch_size; ++b) {",
        "      const int64_t num_boxes = boxes.dim_size(1);",
        "      const auto tboxes = boxes.tensor<T, 3>();",
        "      for (int64_t bb = 0; bb < num_boxes; ++bb) {",
        "        int64_t color_index = bb % color_table.size();",
        "        const int64_t min_box_row =",
        "            static_cast<float>(tboxes(b, bb, 0)) * (height - 1);"
    ],
    "Clean Code": [
        "    for (int64_t b = 0; b < batch_size; ++b) {",
        "      const int64_t num_boxes = boxes.dim_size(1);",
        "      const auto tboxes = boxes.tensor<float, 3>();",
        "      for (int64_t bb = 0; bb < num_boxes; ++bb) {",
        "        int64_t color_index = bb % color_table.size();",
        "        const int64_t min_box_row =",
        "            static_cast<float>(tboxes(b, bb, 0)) * (height - 1);"
    ],
    "Added_Lines": "+      const auto tboxes = boxes.tensor<float, 3>();\n",
    "Deleted Lines": "-      const auto tboxes = boxes.tensor<T, 3>();\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/aed36912609fc07229b4d0a7b44f3f48efc00fd0",
    "API Name": "tf.raw_ops.Eig",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "Eig can be fed an incorrect Tout input, resulting in a CHECK fail that can trigger a denial of service attack.",
    "Backend Root Cause": "If calling the `tf.raw_ops` versions, it's possible to provide bad output scalar types (e.g. for `Eig`), causing a failing check when trying to actually compute outputs.",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": " Check correct input/output scalar types for LinearAlgebraOp. ",
    "Vulnerable Code": [
        "void LinearAlgebraOp<InputScalar, OutputScalar>::ComputeTensorSlice(",
        "    OpKernelContext* context, int64_t matrix_index, const TensorInputs& inputs,",
        "    const TensorShapes& input_matrix_shapes, const TensorOutputs& outputs,",
        "    const TensorShapes& output_matrix_shapes) {",
        "  InputConstMatrixMaps matrix_inputs;",
        "  for (size_t i = 0; i < inputs.size(); ++i) {",
        "    // TODO(kalakris): Handle alignment if possible. Eigen::Map is",
        "    // unaligned by default.",
        "    matrix_inputs.emplace_back(",
        "        inputs[i]->flat<InputScalar>().data() +",
        "            matrix_index * input_matrix_shapes[i].num_elements(),"
    ],
    "Clean Code": [
        "                                  output_idx, output_tensor_shape, &out));",
        "    }",
        "    OP_REQUIRES(",
        "        context, out->dtype() == DataTypeToEnum<OutputScalar>::v(),",
        "        errors::InvalidArgument(\"Invalid output dtype \", out->dtype(), \" vs \",",
        "                                DataTypeToEnum<OutputScalar>::v()));",
        "",
        "    outputs->emplace_back(out);",
        "  }",
        "}",
        ""
    ],
    "Added_Lines": "+#include <initializer_list>\n+#include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n+    OP_REQUIRES(\n+        context, in.dtype() == DataTypeToEnum<InputScalar>::v(),\n+        errors::InvalidArgument(\"Invalid input dtype \", in.dtype(), \" vs \",\n+                                DataTypeToEnum<InputScalar>::v()));\n+    OP_REQUIRES(\n+        context, out->dtype() == DataTypeToEnum<OutputScalar>::v(),\n+        errors::InvalidArgument(\"Invalid output dtype \", out->dtype(), \" vs \",\n+                                DataTypeToEnum<OutputScalar>::v()));\n+\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/27a65a43cf763897fecfa5cdb5cc653fc5dd0346",
    "API Name": "tf.raw_ops.Conv2DBackpropInput",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "In Python, a zero integer list element refers to a list element that has the value of zero (0). It is simply a list element that holds the integer value of zero.",
    "Backend Root Cause": "For empty `out_backprop` inputs (e.g. `[3, 1, 0, 1]`), the current CPU/GPU kernels fail (one with dnnl, the other with cudnn).",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Added a shortcut path to return a zero input.",
    "Vulnerable Code": [
        "        GetWindowedOutputSizeVerbose(",
        "            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,",
        "            dims.spatial_dims[0].stride, padding_,",
        "            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));",
        "    OP_REQUIRES_OK(",
        "        context,",
        "        GetWindowedOutputSizeVerbose(",
        "            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,",
        "            dims.spatial_dims[1].stride, padding_,",
        "            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));",
        "",
        "    if (pad_left == pad_right && pad_top == pad_bottom) {",
        "      if (LaunchXsmmBackwardInputConvolution<Device, T>()(",
        "              context, context->eigen_device<Device>(),",
        "              in_backprop->tensor<T, 4>(), filter.tensor<T, 4>(),"
    ],
    "Clean Code": [
        "    }",
        "",
        "    // If shapes are valid but `out_backprop` is empty, in_backprop should be",
        "    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.",
        "    if (out_backprop.NumElements() == 0) {",
        "      functor::SetZeroFunctor<Device, T> set_zero;",
        "      set_zero(context->eigen_device<Device>(),",
        "               in_backprop->template flat<T>());",
        "      return;",
        "    }",
        "",
        "// TODO(ezhulenev): Remove custom kernel and move XSMM support to",
        "// LaunchConv2DBackpropInputOp functor.",
        "#if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\",
        "    defined TENSORFLOW_USE_LIBXSMM_BACKWARD_CONVOLUTIONS"
    ],
    "Added_Lines": "+#include \"tensorflow/core/kernels/fill_functor.h\"\n+    // If shapes are valid but `out_backprop` is empty, in_backprop should be\n+    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.\n+    if (out_backprop.NumElements() == 0) {\n+      functor::SetZeroFunctor<Device, T> set_zero;\n+      set_zero(context->eigen_device<Device>(),\n+               in_backprop->template flat<T>());\n+      return;\n+    }\n+\n+    // If shapes are valid but `out_backprop` is empty, in_backprop should be\n+    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.\n+    if (out_backprop.NumElements() == 0) {\n+      functor::SetZeroFunctor<Device, T> set_zero;\n+      set_zero(context->eigen_device<Device>(),\n+               in_backprop->template flat<T>());\n+      return;\n+    }\n+\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c8ba76d48567aed347508e0552a257641931024d",
    "API Name": "tf.raw_ops.EmptyTensorList",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "If EmptyTensorList receives an input element_shape with more than one dimension, it gives a CHECK fail that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "invalid `element_shape`",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Check that given `element_shape` is valid. Add graph/eager unit tests. Graph mode was already ok but eager mode was not.",
    "Vulnerable Code": [
        "        \"The only valid scalar shape tensor is the fully unknown shape \"",
        "        \"specified as -1.\");",
        "  }",
        "  if (t.dtype() == DT_INT32) {",
        "    return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),",
        "                                                t.NumElements(), out);",
        "  } else if (t.dtype() == DT_INT64) {",
        "    return PartialTensorShape::MakePartialShape(t.vec<int64_t>().data(),",
        "                                                t.NumElements(), out);"
    ],
    "Clean Code": [
        "        \"The only valid scalar shape tensor is the fully unknown shape \"",
        "        \"specified as -1.\");",
        "  } else if (t.shape().dims() != 1) {",
        "    return errors::InvalidArgument(\"Shape must be at most rank 1 but is rank \",",
        "                                   t.shape().dims());",
        "  }",
        "  if (t.dtype() == DT_INT32) {",
        "    return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),",
        "                                                t.NumElements(), out);"
    ],
    "Added_Lines": "+#include <algorithm>\n+#include <iterator>\n+#include <memory>\n+#include <utility>\n+  } else if (t.shape().dims() != 1) {\n+    return errors::InvalidArgument(\"Shape must be at most rank 1 but is rank \",\n+                                   t.shape().dims());\n",
    "Deleted Lines": "-#include \"tensorflow/core/kernels/concat_lib.h\"\n-#include \"tensorflow/core/lib/core/coding.h\"\n-#include \"tensorflow/core/lib/core/errors.h\"\n-#include \"tensorflow/core/util/util.h\"\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/83dcb4dbfa094e33db084e97c4d0531a559e0ebf",
    "API Name": "tf.sparse.cross",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "If tf.sparse.cross receives an input separator that is not a scalar, it gives a CHECK fail that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking if the Input separator should be a scalar",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": " Fix check failure in SparseCrossV2Op by adding check for scalar value for separator.",
    "Vulnerable Code": [
        "    const tstring separator = sep_t->scalar<tstring>()();",
        "",
        "    std::vector<std::unique_ptr<ColumnInterface<tstring>>> columns =",
        "        GenerateColumnsFromInput<tstring>(indices_list_in, values_list_in,",
        "                                          shapes_list_in, dense_list_in);",
        "    Tensor* indices_out;",
        "    Tensor* values_out;",
        "    Tensor* shape_out;",
        "    const int64_t batch_size =",
        "        CalculateBatchSize(shapes_list_in, dense_list_in);"
    ],
    "Clean Code": [
        "    const Tensor* sep_t;",
        "    OP_REQUIRES_OK(context, context->input(\"sep\", &sep_t));",
        "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(sep_t->shape()),",
        "                errors::InvalidArgument(\"Input separator should be a scalar. \"",
        "                                        \"Received: \",",
        "                                        sep_t->DebugString()));",
        "    const tstring separator = sep_t->scalar<tstring>()();",
        "",
        "    std::vector<std::unique_ptr<ColumnInterface<tstring>>> columns =",
        "        GenerateColumnsFromInput<tstring>(indices_list_in, values_list_in,"
    ],
    "Added_Lines": "+#include \"tensorflow/core/framework/op_requires.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(sep_t->shape()),\n+                errors::InvalidArgument(\"Input separator should be a scalar. \"\n+                                        \"Received: \",\n+                                        sep_t->DebugString()));\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/611d80db29dd7b0cfb755772c69d60ae5bca05f9",
    "API Name": "tf.raw_ops.Conv2D",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "If Conv2D is given empty input and the filter and padding sizes are valid, the output is all-zeros. This causes division-by-zero floating point exceptions that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "If the input is empty (so convolution is only applied to padding), and if the filter and padding sizes are still valid, then the output will be all-zeros.  This previously caused a division-by-zero crash in multiple kernels.",
    "Vulnerability Impact": "division by zero",
    "Vulnerability Fixing Commit Description": "Check if the input is empty",
    "Vulnerable Code": [
        "",
        "#ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS",
        "    if (params_.padding != EXPLICIT &&",
        "        LaunchXsmmConvOp<Device, T>::Run(",
        "            context, input, filter, dimensions.batch, dimensions.input_rows,",
        "            dimensions.input_cols, dimensions.in_depth, dimensions.filter_rows,",
        "            dimensions.filter_cols, dimensions.pad_rows_before,",
        "            dimensions.pad_cols_before, dimensions.out_rows,",
        "            dimensions.out_cols, dimensions.out_depth, dimensions.dilation_rows,",
        "            dimensions.dilation_cols, dimensions.stride_rows,",
        "            dimensions.stride_cols, output, params_.data_format)) {",
        "      return;",
        "    }",
        "#endif",
        ""
    ],
    "Clean Code": [
        "    }",
        "",
        "    // If the input is empty, result can only be due to padding.",
        "    if (input.NumElements() == 0) {",
        "      // Zero-out output and return.",
        "      functor::SetZeroFunctor<Device, T>()(context->eigen_device<Device>(),",
        "                                           output->template flat<T>());",
        "",
        "      return;",
        "    }",
        "",
        "#ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS",
        "    if (params_.padding != EXPLICIT &&",
        "        LaunchXsmmConvOp<Device, T>::Run(",
        "            context, input, filter, dimensions.batch, dimensions.input_rows,"
    ],
    "Added_Lines": "+#include \"tensorflow/core/kernels/fill_functor.h\"\n+    // If the input is empty, result can only be due to padding.\n+    if (input.NumElements() == 0) {\n+      // Zero-out output and return.\n+      functor::SetZeroFunctor<Device, T>()(context->eigen_device<Device>(),\n+                                           output->template flat<T>());\n+\n+      return;\n+    }\n+\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/bf6b45244992e2ee543c258e519489659c99fb7f",
    "API Name": "tf.raw_ops.AudioSummaryV2",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "When AudioSummaryV2 receives an input sample_rate with more than one element, it gives a CHECK fails that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking if sample_rate must be rank-0 or contain a single value",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Check that `sample_rate` has the required shape.",
    "Vulnerable Code": [
        "    if (!has_sample_rate_attr_) {",
        "      const Tensor& sample_rate_tensor = c->input(2);",
        "      sample_rate = sample_rate_tensor.scalar<float>()();",
        "    }",
        "    OP_REQUIRES(c, sample_rate > 0.0f,",
        "                errors::InvalidArgument(\"sample_rate must be > 0\"));",
        "",
        "    const int batch_size = tensor.dim_size(0);",
        "    const int64_t length_frames = tensor.dim_size(1);",
        "    const int64_t num_channels =",
        "        tensor.dims() == 2 ? 1 : tensor.dim_size(tensor.dims() - 1);"
    ],
    "Clean Code": [
        "    if (!has_sample_rate_attr_) {",
        "      const Tensor& sample_rate_tensor = c->input(2);",
        "      OP_REQUIRES(c,",
        "                  sample_rate_tensor.IsAligned() &&",
        "                      sample_rate_tensor.NumElements() == 1,",
        "                  errors::InvalidArgument(",
        "                      \"sample_rate must be rank-0 or contain a single value\"));",
        "      sample_rate = sample_rate_tensor.scalar<float>()();",
        "    }",
        "    OP_REQUIRES(c, sample_rate > 0.0f,",
        "                errors::InvalidArgument(\"sample_rate must be > 0\"));"
    ],
    "Added_Lines": "+      OP_REQUIRES(c,\n+                  sample_rate_tensor.IsAligned() &&\n+                      sample_rate_tensor.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"sample_rate must be rank-0 or contain a single value\"));\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c1f491817dec39a26be3c574e86a88c30f3c4770",
    "API Name": "tf.raw_ops.CollectiveGather",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "When CollectiveGather receives an scalar input input, it gives a CHECK fails that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking input should have rank > 0",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "The fix is required only for Eager mode, graph mode already checked for input shape in shape inference pass.",
    "Vulnerable Code": [
        "                        DoneCallback done) override {",
        "    auto output_shape = c->input(0).shape();",
        "    output_shape.set_dim(",
        "        0, output_shape.dim_size(0) * col_params_->group.group_size);",
        "    col_params_->instance.shape = output_shape;",
        "",
        "    // Allocate output on the first pass through this function.  This must be",
        "    // done immediately, while we're still in the executor thread.  Otherwise",
        "    // the memory is not guaranteed to be unused by any concurrently executing",
        "    // GPU kernel."
    ],
    "Clean Code": [
        "                        DoneCallback done) override {",
        "    auto output_shape = c->input(0).shape();",
        "    OP_REQUIRES_ASYNC(c, output_shape.dims() > 0,",
        "                      errors::InvalidArgument(\"input should have rank > 0, \",",
        "                                              \"recieved \", output_shape.dims()),",
        "                      done);",
        "    output_shape.set_dim(",
        "        0, output_shape.dim_size(0) * col_params_->group.group_size);",
        "    col_params_->instance.shape = output_shape;",
        ""
    ],
    "Added_Lines": "+    OP_REQUIRES_ASYNC(c, output_shape.dims() > 0,\n+                      errors::InvalidArgument(\"input should have rank > 0, \",\n+                                              \"recieved \", output_shape.dims()),\n+                      done);\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/cf70b79d2662c0d3c6af74583641e345fc939467",
    "API Name": "tf.raw_ops.SetSize",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "When SetSize receives an input set_shape that is not a 1D tensor, it gives a CHECK fails that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking Shape must be a 1D tensor",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Check that given input is a 1D tensor, as required.",
    "Vulnerable Code": [
        "  // Assume row-major order.",
        "  TensorShape shape;",
        "  TF_RETURN_IF_ERROR(TensorShape::BuildTensorShape(",
        "      ctx->input(base_index + 2).vec<int64_t>(), &shape));",
        "  CheckRankAtLeast2(ctx, shape);",
        "  std::vector<int64_t> order(shape.dims());",
        "  std::iota(order.begin(), order.end(), 0);",
        "",
        "  Status status = sparse::SparseTensor::Create(",
        "      ctx->input(base_index), ctx->input(base_index + 1), shape, order, tensor);",
        "",
        "  if (!validate_indices || !status.ok()) return status;"
    ],
    "Clean Code": [
        "  // Assume row-major order.",
        "  TensorShape shape;",
        "  const Tensor& shape_tensor = ctx->input(base_index + 2);",
        "  if (shape_tensor.dims() != 1) {",
        "    return errors::InvalidArgument(\"Shape must be a 1D tensor.\");",
        "  }",
        "  TF_RETURN_IF_ERROR(",
        "      TensorShape::BuildTensorShape(shape_tensor.vec<int64_t>(), &shape));",
        "  CheckRankAtLeast2(ctx, shape);",
        "  std::vector<int64_t> order(shape.dims());",
        "  std::iota(order.begin(), order.end(), 0);",
        ""
    ],
    "Added_Lines": "+  const Tensor& shape_tensor = ctx->input(base_index + 2);\n+  if (shape_tensor.dims() != 1) {\n+    return errors::InvalidArgument(\"Shape must be a 1D tensor.\");\n+  }\n+  TF_RETURN_IF_ERROR(\n+      TensorShape::BuildTensorShape(shape_tensor.vec<int64_t>(), &shape));\n",
    "Deleted Lines": "-  TF_RETURN_IF_ERROR(TensorShape::BuildTensorShape(\n-      ctx->input(base_index + 2).vec<int64_t>(), &shape));\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/3db59a042a38f4338aa207922fa2f476e000a6ee",
    "API Name": "tf.raw_ops.TensorListFromTensor",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "When TensorListFromTensor receives an element_shape of a rank greater than one, it gives a CHECK fail that can trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking if element_shape must be at most rank 1",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Check for element_shape in TensorListFromTensor",
    "Vulnerable Code": [
        "    OP_REQUIRES_OK(c, c->allocate_output(0, {}, &output_tensor, attr));",
        "    PartialTensorShape element_shape;",
        "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(1), &element_shape));",
        "    TensorList output_list;",
        "    const Tensor& t = c->input(0);",
        "    output_list.element_dtype = t.dtype();",
        "    OP_REQUIRES(c, TensorShapeUtils::IsVectorOrHigher(t.shape()),",
        "                errors::InvalidArgument(",
        "                    \"Tensor must be at least a vector, but saw shape: \",",
        "                    t.shape().DebugString()));",
        "    TensorShape output_shape(t.shape());"
    ],
    "Clean Code": [
        "    OP_REQUIRES_OK(c, c->allocate_output(0, {}, &output_tensor, attr));",
        "    PartialTensorShape element_shape;",
        "    OP_REQUIRES(",
        "        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(1).shape()),",
        "        errors::InvalidArgument(",
        "            \"TensorListFromTensor: element_shape must be at most rank 1 but \",",
        "            \"has the shape of \", c->input(1).shape().DebugString()));",
        "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(1), &element_shape));",
        "    TensorList output_list;",
        "    const Tensor& t = c->input(0);",
        "    output_list.element_dtype = t.dtype();"
    ],
    "Added_Lines": "+    OP_REQUIRES(\n+        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(1).shape()),\n+        errors::InvalidArgument(\n+            \"TensorListFromTensor: element_shape must be at most rank 1 but \",\n+            \"has the shape of \", c->input(1).shape().DebugString()));\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/bb03fdf4aae944ab2e4b35c7daa051068a8b7f61",
    "API Name": "tf.raw_ops.TensorListScatter",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "When TensorListScatter and TensorListScatterV2 receive an element_shape of a rank greater than one, they give a CHECK fail that can trigger a denial of service attack.",
    "Backend Root Cause": "Lack of Checking element_shape must be at most rank 1 but",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Check element_shape must be at most rank 1 but",
    "Vulnerable Code": [
        "    Tensor indices = c->input(1);",
        "    PartialTensorShape element_shape;",
        "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(2), &element_shape));",
        "    // TensorListScatterV2 passes the num_elements input, TensorListScatter does",
        "    // not.",
        "    int num_elements = c->num_inputs() >= 4 ? c->input(3).scalar<int>()() : -1;",
        "    OP_REQUIRES(c, num_elements >= -1,",
        "                errors::InvalidArgument(",
        "                    \"TensorListScatter expects num_elements >= -1, found: \",",
        "                    num_elements));",
        "    TensorList output_list;"
    ],
    "Clean Code": [
        "    Tensor indices = c->input(1);",
        "    PartialTensorShape element_shape;",
        "    OP_REQUIRES(",
        "        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(2).shape()),",
        "        errors::InvalidArgument(",
        "            \"TensorListScatter: element_shape must be at most rank 1 but has \",",
        "            \"the shape of \", c->input(2).shape().DebugString()));",
        "    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(2), &element_shape));",
        "    // TensorListScatterV2 passes the num_elements input, TensorListScatter does",
        "    // not.",
        "    int num_elements = c->num_inputs() >= 4 ? c->input(3).scalar<int>()() : -1;"
    ],
    "Added_Lines": "+    OP_REQUIRES(\n+        c, !TensorShapeUtils::IsMatrixOrHigher(c->input(2).shape()),\n+        errors::InvalidArgument(\n+            \"TensorListScatter: element_shape must be at most rank 1 but has \",\n+            \"the shape of \", c->input(2).shape().DebugString()));\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/f3cf67ac5705f4f04721d15e485e192bb319feed",
    "API Name": "tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "When tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient receives input min or max of rank other than 1, it gives a CHECK fail that can trigger a denial of service attack.",
    "Backend Root Cause": "Lack of adding IsVector (rank) checks",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": " Add IsScalar / IsVector (rank) checks to input min/max tensors for FakeQuantWithMinMaxVarsPerChannelGradientOp and FakeQuantWithMinMaxVarsGradientOp.",
    "Vulnerable Code": [
        "    OP_REQUIRES(context, max.dim_size(0) == depth,",
        "                InvalidArgument(\"max has incorrect size, expected \", depth,",
        "                                \" was \", max.dim_size(0)));",
        "",
        "    Tensor* grad_wrt_input;",
        "    OP_REQUIRES_OK(context,",
        "                   context->allocate_output(0, input.shape(), &grad_wrt_input));",
        "",
        "    TensorShape min_max_shape({input.dim_size(input.dims() - 1)});",
        "    Tensor* grad_wrt_min;",
        "    OP_REQUIRES_OK(context,",
        "                   context->allocate_output(1, min_max_shape, &grad_wrt_min));",
        "",
        "    Tensor* grad_wrt_max;",
        "    OP_REQUIRES_OK(context,",
        "                   context->allocate_output(2, min_max_shape, &grad_wrt_max));"
    ],
    "Clean Code": [
        "    const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
        "    const Tensor& min = context->input(2);",
        "    OP_REQUIRES(",
        "        context, TensorShapeUtils::IsVector(min.shape()),",
        "        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
        "    OP_REQUIRES(context, min.dim_size(0) == depth,",
        "                InvalidArgument(\"min has incorrect size, expected \", depth,",
        "                                \" was \", min.dim_size(0)));",
        "    const Tensor& max = context->input(3);",
        "    OP_REQUIRES(",
        "        context, TensorShapeUtils::IsVector(max.shape()),",
        "        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
        "    OP_REQUIRES(context, max.dim_size(0) == depth,",
        "                InvalidArgument(\"max has incorrect size, expected \", depth,",
        "                                \" was \", max.dim_size(0)));",
        ""
    ],
    "Added_Lines": "+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/32d7bd3defd134f21a4e344c8dfd40099aaf6b18",
    "API Name": "tf.raw_ops.MaxPool",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "When MaxPool receives a window size input array ksize with dimensions greater than its input tensor input, the GPU kernel gives a CHECK fail that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "If the filter size exceeds the input size by one for `VALID` padding, return an empty tensor. This is consistent with XLA.",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Add check to make sure that the number of tensor elements is not zero",
    "Vulnerable Code": [
        "                        params.out_width, params.depth);",
        "",
        "    // Assuming qint8 <--> NCHW_VECT_C (int8x4) here.",
        "    constexpr bool is_int8x4 = std::is_same<T, qint8>::value;",
        "    OP_REQUIRES(context, (is_int8x4 == (data_format_ == FORMAT_NCHW_VECT_C)),",
        "                errors::InvalidArgument(",
        "                    \"qint8 should be used with data_format NCHW_VECT_C.\"));",
        "",
        "#if CUDNN_VERSION >= 7300",
        "    DnnPoolingOp<T>::Compute(context, se::dnn::PoolingMode::kMaximum, ksize_,",
        "                             stride_, padding_, explicit_paddings_,",
        "                             data_format_, tensor_in, out_shape,",
        "                             propagate_nans_);"
    ],
    "Clean Code": [
        "                        params.out_width, params.depth);",
        "",
        "    // Degenerate pooling output should return an empty tensor.",
        "    if (out_shape.num_elements() == 0) {",
        "      Tensor* output = nullptr;",
        "      OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));",
        "      return;",
        "    }",
        "",
        "    // Assuming qint8 <--> NCHW_VECT_C (int8x4) here.",
        "    constexpr bool is_int8x4 = std::is_same<T, qint8>::value;",
        "    OP_REQUIRES(context, (is_int8x4 == (data_format_ == FORMAT_NCHW_VECT_C)),",
        "                errors::InvalidArgument("
    ],
    "Added_Lines": "+    // Degenerate pooling output should return an empty tensor.\n+    if (out_shape.num_elements() == 0) {\n+      Tensor* output = nullptr;\n+      OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));\n+      return;\n+    }\n+\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/c55b476aa0e0bd4ee99d0f3ad18d9d706cd1260a",
    "API Name": "tf.linalg.matrix_rank",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "When tf.linalg.matrix_rank receives an empty input a, the GPU kernel gives a CHECK fail that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "If there are zero batches, the GPU kernel previously failed with a `work_element_count > 0` check failure.",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "In the zero batch case, there is no output, so simply return.",
    "Vulnerable Code": [
        "                         done);",
        "",
        "    if (n == 0 || m == 0) {",
        "      if (n == m || !compute_uv_ || !full_matrices_) {",
        "        // S, U, and V are all empty. Nothing to do.",
        "        done();",
        "        return;",
        "      }",
        "      auto device = context->eigen_device<GPUDevice>();",
        "      functor::EyeFunctor<GPUDevice, Scalar> eye;",
        "      if (m > 0) {",
        "        // Return a full canonical basis for the column space."
    ],
    "Clean Code": [
        "                         done);",
        "",
        "    // If there are zero batches, we are done.",
        "    if (shapeRaw.num_elements() == 0) {",
        "      done();",
        "      return;",
        "    }",
        "",
        "    if (n == 0 || m == 0) {",
        "      if (n == m || !compute_uv_ || !full_matrices_) {",
        "        // S, U, and V are all empty. Nothing to do.",
        "        done();"
    ],
    "Added_Lines": "+    // If there are zero batches, we are done.\n+    if (shapeRaw.num_elements() == 0) {\n+      done();\n+      return;\n+    }\n+\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/bf4c14353c2328636a18bfad1e151052c81d5f43",
    "API Name": "tf.raw_ops.DenseBincount",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "DenseBincount assumes its input tensor weights to either have the same shape as its input tensor input or to be length-0. A different weights shape will trigger a CHECK fail that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking if weights` must be the same shape as `arr` or a length-0",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": " checking if weights` must be the same shape as `arr` or a length-0",
    "Vulnerable Code": [
        "                errors::InvalidArgument(\"Shape must be rank 0 but is rank \",",
        "                                        size_t.dims()));",
        "    Tidx size = size_t.scalar<Tidx>()();",
        "    OP_REQUIRES(",
        "        ctx, size >= 0,",
        "        errors::InvalidArgument(\"size (\", size, \") must be non-negative\"));",
        "",
        "    Tensor* out_t;",
        "    functor::SetZeroFunctor<Device, T> fill;",
        "    if (data.dims() == 1) {",
        "      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({size}), &out_t));",
        "      auto out = out_t->flat<T>();",
        "      fill(ctx->eigen_device<Device>(), out);",
        "      if (binary_output_) {"
    ],
    "Clean Code": [
        "                errors::InvalidArgument(\"Shape must be rank 0 but is rank \",",
        "                                        size_t.dims()));",
        "    OP_REQUIRES(ctx,",
        "                weights.shape() == data.shape() || weights.NumElements() == 0,",
        "                errors::InvalidArgument(",
        "                    \"`weights` must be the same shape as `arr` or a length-0 \"",
        "                    \"`Tensor`, in which case it acts as all weights equal to \"",
        "                    \"1. Received \",",
        "                    weights.shape().DebugString()));",
        "",
        "    Tidx size = size_t.scalar<Tidx>()();",
        "    OP_REQUIRES(",
        "        ctx, size >= 0,",
        "        errors::InvalidArgument(\"size (\", size, \") must be non-negative\"));"
    ],
    "Added_Lines": "+    OP_REQUIRES(ctx,\n+                xla::ShapeUtil::CompatibleIgnoringElementType(weights_shape,\n+                                                              input_shape) ||\n+                    (weights_shape.dimensions_size() > 0 &&\n+                     weights_shape.dimensions(0) == 0),\n+                errors::InvalidArgument(\n+                    \"`weights` must be the same shape as `arr` or a length-0 \"\n+                    \"`Tensor`, in which case it acts as all weights equal to \"\n+                    \"1. Received \",\n+                    weights_shape.DebugString()));\n+\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/7a4591fd4f065f4fa903593bc39b2f79530a74b8",
    "API Name": "tf.raw_ops.RaggedBincount",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "If RaggedBincount is given an empty input tensor splits, it results in a segfault that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking Splits must be non-empty",
    "Vulnerability Impact": "segfault",
    "Vulnerability Fixing Commit Description": "Fix RaggedBincount Segmentation Fault from the Splits arg ",
    "Vulnerable Code": [
        "    int batch_idx = 0;",
        "",
        "    OP_REQUIRES(ctx, splits(0) == 0,",
        "                errors::InvalidArgument(\"Splits must start with 0, not with \",",
        "                                        splits(0)));",
        "",
        "    OP_REQUIRES(ctx, splits(num_rows) == num_values,",
        "                errors::InvalidArgument(",
        "                    \"Splits must end with the number of values, got \","
    ],
    "Clean Code": [
        "    int batch_idx = 0;",
        "",
        "    OP_REQUIRES(ctx, splits.size() > 0,",
        "                errors::InvalidArgument(\"Splits must be non-empty\"));",
        "",
        "    OP_REQUIRES(ctx, splits(0) == 0,",
        "                errors::InvalidArgument(\"Splits must start with 0, not with \",",
        "                                        splits(0)));",
        ""
    ],
    "Added_Lines": "+    OP_REQUIRES(ctx, splits.size() > 0,\n+                errors::InvalidArgument(\"Splits must be non-empty\"));\n+\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/bd90b3efab4ec958b228cd7cfe9125be1c0cf255",
    "API Name": "tf.raw_ops.LRNGrad",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "If LRNGrad is given an output_image input tensor that is not 4-D, it results in a CHECK fail that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of Check if dimensions of tensors match",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Check if dimensions of tensors match",
    "Vulnerable Code": [
        "            in_image.dim_size(2) == cols && in_image.dim_size(3) == depth &&",
        "            out_image.dim_size(0) == batch && out_image.dim_size(1) == rows &&",
        "            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth,",
        "        errors::InvalidArgument(",
        "            \"input_grads, input_image, and out_image should have the same \"",
        "            \"shape\"));",
        "",
        "    Tensor* output = nullptr;"
    ],
    "Clean Code": [
        "            in_image.dim_size(2) == cols && in_image.dim_size(3) == depth &&",
        "            out_image.dim_size(0) == batch && out_image.dim_size(1) == rows &&",
        "            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth &&",
        "            out_image.dims() == 4,",
        "        errors::InvalidArgument(",
        "            \"input_grads, input_image, and out_image should have the same \"",
        "            \"shape\"));",
        ""
    ],
    "Added_Lines": "+            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth &&\n+            out_image.dims() == 4,\n",
    "Deleted Lines": "-            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth,\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/72180be03447a10810edca700cbc9af690dfeb51",
    "API Name": "tf.raw_ops.ParameterizedTruncatedNormal",
    "Vulnerability Category": "Data Type Issue",
    "Trigger Mechanism": "ParameterizedTruncatedNormal assumes shape is of type int32. A valid shape of type int64 results in a mismatched type CHECK fail that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "The original made the assumption that the dtype is int32 when it could also be int64 - leading to a crash due to mismatched type.",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Resolve type mismatch",
    "Vulnerable Code": [
        "                                        shape_tensor.DebugString()));",
        "    int32_t num_batches = shape_tensor.flat<int32>()(0);",
        "",
        "    int32_t samples_per_batch = 1;",
        "    const int32_t num_dims = shape_tensor.dim_size(0);",
        "    for (int32_t i = 1; i < num_dims; i++) {",
        "      samples_per_batch *= shape_tensor.flat<int32>()(i);",
        "    }",
        "    const int32_t num_elements = num_batches * samples_per_batch;",
        "",
        "    // Allocate the output before fudging num_batches and samples_per_batch.",
        "    auto shape_vec = shape_tensor.flat<int32>();",
        "    TensorShape tensor_shape;",
        "    OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(",
        "                            shape_vec.data(), shape_vec.size(), &tensor_shape));",
        "    Tensor* samples_tensor;",
        "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, tensor_shape, &samples_tensor));",
        ""
    ],
    "Clean Code": [
        "                errors::InvalidArgument(\"Shape tensor must not be empty, got \",",
        "                                        shape_tensor.DebugString()));",
        "    TensorShape tensor_shape;",
        "    OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_tensor, &tensor_shape));",
        "",
        "    int32_t num_batches = tensor_shape.dim_size(0);",
        "    int32_t samples_per_batch = 1;",
        "    const int32_t num_dims = tensor_shape.dims();",
        "    for (int32_t i = 1; i < num_dims; i++) {",
        "      samples_per_batch *= tensor_shape.dim_size(i);",
        "    }",
        "    const int32_t num_elements = num_batches * samples_per_batch;",
        "",
        "    // Allocate the output before fudging num_batches and samples_per_batch.",
        "    Tensor* samples_tensor;",
        "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, tensor_shape, &samples_tensor));",
        "",
        "    // Parameters must be 0-d or 1-d."
    ],
    "Added_Lines": "+#include \"tensorflow/core/framework/tensor_util.h\"\n+    TensorShape tensor_shape;\n+    OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_tensor, &tensor_shape));\n+    int32_t num_batches = tensor_shape.dim_size(0);\n+    const int32_t num_dims = tensor_shape.dims();\n+      samples_per_batch *= tensor_shape.dim_size(i);\n",
    "Deleted Lines": "-    int32_t num_batches = shape_tensor.flat<int32>()(0);\n-    const int32_t num_dims = shape_tensor.dim_size(0);\n-      samples_per_batch *= shape_tensor.flat<int32>()(i);\n-    auto shape_vec = shape_tensor.flat<int32>();\n-    TensorShape tensor_shape;\n-    OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(\n-                            shape_vec.data(), shape_vec.size(), &tensor_shape));\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/5dd7b86b84a864b834c6fa3d7f9f51c87efa99d4",
    "API Name": "tf.raw_ops.Save",
    "Vulnerability Category": "Data Type Issue",
    "Trigger Mechanism": "If Save or SaveSlices is run over tensors of an unsupported dtype, it results in a CHECK fail that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Unsupported data type",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Check that given dtype is supported and emit a descriptive error if not.",
    "Vulnerable Code": [
        "  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +",
        "                      (num_elements * MaxBytesPerElement(DT_INT32));",
        "  for (int64_t i = 0; i < num_elements; ++i) {",
        "    size_bound += data[i].size();",
        "  }",
        "  if (size_bound > kMaxMessageBytes) {",
        "    return errors::InvalidArgument(",
        "        \"Tensor slice is too large to serialize (conservative estimate: \","
    ],
    "Clean Code": [
        "    case DT_BFLOAT16:",
        "    default:",
        "      return 0;",
        "  }",
        "}",
        "",
        "template <>",
        "Status TensorSliceWriter::SaveData(const tstring* data, int64_t num_elements,"
    ],
    "Added_Lines": "+  size_t max_bytes_per_element =\n+      TensorSliceWriter::MaxBytesPerElementOrZero(dt);\n+  if (max_bytes_per_element == 0) {\n+    LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n+  }\n+  return max_bytes_per_element;\n+}\n+\n+/* static */\n+size_t TensorSliceWriter::MaxBytesPerElementOrZero(DataType dt) {\n+      return 0;\n",
    "Deleted Lines": "-      LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n-  return 0;\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/40adbe4dd15b582b0210dfbf40c243a62f5119fa",
    "API Name": "tf.raw_ops.SparseBincount",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "If SparseBincount is given inputs for indices, values, and dense_shape that do not make a valid sparse tensor, it results in a segfault that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking for size must be non-negative",
    "Vulnerability Impact": "segfault",
    "Vulnerability Fixing Commit Description": "Add sparse tensor validation to SparseBincountOp. ",
    "Vulnerable Code": [
        "            errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,",
        "                                    \") must be less than the dimension size (\",",
        "                                    out.dimension(0), \").\"));",
        "        OP_REQUIRES(",
        "            ctx, bin < out.dimension(1),",
        "            errors::InvalidArgument(\"Index out ouf bound. `bin` (\", bin,",
        "                                    \") must be less then the dimension size (\","
    ],
    "Clean Code": [
        "      for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {",
        "        const int64_t batch = indices_mat(i, 0);",
        "        const Tidx bin = values_flat(i);",
        "        OP_REQUIRES(",
        "            ctx, batch < out.dimension(0),",
        "            errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,",
        "                                    \") must be less than the dimension size (\","
    ],
    "Added_Lines": "+#include \"tensorflow/core/kernels/sparse_utils.h\"\n+    const Tensor& values = ctx->input(1);\n+    const auto values_flat = values.flat<Tidx>();\n+    OP_REQUIRES_OK(\n+        ctx, sparse_utils::ValidateSparseTensor<int64_t>(\n+                 indices, values, dense_shape, /*validate_indices=*/true));\n+                           ctx, values_flat, weights, out, size));\n+                     ctx, values_flat, weights, out, size));\n+        const Tidx bin = values_flat(i);\n",
    "Deleted Lines": "-    const auto values = ctx->input(1).flat<Tidx>();\n-                           ctx, values, weights, out, size));\n-                     ctx, values, weights, out, size));\n-        const Tidx bin = values(i);\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/88f93dfe691563baa4ae1e80ccde2d5c7a143821",
    "API Name": "tf.raw_ops.RaggedTensorToVariant",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "If RaggedTensorToVariant is given a rt_nested_splits list that contains tensors of ranks other than one, it results in a CHECK fail that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "lack of checking if `row_splits` must have rank 1.",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "add check to `row_splits` must have rank 1.",
    "Vulnerable Code": [
        "        ragged_nested_splits_len);",
        "    for (int i = 0; i < ragged_nested_splits_len; i++) {",
        "      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);",
        "    }",
        "",
        "    if (!batched_input_) {",
        "      // Encode as a Scalar Variant Tensor.",
        "      Tensor* encoded_scalar;",
        "      OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({}),",
        "                                                       &encoded_scalar));"
    ],
    "Clean Code": [
        "        ragged_nested_splits_len);",
        "    for (int i = 0; i < ragged_nested_splits_len; i++) {",
        "      OP_REQUIRES(context, ragged_nested_splits_in[i].dims() == 1,",
        "                  errors::InvalidArgument(\"Requires nested_row_splits[\", i, \"]\",",
        "                                          \" to be rank 1 but is rank \",",
        "                                          ragged_nested_splits_in[i].dims()));",
        "      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);",
        "    }",
        "",
        "    if (!batched_input_) {"
    ],
    "Added_Lines": "+      OP_REQUIRES(context, ragged_nested_splits_in[i].dims() == 1,\n+                  errors::InvalidArgument(\"Requires nested_row_splits[\", i, \"]\",\n+                                          \" to be rank 1 but is rank \",\n+                                          ragged_nested_splits_in[i].dims()));\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/8741e57d163a079db05a7107a7609af70931def4",
    "API Name": "tf.raw_ops.FractionalMaxPoolGrad",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "FractionalMaxPoolGrad validates its inputs with CHECK failures instead of with returning errors. If it gets incorrectly sized inputs, the CHECK failure can be used to trigger a denial of service attack:",
    "Backend Root Cause": "Lack of checking tensor_out_dup is not the same as tensor_out",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Update checker to tensor_out_dup is not the same as tensor_out",
    "Vulnerable Code": [
        "      CHECK(input_backprop_index >= 0 &&",
        "            input_backprop_index < num_total_inputs)",
        "          << \"Invalid input backprop index: \" << input_backprop_index << \", \"",
        "          << num_total_inputs;",
        "      input_backprop_flat(input_backprop_index) += out_backprop_flat(index);",
        "    }",
        "  }",
        "",
        " private:",
        "  bool overlapping_;",
        "};",
        ""
    ],
    "Clean Code": [
        "    for (int index = 0; index < num_total_outputs; ++index) {",
        "      int input_backprop_index = out_arg_max_flat(index);",
        "      OP_REQUIRES(",
        "          context,",
        "          input_backprop_index >= 0 && input_backprop_index < num_total_inputs,",
        "          errors::InvalidArgument(",
        "              \"Invalid input backprop index: \", input_backprop_index, \", \",",
        "              num_total_inputs));",
        "      input_backprop_flat(input_backprop_index) += out_backprop_flat(index);",
        "    }",
        "  }",
        ""
    ],
    "Added_Lines": "+#include \"tensorflow/core/framework/op_requires.h\"\n+#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n+        OP_REQUIRES(context, tensor_out_dup_mat(j, i) == tensor_out_mat(j, i),\n+                    errors::InvalidArgument(\n+                        \"tensor_out_dup is not the same as tensor_out\"));\n+      OP_REQUIRES(\n+          context,\n+          input_backprop_index >= 0 && input_backprop_index < num_total_inputs,\n+          errors::InvalidArgument(\n+              \"Invalid input backprop index: \", input_backprop_index, \", \",\n+              num_total_inputs));\n",
    "Deleted Lines": "-#include \"tensorflow/core/kernels/fractional_pool_common.h\"\n-\n-        DCHECK_EQ(tensor_out_dup_mat(j, i), tensor_out_mat(j, i));\n-      // According to maxpooling_op.cc, the performance impact below is small.\n-      CHECK(input_backprop_index >= 0 &&\n-            input_backprop_index < num_total_inputs)\n-          << \"Invalid input backprop index: \" << input_backprop_index << \", \"\n-          << num_total_inputs;\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/49b3824d83af706df0ad07e4e677d88659756d89",
    "API Name": "tf.raw_ops.QuantizedRelu6",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "If QuantizedRelu or QuantizedRelu6 are given nonscalar inputs for min_features or max_features, it results in a segfault that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking if IsScalar (rank == 0) to min/max input tensors for Quantized Add/Relu/Relu6 op.",
    "Vulnerability Impact": "segfault",
    "Vulnerability Fixing Commit Description": "Add IsScalar (rank == 0) check to min/max input tensors for Quantized Add/Relu/Relu6 op.",
    "Vulnerable Code": [
        "                  min_as_quantized, max_as_quantized,",
        "                  output->flat<quint8>().data());",
        "    } else {",
        "      output->flat<T>().device(context->eigen_cpu_device()) =",
        "          input.flat<T>()",
        "              .cwiseMax(min_as_quantized)",
        "              .cwiseMin(max_as_quantized)",
        "              .template cast<T>();",
        "    }",
        "",
        "    Tensor* output_min = nullptr;",
        "    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));",
        "    output_min->flat<float>()(0) = min_input;",
        "    Tensor* output_max = nullptr;",
        "    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));",
        "    output_max->flat<float>()(0) = max_input;",
        "  }",
        "};",
        "",
        "REGISTER_KERNEL_BUILDER(Name(\"QuantizedRelu\")",
        "                            .Device(DEVICE_CPU)"
    ],
    "Clean Code": [
        "  void Compute(OpKernelContext* context) override {",
        "    const Tensor& input = context->input(0);",
        "    const Tensor& min_input_tensor = context->input(1);",
        "    const Tensor& max_input_tensor = context->input(2);",
        "",
        "    OP_REQUIRES(",
        "        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
        "        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
        "                                min_input_tensor.dims()));",
        "    OP_REQUIRES(",
        "        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
        "        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
        "                                max_input_tensor.dims()));",
        "",
        "    const float min_input = min_input_tensor.scalar<float>()();",
        "    const float max_input = max_input_tensor.scalar<float>()();",
        "",
        "    Tensor* output = nullptr;",
        "    OP_REQUIRES_OK(context,",
        "                   context->allocate_output(0, input.shape(), &output));",
        "    const T min_as_quantized = FloatToQuantized<T>(0.0f, min_input, max_input);"
    ],
    "Added_Lines": "+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n",
    "Deleted Lines": "-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/73ad1815ebcfeb7c051f9c2f7ab5024380ca8613",
    "API Name": "tf.raw_ops.QuantizeDownAndShrinkRange",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "If QuantizeDownAndShrinkRange is given nonscalar inputs for input_min or input_max, it results in a segfault that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking if input_min` must be rank 0 but is rank",
    "Vulnerability Impact": "segfault",
    "Vulnerability Fixing Commit Description": " Add IsScalar (rank == 0) check to input_min/max tensors for QuantizeD ownAndShrinkRangeOp.",
    "Vulnerable Code": [
        "  void Compute(OpKernelContext* ctx) override {",
        "    const Tensor& input = ctx->input(0);",
        "    const float input_min_float = ctx->input(1).flat<float>()(0);",
        "    const float input_max_float = ctx->input(2).flat<float>()(0);",
        "    Tensor* output = nullptr;",
        "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
        "    Tensor* output_min = nullptr;",
        "    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));",
        "    Tensor* output_max = nullptr;",
        "    OP_REQUIRES_OK(ctx, ctx->allocate_output(2, TensorShape({}), &output_max));",
        "",
        "    // See QuantizationRangeOp as well, which has a copy of this logic.",
        "    auto input_array = input.flat<T1>();",
        "    const int32_t input_lowest_quantized =",
        "        static_cast<int32>(Eigen::NumTraits<T1>::lowest());",
        "    const int32_t input_highest_quantized =",
        "        static_cast<int32>(Eigen::NumTraits<T1>::highest());",
        "    T1 actual_min_quantized = input_highest_quantized;",
        "    T1 actual_max_quantized = input_lowest_quantized;",
        "    for (int i = 0; i < input_array.size(); ++i) {"
    ],
    "Clean Code": [
        "  void Compute(OpKernelContext* ctx) override {",
        "    const Tensor& input = ctx->input(0);",
        "    const Tensor& input_min = ctx->input(1);",
        "    const Tensor& input_max = ctx->input(2);",
        "",
        "    OP_REQUIRES(",
        "        ctx, TensorShapeUtils::IsScalar(input_min.shape()),",
        "        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",",
        "                                input_min.dims()));",
        "    OP_REQUIRES(",
        "        ctx, TensorShapeUtils::IsScalar(input_max.shape()),",
        "        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",",
        "                                input_max.dims()));",
        "",
        "    const float input_min_float = input_min.scalar<float>()();",
        "    const float input_max_float = input_max.scalar<float>()();",
        "    Tensor* output = nullptr;",
        "    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
        "    Tensor* output_min = nullptr;",
        "    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));"
    ],
    "Added_Lines": "+    const Tensor& input_min = ctx->input(1);\n+    const Tensor& input_max = ctx->input(2);\n+\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n+        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n+                                input_min.dims()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n+        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n+                                input_max.dims()));\n+\n+    const float input_min_float = input_min.scalar<float>()();\n+    const float input_max_float = input_max.scalar<float>()();\n",
    "Deleted Lines": "-    const float input_min_float = ctx->input(1).flat<float>()(0);\n-    const float input_max_float = ctx->input(2).flat<float>()(0);\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/aca766ac7693bf29ed0df55ad6bfcc78f35e7f48",
    "API Name": "tf.raw_ops.QuantizedMatMul",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": " If QuantizedMatMul is given nonscalar input for: min_a, max_a, min_b, max_b It gives a segfault that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking that the input values must be scalar",
    "Vulnerability Impact": "segfault",
    "Vulnerability Fixing Commit Description": " Fix tf.raw_ops. QuantizedMatMul vulnerability from non scalar min/max a/b arguments.",
    "Vulnerable Code": [
        "    const float max_a = context->input(3).flat<float>()(0);",
        "    const float min_b = context->input(4).flat<float>()(0);",
        "    const float max_b = context->input(5).flat<float>()(0);",
        "",
        "    // Make sure that we have valid quantization ranges for the input buffers.",
        "    // If the difference between the min and max is negative or zero, it makes",
        "    // it hard to do meaningful intermediate operations on the values.",
        "    OP_REQUIRES(context, (max_a > min_a),",
        "                errors::InvalidArgument(\"max_a must be larger than min_a.\"));",
        "    OP_REQUIRES(context, (max_b > min_b),",
        "                errors::InvalidArgument(\"max_b must be larger than min_b.\"));",
        "    const int32_t offset_a = FloatToQuantizedUnclamped<T1>(0.0f, min_a, max_a);",
        "    const int32_t offset_b = FloatToQuantizedUnclamped<T2>(0.0f, min_b, max_b);",
        "    const int32_t offset_c = 0;",
        "    const int32_t mult_c = 1;",
        "    const int32_t shift_c = 0;",
        "",
        "    // Check that the dimensions of the two matrices are valid.",
        "    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(a.shape()),",
        "                errors::InvalidArgument(\"In[0] is not a matrix\"));",
        "    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(b.shape()),"
    ],
    "Clean Code": [
        "    const Tensor& a = context->input(0);",
        "    const Tensor& b = context->input(1);",
        "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(2).shape()),",
        "                errors::InvalidArgument(\"min_a must be a scalar, but got shape\",",
        "                                        context->input(2).shape()));",
        "    const float min_a = context->input(2).flat<float>()(0);",
        "    OP_REQUIRES(context, context->input(3).NumElements() == 1,",
        "                errors::InvalidArgument(\"max_a must be a scalar, but got shape\",",
        "                                        context->input(3).shape()));",
        "    const float max_a = context->input(3).flat<float>()(0);",
        "    OP_REQUIRES(context, context->input(4).NumElements() == 1,",
        "                errors::InvalidArgument(\"min_b must be a scalar, but got shape\",",
        "                                        context->input(4).shape()));",
        "    const float min_b = context->input(4).flat<float>()(0);",
        "    OP_REQUIRES(context, context->input(5).NumElements() == 1,",
        "                errors::InvalidArgument(\"max_b must be a scalar, but got shape\",",
        "                                        context->input(5).shape()));",
        "    const float max_b = context->input(5).flat<float>()(0);",
        "",
        "    // Make sure that we have valid quantization ranges for the input buffers.",
        "    // If the difference between the min and max is negative or zero, it makes"
    ],
    "Added_Lines": "+#include \"tensorflow/core/framework/op_requires.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(2).shape()),\n+                errors::InvalidArgument(\"min_a must be a scalar, but got shape\",\n+                                        context->input(2).shape()));\n+    OP_REQUIRES(context, context->input(3).NumElements() == 1,\n+                errors::InvalidArgument(\"max_a must be a scalar, but got shape\",\n+                                        context->input(3).shape()));\n+    OP_REQUIRES(context, context->input(4).NumElements() == 1,\n+                errors::InvalidArgument(\"min_b must be a scalar, but got shape\",\n+                                        context->input(4).shape()));\n+    OP_REQUIRES(context, context->input(5).NumElements() == 1,\n+                errors::InvalidArgument(\"max_b must be a scalar, but got shape\",\n+                                        context->input(5).shape()));\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/785d67a78a1d533759fcd2f5e8d6ef778de849e0",
    "API Name": "tf.raw_ops.FakeQuantWithMinMaxVarsPerChannel",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "If FakeQuantWithMinMaxVarsPerChannel is given min or max tensors of a rank other than one, it results in a CHECK fail that can be used to trigger a denial of service attack.",
    "Backend Root Cause": "Lack of checking the rank of input tensors",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": " Fix quantize ops input validation issues. The majority of these are just missing checks on min/max.",
    "Vulnerable Code": [
        "                                \" was \", max.dim_size(0)));",
        "",
        "    Tensor* output;",
        "    OP_REQUIRES_OK(context,",
        "                   context->allocate_output(0, input.shape(), &output));",
        "",
        "    FakeQuantWithMinMaxVarsPerChannelFunctor<Device> functor;",
        "    functor(context->eigen_device<Device>(), input.flat_inner_dims<float, 2>(),",
        "            min.vec<float>(), max.vec<float>(), quant_min_, quant_max_,",
        "            output->flat_inner_dims<float, 2>());",
        "  }",
        "",
        " private:",
        "  int quant_min_;",
        "  int quant_max_;",
        "};",
        ""
    ],
    "Clean Code": [
        "    const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
        "    const Tensor& min = context->input(1);",
        "    const Tensor& max = context->input(2);",
        "",
        "    OP_REQUIRES(",
        "        context, TensorShapeUtils::IsVector(min.shape()),",
        "        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
        "    OP_REQUIRES(context, min.dim_size(0) == depth,",
        "                InvalidArgument(\"min has incorrect size, expected \", depth,",
        "                                \" was \", min.dim_size(0)));",
        "    OP_REQUIRES(",
        "        context, TensorShapeUtils::IsVector(max.shape()),",
        "        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
        "    OP_REQUIRES(context, max.dim_size(0) == depth,",
        "                InvalidArgument(\"max has incorrect size, expected \", depth,",
        "                                \" was \", max.dim_size(0)));",
        ""
    ],
    "Added_Lines": "+#include \"tensorflow/core/framework/tensor_shape.h\"\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min.shape()),\n+        InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max.shape()),\n+        InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));\n+\n+    const Tensor& max = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n",
    "Deleted Lines": "-    const Tensor& max = context->input(2);\n"
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/50156d547b9a1da0144d7babe665cf690305b33c",
    "API Name": "tf.raw_ops.Conv2DBackpropInput",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "The implementation of Conv2DBackpropInput requires input_sizes to be 4-dimensional. Otherwise, it gives a CHECK failure which can be used to trigger a denial of service attack:",
    "Backend Root Cause": "Lack of checking if the tensor is 4 dimensional",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "Add checker to make sure input_sizes must be 4-dimensional",
    "Vulnerable Code": [
        "                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),",
        "                                                   out_backprop.shape(),",
        "                                                   data_format_, &input_shape));",
        "",
        "    ConvBackpropDimensions dims;",
        "    OP_REQUIRES_OK(context,",
        "                   ConvBackpropComputeDimensionsV2(",
        "                       \"Conv2DCustomBackpropInput\", /*num_spatial_dims=*/2,",
        "                       input_shape, filter.shape(), out_backprop.shape(),",
        "                       /*dilations=*/{1, 1, 1, 1}, strides_, padding_,"
    ],
    "Clean Code": [
        "    const Tensor& filter = context->input(1);",
        "    const Tensor& out_backprop = context->input(2);",
        "    OP_REQUIRES(",
        "        context, out_backprop.dims() == 4,",
        "        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",",
        "                                out_backprop.dims()));",
        "",
        "    TensorShape input_shape;",
        "    OP_REQUIRES_OK(context,",
        "                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),"
    ],
    "Added_Lines": "+    OP_REQUIRES(\n+        context, out_backprop.dims() == 4,\n+        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",\n+                                out_backprop.dims()));\n+\n+    OP_REQUIRES(\n+        context, out_backprop.dims() == 4,\n+        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",\n+                                out_backprop.dims()));\n",
    "Deleted Lines": ""
},
{
    "Commit Link": "https://github.com/tensorflow/tensorflow/commit/3a6ac52664c6c095aa2b114e742b0aa17fdce78f",
    "API Name": "tf.raw_ops.AvgPoolGrad",
    "Vulnerability Category": "Improper Input Validation",
    "Trigger Mechanism": "The implementation of AvgPoolGrad does not fully validate the input orig_input_shape. This results in a CHECK failure which can be used to trigger a denial of service attack:",
    "Backend Root Cause": "The implementation of AvgPoolGrad does not fully validate the input orig_input_shape. This results in a CHECK failure which can be used to trigger a denial of service attack:",
    "Vulnerability Impact": "check failure",
    "Vulnerability Fixing Commit Description": "fully validate the input received from frontend",
    "Vulnerable Code": [
        "    auto shape_vec = tensor_in_shape.vec<int32>();",
        "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
        "      output_shape.AddDim(shape_vec(i));",
        "    }",
        "    if (output_shape.num_elements() == 0) {",
        "      Tensor* output = nullptr;",
        "      OP_REQUIRES_OK(context,"
    ],
    "Clean Code": [
        "    auto shape_vec = tensor_in_shape.vec<int32>();",
        "    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {",
        "      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));",
        "    }",
        "    if (output_shape.num_elements() == 0) {",
        "      Tensor* output = nullptr;",
        "      OP_REQUIRES_OK(context,"
    ],
    "Added_Lines": "+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n",
    "Deleted Lines": "-      output_shape.AddDim(shape_vec(i));\n-      output_shape.AddDim(shape_vec(i));\n-      output_shape.AddDim(shape_vec(i));\n"
}]